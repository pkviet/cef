From f87d704af7d465adaa538c09af599373e8a04b0d Mon Sep 17 00:00:00 2001
From: pkv <pkv@obsproject.com>
Date: Sun, 4 Dec 2022 14:02:53 +0100
Subject: [PATCH] Revert "Delete GLRenderer and related classes"

This reverts commit 18a2fffafb2303d1458ee4eaa4ae70dc9bb99635.
---
 .../browser/gfx/hardware_renderer_viz.cc      |    1 +
 .../gfx/output_surface_provider_webview.cc    |    8 +
 .../gfx/scoped_app_gl_state_restore_impl.cc   |   56 +-
 android_webview/lib/aw_main_delegate.cc       |    3 +
 cc/test/pixel_test.cc                         |    1 +
 chrome/browser/about_flags.cc                 |    4 +
 chrome/browser/flag_descriptions.cc           |    5 +
 components/viz/common/BUILD.gn                |    6 +
 .../viz/common/display/renderer_settings.h    |    1 +
 components/viz/common/features.cc             |   17 +
 components/viz/common/features.h              |    5 +
 components/viz/common/gl_i420_converter.cc    |  209 +
 components/viz/common/gl_i420_converter.h     |  195 +
 components/viz/common/gl_nv12_converter.cc    |  195 +
 components/viz/common/gl_nv12_converter.h     |  200 +
 components/viz/common/gl_scaler.cc            | 1661 ++++++
 components/viz/common/gl_scaler.h             |  538 ++
 .../common/resources/resource_format_utils.cc |   38 +
 .../common/resources/resource_format_utils.h  |    2 +
 .../viz/host/renderer_settings_creation.cc    |    1 +
 components/viz/service/BUILD.gn               |   57 +
 ...fuzzer_software_output_surface_provider.cc |    3 +-
 .../fuzzer_software_output_surface_provider.h |    3 +-
 .../viz/service/display/direct_renderer.cc    |   27 +-
 .../viz/service/display/direct_renderer.h     |    3 +
 components/viz/service/display/display.cc     |   28 +-
 .../display/display_resource_provider_gl.cc   |  427 ++
 .../display/display_resource_provider_gl.h    |  165 +
 .../display_resource_provider_gl_unittest.cc  |  722 +++
 .../viz/service/display/display_unittest.cc   |    9 +-
 .../display/dynamic_geometry_binding.cc       |   68 +
 .../display/dynamic_geometry_binding.h        |   40 +
 .../viz/service/display/geometry_binding.cc   |   75 +
 .../viz/service/display/geometry_binding.h    |   64 +
 components/viz/service/display/gl_renderer.cc | 4505 +++++++++++++++++
 components/viz/service/display/gl_renderer.h  |  525 ++
 .../viz/service/display/gl_renderer_copier.cc | 1298 +++++
 .../viz/service/display/gl_renderer_copier.h  |  485 ++
 .../service/display/gl_renderer_draw_cache.cc |   13 +
 .../service/display/gl_renderer_draw_cache.h  |   62 +
 components/viz/service/display/layer_quad.cc  |  121 +
 components/viz/service/display/layer_quad.h   |  110 +
 .../service/display/layer_quad_unittest.cc    |   69 +
 .../viz/service/display/program_binding.cc    |  301 ++
 .../viz/service/display/program_binding.h     |  480 ++
 .../scoped_gpu_memory_buffer_texture.cc       |   96 +
 .../scoped_gpu_memory_buffer_texture.h        |   49 +
 .../display/scoped_render_pass_texture.cc     |  127 +
 .../display/scoped_render_pass_texture.h      |   61 +
 components/viz/service/display/shader.cc      | 1167 +++++
 components/viz/service/display/shader.h       |  324 ++
 .../viz/service/display/shader_unittest.cc    |   58 +
 .../viz/service/display/skia_renderer.h       |    1 +
 .../display/static_geometry_binding.cc        |   74 +
 .../service/display/static_geometry_binding.h |   41 +
 .../service/display/sync_query_collection.cc  |  151 +
 .../service/display/sync_query_collection.h   |   42 +
 .../viz/service/display/texture_deleter.cc    |   87 +
 .../viz/service/display/texture_deleter.h     |   64 +
 .../display/texture_deleter_unittest.cc       |   84 +
 components/viz/service/display_embedder/DEPS  |    2 +
 .../display_embedder/gl_output_surface.cc     |  262 +
 .../display_embedder/gl_output_surface.h      |  110 +
 .../gl_output_surface_android.cc              |   26 +
 .../gl_output_surface_android.h               |   32 +
 .../gl_output_surface_buffer_queue.cc         |  309 ++
 .../gl_output_surface_buffer_queue.h          |  107 +
 ...gl_output_surface_buffer_queue_unittest.cc |  362 ++
 .../gl_output_surface_chromeos.cc             |   25 +
 .../gl_output_surface_chromeos.h              |   33 +
 .../gl_output_surface_offscreen.cc            |  135 +
 .../gl_output_surface_offscreen.h             |   54 +
 .../output_surface_provider.h                 |    3 +-
 .../output_surface_provider_impl.cc           |  101 +-
 .../output_surface_provider_impl.h            |    3 +-
 .../skia_output_surface_impl_unittest.cc      |    6 +-
 .../viz_process_context_provider.cc           |  348 ++
 .../viz_process_context_provider.h            |  136 +
 .../root_compositor_frame_sink_impl.cc        |    6 +-
 .../test/test_in_process_context_provider.cc  |   37 +-
 .../test/test_in_process_context_provider.h   |    2 +
 .../viz/test/test_output_surface_provider.cc  |    3 +-
 .../viz/test/test_output_surface_provider.h   |    3 +-
 .../renderer_host/compositor_impl_android.cc  |    1 +
 .../mojom/compositing/renderer_settings.mojom |    1 +
 .../renderer_settings_mojom_traits.cc         |    1 +
 .../renderer_settings_mojom_traits.h          |    4 +
 .../privileged/mojom/mojom_traits_unittest.cc |    2 +
 .../synchronous_layer_tree_frame_sink.cc      |    1 +
 89 files changed, 17289 insertions(+), 58 deletions(-)
 create mode 100644 components/viz/common/gl_i420_converter.cc
 create mode 100644 components/viz/common/gl_i420_converter.h
 create mode 100644 components/viz/common/gl_nv12_converter.cc
 create mode 100644 components/viz/common/gl_nv12_converter.h
 create mode 100644 components/viz/common/gl_scaler.cc
 create mode 100644 components/viz/common/gl_scaler.h
 create mode 100644 components/viz/service/display/display_resource_provider_gl.cc
 create mode 100644 components/viz/service/display/display_resource_provider_gl.h
 create mode 100644 components/viz/service/display/display_resource_provider_gl_unittest.cc
 create mode 100644 components/viz/service/display/dynamic_geometry_binding.cc
 create mode 100644 components/viz/service/display/dynamic_geometry_binding.h
 create mode 100644 components/viz/service/display/geometry_binding.cc
 create mode 100644 components/viz/service/display/geometry_binding.h
 create mode 100644 components/viz/service/display/gl_renderer.cc
 create mode 100644 components/viz/service/display/gl_renderer.h
 create mode 100644 components/viz/service/display/gl_renderer_copier.cc
 create mode 100644 components/viz/service/display/gl_renderer_copier.h
 create mode 100644 components/viz/service/display/gl_renderer_draw_cache.cc
 create mode 100644 components/viz/service/display/gl_renderer_draw_cache.h
 create mode 100644 components/viz/service/display/layer_quad.cc
 create mode 100644 components/viz/service/display/layer_quad.h
 create mode 100644 components/viz/service/display/layer_quad_unittest.cc
 create mode 100644 components/viz/service/display/program_binding.cc
 create mode 100644 components/viz/service/display/program_binding.h
 create mode 100644 components/viz/service/display/scoped_gpu_memory_buffer_texture.cc
 create mode 100644 components/viz/service/display/scoped_gpu_memory_buffer_texture.h
 create mode 100644 components/viz/service/display/scoped_render_pass_texture.cc
 create mode 100644 components/viz/service/display/scoped_render_pass_texture.h
 create mode 100644 components/viz/service/display/shader.cc
 create mode 100644 components/viz/service/display/shader.h
 create mode 100644 components/viz/service/display/shader_unittest.cc
 create mode 100644 components/viz/service/display/static_geometry_binding.cc
 create mode 100644 components/viz/service/display/static_geometry_binding.h
 create mode 100644 components/viz/service/display/sync_query_collection.cc
 create mode 100644 components/viz/service/display/sync_query_collection.h
 create mode 100644 components/viz/service/display/texture_deleter.cc
 create mode 100644 components/viz/service/display/texture_deleter.h
 create mode 100644 components/viz/service/display/texture_deleter_unittest.cc
 create mode 100644 components/viz/service/display_embedder/gl_output_surface.cc
 create mode 100644 components/viz/service/display_embedder/gl_output_surface.h
 create mode 100644 components/viz/service/display_embedder/gl_output_surface_android.cc
 create mode 100644 components/viz/service/display_embedder/gl_output_surface_android.h
 create mode 100644 components/viz/service/display_embedder/gl_output_surface_buffer_queue.cc
 create mode 100644 components/viz/service/display_embedder/gl_output_surface_buffer_queue.h
 create mode 100644 components/viz/service/display_embedder/gl_output_surface_buffer_queue_unittest.cc
 create mode 100644 components/viz/service/display_embedder/gl_output_surface_chromeos.cc
 create mode 100644 components/viz/service/display_embedder/gl_output_surface_chromeos.h
 create mode 100644 components/viz/service/display_embedder/gl_output_surface_offscreen.cc
 create mode 100644 components/viz/service/display_embedder/gl_output_surface_offscreen.h
 create mode 100644 components/viz/service/display_embedder/viz_process_context_provider.cc
 create mode 100644 components/viz/service/display_embedder/viz_process_context_provider.h

diff --git android_webview/browser/gfx/hardware_renderer_viz.cc android_webview/browser/gfx/hardware_renderer_viz.cc
index 05009d8ff4b15..6241b71212fd6 100644
--- android_webview/browser/gfx/hardware_renderer_viz.cc
+++ android_webview/browser/gfx/hardware_renderer_viz.cc
@@ -361,6 +361,7 @@ HardwareRendererViz::HardwareRendererViz(
     AwVulkanContextProvider* context_provider)
     : HardwareRenderer(state), output_surface_provider_(context_provider) {
   DCHECK_CALLED_ON_VALID_THREAD(render_thread_checker_);
+  DCHECK(output_surface_provider_.renderer_settings().use_skia_renderer);
 
   VizCompositorThreadRunnerWebView::GetInstance()->ScheduleOnVizAndBlock(
       base::BindOnce(&HardwareRendererViz::InitializeOnViz,
diff --git android_webview/browser/gfx/output_surface_provider_webview.cc android_webview/browser/gfx/output_surface_provider_webview.cc
index 9de4a4566b24c..c415d0a644f58 100644
--- android_webview/browser/gfx/output_surface_provider_webview.cc
+++ android_webview/browser/gfx/output_surface_provider_webview.cc
@@ -92,9 +92,17 @@ OutputSurfaceProviderWebView::OutputSurfaceProviderWebView(
   // Webview does not own the surface so should not clear it.
   renderer_settings_.should_clear_root_render_pass = false;
 
+  renderer_settings_.use_skia_renderer = features::IsUsingSkiaRenderer();
+  LOG_IF(FATAL, !renderer_settings_.use_skia_renderer)
+      << "WebView requires skia renderer";
+
   enable_vulkan_ = features::IsUsingVulkan();
   DCHECK(!enable_vulkan_ || vulkan_context_provider_);
 
+  LOG_IF(FATAL, enable_vulkan_ && !renderer_settings_.use_skia_renderer)
+      << "--webview-enable-vulkan only works with skia renderer "
+         "(--enable-features=UseSkiaRenderer).";
+
   auto* command_line = base::CommandLine::ForCurrentProcess();
   debug_settings_.tint_composited_content =
       command_line->HasSwitch(switches::kTintCompositedContent);
diff --git android_webview/browser/gfx/scoped_app_gl_state_restore_impl.cc android_webview/browser/gfx/scoped_app_gl_state_restore_impl.cc
index c57842dd57cc4..25947d52238b7 100644
--- android_webview/browser/gfx/scoped_app_gl_state_restore_impl.cc
+++ android_webview/browser/gfx/scoped_app_gl_state_restore_impl.cc
@@ -92,6 +92,7 @@ bool g_supports_oes_vertex_array_object = false;
 bool g_supports_arm_shader_framebuffer_fetch = false;
 bool g_supports_nv_concervative_raster = false;
 bool g_supports_disable_multisample = false;
+bool g_use_skia_renderer = false;
 
 }  // namespace
 
@@ -165,6 +166,7 @@ ScopedAppGLStateRestoreImpl::ScopedAppGLStateRestoreImpl(
       g_supports_disable_multisample =
           extensions.contains("GL_EXT_multisample_compatibility");
     }
+    g_use_skia_renderer = features::IsUsingSkiaRenderer();
   }
 
   SaveHWUIState(save_restore);
@@ -181,16 +183,21 @@ ScopedAppGLStateRestoreImpl::ScopedAppGLStateRestoreImpl(
 }
 
 void ScopedAppGLStateRestoreImpl::SaveHWUIState(bool save_restore) {
-  if (g_supports_arm_shader_framebuffer_fetch)
-    glGetBooleanv(GL_FETCH_PER_SAMPLE_ARM, &fetch_per_sample_arm_enabled_);
+  if (g_use_skia_renderer) {
+    if (g_supports_arm_shader_framebuffer_fetch)
+      glGetBooleanv(GL_FETCH_PER_SAMPLE_ARM, &fetch_per_sample_arm_enabled_);
 
-  if (g_supports_disable_multisample)
-    glGetBooleanv(GL_MULTISAMPLE, &multisample_enabled_);
+    if (g_supports_disable_multisample)
+      glGetBooleanv(GL_MULTISAMPLE, &multisample_enabled_);
+  }
 
-  vertex_attrib_.resize(g_gl_max_vertex_attribs);
-  for (GLint i = 0; i < g_gl_max_vertex_attribs; ++i) {
-    glGetVertexAttribiv(i, GL_VERTEX_ATTRIB_ARRAY_BUFFER_BINDING,
-                        &vertex_attrib_[i].vertex_attrib_array_buffer_binding);
+  if (g_use_skia_renderer || save_restore) {
+    vertex_attrib_.resize(g_gl_max_vertex_attribs);
+    for (GLint i = 0; i < g_gl_max_vertex_attribs; ++i) {
+      glGetVertexAttribiv(
+          i, GL_VERTEX_ATTRIB_ARRAY_BUFFER_BINDING,
+          &vertex_attrib_[i].vertex_attrib_array_buffer_binding);
+    }
   }
 
   if (!save_restore)
@@ -297,24 +304,26 @@ void ScopedAppGLStateRestoreImpl::RestoreHWUIState(bool save_restore) {
   // to default state for this reason. This code is currently conservative;
   // it's likely that not all android versions needs all of these states
   // restored.
-  if (gl::g_current_gl_driver->fn.glWindowRectanglesEXTFn)
-    glWindowRectanglesEXT(GL_EXCLUSIVE_EXT, 0, nullptr);
+  if (g_use_skia_renderer) {
+    if (gl::g_current_gl_driver->fn.glWindowRectanglesEXTFn)
+      glWindowRectanglesEXT(GL_EXCLUSIVE_EXT, 0, nullptr);
 
-  if (gl::g_current_gl_driver->fn.glCoverageModulationNVFn)
-    glCoverageModulationNV(GL_NONE);
+    if (gl::g_current_gl_driver->fn.glCoverageModulationNVFn)
+      glCoverageModulationNV(GL_NONE);
 
-  if (g_supports_arm_shader_framebuffer_fetch)
-    GLEnableDisable(GL_FETCH_PER_SAMPLE_ARM, fetch_per_sample_arm_enabled_);
+    if (g_supports_arm_shader_framebuffer_fetch)
+      GLEnableDisable(GL_FETCH_PER_SAMPLE_ARM, fetch_per_sample_arm_enabled_);
 
-  if (g_supports_disable_multisample)
-    GLEnableDisable(GL_MULTISAMPLE, multisample_enabled_);
+    if (g_supports_disable_multisample)
+      GLEnableDisable(GL_MULTISAMPLE, multisample_enabled_);
 
-  // We do restore it even with Skia on the other side because it's new
-  // extension that skia on Android P and Q didn't use.
-  if (g_supports_nv_concervative_raster)
-    glDisable(GL_CONSERVATIVE_RASTERIZATION_NV);
+    // We do restore it even with Skia on the other side because it's new
+    // extension that skia on Android P and Q didn't use.
+    if (g_supports_nv_concervative_raster)
+      glDisable(GL_CONSERVATIVE_RASTERIZATION_NV);
+  }
 
-  if (!save_restore) {
+  if (g_use_skia_renderer && !save_restore) {
     if (gl::g_current_gl_driver->fn.glVertexAttribDivisorANGLEFn) {
       for (GLint i = 0; i < g_gl_max_vertex_attribs; ++i) {
         glBindBuffer(GL_ARRAY_BUFFER,
@@ -353,7 +362,8 @@ void ScopedAppGLStateRestoreImpl::RestoreHWUIState(bool save_restore) {
     // below) Android versions and HWUI there doesn't use the state, while
     // SkiaRenderer does, so we just reset it to default value.
     // Note despite the name function is no ANGLE specific.
-    if (gl::g_current_gl_driver->fn.glVertexAttribDivisorANGLEFn) {
+    if (g_use_skia_renderer &&
+        gl::g_current_gl_driver->fn.glVertexAttribDivisorANGLEFn) {
       glVertexAttribDivisorANGLE(i, 0);
     }
 
@@ -377,7 +387,7 @@ void ScopedAppGLStateRestoreImpl::RestoreHWUIState(bool save_restore) {
     glBindTexture(GL_TEXTURE_EXTERNAL_OES, bindings.texture_external_oes);
 
     // reset glSamplers if supported.
-    if (gl::g_current_gl_driver->fn.glBindSamplerFn)
+    if (g_use_skia_renderer && gl::g_current_gl_driver->fn.glBindSamplerFn)
       glBindSampler(ii, 0);
   }
   glActiveTexture(active_texture_);
diff --git android_webview/lib/aw_main_delegate.cc android_webview/lib/aw_main_delegate.cc
index 19a141a7a2caf..0f6ea525a1f26 100644
--- android_webview/lib/aw_main_delegate.cc
+++ android_webview/lib/aw_main_delegate.cc
@@ -253,6 +253,9 @@ absl::optional<int> AwMainDelegate::BasicStartupComplete() {
     features.DisableIfNotSet(::features::kWebPayments);
     features.DisableIfNotSet(::features::kServiceWorkerPaymentApps);
 
+    // WebView requires SkiaRenderer.
+    features.EnableIfNotSet(::features::kUseSkiaRenderer);
+
     // WebView does not support overlay fullscreen yet for video overlays.
     features.DisableIfNotSet(media::kOverlayFullscreenVideo);
 
diff --git cc/test/pixel_test.cc cc/test/pixel_test.cc
index b989570ef45ec..1410c035926d7 100644
--- cc/test/pixel_test.cc
+++ cc/test/pixel_test.cc
@@ -29,6 +29,7 @@
 #include "components/viz/common/quads/compositor_frame_metadata.h"
 #include "components/viz/common/resources/bitmap_allocation.h"
 #include "components/viz/common/resources/shared_bitmap.h"
+#include "components/viz/service/display/display_resource_provider_gl.h"
 #include "components/viz/service/display/display_resource_provider_skia.h"
 #include "components/viz/service/display/display_resource_provider_software.h"
 #include "components/viz/service/display/output_surface_client.h"
diff --git chrome/browser/about_flags.cc chrome/browser/about_flags.cc
index eec961dafc738..7dda6bfca47ad 100644
--- chrome/browser/about_flags.cc
+++ chrome/browser/about_flags.cc
@@ -6915,6 +6915,10 @@ const FeatureEntry kFeatureEntries[] = {
      FEATURE_VALUE_TYPE(features::kLogJsConsoleMessages)},
 #endif  // BUILDFLAG(IS_ANDROID)
 
+    {"enable-skia-renderer", flag_descriptions::kSkiaRendererName,
+     flag_descriptions::kSkiaRendererDescription, kOsAll,
+     FEATURE_VALUE_TYPE(features::kUseSkiaRenderer)},
+
 #if BUILDFLAG(IS_CHROMEOS_ASH)
     {"allow-disable-touchpad-haptic-feedback",
      flag_descriptions::kAllowDisableTouchpadHapticFeedbackName,
diff --git chrome/browser/flag_descriptions.cc chrome/browser/flag_descriptions.cc
index 2904162779c98..838390690d434 100644
--- chrome/browser/flag_descriptions.cc
+++ chrome/browser/flag_descriptions.cc
@@ -2748,6 +2748,11 @@ extern const char kSimLockPolicyDescription[] =
     "Enable the support for policy controlled enabling or disabling of PIN "
     "Locking SIMs on managed devices.";
 
+const char kSkiaRendererName[] = "Skia API for compositing";
+const char kSkiaRendererDescription[] =
+    "If enabled, the display compositor will use Skia as the graphics API "
+    "instead of OpenGL ES.";
+
 const char kIsolateOriginsName[] = "Isolate additional origins";
 const char kIsolateOriginsDescription[] =
     "Requires dedicated processes for an additional set of origins, "
diff --git components/viz/common/BUILD.gn components/viz/common/BUILD.gn
index e275a1dd7ccfc..2b37dde66be6b 100644
--- components/viz/common/BUILD.gn
+++ components/viz/common/BUILD.gn
@@ -195,6 +195,12 @@ viz_component("common") {
     "frame_sinks/delay_based_time_source.h",
     "frame_timing_details.h",
     "frame_timing_details_map.h",
+    "gl_i420_converter.cc",
+    "gl_i420_converter.h",
+    "gl_nv12_converter.cc",
+    "gl_nv12_converter.h",
+    "gl_scaler.cc",
+    "gl_scaler.h",
     "gpu/context_cache_controller.cc",
     "gpu/context_cache_controller.h",
     "gpu/context_lost_observer.h",
diff --git components/viz/common/display/renderer_settings.h components/viz/common/display/renderer_settings.h
index 893291f2c79dd..025d2ff13615e 100644
--- components/viz/common/display/renderer_settings.h
+++ components/viz/common/display/renderer_settings.h
@@ -30,6 +30,7 @@ class VIZ_COMMON_EXPORT RendererSettings {
   bool partial_swap_enabled = false;
   bool should_clear_root_render_pass = true;
   bool release_overlay_resources_after_gpu_query = false;
+  bool use_skia_renderer = true;
   bool dont_round_texture_sizes_for_pixel_tests = false;
   int highp_threshold_min = 0;
   bool auto_resize_output_surface = true;
diff --git components/viz/common/features.cc components/viz/common/features.cc
index dbd3021244104..c7997670068c3 100644
--- components/viz/common/features.cc
+++ components/viz/common/features.cc
@@ -77,6 +77,10 @@ BASE_FEATURE(kSimpleFrameRateThrottling,
              "SimpleFrameRateThrottling",
              base::FEATURE_DISABLED_BY_DEFAULT);
 
+// Use the SkiaRenderer.
+const base::Feature kUseSkiaRenderer{"UseSkiaRenderer",
+                                     base::FEATURE_ENABLED_BY_DEFAULT};
+
 // Kill-switch to disable de-jelly, even if flags/properties indicate it should
 // be enabled.
 BASE_FEATURE(kDisableDeJelly,
@@ -91,6 +95,10 @@ BASE_FEATURE(kDynamicColorGamut,
              base::FEATURE_DISABLED_BY_DEFAULT);
 #endif
 
+// Uses glClear to composite solid color quads whenever possible.
+const base::Feature kFastSolidColorDraw{"FastSolidColorDraw",
+                                        base::FEATURE_DISABLED_BY_DEFAULT};
+
 // Submit CompositorFrame from SynchronousLayerTreeFrameSink directly to viz in
 // WebView.
 BASE_FEATURE(kVizFrameSubmissionForWebView,
@@ -261,6 +269,11 @@ bool IsSimpleFrameRateThrottlingEnabled() {
   return base::FeatureList::IsEnabled(kSimpleFrameRateThrottling);
 }
 
+bool IsUsingSkiaRenderer() {
+  return base::FeatureList::IsEnabled(kUseSkiaRenderer) ||
+         features::IsUsingVulkan();
+}
+
 #if BUILDFLAG(IS_ANDROID)
 bool IsDynamicColorGamutEnabled() {
   if (viz::AlwaysUseWideColorGamut())
@@ -272,6 +285,10 @@ bool IsDynamicColorGamutEnabled() {
 }
 #endif
 
+bool IsUsingFastPathForSolidColorQuad() {
+  return base::FeatureList::IsEnabled(kFastSolidColorDraw);
+}
+
 bool IsUsingVizFrameSubmissionForWebView() {
   return base::FeatureList::IsEnabled(kVizFrameSubmissionForWebView);
 }
diff --git components/viz/common/features.h components/viz/common/features.h
index 5176e7be36768..6a5dab7c9fa93 100644
--- components/viz/common/features.h
+++ components/viz/common/features.h
@@ -22,6 +22,7 @@ namespace features {
 VIZ_COMMON_EXPORT BASE_DECLARE_FEATURE(kAdpf);
 VIZ_COMMON_EXPORT extern const base::FeatureParam<int> kAdpfTargetDurationMs;
 VIZ_COMMON_EXPORT BASE_DECLARE_FEATURE(kEnableOverlayPrioritization);
+VIZ_COMMON_EXPORT BASE_DECLARE_FEATURE(kUseSkiaRenderer);
 VIZ_COMMON_EXPORT BASE_DECLARE_FEATURE(kDelegatedCompositing);
 VIZ_COMMON_EXPORT BASE_DECLARE_FEATURE(kRecordSkPicture);
 VIZ_COMMON_EXPORT BASE_DECLARE_FEATURE(kDisableDeJelly);
@@ -31,7 +32,9 @@ VIZ_COMMON_EXPORT BASE_DECLARE_FEATURE(kVideoDetectorIgnoreNonVideos);
 #if BUILDFLAG(IS_ANDROID)
 VIZ_COMMON_EXPORT BASE_DECLARE_FEATURE(kDynamicColorGamut);
 #endif
+VIZ_COMMON_EXPORT BASE_DECLARE_FEATURE(kFastSolidColorDraw);
 VIZ_COMMON_EXPORT BASE_DECLARE_FEATURE(kVizFrameSubmissionForWebView);
+VIZ_COMMON_EXPORT BASE_DECLARE_FEATURE(kUsePreferredIntervalForVideo);
 VIZ_COMMON_EXPORT BASE_DECLARE_FEATURE(kUseRealBuffersForPageFlipTest);
 #if BUILDFLAG(IS_FUCHSIA)
 VIZ_COMMON_EXPORT BASE_DECLARE_FEATURE(kUseSkiaOutputDeviceBufferQueue);
@@ -82,6 +85,8 @@ VIZ_COMMON_EXPORT bool IsDynamicColorGamutEnabled();
 VIZ_COMMON_EXPORT bool IsOverlayPrioritizationEnabled();
 VIZ_COMMON_EXPORT bool IsDelegatedCompositingEnabled();
 VIZ_COMMON_EXPORT bool IsSyncWindowDestructionEnabled();
+VIZ_COMMON_EXPORT bool IsUsingFastPathForSolidColorQuad();
+VIZ_COMMON_EXPORT bool IsUsingSkiaRenderer();
 VIZ_COMMON_EXPORT bool IsUsingVizFrameSubmissionForWebView();
 VIZ_COMMON_EXPORT bool IsUsingPreferredIntervalForVideo();
 VIZ_COMMON_EXPORT bool ShouldUseRealBuffersForPageFlipTest();
diff --git components/viz/common/gl_i420_converter.cc components/viz/common/gl_i420_converter.cc
new file mode 100644
index 0000000000000..c00e202c35197
--- /dev/null
+++ components/viz/common/gl_i420_converter.cc
@@ -0,0 +1,209 @@
+// Copyright 2018 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "components/viz/common/gl_i420_converter.h"
+
+#include <utility>
+
+#include "components/viz/common/gpu/context_provider.h"
+
+namespace viz {
+
+GLI420Converter::GLI420Converter(ContextProvider* context_provider)
+    : GLI420Converter(context_provider, true) {
+  DCHECK(context_provider_);
+}
+
+GLI420Converter::GLI420Converter(ContextProvider* context_provider,
+                                 bool allow_mrt_path)
+    : context_provider_(context_provider),
+      step1_(context_provider_),
+      step2_(context_provider_) {
+  DCHECK(context_provider_);
+  context_provider_->AddObserver(this);
+  if (!allow_mrt_path || step1_.GetMaxDrawBuffersSupported() < 2) {
+    step3_ = std::make_unique<GLScaler>(context_provider_);
+    step4_ = std::make_unique<GLScaler>(context_provider_);
+  }
+}
+
+GLI420Converter::~GLI420Converter() {
+  OnContextLost();  // Free context-related resources.
+}
+
+bool GLI420Converter::Configure(const Parameters& params) {
+  Parameters step1_params = params;
+  if (!step1_params.output_color_space.IsValid()) {
+    step1_params.output_color_space = gfx::ColorSpace::CreateREC709();
+  }
+
+  // Configure the "step 1" scaler.
+  if (is_using_mrt_path()) {
+    step1_params.export_format = Parameters::ExportFormat::NV61;
+    DCHECK_EQ(step1_params.swizzle[0], params.swizzle[0]);
+    step1_params.swizzle[1] = GL_RGBA;  // Don't swizzle 2nd rendering target.
+  } else {
+    step1_params.export_format = Parameters::ExportFormat::INTERLEAVED_QUADS;
+    step1_params.swizzle[0] = GL_RGBA;  // Will swizzle in steps 2-4.
+  }
+  if (!step1_.Configure(step1_params)) {
+    return false;
+  }
+
+  // Configure the "step 2" scaler (and steps 3 and 4 for the non-MRT path) that
+  // further transform the output from the "step 1" scaler to produce the final
+  // outputs.
+  Parameters step2_params;
+  step2_params.scale_to = gfx::Vector2d(1, 1);
+  step2_params.source_color_space = step1_params.output_color_space;
+  step2_params.output_color_space = step1_params.output_color_space;
+  // Use FAST quality, a single bilinear pass, because there will either be no
+  // scaling or exactly 50% scaling.
+  step2_params.quality = Parameters::Quality::FAST;
+  step2_params.swizzle[0] = params.swizzle[0];
+  if (is_using_mrt_path()) {
+    // NV61 provides half-width and full-height U/V. I420 U/V planes are
+    // half-width and half-height. So, scale Y by 50%.
+    step2_params.scale_from = gfx::Vector2d(1, 2);
+    step2_params.export_format =
+        Parameters::ExportFormat::DEINTERLEAVE_PAIRWISE;
+    step2_params.swizzle[1] = step2_params.swizzle[0];
+    if (!step2_.Configure(step2_params)) {
+      return false;
+    }
+  } else {
+    // Extract a full-size Y plane from the interleaved YUVA from step 1.
+    step2_params.scale_from = gfx::Vector2d(1, 1);
+    step2_params.export_format = Parameters::ExportFormat::CHANNEL_0;
+    if (!step2_.Configure(step2_params)) {
+      return false;
+    }
+    // Extract half-size U/V planes from the interleaved YUVA from step 1.
+    step2_params.scale_from = gfx::Vector2d(2, 2);
+    step2_params.export_format = Parameters::ExportFormat::CHANNEL_1;
+    if (!step3_->Configure(step2_params)) {
+      return false;
+    }
+    step2_params.export_format = Parameters::ExportFormat::CHANNEL_2;
+    if (!step4_->Configure(step2_params)) {
+      return false;
+    }
+  }
+
+  params_ = params;
+  return true;
+}
+
+bool GLI420Converter::Convert(GLuint src_texture,
+                              const gfx::Size& src_texture_size,
+                              const gfx::Vector2d& src_offset,
+                              const gfx::Rect& output_rect,
+                              const GLuint yuv_textures[3]) {
+  DCHECK_EQ(output_rect.x() % 8, 0);
+  DCHECK_EQ(output_rect.width() % 8, 0);
+  DCHECK_EQ(output_rect.y() % 2, 0);
+  DCHECK_EQ(output_rect.height() % 2, 0);
+
+  if (!context_provider_) {
+    return false;
+  }
+
+  if (is_using_mrt_path()) {
+    const gfx::Rect luma_output_rect(output_rect.x() / 4, output_rect.y(),
+                                     output_rect.width() / 4,
+                                     output_rect.height());
+    EnsureIntermediateTextureDefined(luma_output_rect.size());
+    const gfx::Rect chroma_output_rect(
+        gfx::Size(luma_output_rect.width() / 2, luma_output_rect.height() / 2));
+    return (step1_.ScaleToMultipleOutputs(
+                src_texture, src_texture_size, src_offset, yuv_textures[0],
+                intermediate_texture_, luma_output_rect) &&
+            step2_.ScaleToMultipleOutputs(intermediate_texture_,
+                                          intermediate_texture_size_,
+                                          gfx::Vector2d(), yuv_textures[1],
+                                          yuv_textures[2], chroma_output_rect));
+  }
+
+  // Non-MRT path:
+  EnsureIntermediateTextureDefined(output_rect.size());
+  const gfx::Rect luma_output_rect(0, 0, output_rect.width() / 4,
+                                   output_rect.height());
+  const gfx::Rect chroma_output_rect(0, 0, luma_output_rect.width() / 2,
+                                     luma_output_rect.height() / 2);
+  return (step1_.Scale(src_texture, src_texture_size, src_offset,
+                       intermediate_texture_, output_rect) &&
+          step2_.Scale(intermediate_texture_, intermediate_texture_size_,
+                       gfx::Vector2d(), yuv_textures[0], luma_output_rect) &&
+          step3_->Scale(intermediate_texture_, intermediate_texture_size_,
+                        gfx::Vector2d(), yuv_textures[1], chroma_output_rect) &&
+          step4_->Scale(intermediate_texture_, intermediate_texture_size_,
+                        gfx::Vector2d(), yuv_textures[2], chroma_output_rect));
+}
+
+// static
+gfx::Rect GLI420Converter::ToAlignedRect(const gfx::Rect& rect) {
+  // Origin coordinates: FLOOR(...)
+  const int aligned_x =
+      ((rect.x() < 0) ? ((rect.x() - 7) / 8) : (rect.x() / 8)) * 8;
+  const int aligned_y =
+      ((rect.y() < 0) ? ((rect.y() - 1) / 2) : (rect.y() / 2)) * 2;
+  // Span coordinates: CEIL(...)
+  const int aligned_right =
+      ((rect.right() < 0) ? (rect.right() / 8) : ((rect.right() + 7) / 8)) * 8;
+  const int aligned_bottom =
+      ((rect.bottom() < 0) ? (rect.bottom() / 2) : ((rect.bottom() + 1) / 2)) *
+      2;
+  return gfx::Rect(aligned_x, aligned_y, aligned_right - aligned_x,
+                   aligned_bottom - aligned_y);
+}
+
+// static
+bool GLI420Converter::ParametersAreEquivalent(const Parameters& a,
+                                              const Parameters& b) {
+  const auto Resolve = [](Parameters params) {
+    // Per header comments, if an invalid output_color_space is specified, use
+    // REC709.
+    if (!params.output_color_space.IsValid()) {
+      params.output_color_space = gfx::ColorSpace::CreateREC709();
+    }
+    // Both of these fields are overwritten, in Configure(), whether the MRT
+    // path is going to be used or not. So, for the purposes of "equivalence,"
+    // just set these like the MRT path would.
+    params.export_format = Parameters::ExportFormat::NV61;
+    params.swizzle[1] = GL_RGBA;
+    return params;
+  };
+  return GLScaler::ParametersAreEquivalent(Resolve(a), Resolve(b));
+}
+
+void GLI420Converter::EnsureIntermediateTextureDefined(
+    const gfx::Size& required) {
+  if (intermediate_texture_size_ == required) {
+    return;
+  }
+  auto* const gl = context_provider_->ContextGL();
+  if (intermediate_texture_ == 0) {
+    gl->GenTextures(1, &intermediate_texture_);
+  }
+  gl->BindTexture(GL_TEXTURE_2D, intermediate_texture_);
+  gl->TexImage2D(GL_TEXTURE_2D, 0, GL_RGBA, required.width(), required.height(),
+                 0, GL_RGBA, GL_UNSIGNED_BYTE, nullptr);
+  intermediate_texture_size_ = required;
+}
+
+void GLI420Converter::OnContextLost() {
+  if (intermediate_texture_ != 0) {
+    if (auto* gl = context_provider_->ContextGL()) {
+      gl->DeleteTextures(1, &intermediate_texture_);
+    }
+    intermediate_texture_ = 0;
+    intermediate_texture_size_ = gfx::Size();
+  }
+  if (context_provider_) {
+    context_provider_->RemoveObserver(this);
+    context_provider_ = nullptr;
+  }
+}
+
+}  // namespace viz
diff --git components/viz/common/gl_i420_converter.h components/viz/common/gl_i420_converter.h
new file mode 100644
index 0000000000000..6792ca8fdc8b0
--- /dev/null
+++ components/viz/common/gl_i420_converter.h
@@ -0,0 +1,195 @@
+// Copyright 2018 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef COMPONENTS_VIZ_COMMON_GL_I420_CONVERTER_H_
+#define COMPONENTS_VIZ_COMMON_GL_I420_CONVERTER_H_
+
+#include <memory>
+
+#include "base/memory/raw_ptr.h"
+#include "base/memory/scoped_refptr.h"
+#include "components/viz/common/gl_scaler.h"
+#include "components/viz/common/gpu/context_lost_observer.h"
+#include "components/viz/common/viz_common_export.h"
+#include "ui/gfx/color_space.h"
+#include "ui/gfx/geometry/size.h"
+
+namespace gfx {
+class Rect;
+class Vector2d;
+}  // namespace gfx
+
+namespace viz {
+
+class ContextProvider;
+
+// A convenience wrapper around GLScaler that also reformats the scaler's output
+// from interleaved RGBA to I420 planes. The I420 format consists of three
+// planes of image data: the Y (luma) plane at full size, plus U and V (chroma)
+// planes at half-width and half-height. There are two possible modes of
+// operation (auto-detected at runtime):
+//
+// The faster, multiple rendering target (MRT) path: If the platform supports
+// MRTs (most of the GPUs in use today), scaling and conversion is a two step
+// process:
+//
+//   Step 1: Produce NV61 format output, a luma plane and a UV-interleaved
+//   image. The luma plane is the same as the desired I420 luma plane. Note,
+//   that the UV image is of half-width but not yet half-height.
+//
+//               (interleaved quads)
+//     RGBA RGBA RGBA RGBA RGBA RGBA RGBA RGBA
+//     RGBA RGBA RGBA RGBA RGBA RGBA RGBA RGBA
+//     RGBA RGBA RGBA RGBA RGBA RGBA RGBA RGBA
+//     RGBA RGBA RGBA RGBA RGBA RGBA RGBA RGBA
+//       |
+//       |     (luma plane)  (chroma, interleaved)
+//       |       YYYY YYYY      UVUV UVUV
+//       +---> { YYYY YYYY  +   UVUV UVUV }
+//               YYYY YYYY      UVUV UVUV
+//               YYYY YYYY      UVUV UVUV
+//
+//   Step 2: Derives the two I420 chroma planes from the UV-interleaved image
+//   from Step 1. This step separates the U and V pixels into separate planes,
+//   and also scales the height by half. This produces the desired I420 chroma
+//   planes.
+//
+//     (chroma, interleaved)     (two chroma planes)
+//           UVUV UVUV
+//           UVUV UVUV       -->   { UUUU + VVVV }
+//           UVUV UVUV               UUUU   VVVV
+//           UVUV UVUV
+//
+// The non-MRT path: For platforms that can only render to a single target at a
+// time. This first scales the source to its final size and color-converts,
+// transforming an RGBA input into a YUVA output. Then, it scans the YUVA image
+// three times to generate each of the Y+U+V planes.
+//
+// Texture packing: OpenGLES2 treats all of the input and output textures as
+// RGBA format. See comments for the Convert() method, which explains how the
+// planar image data is packed into GL_RGBA textures, how the output textures
+// should be sized, and why there are alignment requirements when specifying the
+// output rect.
+class VIZ_COMMON_EXPORT GLI420Converter final : public ContextLostObserver {
+ public:
+  // GLI420Converter uses the exact same parameters as GLScaler.
+  using Parameters = GLScaler::Parameters;
+
+  explicit GLI420Converter(ContextProvider* context_provider);
+
+  GLI420Converter(const GLI420Converter&) = delete;
+  GLI420Converter& operator=(const GLI420Converter&) = delete;
+
+  ~GLI420Converter() final;
+
+  // Returns true if the GL context provides the necessary support for enabling
+  // precise color management (see Parameters::enable_precise_color_management).
+  bool SupportsPreciseColorManagement() const {
+    return step1_.SupportsPreciseColorManagement();
+  }
+
+  // [Re]Configure the converter with the given |new_params|. Returns true on
+  // success, or false on failure. If |new_params| does not specify an
+  // |output_color_space|, it will be default to REC709.
+  [[nodiscard]] bool Configure(const Parameters& new_params);
+
+  // Returns the currently-configured and resolved Parameters. Results are
+  // undefined if Configure() has never been called successfully.
+  const Parameters& params() const { return params_; }
+
+  // Scales a portion of |src_texture|, then format-converts it to three I420
+  // planes, placing the results into |yuv_textures| at offset (0, 0). Returns
+  // true to indicate success, or false if this GLI420Converter is not valid.
+  //
+  // |src_texture_size| is the full, allocated size of the |src_texture|. This
+  // is required for computing texture coordinate transforms (and only because
+  // the OpenGL ES 2.0 API lacks the ability to query this info).
+  //
+  // |src_offset| is the offset in the source texture corresponding to point
+  // (0,0) in the source/output coordinate spaces. This prevents the need for
+  // extra texture copies just to re-position the source coordinate system.
+  //
+  // |aligned_output_rect| selects the region to draw (in the scaled, not the
+  // source, coordinate space). This is used to save work in cases where only a
+  // portion needs to be re-scaled. Because of the way the planar image data is
+  // packed in the output textures, the output rect's coordinates must be
+  // aligned (see ToAlignedRect() below).
+  //
+  // The |yuv_textures| are packed with planar data, meaning that each RGBA quad
+  // contains four pixel values: R is pixel 0, G is pixel 1, and so on. This
+  // makes it trivial to read-back the textures from a pixel buffer as a
+  // sequence of unsigned bytes. Thus, the output texture for the Y plane should
+  // be defined as GL_RGBA and be at least 1/4 the width of that specified in
+  // |aligned_output_rect|. Similarly, the output textures for the U and V
+  // planes should be defined as GL_RGBA and have at least 1/8 the width and 1/2
+  // the height of |aligned_output_rect|.
+  //
+  // WARNING: The output will always be placed at (0, 0) in the output textures,
+  // and not at |aligned_output_rect.origin()|.
+  //
+  // Note that the |src_texture| will have the min/mag filter set to GL_LINEAR
+  // and wrap_s/t set to CLAMP_TO_EDGE in this call.
+  bool Convert(GLuint src_texture,
+               const gfx::Size& src_texture_size,
+               const gfx::Vector2d& src_offset,
+               const gfx::Rect& aligned_output_rect,
+               const GLuint yuv_textures[3]);
+
+  // Returns the smallest Rect that encloses |rect| and lays on aligned
+  // boundaries, as required by the |aligned_output_rect| argument passed to
+  // Convert(). The horizontal coordinates will always be a multiple of 8, and
+  // the vertical coordinates a multiple of 2.
+  static gfx::Rect ToAlignedRect(const gfx::Rect& rect);
+
+  // Returns true if configuring a GLI420Converter with either |a| or |b| will
+  // produce identical behaviors and results.
+  static bool ParametersAreEquivalent(const Parameters& a, const Parameters& b);
+
+ private:
+  friend class GLI420ConverterPixelTest;
+
+  GLI420Converter(ContextProvider* context_provider, bool allow_mrt_path);
+
+  bool is_using_mrt_path() const { return !step3_; }
+
+  // Creates or re-defines the intermediate texture, to ensure a texture of the
+  // given |required| size is defined.
+  void EnsureIntermediateTextureDefined(const gfx::Size& required);
+
+  // ContextLostObserver implementation.
+  void OnContextLost() final;
+
+  // The provider of the GL context. This is non-null while the GL context is
+  // valid and GLI420Converter is observing for context loss.
+  raw_ptr<ContextProvider> context_provider_;
+
+  // Scales the source content and produces either:
+  //   * MRT path: NV61-format output in two textures.
+  //   * Non-MRT path: YUVA interleaved output in one texture.
+  GLScaler step1_;
+
+  // Holds the results from executing the first-stage |scaler_|, and is read by
+  // the other scalers:
+  //   * MRT path: This holds the UV-interleaved data (2nd rendering target).
+  //   * Non-MRT path: The scaled YUVA interleaved data.
+  GLuint intermediate_texture_ = 0;
+  gfx::Size intermediate_texture_size_;
+
+  // Step 2 operation using the |intermediate_texture_| as input:
+  //   * MRT path: Separates-out the U and V planes (and scales height by half).
+  //   * Non-MRT path: Extracts the luma plane.
+  GLScaler step2_;
+
+  // Steps 3 and 4 are used by the non-MRT path only, to extract the two chroma
+  // planes from |intermediate_texture_|.
+  std::unique_ptr<GLScaler> step3_;
+  std::unique_ptr<GLScaler> step4_;
+
+  // The Parameters that were provided to the last successful Configure() call.
+  Parameters params_;
+};
+
+}  // namespace viz
+
+#endif  // COMPONENTS_VIZ_COMMON_GL_I420_CONVERTER_H_
diff --git components/viz/common/gl_nv12_converter.cc components/viz/common/gl_nv12_converter.cc
new file mode 100644
index 0000000000000..2c737130a6b4a
--- /dev/null
+++ components/viz/common/gl_nv12_converter.cc
@@ -0,0 +1,195 @@
+// Copyright 2021 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "components/viz/common/gl_nv12_converter.h"
+
+#include "base/memory/ptr_util.h"
+#include "components/viz/common/gl_i420_converter.h"
+#include "components/viz/common/gpu/context_provider.h"
+
+namespace viz {
+
+// static
+std::unique_ptr<GLNV12Converter> GLNV12Converter::CreateConverterForTest(
+    ContextProvider* context_provider,
+    bool allow_mrt_path) {
+  return base::WrapUnique(
+      new GLNV12Converter(context_provider, allow_mrt_path));
+}
+
+GLNV12Converter::GLNV12Converter(ContextProvider* context_provider)
+    : GLNV12Converter(context_provider, true) {}
+
+GLNV12Converter::GLNV12Converter(ContextProvider* context_provider,
+                                 bool allow_mrt_path)
+    : context_provider_(context_provider),
+      step1_(context_provider_),
+      step2_(context_provider_) {
+  DCHECK(context_provider_);
+  context_provider_->AddObserver(this);
+  if (!allow_mrt_path || step1_.GetMaxDrawBuffersSupported() < 2) {
+    step3_ = std::make_unique<GLScaler>(context_provider_);
+  }
+}
+
+GLNV12Converter::~GLNV12Converter() {
+  OnContextLost();  // Free context-related resources.
+}
+
+// static
+gfx::Rect GLNV12Converter::ToAlignedRect(const gfx::Rect& rect) {
+  // Origin coordinates: FLOOR(...)
+  const int aligned_x =
+      ((rect.x() < 0) ? ((rect.x() - 3) / 4) : (rect.x() / 4)) * 4;
+  const int aligned_y =
+      ((rect.y() < 0) ? ((rect.y() - 1) / 2) : (rect.y() / 2)) * 2;
+  // Span coordinates: CEIL(...)
+  const int aligned_right =
+      ((rect.right() < 0) ? (rect.right() / 4) : ((rect.right() + 3) / 4)) * 4;
+  const int aligned_bottom =
+      ((rect.bottom() < 0) ? (rect.bottom() / 2) : ((rect.bottom() + 1) / 2)) *
+      2;
+  return gfx::Rect(aligned_x, aligned_y, aligned_right - aligned_x,
+                   aligned_bottom - aligned_y);
+}
+
+// static
+bool GLNV12Converter::ParametersAreEquivalent(const Parameters& a,
+                                              const Parameters& b) {
+  // Implemented in terms of GLI420Converter:
+  return GLI420Converter::ParametersAreEquivalent(a, b);
+}
+
+void GLNV12Converter::EnsureIntermediateTextureDefined(
+    const gfx::Size& required) {
+  if (intermediate_texture_size_ == required) {
+    return;
+  }
+  auto* const gl = context_provider_->ContextGL();
+  if (intermediate_texture_ == 0) {
+    gl->GenTextures(1, &intermediate_texture_);
+  }
+  gl->BindTexture(GL_TEXTURE_2D, intermediate_texture_);
+  gl->TexImage2D(GL_TEXTURE_2D, 0, GL_RGBA, required.width(), required.height(),
+                 0, GL_RGBA, GL_UNSIGNED_BYTE, nullptr);
+  intermediate_texture_size_ = required;
+}
+
+bool GLNV12Converter::Configure(const Parameters& params) {
+  Parameters step1_params = params;
+  if (!step1_params.output_color_space.IsValid()) {
+    step1_params.output_color_space = gfx::ColorSpace::CreateREC709();
+  }
+
+  // Configure the "step 1" scaler.
+  if (is_using_mrt_path()) {
+    step1_params.export_format = Parameters::ExportFormat::NV61;
+    DCHECK_EQ(step1_params.swizzle[0], params.swizzle[0]);
+    step1_params.swizzle[1] = GL_RGBA;  // Don't swizzle 2nd rendering target.
+  } else {
+    step1_params.export_format = Parameters::ExportFormat::INTERLEAVED_QUADS;
+    step1_params.swizzle[0] = GL_RGBA;  // Will swizzle in steps 2-3.
+  }
+  if (!step1_.Configure(step1_params)) {
+    return false;
+  }
+
+  // Configure the "step 2" scaler (and step 3 for the non-MRT path) that
+  // further transform the output from the "step 1" scaler to produce the final
+  // outputs.
+  Parameters step2_params;
+  step2_params.scale_to = gfx::Vector2d(1, 1);
+  step2_params.source_color_space = step1_params.output_color_space;
+  step2_params.output_color_space = step1_params.output_color_space;
+  // Use FAST quality, a single bilinear pass, because there will either be no
+  // scaling or exactly 50% scaling.
+  step2_params.quality = Parameters::Quality::FAST;
+  step2_params.swizzle[0] = params.swizzle[0];
+  if (is_using_mrt_path()) {
+    // NV61 provides half-width and full-height U/V. NV12 UV planes are
+    // half-width and half-height. So, scale just the Y by 50%.
+    step2_params.scale_from = gfx::Vector2d(1, 2);
+    step2_params.export_format = Parameters::ExportFormat::INTERLEAVED_QUADS;
+    step2_params.swizzle[1] = step2_params.swizzle[0];
+    if (!step2_.Configure(step2_params)) {
+      return false;
+    }
+  } else {
+    // Extract a full-size Y plane from the interleaved YUVA from step 1.
+    step2_params.scale_from = gfx::Vector2d(1, 1);
+    step2_params.export_format = Parameters::ExportFormat::CHANNEL_0;
+    if (!step2_.Configure(step2_params)) {
+      return false;
+    }
+    // Extract a half-size UV plane from the interleaved YUVA from step 1.
+    // UV_CHANNELS provides half-width and full-height UV plane. NV12 UV planes
+    // are half-wifth and half-height. So, scale just the Y by 50%.
+    step2_params.scale_from = gfx::Vector2d(1, 2);
+    step2_params.export_format = Parameters::ExportFormat::UV_CHANNELS;
+    if (!step3_->Configure(step2_params)) {
+      return false;
+    }
+  }
+
+  params_ = params;
+  return true;
+}
+
+bool GLNV12Converter::Convert(GLuint src_texture,
+                              const gfx::Size& src_texture_size,
+                              const gfx::Vector2d& src_offset,
+                              const gfx::Rect& aligned_output_rect,
+                              const GLuint yuv_textures[2]) {
+  DCHECK_EQ(aligned_output_rect.x() % 4, 0);
+  DCHECK_EQ(aligned_output_rect.width() % 4, 0);
+  DCHECK_EQ(aligned_output_rect.y() % 2, 0);
+  DCHECK_EQ(aligned_output_rect.height() % 2, 0);
+
+  if (!context_provider_) {
+    return false;
+  }
+
+  if (is_using_mrt_path()) {
+    const gfx::Rect luma_output_rect(
+        aligned_output_rect.x() / 4, aligned_output_rect.y(),
+        aligned_output_rect.width() / 4, aligned_output_rect.height());
+    EnsureIntermediateTextureDefined(luma_output_rect.size());
+    const gfx::Rect chroma_output_rect(
+        gfx::Size(luma_output_rect.width(), luma_output_rect.height() / 2));
+    return (step1_.ScaleToMultipleOutputs(
+                src_texture, src_texture_size, src_offset, yuv_textures[0],
+                intermediate_texture_, luma_output_rect) &&
+            step2_.Scale(intermediate_texture_, intermediate_texture_size_,
+                         gfx::Vector2d(), yuv_textures[1], chroma_output_rect));
+  }
+
+  // Non-MRT path:
+  EnsureIntermediateTextureDefined(aligned_output_rect.size());
+  const gfx::Rect luma_output_rect(0, 0, aligned_output_rect.width() / 4,
+                                   aligned_output_rect.height());
+  const gfx::Rect chroma_output_rect(0, 0, luma_output_rect.width(),
+                                     luma_output_rect.height() / 2);
+  return (step1_.Scale(src_texture, src_texture_size, src_offset,
+                       intermediate_texture_, aligned_output_rect) &&
+          step2_.Scale(intermediate_texture_, intermediate_texture_size_,
+                       gfx::Vector2d(), yuv_textures[0], luma_output_rect) &&
+          step3_->Scale(intermediate_texture_, intermediate_texture_size_,
+                        gfx::Vector2d(), yuv_textures[1], chroma_output_rect));
+}
+
+void GLNV12Converter::OnContextLost() {
+  if (intermediate_texture_ != 0) {
+    if (auto* gl = context_provider_->ContextGL()) {
+      gl->DeleteTextures(1, &intermediate_texture_);
+    }
+    intermediate_texture_ = 0;
+    intermediate_texture_size_ = gfx::Size();
+  }
+  if (context_provider_) {
+    context_provider_->RemoveObserver(this);
+    context_provider_ = nullptr;
+  }
+}
+
+}  // namespace viz
diff --git components/viz/common/gl_nv12_converter.h components/viz/common/gl_nv12_converter.h
new file mode 100644
index 0000000000000..15c6944270f5b
--- /dev/null
+++ components/viz/common/gl_nv12_converter.h
@@ -0,0 +1,200 @@
+// Copyright 2021 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef COMPONENTS_VIZ_COMMON_GL_NV12_CONVERTER_H_
+#define COMPONENTS_VIZ_COMMON_GL_NV12_CONVERTER_H_
+
+#include <memory>
+
+#include "base/memory/raw_ptr.h"
+#include "base/memory/scoped_refptr.h"
+#include "components/viz/common/gl_scaler.h"
+#include "components/viz/common/gpu/context_lost_observer.h"
+#include "components/viz/common/viz_common_export.h"
+#include "ui/gfx/color_space.h"
+#include "ui/gfx/geometry/size.h"
+
+namespace gfx {
+class Rect;
+class Vector2d;
+}  // namespace gfx
+
+namespace viz {
+
+class ContextProvider;
+
+// A convenience wrapper around GLScaler that also reformats the scaler's output
+// from interleaved RGBA to NV12 planes. The NV12 format consists of two
+// planes of image data: the Y (luma) plane at full size, plus interleaved UV
+// (chroma) plane at half-width and half-height. There are two possible modes of
+// operation (auto-detected at runtime):
+//
+// The faster, multiple rendering target (MRT) path: If the platform supports
+// MRTs (most of the GPUs in use today), scaling and conversion is a two step
+// process:
+//
+//   Step 1: Produce NV61 format output, a luma plane and a UV-interleaved
+//   image. The luma plane is the same as the desired NV12 luma plane. Note,
+//   that the UV image is of half-width but not yet half-height.
+//
+//               (interleaved quads)
+//     RGBA RGBA RGBA RGBA RGBA RGBA RGBA RGBA
+//     RGBA RGBA RGBA RGBA RGBA RGBA RGBA RGBA
+//     RGBA RGBA RGBA RGBA RGBA RGBA RGBA RGBA
+//     RGBA RGBA RGBA RGBA RGBA RGBA RGBA RGBA
+//       |
+//       |     (luma plane)  (chroma, interleaved)
+//       |       YYYY YYYY      UVUV UVUV
+//       +---> { YYYY YYYY  +   UVUV UVUV }
+//               YYYY YYYY      UVUV UVUV
+//               YYYY YYYY      UVUV UVUV
+//
+//   Step 2: Downscales the chroma plane.
+//
+//     (chroma, interleaved)     (chroma, interleaved)
+//           UVUV UVUV
+//           UVUV UVUV     -->   UVUV UVUV
+//           UVUV UVUV           UVUV UVUV
+//           UVUV UVUV
+//
+// The non-MRT path: For platforms that can only render to a single target at a
+// time. This first scales the source to its final size and color-converts,
+// transforming an RGBA input into a YUVx output. Then, it scans the YUVA image
+// two times to generate each of the Y+UV planes.
+//
+// Texture packing: OpenGLES2 treats all of the input and output textures as
+// RGBA format. See comments for the Convert() method, which explains how the
+// planar image data is packed into GL_RGBA textures, how the output textures
+// should be sized, and why there are alignment requirements when specifying the
+// output rect.
+class VIZ_COMMON_EXPORT GLNV12Converter final : public ContextLostObserver {
+ public:
+  // GLNV12Converter uses the exact same parameters as GLScaler.
+  using Parameters = GLScaler::Parameters;
+
+  explicit GLNV12Converter(ContextProvider* context_provider);
+  ~GLNV12Converter() final;
+
+  // Returns true if the GL context provides the necessary support for enabling
+  // precise color management (see Parameters::enable_precise_color_management).
+  bool SupportsPreciseColorManagement() const {
+    return step1_.SupportsPreciseColorManagement();
+  }
+
+  // [Re]Configure the converter with the given |new_params|. Returns true on
+  // success, or false on failure. If |new_params| does not specify an
+  // |output_color_space|, it will be default to REC709.
+  [[nodiscard]] bool Configure(const Parameters& new_params);
+
+  // Returns the currently-configured and resolved Parameters. Results are
+  // undefined if Configure() has never been called successfully.
+  const Parameters& params() const { return params_; }
+
+  // Scales a portion of |src_texture|, then format-converts it to two NV12
+  // planes, placing the results into |yuv_textures| at offset (0, 0). Returns
+  // true to indicate success, or false if this GLNV12Converter is not valid.
+  //
+  // |src_texture_size| is the full, allocated size of the |src_texture|. This
+  // is required for computing texture coordinate transforms (and only because
+  // the OpenGL ES 2.0 API lacks the ability to query this info).
+  //
+  // |src_offset| is the offset in the source texture corresponding to point
+  // (0,0) in the source/output coordinate spaces. This prevents the need for
+  // extra texture copies just to re-position the source coordinate system.
+  //
+  // |aligned_output_rect| selects the region to draw (in the scaled, not the
+  // source, coordinate space). This is used to save work in cases where only a
+  // portion needs to be re-scaled. Because of the way the planar image data is
+  // packed in the output textures, the output rect's coordinates must be
+  // aligned (see ToAlignedRect() below).
+  //
+  // The |yuv_textures| are packed with planar data. Depending on the plane,
+  // the packing is as follows:
+  // - for Y plane, each RGBA quad contains four pixel values: R is pixel 0,
+  //   G is pixel 1, and so on.
+  // - for UV plane, each RGBA quad contains 2 pixel values: RG are UV values
+  //   for pixel 0, BA are UV values for pixel 1, and so on.
+  // This makes it trivial to read-back the textures from a pixel buffer as a
+  // sequence of unsigned bytes. Thus, the output texture for the Y plane should
+  // be defined as GL_RGBA and be at least 1/4 the width of that specified in
+  // |aligned_output_rect|. Similarly, the output texture for the UV plane
+  // should be defined as GL_RGBA and have at least 1/4 the width [1]
+  // and 1/2 the height [2] of |aligned_output_rect|.
+  //
+  // [1] 1/4 width  = 1/4     // we pack 4 values per pixel
+  //                * 1/2     // chroma planes are subsampled
+  //                * 2       // we pack 2 chroma planes
+  //                * width
+  // [2] 1/2 height = 1/2     // chroma planes are subsampled
+  //                * height
+  //
+  // WARNING: The output will always be placed at (0, 0) in the output textures,
+  // and not at |aligned_output_rect.origin()|.
+  //
+  // Note that the |src_texture| will have the min/mag filter set to GL_LINEAR
+  // and wrap_s/t set to CLAMP_TO_EDGE in this call.
+  bool Convert(GLuint src_texture,
+               const gfx::Size& src_texture_size,
+               const gfx::Vector2d& src_offset,
+               const gfx::Rect& aligned_output_rect,
+               const GLuint yuv_textures[2]);
+
+  // Returns the smallest Rect that encloses |rect| and lays on aligned
+  // boundaries, as required by the |aligned_output_rect| argument passed to
+  // Convert(). The horizontal coordinates will always be a multiple of 4, and
+  // the vertical coordinates a multiple of 2.
+  static gfx::Rect ToAlignedRect(const gfx::Rect& rect);
+
+  // Returns true if configuring a GLNV12Converter with either |a| or |b| will
+  // produce identical behaviors and results.
+  static bool ParametersAreEquivalent(const Parameters& a, const Parameters& b);
+
+  static std::unique_ptr<GLNV12Converter> CreateConverterForTest(
+      ContextProvider* context_provider,
+      bool allow_mrt_path);
+
+ private:
+  GLNV12Converter(ContextProvider* context_provider, bool allow_mrt_path);
+
+  bool is_using_mrt_path() const { return !step3_; }
+
+  // Creates or re-defines the intermediate texture, to ensure a texture of the
+  // given |required| size is defined.
+  void EnsureIntermediateTextureDefined(const gfx::Size& required);
+
+  // ContextLostObserver implementation.
+  void OnContextLost() final;
+
+  // The provider of the GL context. This is non-null while the GL context is
+  // valid and GLNV12Converter is observing for context loss.
+  raw_ptr<ContextProvider> context_provider_;
+
+  // Scales the source content and produces either:
+  //   * MRT path: NV61-format output in two textures.
+  //   * Non-MRT path: YUVA interleaved output in one texture.
+  GLScaler step1_;
+
+  // Holds the results from executing the first-stage |scaler_|, and is read by
+  // the other scalers:
+  //   * MRT path: This holds the UV-interleaved data (2nd rendering target).
+  //   * Non-MRT path: The scaled YUVA interleaved data.
+  GLuint intermediate_texture_ = 0;
+  gfx::Size intermediate_texture_size_;
+
+  // Step 2 operation using the |intermediate_texture_| as input:
+  //   * MRT path: Scales the height by half.
+  //   * Non-MRT path: Extracts the luma plane.
+  GLScaler step2_;
+
+  // Steps 3 is used by the non-MRT path only, to extract the interleaved chroma
+  // planes from |intermediate_texture_|.
+  std::unique_ptr<GLScaler> step3_;
+
+  // The Parameters that were provided to the last successful Configure() call.
+  Parameters params_;
+};
+
+}  // namespace viz
+
+#endif  // COMPONENTS_VIZ_COMMON_GL_NV12_CONVERTER_H_
diff --git components/viz/common/gl_scaler.cc components/viz/common/gl_scaler.cc
new file mode 100644
index 0000000000000..2393ebc8d0904
--- /dev/null
+++ components/viz/common/gl_scaler.cc
@@ -0,0 +1,1661 @@
+// Copyright 2018 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "components/viz/common/gl_scaler.h"
+
+#include <algorithm>
+#include <array>
+#include <sstream>
+#include <string>
+
+#include "base/logging.h"
+#include "components/viz/common/gpu/context_provider.h"
+#include "gpu/GLES2/gl2chromium.h"
+#include "gpu/GLES2/gl2extchromium.h"
+#include "third_party/skia/include/third_party/skcms/skcms.h"
+#include "ui/gfx/color_transform.h"
+#include "ui/gfx/geometry/rect_conversions.h"
+
+namespace viz {
+
+namespace {
+
+// The code in GLScaler that computes the ScalerStages is greatly simplified by
+// being able to access the X and Y components by index (instead of
+// Vector2d::x() or Vector2d::y()). Thus, define a helper class to represent the
+// relative size as a 2-element std::array and convert to/from Vector2d.
+struct RelativeSize : public std::array<int, 2> {
+  using std::array<int, 2>::operator[];
+
+  RelativeSize(int width, int height) : std::array<int, 2>{{width, height}} {}
+  explicit RelativeSize(const gfx::Vector2d& v)
+      : std::array<int, 2>{{v.x(), v.y()}} {}
+
+  gfx::Vector2d AsVector2d() const {
+    return gfx::Vector2d((*this)[0], (*this)[1]);
+  }
+};
+
+std::ostream& operator<<(std::ostream& out, const RelativeSize& size) {
+  return (out << size[0] << 'x' << size[1]);
+}
+
+}  // namespace
+
+GLScaler::GLScaler(ContextProvider* context_provider)
+    : context_provider_(context_provider) {
+  if (context_provider_) {
+    DCHECK(context_provider_->ContextGL());
+    context_provider_->AddObserver(this);
+  }
+}
+
+GLScaler::~GLScaler() {
+  OnContextLost();  // Ensures destruction in dependency order.
+}
+
+bool GLScaler::SupportsPreciseColorManagement() const {
+  if (!context_provider_) {
+    return false;
+  }
+  if (!supports_half_floats_.has_value()) {
+    supports_half_floats_ = AreAllGLExtensionsPresent(
+        context_provider_->ContextGL(),
+        {"GL_EXT_color_buffer_half_float", "GL_OES_texture_half_float_linear"});
+  }
+  return supports_half_floats_.value();
+}
+
+int GLScaler::GetMaxDrawBuffersSupported() const {
+  if (!context_provider_) {
+    return 0;
+  }
+
+  if (max_draw_buffers_ < 0) {
+    // Query the GL context for the multiple draw buffers extension and, if
+    // present, the actual platform-supported maximum.
+    GLES2Interface* const gl = context_provider_->ContextGL();
+    DCHECK(gl);
+    if (AreAllGLExtensionsPresent(gl, {"GL_EXT_draw_buffers"})) {
+      gl->GetIntegerv(GL_MAX_DRAW_BUFFERS_EXT, &max_draw_buffers_);
+    } else {
+      // The extension is not present & OpenGL ES 2.0 does not support
+      // glDrawBuffers function without it.
+      max_draw_buffers_ = 0;
+    }
+  }
+
+  return max_draw_buffers_;
+}
+
+bool GLScaler::Configure(const Parameters& new_params) {
+  chain_.reset();
+  shader_programs_.clear();
+
+  if (!context_provider_) {
+    return false;
+  }
+  GLES2Interface* const gl = context_provider_->ContextGL();
+  DCHECK(gl);
+
+  params_ = new_params;
+
+  // Ensure the client has provided valid scaling vectors.
+  if (params_.scale_from.x() == 0 || params_.scale_from.y() == 0 ||
+      params_.scale_to.x() == 0 || params_.scale_to.y() == 0) {
+    // The caller computed invalid scale_from and/or scale_to values.
+    DVLOG(1) << __func__ << ": Invalid scaling vectors: scale_from="
+             << params_.scale_from.ToString()
+             << ", scale_to=" << params_.scale_to.ToString();
+    return false;
+  }
+
+  // Resolve the color spaces according to the rules described in the header
+  // file.
+  if (!params_.source_color_space.IsValid()) {
+    params_.source_color_space = gfx::ColorSpace::CreateSRGB();
+  }
+  if (!params_.output_color_space.IsValid()) {
+    params_.output_color_space = params_.source_color_space;
+  }
+
+  // Check that 16-bit half floats are supported if precise color management is
+  // being requested.
+  if (params_.enable_precise_color_management) {
+    if (!SupportsPreciseColorManagement()) {
+      DVLOG(1) << __func__
+               << ": GL context does not support the half-floats "
+                  "required for precise color management.";
+      return false;
+    }
+  }
+
+  // Check that MRT support is available if certain export formats were
+  // specified in the Parameters.
+  if (params_.export_format == Parameters::ExportFormat::NV61 ||
+      params_.export_format ==
+          Parameters::ExportFormat::DEINTERLEAVE_PAIRWISE) {
+    if (GetMaxDrawBuffersSupported() < 2) {
+      DVLOG(1) << __func__ << ": GL context does not support 2+ draw buffers.";
+      return false;
+    }
+  }
+
+  // Color space transformation is meaningless when using the deinterleaver
+  // because it only deals with two color channels. This also means precise
+  // color management must be disabled.
+  if (params_.export_format ==
+          Parameters::ExportFormat::DEINTERLEAVE_PAIRWISE &&
+      (params_.source_color_space != params_.output_color_space ||
+       params_.enable_precise_color_management)) {
+    NOTIMPLEMENTED();
+    return false;
+  }
+
+  // Check that one of the two implemented output swizzles has been specified.
+  for (GLenum s : params_.swizzle) {
+    if (s != GL_RGBA && s != GL_BGRA_EXT) {
+      NOTIMPLEMENTED();
+      return false;
+    }
+  }
+
+  // Create the chain of ScalerStages. If the quality setting is FAST or there
+  // is no scaling to be done, just create a single stage.
+  std::unique_ptr<ScalerStage> chain;
+  if (params_.quality == Parameters::Quality::FAST ||
+      params_.scale_from == params_.scale_to) {
+    chain = std::make_unique<ScalerStage>(gl, Shader::BILINEAR, HORIZONTAL,
+                                          params_.scale_from, params_.scale_to);
+  } else if (params_.quality == Parameters::Quality::GOOD) {
+    chain = CreateAGoodScalingChain(gl, params_.scale_from, params_.scale_to);
+  } else if (params_.quality == Parameters::Quality::BEST) {
+    chain = CreateTheBestScalingChain(gl, params_.scale_from, params_.scale_to);
+  } else {
+    NOTREACHED();
+  }
+  chain = MaybeAppendExportStage(gl, std::move(chain), params_.export_format);
+
+  // Determine the color space and the data type of the pixels in the
+  // intermediate textures, depending on whether precise color management is
+  // enabled. Note that nothing special need be done here if no scaling will be
+  // performed.
+  GLenum intermediate_texture_type;
+  if (params_.enable_precise_color_management &&
+      params_.scale_from != params_.scale_to) {
+    // Ensure the scaling color space is using a linear transfer function.
+    constexpr auto kLinearFunction = std::make_tuple(1, 0, 1, 0, 0, 0, 1);
+    skcms_TransferFunction fn;
+    if (params_.source_color_space.GetTransferFunction(&fn) &&
+        std::make_tuple(fn.a, fn.b, fn.c, fn.d, fn.e, fn.f, fn.g) ==
+            kLinearFunction) {
+      scaling_color_space_ = params_.source_color_space;
+    } else {
+      // Use the source color space, but with a linear transfer function.
+      skcms_Matrix3x3 to_XYZD50;
+      params_.source_color_space.GetPrimaryMatrix(&to_XYZD50);
+      std::tie(fn.a, fn.b, fn.c, fn.d, fn.e, fn.f, fn.g) = kLinearFunction;
+      scaling_color_space_ = gfx::ColorSpace::CreateCustom(to_XYZD50, fn);
+    }
+    intermediate_texture_type = GL_HALF_FLOAT_OES;
+  } else {
+    scaling_color_space_ = params_.source_color_space;
+    intermediate_texture_type = GL_UNSIGNED_BYTE;
+  }
+
+  // Set the shader program on the final stage. Include color space
+  // transformation and swizzling, if necessary.
+  std::unique_ptr<gfx::ColorTransform> transform;
+  if (scaling_color_space_ != params_.output_color_space) {
+    transform = gfx::ColorTransform::NewColorTransform(
+        scaling_color_space_, params_.output_color_space);
+  }
+  ScalerStage* const final_stage = chain.get();
+  final_stage->set_shader_program(
+      GetShaderProgram(final_stage->shader(), intermediate_texture_type,
+                       transform.get(), params_.swizzle));
+
+  // Set the shader program on all prior stages. These stages are all operating
+  // in the same color space, |scaling_color_space_|.
+  static const GLenum kNoSwizzle[2] = {GL_RGBA, GL_RGBA};
+  ScalerStage* input_stage = final_stage;
+  while (input_stage->input_stage()) {
+    input_stage = input_stage->input_stage();
+    input_stage->set_shader_program(GetShaderProgram(
+        input_stage->shader(), intermediate_texture_type, nullptr, kNoSwizzle));
+  }
+  // From this point, |input_stage| points to the first ScalerStage (i.e., the
+  // one that will be reading from the source).
+
+  // If necessary, prepend an extra "import stage" that color-converts the input
+  // before any scaling occurs. It's important not to merge color space
+  // conversion of the source with any other steps because the texture sampler
+  // must not linearly interpolate until after the colors have been mapped to a
+  // linear color space.
+  if (params_.source_color_space != scaling_color_space_) {
+    input_stage->set_input_stage(std::make_unique<ScalerStage>(
+        gl, Shader::BILINEAR, HORIZONTAL, input_stage->scale_from(),
+        input_stage->scale_from()));
+    input_stage = input_stage->input_stage();
+    transform = gfx::ColorTransform::NewColorTransform(
+        params_.source_color_space, scaling_color_space_);
+    input_stage->set_shader_program(
+        GetShaderProgram(input_stage->shader(), intermediate_texture_type,
+                         transform.get(), kNoSwizzle));
+  }
+
+  // If the source content is Y-flipped, the input scaler stage will perform
+  // math to account for this. It also will flip the content during scaling so
+  // that all following stages may assume the content is not flipped. Then, the
+  // final stage must ensure the final output is correctly flipped-back (or not)
+  // based on what the first stage did PLUS what is being requested by the
+  // client code.
+  if (params_.is_flipped_source) {
+    input_stage->set_is_flipped_source(true);
+    input_stage->set_flip_output(true);
+  }
+  if (input_stage->flip_output() != params_.flip_output) {
+    final_stage->set_flip_output(!final_stage->flip_output());
+  }
+
+  chain_ = std::move(chain);
+  VLOG(2) << __func__ << " built this: " << *this;
+  return true;
+}
+
+bool GLScaler::ScaleToMultipleOutputs(GLuint src_texture,
+                                      const gfx::Size& src_texture_size,
+                                      const gfx::Vector2d& src_offset,
+                                      GLuint dest_texture_0,
+                                      GLuint dest_texture_1,
+                                      const gfx::Rect& output_rect) {
+  if (!chain_) {
+    return false;
+  }
+
+  // Bind the vertex attributes used to sweep the entire source area when
+  // executing the shader programs.
+  GLES2Interface* const gl = context_provider_->ContextGL();
+  DCHECK(gl);
+  if (vertex_attributes_buffer_) {
+    gl->BindBuffer(GL_ARRAY_BUFFER, vertex_attributes_buffer_);
+  } else {
+    gl->GenBuffers(1, &vertex_attributes_buffer_);
+    gl->BindBuffer(GL_ARRAY_BUFFER, vertex_attributes_buffer_);
+    gl->BufferData(GL_ARRAY_BUFFER, sizeof(ShaderProgram::kVertexAttributes),
+                   ShaderProgram::kVertexAttributes, GL_STATIC_DRAW);
+  }
+
+  // Disable GL clipping/blending features that interfere with assumptions made
+  // by the implementation. Only those known to possibly be enabled elsewhere in
+  // Chromium code are disabled here, while the remainder are sanity-DCHECK'ed.
+  gl->Disable(GL_SCISSOR_TEST);
+  gl->Disable(GL_STENCIL_TEST);
+  gl->Disable(GL_BLEND);
+  DCHECK_NE(gl->IsEnabled(GL_CULL_FACE), GL_TRUE);
+  DCHECK_NE(gl->IsEnabled(GL_DEPTH_TEST), GL_TRUE);
+  DCHECK_NE(gl->IsEnabled(GL_POLYGON_OFFSET_FILL), GL_TRUE);
+  DCHECK_NE(gl->IsEnabled(GL_SAMPLE_ALPHA_TO_COVERAGE), GL_TRUE);
+  DCHECK_NE(gl->IsEnabled(GL_SAMPLE_COVERAGE), GL_TRUE);
+  DCHECK_NE(gl->IsEnabled(GL_SCISSOR_TEST), GL_TRUE);
+  DCHECK_NE(gl->IsEnabled(GL_STENCIL_TEST), GL_TRUE);
+
+  chain_->ScaleToMultipleOutputs(src_texture, src_texture_size, src_offset,
+                                 dest_texture_0, dest_texture_1, output_rect);
+
+  gl->BindBuffer(GL_ARRAY_BUFFER, 0);
+  return true;
+}
+
+// static
+bool GLScaler::ParametersHasSameScaleRatio(const GLScaler::Parameters& params,
+                                           const gfx::Vector2d& from,
+                                           const gfx::Vector2d& to) {
+  // Returns true iff a_num/a_denom == b_num/b_denom.
+  const auto AreRatiosEqual = [](int32_t a_num, int32_t a_denom, int32_t b_num,
+                                 int32_t b_denom) -> bool {
+    // The math (for each dimension):
+    //   If: a_num/a_denom == b_num/b_denom
+    //   Then: a_num*b_denom == b_num*a_denom
+    //
+    // ...and cast to int64_t to guarantee no overflow from the multiplications.
+    return (static_cast<int64_t>(a_num) * b_denom) ==
+           (static_cast<int64_t>(b_num) * a_denom);
+  };
+
+  return AreRatiosEqual(params.scale_from.x(), params.scale_to.x(), from.x(),
+                        to.x()) &&
+         AreRatiosEqual(params.scale_from.y(), params.scale_to.y(), from.y(),
+                        to.y());
+}
+
+// static
+bool GLScaler::ParametersAreEquivalent(const Parameters& a,
+                                       const Parameters& b) {
+  if (!ParametersHasSameScaleRatio(a, b.scale_from, b.scale_to) ||
+      a.enable_precise_color_management != b.enable_precise_color_management ||
+      a.quality != b.quality || a.is_flipped_source != b.is_flipped_source ||
+      a.flip_output != b.flip_output || a.export_format != b.export_format ||
+      a.swizzle[0] != b.swizzle[0] || a.swizzle[1] != b.swizzle[1]) {
+    return false;
+  }
+
+  const gfx::ColorSpace source_color_space_a =
+      a.source_color_space.IsValid() ? a.source_color_space
+                                     : gfx::ColorSpace::CreateSRGB();
+  const gfx::ColorSpace source_color_space_b =
+      b.source_color_space.IsValid() ? b.source_color_space
+                                     : gfx::ColorSpace::CreateSRGB();
+  if (source_color_space_a != source_color_space_b) {
+    return false;
+  }
+
+  const gfx::ColorSpace output_color_space_a = a.output_color_space.IsValid()
+                                                   ? a.output_color_space
+                                                   : source_color_space_a;
+  const gfx::ColorSpace output_color_space_b = b.output_color_space.IsValid()
+                                                   ? b.output_color_space
+                                                   : source_color_space_b;
+  return output_color_space_a == output_color_space_b;
+}
+
+void GLScaler::OnContextLost() {
+  // The destruction order here is important due to data dependencies.
+  chain_.reset();
+  shader_programs_.clear();
+  if (vertex_attributes_buffer_) {
+    if (auto* gl = context_provider_->ContextGL()) {
+      gl->DeleteBuffers(1, &vertex_attributes_buffer_);
+    }
+    vertex_attributes_buffer_ = 0;
+  }
+  if (context_provider_) {
+    context_provider_->RemoveObserver(this);
+    context_provider_ = nullptr;
+  }
+}
+
+GLScaler::ShaderProgram* GLScaler::GetShaderProgram(
+    Shader shader,
+    GLenum texture_type,
+    const gfx::ColorTransform* color_transform,
+    const GLenum swizzle[2]) {
+  const ShaderCacheKey key{
+      shader,
+      texture_type,
+      color_transform ? color_transform->GetSrcColorSpace() : gfx::ColorSpace(),
+      color_transform ? color_transform->GetDstColorSpace() : gfx::ColorSpace(),
+      swizzle[0],
+      swizzle[1]};
+  auto it = shader_programs_.find(key);
+  if (it == shader_programs_.end()) {
+    GLES2Interface* const gl = context_provider_->ContextGL();
+    DCHECK(gl);
+    it = shader_programs_
+             .emplace(std::piecewise_construct, std::forward_as_tuple(key),
+                      std::forward_as_tuple(gl, shader, texture_type,
+                                            color_transform, swizzle))
+             .first;
+  }
+  return &it->second;
+}
+
+// static
+std::unique_ptr<GLScaler::ScalerStage> GLScaler::CreateAGoodScalingChain(
+    gpu::gles2::GLES2Interface* gl,
+    const gfx::Vector2d& scale_from,
+    const gfx::Vector2d& scale_to) {
+  DCHECK(scale_from.x() != 0 && scale_from.y() != 0)
+      << "Bad scale_from: " << scale_from.ToString();
+  DCHECK(scale_to.x() != 0 && scale_to.y() != 0)
+      << "Bad scale_to: " << scale_to.ToString();
+  DCHECK(scale_from != scale_to);
+
+  // The GOOD quality chain performs one bilinear upscale followed by N bilinear
+  // halvings, and does this is both directions. Exception: No upscale is needed
+  // when |scale_from| is a power of two multiple of |scale_to|.
+  //
+  // Since all shaders use bilinear filtering, the heuristics below attempt to
+  // greedily merge steps wherever possible to minimize GPU memory usage and
+  // processing time. This also means that it will be extremely rare for the
+  // stage doing the initial upscale to actually require a larger output texture
+  // than the source texture (a downscale will be merged into the same stage).
+
+  // Determine the initial upscaled-to size, as the minimum number of doublings
+  // to make |scale_to| greater than |scale_from|.
+  const RelativeSize from(scale_from);
+  const RelativeSize to(scale_to);
+  RelativeSize upscale_to = to;
+  for (Axis x_or_y : std::array<Axis, 2>{HORIZONTAL, VERTICAL}) {
+    while (upscale_to[x_or_y] < from[x_or_y]) {
+      upscale_to[x_or_y] *= 2;
+    }
+  }
+
+  // Create the stages in order from first-to-last, taking the greediest path
+  // each time. Something like an A* algorithm would be better for discovering
+  // an optimal sequence of operations, and would allow using the BILINEAR3
+  // shader as well, but the run-time performance to compute the stages would be
+  // too prohibitive.
+  std::unique_ptr<ScalerStage> chain;
+  struct CandidateOp {
+    Shader shader;
+    Axis primary_axis;
+    RelativeSize output_size;
+  };
+  std::vector<CandidateOp> candidates;
+  for (RelativeSize cur = from; cur != to;
+       cur = RelativeSize(chain->scale_to())) {
+    candidates.clear();
+
+    // Determine whether it's possible to do exactly 2 bilinear passes in both
+    // directions.
+    RelativeSize output_size_2x2 = {0, 0};
+    for (Axis x_or_y : std::array<Axis, 2>{VERTICAL, HORIZONTAL}) {
+      if (cur[x_or_y] == from[x_or_y]) {
+        // For the first stage, the 2 bilinear passes must be the initial
+        // upscale followed by one downscale. If there is no initial upscale,
+        // then the 2 passes must both be downscales.
+        if (upscale_to[x_or_y] != from[x_or_y] &&
+            upscale_to[x_or_y] / 2 >= to[x_or_y]) {
+          output_size_2x2[x_or_y] = upscale_to[x_or_y] / 2;
+        } else if (upscale_to[x_or_y] == from[x_or_y] &&
+                   upscale_to[x_or_y] / 4 >= to[x_or_y]) {
+          output_size_2x2[x_or_y] = cur[x_or_y] / 4;
+        }
+      } else {
+        // For all later stages, the 2 bilinear passes must be 2 halvings.
+        if (cur[x_or_y] / 4 >= to[x_or_y]) {
+          output_size_2x2[x_or_y] = cur[x_or_y] / 4;
+        }
+      }
+    }
+    if (output_size_2x2[HORIZONTAL] != 0 && output_size_2x2[VERTICAL] != 0) {
+      candidates.push_back(
+          CandidateOp{Shader::BILINEAR2X2, HORIZONTAL, output_size_2x2});
+    }
+
+    // Determine the valid set of Ops that do 1 to 3 bilinear passes in one
+    // direction and 0 or 1 pass in the other direction.
+    for (Axis x_or_y : std::array<Axis, 2>{VERTICAL, HORIZONTAL}) {
+      // The first bilinear pass in x_or_y must be an upscale or a halving.
+      Shader shader = Shader::BILINEAR;
+      RelativeSize output_size = cur;
+      if (cur[x_or_y] == from[x_or_y] && upscale_to[x_or_y] != from[x_or_y]) {
+        output_size[x_or_y] = upscale_to[x_or_y];
+      } else if (cur[x_or_y] / 2 >= to[x_or_y]) {
+        output_size[x_or_y] /= 2;
+      } else {
+        DCHECK_EQ(cur[x_or_y], to[x_or_y]);
+        continue;
+      }
+
+      // Determine whether 1 or 2 additional passes can be made in the same
+      // direction.
+      if (output_size[x_or_y] / 4 >= to[x_or_y]) {
+        shader = Shader::BILINEAR4;  // 2 more passes == 3 total.
+        output_size[x_or_y] /= 4;
+      } else if (output_size[x_or_y] / 2 >= to[x_or_y]) {
+        shader = Shader::BILINEAR2;  // 1 more pass == 2 total.
+        output_size[x_or_y] /= 2;
+      } else {
+        DCHECK_EQ(output_size[x_or_y], to[x_or_y]);
+      }
+
+      // Determine whether 0 or 1 bilinear passes can be made in the other
+      // direction at the same time.
+      const Axis y_or_x = TheOtherAxis(x_or_y);
+      if (cur[y_or_x] == from[y_or_x] && upscale_to[y_or_x] != from[y_or_x]) {
+        output_size[y_or_x] = upscale_to[y_or_x];
+      } else if (cur[y_or_x] / 2 >= to[y_or_x]) {
+        output_size[y_or_x] /= 2;
+      } else {
+        DCHECK_EQ(cur[y_or_x], to[y_or_x]);
+      }
+
+      candidates.push_back(CandidateOp{shader, x_or_y, output_size});
+    }
+
+    // From the candidates, pick the one that produces the fewest number of
+    // output pixels, and append a new ScalerStage. There are opportunities to
+    // improve the "cost function" here (e.g., pixels in the Y direction
+    // probably cost more to process than pixels in the X direction), but that
+    // would require more research.
+    const auto best_candidate = std::min_element(
+        candidates.begin(), candidates.end(),
+        [](const CandidateOp& a, const CandidateOp& b) {
+          static_assert(sizeof(a.output_size[0]) <= sizeof(int32_t),
+                        "Overflow issue in the math here.");
+          const int64_t cost_of_a =
+              int64_t{a.output_size[HORIZONTAL]} * a.output_size[VERTICAL];
+          const int64_t cost_of_b =
+              int64_t{b.output_size[HORIZONTAL]} * b.output_size[VERTICAL];
+          return cost_of_a < cost_of_b;
+        });
+    DCHECK(best_candidate != candidates.end());
+    DCHECK(cur != best_candidate->output_size)
+        << "Best candidate's output size (" << best_candidate->output_size
+        << ") should not equal the input size.";
+    auto next_stage = std::make_unique<ScalerStage>(
+        gl, best_candidate->shader, best_candidate->primary_axis,
+        cur.AsVector2d(), best_candidate->output_size.AsVector2d());
+    next_stage->set_input_stage(std::move(chain));
+    chain = std::move(next_stage);
+  }
+
+  return chain;
+}
+
+// static
+std::unique_ptr<GLScaler::ScalerStage> GLScaler::CreateTheBestScalingChain(
+    gpu::gles2::GLES2Interface* gl,
+    const gfx::Vector2d& scale_from,
+    const gfx::Vector2d& scale_to) {
+  // The BEST quality chain performs one bicubic upscale followed by N bicubic
+  // halvings, and does this is both directions. Exception: No upscale is needed
+  // when |scale_from| is a power of two multiple of |scale_to|.
+
+  // Determine the initial upscaled-to size, as the minimum number of doublings
+  // to make |scale_to| greater than |scale_from|.
+  const RelativeSize from(scale_from);
+  const RelativeSize to(scale_to);
+  RelativeSize upscale_to = to;
+  for (Axis x_or_y : std::array<Axis, 2>{HORIZONTAL, VERTICAL}) {
+    while (upscale_to[x_or_y] < from[x_or_y]) {
+      upscale_to[x_or_y] *= 2;
+    }
+  }
+
+  // Create the stages in order from first-to-last.
+  RelativeSize cur = from;
+  std::unique_ptr<ScalerStage> chain;
+  for (Axis x_or_y : std::array<Axis, 2>{VERTICAL, HORIZONTAL}) {
+    if (upscale_to[x_or_y] != from[x_or_y]) {
+      RelativeSize next = cur;
+      next[x_or_y] = upscale_to[x_or_y];
+      auto upscale_stage =
+          std::make_unique<ScalerStage>(gl, Shader::BICUBIC_UPSCALE, x_or_y,
+                                        cur.AsVector2d(), next.AsVector2d());
+      upscale_stage->set_input_stage(std::move(chain));
+      chain = std::move(upscale_stage);
+      cur = next;
+    }
+    while (cur[x_or_y] > to[x_or_y]) {
+      RelativeSize next = cur;
+      next[x_or_y] /= 2;
+      auto next_stage =
+          std::make_unique<ScalerStage>(gl, Shader::BICUBIC_HALF_1D, x_or_y,
+                                        cur.AsVector2d(), next.AsVector2d());
+      next_stage->set_input_stage(std::move(chain));
+      chain = std::move(next_stage);
+      cur = next;
+    }
+  }
+  DCHECK_EQ(cur, to);
+
+  return chain;
+}
+
+// static
+std::unique_ptr<GLScaler::ScalerStage> GLScaler::MaybeAppendExportStage(
+    gpu::gles2::GLES2Interface* gl,
+    std::unique_ptr<GLScaler::ScalerStage> chain,
+    GLScaler::Parameters::ExportFormat export_format) {
+  DCHECK(chain);
+
+  if (export_format == Parameters::ExportFormat::INTERLEAVED_QUADS) {
+    return chain;  // No format change.
+  }
+
+  // If the final stage uses the BILINEAR shader that is not upscaling, the
+  // export stage can replace it with no change in the results. Otherwise, a
+  // separate export stage will be appended.
+  gfx::Vector2d scale_from = chain->scale_from();
+  const gfx::Vector2d scale_to = chain->scale_to();
+  if (chain->shader() == Shader::BILINEAR && scale_from.x() >= scale_to.x() &&
+      scale_from.y() >= scale_to.y()) {
+    chain = chain->take_input_stage();
+  } else {
+    scale_from = scale_to;
+  }
+
+  Shader shader = Shader::BILINEAR;
+  scale_from.set_x(scale_from.x() * 4);
+  switch (export_format) {
+    case Parameters::ExportFormat::INTERLEAVED_QUADS:
+      NOTREACHED();
+      break;
+    case Parameters::ExportFormat::CHANNEL_0:
+      shader = Shader::PLANAR_CHANNEL_0;
+      break;
+    case Parameters::ExportFormat::CHANNEL_1:
+      shader = Shader::PLANAR_CHANNEL_1;
+      break;
+    case Parameters::ExportFormat::CHANNEL_2:
+      shader = Shader::PLANAR_CHANNEL_2;
+      break;
+    case Parameters::ExportFormat::CHANNEL_3:
+      shader = Shader::PLANAR_CHANNEL_3;
+      break;
+    case Parameters::ExportFormat::NV61:
+      shader = Shader::I422_NV61_MRT;
+      break;
+    case Parameters::ExportFormat::DEINTERLEAVE_PAIRWISE:
+      shader = Shader::DEINTERLEAVE_PAIRWISE_MRT;
+      // Horizontal scale is only 0.5X, not 0.25X like all the others.
+      scale_from.set_x(scale_from.x() / 2);
+      break;
+    case Parameters::ExportFormat::UV_CHANNELS:
+      shader = Shader::PLANAR_CHANNELS_1_2;
+      break;
+  }
+
+  auto export_stage = std::make_unique<ScalerStage>(gl, shader, HORIZONTAL,
+                                                    scale_from, scale_to);
+  export_stage->set_input_stage(std::move(chain));
+  return export_stage;
+}
+
+// static
+GLScaler::Axis GLScaler::TheOtherAxis(GLScaler::Axis x_or_y) {
+  return x_or_y == HORIZONTAL ? VERTICAL : HORIZONTAL;
+}
+
+// static
+const char* GLScaler::GetShaderName(GLScaler::Shader shader) {
+  switch (shader) {
+#define CASE_RETURN_SHADER_STR(x) \
+  case Shader::x:                 \
+    return #x
+    CASE_RETURN_SHADER_STR(BILINEAR);
+    CASE_RETURN_SHADER_STR(BILINEAR2);
+    CASE_RETURN_SHADER_STR(BILINEAR3);
+    CASE_RETURN_SHADER_STR(BILINEAR4);
+    CASE_RETURN_SHADER_STR(BILINEAR2X2);
+    CASE_RETURN_SHADER_STR(BICUBIC_UPSCALE);
+    CASE_RETURN_SHADER_STR(BICUBIC_HALF_1D);
+    CASE_RETURN_SHADER_STR(PLANAR_CHANNEL_0);
+    CASE_RETURN_SHADER_STR(PLANAR_CHANNEL_1);
+    CASE_RETURN_SHADER_STR(PLANAR_CHANNEL_2);
+    CASE_RETURN_SHADER_STR(PLANAR_CHANNEL_3);
+    CASE_RETURN_SHADER_STR(I422_NV61_MRT);
+    CASE_RETURN_SHADER_STR(DEINTERLEAVE_PAIRWISE_MRT);
+    CASE_RETURN_SHADER_STR(PLANAR_CHANNELS_1_2);
+#undef CASE_RETURN_SHADER_STR
+  }
+}
+
+// static
+bool GLScaler::AreAllGLExtensionsPresent(
+    gpu::gles2::GLES2Interface* gl,
+    const std::vector<std::string>& names) {
+  DCHECK(gl);
+  if (const auto* extensions = gl->GetString(GL_EXTENSIONS)) {
+    const std::string extensions_string =
+        " " + std::string(reinterpret_cast<const char*>(extensions)) + " ";
+    for (const std::string& name : names) {
+      if (extensions_string.find(" " + name + " ") == std::string::npos) {
+        return false;
+      }
+    }
+    return true;
+  }
+  return false;
+}
+
+GLScaler::Parameters::Parameters() = default;
+GLScaler::Parameters::Parameters(const Parameters& other) = default;
+GLScaler::Parameters::~Parameters() = default;
+
+// static
+const GLfloat GLScaler::ShaderProgram::kVertexAttributes[16] = {
+    -1.0f, -1.0f, 0.0f, 0.0f,  // vertex 0
+    1.0f,  -1.0f, 1.0f, 0.0f,  // vertex 1
+    -1.0f, 1.0f,  0.0f, 1.0f,  // vertex 2
+    1.0f,  1.0f,  1.0f, 1.0f,  // vertex 3
+};
+
+GLScaler::ShaderProgram::ShaderProgram(
+    gpu::gles2::GLES2Interface* gl,
+    GLScaler::Shader shader,
+    GLenum texture_type,
+    const gfx::ColorTransform* color_transform,
+    const GLenum swizzle[2])
+    : gl_(gl),
+      shader_(shader),
+      texture_type_(texture_type),
+      program_(gl_->CreateProgram()) {
+  DCHECK(program_);
+
+  std::basic_ostringstream<GLchar> vertex_header;
+  std::basic_ostringstream<GLchar> fragment_directives;
+  std::basic_ostringstream<GLchar> fragment_header;
+  std::basic_ostringstream<GLchar> shared_variables;
+  std::basic_ostringstream<GLchar> vertex_main;
+  std::basic_ostringstream<GLchar> fragment_main;
+
+  vertex_header
+      << ("precision highp float;\n"
+          "attribute vec2 a_position;\n"
+          "attribute vec2 a_texcoord;\n"
+          "uniform vec4 src_rect;\n");
+
+  fragment_header << "precision mediump float;\n";
+  switch (texture_type_) {
+    case GL_FLOAT:
+      fragment_header << "precision highp sampler2D;\n";
+      break;
+    case GL_HALF_FLOAT_OES:
+      fragment_header << "precision mediump sampler2D;\n";
+      break;
+    default:
+      fragment_header << "precision lowp sampler2D;\n";
+      break;
+  }
+  fragment_header << "uniform sampler2D s_texture;\n";
+
+  if (color_transform && shader_ != Shader::PLANAR_CHANNEL_3) {
+    const std::string& source = color_transform->GetShaderSource();
+    // Assumption: gfx::ColorTransform::GetShaderSource() should provide a
+    // function named DoColorConversion() that takes a vec3 argument and returns
+    // a vec3.
+    DCHECK_NE(source.find("DoColorConversion"), std::string::npos);
+    fragment_header << source;
+  }
+
+  vertex_main
+      << ("  gl_Position = vec4(a_position, 0.0, 1.0);\n"
+          "  vec2 texcoord = src_rect.xy + a_texcoord * src_rect.zw;\n");
+
+  switch (shader_) {
+    case Shader::BILINEAR:
+      shared_variables << "varying highp vec2 v_texcoord;\n";
+      vertex_main << "  v_texcoord = texcoord;\n";
+      fragment_main << "  vec4 sample = texture2D(s_texture, v_texcoord);\n";
+      if (color_transform) {
+        fragment_main << "  sample.rgb = DoColorConversion(sample.rgb);\n";
+      }
+      if (swizzle[0] == GL_BGRA_EXT) {
+        fragment_main << "  sample.rb = sample.br;\n";
+      }
+      fragment_main << "  gl_FragColor = sample;\n";
+      break;
+
+    case Shader::BILINEAR2:
+      // This is equivialent to two passes of the BILINEAR shader above. It can
+      // be used to scale an image down 1.0x-2.0x in either dimension, or
+      // exactly 4x.
+      shared_variables << "varying highp vec4 v_texcoords;\n";
+      vertex_header << "uniform vec2 scaling_vector;\n";
+      vertex_main
+          << ("  vec2 step = scaling_vector / 4.0;\n"
+              "  v_texcoords.xy = texcoord + step;\n"
+              "  v_texcoords.zw = texcoord - step;\n");
+      fragment_main
+          << ("  vec4 blended = (texture2D(s_texture, v_texcoords.xy) +\n"
+              "                  texture2D(s_texture, v_texcoords.zw)) /\n"
+              "                 2.0;\n");
+      if (color_transform) {
+        fragment_main << "  blended.rgb = DoColorConversion(blended.rgb);\n";
+      }
+      if (swizzle[0] == GL_BGRA_EXT) {
+        fragment_main << "  blended.rb = blended.br;\n";
+      }
+      fragment_main << "  gl_FragColor = blended;\n";
+      break;
+
+    case Shader::BILINEAR3:
+      // This is kind of like doing 1.5 passes of the BILINEAR shader. It can be
+      // used to scale an image down 1.5x-3.0x, or exactly 6x.
+      shared_variables
+          << ("varying highp vec4 v_texcoords0;\n"
+              "varying highp vec2 v_texcoords1;\n");
+      vertex_header << "uniform vec2 scaling_vector;\n";
+      vertex_main
+          << ("  vec2 step = scaling_vector / 3.0;\n"
+              "  v_texcoords0.xy = texcoord + step;\n"
+              "  v_texcoords0.zw = texcoord;\n"
+              "  v_texcoords1 = texcoord - step;\n");
+      fragment_main
+          << ("  vec4 blended = (texture2D(s_texture, v_texcoords0.xy) +\n"
+              "                  texture2D(s_texture, v_texcoords0.zw) +\n"
+              "                  texture2D(s_texture, v_texcoords1)) / 3.0;\n");
+      if (color_transform) {
+        fragment_main << "  blended.rgb = DoColorConversion(blended.rgb);\n";
+      }
+      if (swizzle[0] == GL_BGRA_EXT) {
+        fragment_main << "  blended.rb = blended.br;\n";
+      }
+      fragment_main << "  gl_FragColor = blended;\n";
+      break;
+
+    case Shader::BILINEAR4:
+      // This is equivialent to three passes of the BILINEAR shader above. It
+      // can be used to scale an image down 2.0x-4.0x or exactly 8x.
+      shared_variables << "varying highp vec4 v_texcoords[2];\n";
+      vertex_header << "uniform vec2 scaling_vector;\n";
+      vertex_main
+          << ("  vec2 step = scaling_vector / 8.0;\n"
+              "  v_texcoords[0].xy = texcoord - step * 3.0;\n"
+              "  v_texcoords[0].zw = texcoord - step;\n"
+              "  v_texcoords[1].xy = texcoord + step;\n"
+              "  v_texcoords[1].zw = texcoord + step * 3.0;\n");
+      fragment_main
+          << ("  vec4 blended = (\n"
+              "      texture2D(s_texture, v_texcoords[0].xy) +\n"
+              "      texture2D(s_texture, v_texcoords[0].zw) +\n"
+              "      texture2D(s_texture, v_texcoords[1].xy) +\n"
+              "      texture2D(s_texture, v_texcoords[1].zw)) / 4.0;\n");
+      if (color_transform) {
+        fragment_main << "  blended.rgb = DoColorConversion(blended.rgb);\n";
+      }
+      if (swizzle[0] == GL_BGRA_EXT) {
+        fragment_main << "  blended.rb = blended.br;\n";
+      }
+      fragment_main << "  gl_FragColor = blended;\n";
+      break;
+
+    case Shader::BILINEAR2X2:
+      // This is equivialent to four passes of the BILINEAR shader above, two in
+      // each dimension. It can be used to scale an image down 1.0x-2.0x in both
+      // X and Y directions. Or, it could be used to scale an image down by
+      // exactly 4x in both dimensions.
+      shared_variables << "varying highp vec4 v_texcoords[2];\n";
+      vertex_header << "uniform vec2 scaling_vector;\n";
+      vertex_main
+          << ("  vec2 step = scaling_vector / 4.0;\n"
+              "  v_texcoords[0].xy = texcoord + vec2(step.x, step.y);\n"
+              "  v_texcoords[0].zw = texcoord + vec2(step.x, -step.y);\n"
+              "  v_texcoords[1].xy = texcoord + vec2(-step.x, step.y);\n"
+              "  v_texcoords[1].zw = texcoord + vec2(-step.x, -step.y);\n");
+      fragment_main
+          << ("  vec4 blended = (\n"
+              "      texture2D(s_texture, v_texcoords[0].xy) +\n"
+              "      texture2D(s_texture, v_texcoords[0].zw) +\n"
+              "      texture2D(s_texture, v_texcoords[1].xy) +\n"
+              "      texture2D(s_texture, v_texcoords[1].zw)) / 4.0;\n");
+      if (color_transform) {
+        fragment_main << "  blended.rgb = DoColorConversion(blended.rgb);\n";
+      }
+      if (swizzle[0] == GL_BGRA_EXT) {
+        fragment_main << "  blended.rb = blended.br;\n";
+      }
+      fragment_main << "  gl_FragColor = blended;\n";
+      break;
+
+    case Shader::BICUBIC_UPSCALE:
+      // When scaling up, 4 texture reads are necessary. However, some
+      // instructions can be saved because the parameter passed to the bicubic
+      // function will be in a known range. Also, when sampling the bicubic
+      // function like this, the sum is always exactly one, so normalization can
+      // be skipped as well.
+      shared_variables << "varying highp vec2 v_texcoord;\n";
+      vertex_main << "  v_texcoord = texcoord;\n";
+      fragment_header
+          << ("uniform highp vec2 src_pixelsize;\n"
+              "uniform highp vec2 scaling_vector;\n"
+              "const float a = -0.5;\n"
+              // This function is equivialent to calling the bicubic
+              // function with x-1, x, 1-x and 2-x (assuming
+              // 0 <= x < 1). The following is the Catmull-Rom spline.
+              // See: http://wikipedia.org/wiki/Cubic_Hermite_spline
+              "vec4 filt4(float x) {\n"
+              "  return vec4(x * x * x, x * x, x, 1) *\n"
+              "         mat4(       a,      -2.0 * a,   a, 0.0,\n"
+              "               a + 2.0,      -a - 3.0, 0.0, 1.0,\n"
+              "              -a - 2.0, 3.0 + 2.0 * a,  -a, 0.0,\n"
+              "                    -a,             a, 0.0, 0.0);\n"
+              "}\n"
+              "mat4 pixels_x(highp vec2 pos, highp vec2 step) {\n"
+              "  return mat4(texture2D(s_texture, pos - step),\n"
+              "              texture2D(s_texture, pos),\n"
+              "              texture2D(s_texture, pos + step),\n"
+              "              texture2D(s_texture, pos + step * 2.0));\n"
+              "}\n");
+      fragment_main
+          << ("  highp vec2 pixel_pos = v_texcoord * src_pixelsize - \n"
+              "      scaling_vector / 2.0;\n"
+              "  highp float frac = fract(dot(pixel_pos, scaling_vector));\n"
+              "  highp vec2 base = \n"
+              "      (floor(pixel_pos) + vec2(0.5)) / src_pixelsize;\n"
+              "  highp vec2 step = scaling_vector / src_pixelsize;\n"
+              "  vec4 blended = pixels_x(base, step) * filt4(frac);\n");
+      if (color_transform) {
+        fragment_main << "  blended.rgb = DoColorConversion(blended.rgb);\n";
+      }
+      if (swizzle[0] == GL_BGRA_EXT) {
+        fragment_main << "  blended.rb = blended.br;\n";
+      }
+      fragment_main << "  gl_FragColor = blended;\n";
+      break;
+
+    case Shader::BICUBIC_HALF_1D:
+      // This scales down an image by exactly half in one dimension. The
+      // bilinear lookup reduces the number of texture reads from 8 to 4.
+      shared_variables << "varying highp vec4 v_texcoords[2];\n";
+      vertex_header
+          << ("uniform vec2 scaling_vector;\n"
+              "const float CenterDist = 99.0 / 140.0;\n"
+              "const float LobeDist = 11.0 / 4.0;\n");
+      vertex_main
+          << ("  vec2 step = scaling_vector / 2.0;\n"
+              "  v_texcoords[0].xy = texcoord - LobeDist * step;\n"
+              "  v_texcoords[0].zw = texcoord - CenterDist * step;\n"
+              "  v_texcoords[1].xy = texcoord + CenterDist * step;\n"
+              "  v_texcoords[1].zw = texcoord + LobeDist * step;\n");
+      fragment_header
+          << ("const float CenterWeight = 35.0 / 64.0;\n"
+              "const float LobeWeight = -3.0 / 64.0;\n");
+      fragment_main
+          << ("  vec4 blended = \n"
+              // Lobe pixels
+              "      (texture2D(s_texture, v_texcoords[0].xy) +\n"
+              "       texture2D(s_texture, v_texcoords[1].zw)) *\n"
+              "          LobeWeight +\n"
+              // Center pixels
+              "      (texture2D(s_texture, v_texcoords[0].zw) +\n"
+              "       texture2D(s_texture, v_texcoords[1].xy)) *\n"
+              "          CenterWeight;\n");
+      if (color_transform) {
+        fragment_main << "  blended.rgb = DoColorConversion(blended.rgb);\n";
+      }
+      if (swizzle[0] == GL_BGRA_EXT) {
+        fragment_main << "  blended.rb = blended.br;\n";
+      }
+      fragment_main << "  gl_FragColor = blended;\n";
+      break;
+
+    case Shader::PLANAR_CHANNEL_0:
+    case Shader::PLANAR_CHANNEL_1:
+    case Shader::PLANAR_CHANNEL_2:
+    case Shader::PLANAR_CHANNEL_3: {
+      // Select one color channel, and pack 4 pixels into one output quad. See
+      // header file for diagram.
+      shared_variables << "varying highp vec4 v_texcoords[2];\n";
+      vertex_header << "uniform vec2 scaling_vector;\n";
+      vertex_main
+          << ("  vec2 step = scaling_vector / 4.0;\n"
+              "  v_texcoords[0].xy = texcoord - step * 1.5;\n"
+              "  v_texcoords[0].zw = texcoord - step * 0.5;\n"
+              "  v_texcoords[1].xy = texcoord + step * 0.5;\n"
+              "  v_texcoords[1].zw = texcoord + step * 1.5;\n");
+      std::basic_string<GLchar> convert_open;
+      std::basic_string<GLchar> convert_close;
+      if (color_transform && shader_ != Shader::PLANAR_CHANNEL_3) {
+        convert_open = "DoColorConversion(";
+        convert_close = ".rgb)";
+      }
+      const char selector = "rgba"[static_cast<int>(shader_) -
+                                   static_cast<int>(Shader::PLANAR_CHANNEL_0)];
+      fragment_main << "  vec4 packed_quad = vec4(\n"
+                    << "      " << convert_open
+                    << "texture2D(s_texture, v_texcoords[0].xy)"
+                    << convert_close << '.' << selector << ",\n"
+                    << "      " << convert_open
+                    << "texture2D(s_texture, v_texcoords[0].zw)"
+                    << convert_close << '.' << selector << ",\n"
+                    << "      " << convert_open
+                    << "texture2D(s_texture, v_texcoords[1].xy)"
+                    << convert_close << '.' << selector << ",\n"
+                    << "      " << convert_open
+                    << "texture2D(s_texture, v_texcoords[1].zw)"
+                    << convert_close << '.' << selector << ");\n";
+      if (swizzle[0] == GL_BGRA_EXT) {
+        fragment_main << "  packed_quad.rb = packed_quad.br;\n";
+      }
+      fragment_main << "  gl_FragColor = packed_quad;\n";
+      break;
+    }
+
+    case Shader::I422_NV61_MRT:
+      // I422 sampling, delivered via two output textures (NV61 format). See
+      // header file for diagram.
+      shared_variables << "varying highp vec4 v_texcoords[2];\n";
+      vertex_header << "uniform vec2 scaling_vector;\n";
+      vertex_main
+          << ("  vec2 step = scaling_vector / 4.0;\n"
+              "  v_texcoords[0].xy = texcoord - step * 1.5;\n"
+              "  v_texcoords[0].zw = texcoord - step * 0.5;\n"
+              "  v_texcoords[1].xy = texcoord + step * 0.5;\n"
+              "  v_texcoords[1].zw = texcoord + step * 1.5;\n");
+      fragment_directives << "#extension GL_EXT_draw_buffers : enable\n";
+      fragment_main
+          << ("  vec3 pixel0 = texture2D(s_texture, v_texcoords[0].xy).rgb;\n"
+              "  vec3 pixel1 = texture2D(s_texture, v_texcoords[0].zw).rgb;\n"
+              "  vec3 pixel01 = (pixel0 + pixel1) / 2.0;\n"
+              "  vec3 pixel2 = texture2D(s_texture, v_texcoords[1].xy).rgb;\n"
+              "  vec3 pixel3 = texture2D(s_texture, v_texcoords[1].zw).rgb;\n"
+              "  vec3 pixel23 = (pixel2 + pixel3) / 2.0;\n");
+      if (color_transform) {
+        fragment_main
+            << ("  pixel0 = DoColorConversion(pixel0);\n"
+                "  pixel1 = DoColorConversion(pixel1);\n"
+                "  pixel01 = DoColorConversion(pixel01);\n"
+                "  pixel2 = DoColorConversion(pixel2);\n"
+                "  pixel3 = DoColorConversion(pixel3);\n"
+                "  pixel23 = DoColorConversion(pixel23);\n");
+      }
+      if (swizzle[0] == GL_BGRA_EXT) {
+        fragment_main
+            << ("  gl_FragData[0] = \n"
+                "      vec4(pixel2.r, pixel1.r, pixel0.r, pixel3.r);\n");
+      } else {
+        fragment_main
+            << ("  gl_FragData[0] = \n"
+                "      vec4(pixel0.r, pixel1.r, pixel2.r, pixel3.r);\n");
+      }
+      if (swizzle[1] == GL_BGRA_EXT) {
+        fragment_main
+            << ("  gl_FragData[1] = \n"
+                "      vec4(pixel23.g, pixel01.b, pixel01.g, pixel23.b);\n");
+      } else {
+        fragment_main
+            << ("  gl_FragData[1] = \n"
+                "      vec4(pixel01.g, pixel01.b, pixel23.g, pixel23.b);\n");
+      }
+      break;
+
+    case Shader::DEINTERLEAVE_PAIRWISE_MRT:
+      // Sample two pixels and unswizzle them. There's no need to do vertical
+      // scaling with math, since the bilinear interpolation in the sampler
+      // takes care of that.
+      shared_variables << "varying highp vec4 v_texcoords;\n";
+      vertex_header << "uniform vec2 scaling_vector;\n";
+      vertex_main
+          << ("  vec2 step = scaling_vector / 2.0;\n"
+              "  v_texcoords.xy = texcoord - step * 0.5;\n"
+              "  v_texcoords.zw = texcoord + step * 0.5;\n");
+      fragment_directives << "#extension GL_EXT_draw_buffers : enable\n";
+      DCHECK(!color_transform);
+      fragment_main
+          << ("  vec4 lo_uvuv = texture2D(s_texture, v_texcoords.xy);\n"
+              "  vec4 hi_uvuv = texture2D(s_texture, v_texcoords.zw);\n"
+              "  vec4 uuuu = vec4(lo_uvuv.rb, hi_uvuv.rb);\n"
+              "  vec4 vvvv = vec4(lo_uvuv.ga, hi_uvuv.ga);\n");
+      if (swizzle[0] == GL_BGRA_EXT) {
+        fragment_main << "  uuuu.rb = uuuu.br;\n";
+      }
+      fragment_main << "  gl_FragData[0] = uuuu;\n";
+      if (swizzle[1] == GL_BGRA_EXT) {
+        fragment_main << "  vvvv.rb = vvvv.br;\n";
+      }
+      fragment_main << "  gl_FragData[1] = vvvv;\n";
+      break;
+
+    case Shader::PLANAR_CHANNELS_1_2: {
+      // Select two color channels, and pack 2 pairs of pixels into one output
+      // quad. See header file for diagram.
+      // This shader performs the same work that is being done by
+      // Shader::I422_NV61_MRT (see above) for its second render target.
+      shared_variables << "varying highp vec4 v_texcoords[2];\n";
+      vertex_header << "uniform vec2 scaling_vector;\n";
+      vertex_main
+          << ("  vec2 step = scaling_vector / 4.0;\n"
+              "  v_texcoords[0].xy = texcoord - step * 1.5;\n"
+              "  v_texcoords[0].zw = texcoord - step * 0.5;\n"
+              "  v_texcoords[1].xy = texcoord + step * 0.5;\n"
+              "  v_texcoords[1].zw = texcoord + step * 1.5;\n");
+      fragment_main
+          << ("  vec3 pixel0 = texture2D(s_texture, v_texcoords[0].xy).rgb;\n"
+              "  vec3 pixel1 = texture2D(s_texture, v_texcoords[0].zw).rgb;\n"
+              "  vec3 pixel01 = (pixel0 + pixel1) / 2.0;\n"
+              "  vec3 pixel2 = texture2D(s_texture, v_texcoords[1].xy).rgb;\n"
+              "  vec3 pixel3 = texture2D(s_texture, v_texcoords[1].zw).rgb;\n"
+              "  vec3 pixel23 = (pixel2 + pixel3) / 2.0;\n");
+
+      if (color_transform) {
+        fragment_main
+            << ("  pixel01 = DoColorConversion(pixel01);\n"
+                "  pixel23 = DoColorConversion(pixel23);\n");
+      }
+
+      fragment_main
+          << ("  vec4 packed_quad = vec4(\n"
+              "      pixel01.g, pixel01.b, pixel23.g, pixel23.b);\n");
+
+      if (swizzle[0] == GL_BGRA_EXT) {
+        fragment_main << "  packed_quad.rb = packed_quad.br;\n";
+      }
+
+      fragment_main << "  gl_FragColor = packed_quad;\n";
+      break;
+    }
+  }
+
+  // Helper function to compile the shader source and log the GLSL compiler's
+  // results.
+  const char* shader_name = GLScaler::GetShaderName(shader_);
+  const auto CompileShaderFromSource =
+      [shader_name](GLES2Interface* gl, const std::basic_string<GLchar>& source,
+                    GLenum type) -> GLuint {
+    VLOG(2) << __func__ << ": Compiling shader " << type
+            << " with source:" << std::endl
+            << source << ", for GLScaler::Shader=" << shader_name;
+    const GLuint shader = gl->CreateShader(type);
+    const GLchar* source_data = source.data();
+    const GLint length = base::checked_cast<GLint>(source.size());
+    gl->ShaderSource(shader, 1, &source_data, &length);
+    gl->CompileShader(shader);
+    GLint compile_status = GL_FALSE;
+    gl->GetShaderiv(shader, GL_COMPILE_STATUS, &compile_status);
+
+    // Fetch logs and forward them to the system logger. If compilation failed,
+    // clean-up and return 0 for error.
+    if (compile_status != GL_TRUE || VLOG_IS_ON(2)) {
+      GLint log_length = 0;
+      gl->GetShaderiv(shader, GL_INFO_LOG_LENGTH, &log_length);
+      std::string log;
+      if (log_length > 0) {
+        std::unique_ptr<GLchar[]> tmp(new GLchar[log_length]);
+        GLsizei returned_log_length = 0;
+        gl->GetShaderInfoLog(shader, log_length, &returned_log_length,
+                             tmp.get());
+        log.assign(tmp.get(), returned_log_length);
+      }
+      if (log.empty()) {
+        log = "<<NO LOG>>";
+      }
+      if (compile_status != GL_TRUE) {
+        LOG(ERROR) << __func__ << ": Compilation of shader " << type
+                   << " failed:" << std::endl
+                   << log;
+        gl->DeleteShader(shader);
+        return 0;
+      }
+      VLOG(2) << __func__ << ": Compilation of shader " << type
+              << " succeeded:" << std::endl
+              << log;
+    }
+    return shader;
+  };
+
+  // Compile the vertex shader and attach it to the program.
+  const std::string shared_variables_str = shared_variables.str();
+  const GLuint vertex_shader =
+      CompileShaderFromSource(gl_,
+                              vertex_header.str() + shared_variables_str +
+                                  "void main() {\n" + vertex_main.str() + "}\n",
+                              GL_VERTEX_SHADER);
+  if (vertex_shader == 0) {
+    return;
+  }
+  gl_->AttachShader(program_, vertex_shader);
+  gl_->DeleteShader(vertex_shader);
+
+  // Compile the fragment shader and attach to |program_|.
+  const GLuint fragment_shader = CompileShaderFromSource(
+      gl_,
+      fragment_directives.str() + fragment_header.str() + shared_variables_str +
+          "void main() {\n" + fragment_main.str() + "}\n",
+      GL_FRAGMENT_SHADER);
+  if (fragment_shader == 0) {
+    return;
+  }
+  gl_->AttachShader(program_, fragment_shader);
+  gl_->DeleteShader(fragment_shader);
+
+  // Link the program.
+  gl_->LinkProgram(program_);
+  GLint link_status = GL_FALSE;
+  gl_->GetProgramiv(program_, GL_LINK_STATUS, &link_status);
+  if (link_status != GL_TRUE) {
+    LOG(ERROR) << "Failed to link shader program.";
+    return;
+  }
+
+#define DCHECK_RESOLVED_LOCATION(member)                                  \
+  DCHECK(member != -1 || gl_->GetGraphicsResetStatusKHR() != GL_NO_ERROR) \
+      << "Failed to get " #member " in program, or GPU process crashed."
+
+  // Resolve the locations of the global variables.
+  position_location_ = gl_->GetAttribLocation(program_, "a_position");
+  DCHECK_RESOLVED_LOCATION(position_location_);
+  texcoord_location_ = gl_->GetAttribLocation(program_, "a_texcoord");
+  DCHECK_RESOLVED_LOCATION(texcoord_location_);
+  texture_location_ = gl_->GetUniformLocation(program_, "s_texture");
+  DCHECK_RESOLVED_LOCATION(texture_location_);
+  src_rect_location_ = gl_->GetUniformLocation(program_, "src_rect");
+  DCHECK_RESOLVED_LOCATION(src_rect_location_);
+  switch (shader_) {
+    case Shader::BILINEAR:
+      break;
+
+    case Shader::BILINEAR2:
+    case Shader::BILINEAR3:
+    case Shader::BILINEAR4:
+    case Shader::BILINEAR2X2:
+    case Shader::BICUBIC_HALF_1D:
+    case Shader::PLANAR_CHANNEL_0:
+    case Shader::PLANAR_CHANNEL_1:
+    case Shader::PLANAR_CHANNEL_2:
+    case Shader::PLANAR_CHANNEL_3:
+    case Shader::I422_NV61_MRT:
+    case Shader::DEINTERLEAVE_PAIRWISE_MRT:
+    case Shader::PLANAR_CHANNELS_1_2:
+      scaling_vector_location_ =
+          gl_->GetUniformLocation(program_, "scaling_vector");
+      DCHECK_RESOLVED_LOCATION(scaling_vector_location_);
+      break;
+
+    case Shader::BICUBIC_UPSCALE:
+      src_pixelsize_location_ =
+          gl_->GetUniformLocation(program_, "src_pixelsize");
+      DCHECK_RESOLVED_LOCATION(src_pixelsize_location_);
+      scaling_vector_location_ =
+          gl_->GetUniformLocation(program_, "scaling_vector");
+      DCHECK_RESOLVED_LOCATION(scaling_vector_location_);
+      break;
+  }
+
+#undef DCHECK_RESOLVED_LOCATION
+}
+
+GLScaler::ShaderProgram::~ShaderProgram() {
+  gl_->DeleteProgram(program_);
+}
+
+void GLScaler::ShaderProgram::UseProgram(const gfx::Size& src_texture_size,
+                                         const gfx::RectF& src_rect,
+                                         const gfx::Size& dst_size,
+                                         GLScaler::Axis primary_axis,
+                                         bool flip_y) {
+  gl_->UseProgram(program_);
+
+  // OpenGL defines the last parameter to VertexAttribPointer as type
+  // "const GLvoid*" even though it is actually an offset into the buffer
+  // object's data store and not a pointer to the client's address space.
+  const void* offsets[2] = {nullptr,
+                            reinterpret_cast<const void*>(2 * sizeof(GLfloat))};
+
+  gl_->VertexAttribPointer(position_location_, 2, GL_FLOAT, GL_FALSE,
+                           4 * sizeof(GLfloat), offsets[0]);
+  gl_->EnableVertexAttribArray(position_location_);
+
+  gl_->VertexAttribPointer(texcoord_location_, 2, GL_FLOAT, GL_FALSE,
+                           4 * sizeof(GLfloat), offsets[1]);
+  gl_->EnableVertexAttribArray(texcoord_location_);
+
+  // Always sample from the first texture unit.
+  gl_->Uniform1i(texture_location_, 0);
+
+  // Convert |src_rect| from pixel coordinates to texture coordinates. The
+  // source texture coordinates are in the range [0.0,1.0] for each dimension,
+  // but the sampling rect may slightly "spill" outside that range (e.g., for
+  // scaler overscan).
+  GLfloat src_rect_texcoord[4] = {
+      src_rect.x() / src_texture_size.width(),
+      src_rect.y() / src_texture_size.height(),
+      src_rect.width() / src_texture_size.width(),
+      src_rect.height() / src_texture_size.height(),
+  };
+  if (flip_y) {
+    src_rect_texcoord[1] += src_rect_texcoord[3];
+    src_rect_texcoord[3] *= -1.0f;
+  }
+  gl_->Uniform4fv(src_rect_location_, 1, src_rect_texcoord);
+
+  // Set shader-specific uniform inputs. The |scaling_vector| is the ratio of
+  // the number of source pixels sampled per dest pixels output. It is used by
+  // the shader programs to locate distinct texels from the source texture, and
+  // sample them at the appropriate offset to produce each output texel.
+  switch (shader_) {
+    case Shader::BILINEAR:
+      break;
+
+    case Shader::BILINEAR2:
+    case Shader::BILINEAR3:
+    case Shader::BILINEAR4:
+    case Shader::BICUBIC_HALF_1D:
+    case Shader::PLANAR_CHANNEL_0:
+    case Shader::PLANAR_CHANNEL_1:
+    case Shader::PLANAR_CHANNEL_2:
+    case Shader::PLANAR_CHANNEL_3:
+    case Shader::I422_NV61_MRT:
+    case Shader::DEINTERLEAVE_PAIRWISE_MRT:
+    case Shader::PLANAR_CHANNELS_1_2:
+      switch (primary_axis) {
+        case HORIZONTAL:
+          gl_->Uniform2f(scaling_vector_location_,
+                         src_rect_texcoord[2] / dst_size.width(), 0.0);
+          break;
+        case VERTICAL:
+          gl_->Uniform2f(scaling_vector_location_, 0.0,
+                         src_rect_texcoord[3] / dst_size.height());
+          break;
+      }
+      break;
+
+    case Shader::BILINEAR2X2:
+      gl_->Uniform2f(scaling_vector_location_,
+                     src_rect_texcoord[2] / dst_size.width(),
+                     src_rect_texcoord[3] / dst_size.height());
+      break;
+
+    case Shader::BICUBIC_UPSCALE:
+      gl_->Uniform2f(src_pixelsize_location_, src_texture_size.width(),
+                     src_texture_size.height());
+      // For this shader program, the |scaling_vector| has an alternate meaning:
+      // It is only being used to select whether bicubic sampling is stepped in
+      // the X or the Y direction.
+      gl_->Uniform2f(scaling_vector_location_,
+                     primary_axis == HORIZONTAL ? 1.0 : 0.0,
+                     primary_axis == VERTICAL ? 1.0 : 0.0);
+      break;
+  }
+}
+
+GLScaler::ScalerStage::ScalerStage(gpu::gles2::GLES2Interface* gl,
+                                   GLScaler::Shader shader,
+                                   GLScaler::Axis primary_axis,
+                                   const gfx::Vector2d& scale_from,
+                                   const gfx::Vector2d& scale_to)
+    : gl_(gl),
+      shader_(shader),
+      primary_axis_(primary_axis),
+      scale_from_(scale_from),
+      scale_to_(scale_to) {
+  DCHECK(gl_);
+}
+
+GLScaler::ScalerStage::~ScalerStage() {
+  if (dest_framebuffer_) {
+    gl_->DeleteFramebuffers(1, &dest_framebuffer_);
+  }
+  if (intermediate_texture_) {
+    gl_->DeleteTextures(1, &intermediate_texture_);
+  }
+}
+
+void GLScaler::ScalerStage::ScaleToMultipleOutputs(
+    GLuint src_texture,
+    gfx::Size src_texture_size,
+    const gfx::Vector2d& src_offset,
+    GLuint dest_texture_0,
+    GLuint dest_texture_1,
+    const gfx::Rect& output_rect) {
+  if (output_rect.IsEmpty())
+    return;  // No work to do.
+
+  // Make a recursive call to the "input" ScalerStage to produce an intermediate
+  // texture for this stage to source from. Adjust src_* variables to use the
+  // intermediate texture as input.
+  //
+  // If there is no input stage, simply modify |src_rect| to account for the
+  // overall |src_offset| and Y-flip.
+  gfx::RectF src_rect = ToSourceRect(output_rect);
+  if (input_stage_) {
+    const gfx::Rect input_rect = ToInputRect(src_rect);
+    EnsureIntermediateTextureDefined(input_rect.size());
+    input_stage_->ScaleToMultipleOutputs(src_texture, src_texture_size,
+                                         src_offset, intermediate_texture_, 0,
+                                         input_rect);
+    src_texture = intermediate_texture_;
+    src_texture_size = intermediate_texture_size_;
+    DCHECK(!is_flipped_source_);
+    src_rect -= input_rect.OffsetFromOrigin();
+  } else {
+    if (is_flipped_source_) {
+      src_rect.set_x(src_rect.x() + src_offset.x());
+      src_rect.set_y(src_texture_size.height() - src_rect.bottom() -
+                     src_offset.y());
+    } else {
+      src_rect += src_offset;
+    }
+  }
+
+  // Attach the output texture(s) to the framebuffer.
+  if (!dest_framebuffer_) {
+    gl_->GenFramebuffers(1, &dest_framebuffer_);
+  }
+  gl_->BindFramebuffer(GL_FRAMEBUFFER, dest_framebuffer_);
+  gl_->FramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D,
+                            dest_texture_0, 0);
+  if (dest_texture_1 > 0) {
+    gl_->FramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0 + 1,
+                              GL_TEXTURE_2D, dest_texture_1, 0);
+  }
+
+  // Bind to the source texture and set the texture sampler to use bilinear
+  // filtering and clamp-to-edge, as required by all shader programs.
+  //
+  // It would be better to stash the existing parameter values, and restore them
+  // back later. However, glGetTexParameteriv() currently requires a blocking
+  // call to the GPU service, which is extremely costly performance-wise.
+  gl_->ActiveTexture(GL_TEXTURE0);
+  gl_->BindTexture(GL_TEXTURE_2D, src_texture);
+  gl_->TexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);
+  gl_->TexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR);
+  gl_->TexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);
+  gl_->TexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);
+
+  // Prepare the shader program for drawing.
+  DCHECK(program_);
+  program_->UseProgram(src_texture_size, src_rect, output_rect.size(),
+                       primary_axis_, flip_output_);
+
+  // Execute the draw.
+  gl_->Viewport(0, 0, output_rect.width(), output_rect.height());
+  const GLenum buffers[] = {GL_COLOR_ATTACHMENT0, GL_COLOR_ATTACHMENT0 + 1};
+  if (dest_texture_1 > 0) {
+    gl_->DrawBuffersEXT(2, buffers);
+  }
+  gl_->DrawArrays(GL_TRIANGLE_STRIP, 0, 4);
+  if (dest_texture_1 > 0) {
+    // Set the draw buffers back, to not disrupt external operations.
+    gl_->DrawBuffersEXT(1, buffers);
+  }
+
+  gl_->BindTexture(GL_TEXTURE_2D, 0);
+  gl_->BindFramebuffer(GL_FRAMEBUFFER, 0);
+}
+
+gfx::RectF GLScaler::ScalerStage::ToSourceRect(
+    const gfx::Rect& output_rect) const {
+  return gfx::ScaleRect(gfx::RectF(output_rect),
+                        static_cast<float>(scale_from_.x()) / scale_to_.x(),
+                        static_cast<float>(scale_from_.y()) / scale_to_.y());
+}
+
+gfx::Rect GLScaler::ScalerStage::ToInputRect(gfx::RectF source_rect) const {
+  int overscan_x = 0;
+  int overscan_y = 0;
+  switch (shader_) {
+    case Shader::BILINEAR:
+    case Shader::BILINEAR2:
+    case Shader::BILINEAR3:
+    case Shader::BILINEAR4: {
+      // These shaders sample 1 or more points along the primary axis, and only
+      // 1 point in the other direction, in order to produce each output pixel.
+      // The amount of overscan is always 0 or 1 pixel along the primary axis,
+      // and this can be determined by looking at the upper-left-most source
+      // texture sampling point: If this point is to the left of the middle of
+      // the upper-left-most source pixel, the texture sampler will also read
+      // the pixel to the left of that (for linear interpolation). Similar
+      // behavior can occur towards the right, upwards, and downwards at the
+      // source boundaries.
+      int threshold;
+      switch (shader_) {
+        default:
+          threshold = 1;
+          break;
+        case Shader::BILINEAR2:
+          threshold = 2;
+          break;
+        case Shader::BILINEAR3:
+          threshold = 3;
+          break;
+        case Shader::BILINEAR4:
+          threshold = 4;
+          break;
+      }
+      switch (primary_axis_) {
+        case HORIZONTAL:
+          if (scale_from_.x() < threshold * scale_to_.x()) {
+            overscan_x = 1;
+          }
+          if (scale_from_.y() < scale_to_.y()) {
+            overscan_y = 1;
+          }
+          break;
+        case VERTICAL:
+          if (scale_from_.x() < scale_to_.x()) {
+            overscan_x = 1;
+          }
+          if (scale_from_.y() < threshold * scale_to_.y()) {
+            overscan_y = 1;
+          }
+          break;
+      }
+      break;
+    }
+
+    case Shader::BILINEAR2X2:
+      // This shader samples 2 points along both axes, and the overscan is 0 or
+      // 1 pixel in both directions (same explanation as for the other BILINEAR
+      // shaders).
+      if (scale_from_.x() < 2 * scale_to_.x()) {
+        overscan_x = 1;
+      }
+      if (scale_from_.y() < 2 * scale_to_.y()) {
+        overscan_y = 1;
+      }
+      break;
+
+    case Shader::BICUBIC_UPSCALE:
+      // For each output pixel, this shader always reads 2 pixels about the
+      // source position in one dimension, and has no overscan in the other
+      // dimension.
+      if (scale_from_.x() < scale_to_.x()) {
+        DCHECK_EQ(HORIZONTAL, primary_axis_);
+        overscan_x = 2;
+      } else if (scale_from_.y() < scale_to_.y()) {
+        DCHECK_EQ(VERTICAL, primary_axis_);
+        overscan_y = 2;
+      } else if (scale_from_ == scale_to_) {
+        // Special case: When not scaling, the math in the shader will resolve
+        // to just outputting the value for a single source pixel. The shader
+        // will sample surrounding pixels, but then apply a zero weight to them
+        // during convolution. Thus, there is effectively no overscan.
+        NOTREACHED();  // This is a crazy-expensive way to do a 1:1 copy!
+      } else {
+        NOTREACHED();  // Downscaling is meaningless.
+      }
+      break;
+
+    case Shader::BICUBIC_HALF_1D: {
+      // For each output pixel, this shader always reads 4 pixels about the
+      // source position in one dimension, and has no overscan in the other
+      // dimension. However, since the source position always has a distance
+      // >= 1 inside the "logical" bounds, there can never be more than 3 pixels
+      // of overscan.
+      if (scale_from_.x() == 2 * scale_to_.x()) {
+        DCHECK_EQ(HORIZONTAL, primary_axis_);
+        overscan_x = 3;
+      } else if (scale_from_.y() == 2 * scale_to_.y()) {
+        DCHECK_EQ(VERTICAL, primary_axis_);
+        overscan_y = 3;
+      } else {
+        // Anything but a half-downscale in one dimension is meaningless.
+        NOTREACHED();
+      }
+      break;
+    }
+
+    case Shader::PLANAR_CHANNEL_0:
+    case Shader::PLANAR_CHANNEL_1:
+    case Shader::PLANAR_CHANNEL_2:
+    case Shader::PLANAR_CHANNEL_3:
+    case Shader::I422_NV61_MRT:
+    case Shader::PLANAR_CHANNELS_1_2:
+      // All of these sample 4x1 source pixels to produce each output "pixel".
+      // There is no overscan. They can also be combined with a bilinear
+      // downscale, but not an upscale.
+      DCHECK_GE(scale_from_.x(), 4 * scale_to_.x());
+      DCHECK_EQ(HORIZONTAL, primary_axis_);
+      break;
+
+    case Shader::DEINTERLEAVE_PAIRWISE_MRT:
+      // This shader samples 2x1 source pixels to produce each output "pixel".
+      // There is no overscan. It can also be combined with a bilinear
+      // downscale, but not an upscale.
+      DCHECK_GE(scale_from_.x(), 2 * scale_to_.x());
+      DCHECK_EQ(HORIZONTAL, primary_axis_);
+      break;
+  }
+
+  source_rect.Inset(gfx::InsetsF::VH(-overscan_y, -overscan_x));
+  return gfx::ToEnclosingRect(source_rect);
+}
+
+void GLScaler::ScalerStage::EnsureIntermediateTextureDefined(
+    const gfx::Size& size) {
+  // Reallocate a new texture, if needed.
+  if (!intermediate_texture_) {
+    gl_->GenTextures(1, &intermediate_texture_);
+  }
+  if (intermediate_texture_size_ != size) {
+    gl_->BindTexture(GL_TEXTURE_2D, intermediate_texture_);
+    // Note: Not setting the filter or wrap parameters on the texture here
+    // because that will be done in ScaleToMultipleOutputs() anyway.
+    gl_->TexImage2D(GL_TEXTURE_2D, 0, GL_RGBA, size.width(), size.height(), 0,
+                    GL_RGBA, program_->texture_type(), nullptr);
+    intermediate_texture_size_ = size;
+  }
+}
+
+std::ostream& operator<<(std::ostream& out, const GLScaler& scaler) {
+  if (!scaler.chain_) {
+    return (out << "[GLScaler NOT configured]");
+  }
+
+  out << "Output";
+  const GLScaler::ScalerStage* const final_stage = scaler.chain_.get();
+  for (auto* stage = final_stage; stage; stage = stage->input_stage()) {
+    out << u8" ← {" << GLScaler::GetShaderName(stage->shader());
+    if (stage->shader_program()) {
+      switch (stage->shader_program()->texture_type()) {
+        case GL_FLOAT:
+          out << "/highp";
+          break;
+        case GL_HALF_FLOAT_OES:
+          out << "/mediump";
+          break;
+        default:
+          out << "/lowp";
+          break;
+      }
+    }
+    if (stage->flip_output()) {
+      out << "+flip_y";
+    }
+    if (stage->scale_from() == stage->scale_to()) {
+      out << " copy";
+    } else {
+      out << ' ' << stage->scale_from().ToString() << " to "
+          << stage->scale_to().ToString();
+    }
+    if (!stage->input_stage() &&
+        scaler.params_.source_color_space != scaler.scaling_color_space_) {
+      out << ", with color x-form "
+          << scaler.params_.source_color_space.ToString() << " to "
+          << scaler.scaling_color_space_.ToString();
+    }
+    if (stage == final_stage) {
+      if (scaler.params_.output_color_space != scaler.scaling_color_space_) {
+        out << ", with color x-form to "
+            << scaler.params_.output_color_space.ToString();
+      }
+      for (int i = 0; i < 2; ++i) {
+        if (scaler.params_.swizzle[i] != GL_RGBA) {
+          out << ", with swizzle(" << i << ')';
+        }
+      }
+    }
+    out << '}';
+  }
+  out << u8" ← Source";
+  return out;
+}
+
+}  // namespace viz
diff --git components/viz/common/gl_scaler.h components/viz/common/gl_scaler.h
new file mode 100644
index 0000000000000..99013e8cadf4d
--- /dev/null
+++ components/viz/common/gl_scaler.h
@@ -0,0 +1,538 @@
+// Copyright 2018 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef COMPONENTS_VIZ_COMMON_GL_SCALER_H_
+#define COMPONENTS_VIZ_COMMON_GL_SCALER_H_
+
+#include <stdint.h>
+
+#include <map>
+#include <memory>
+#include <ostream>
+#include <string>
+#include <tuple>
+#include <utility>
+#include <vector>
+
+#include "base/memory/raw_ptr.h"
+#include "base/memory/scoped_refptr.h"
+#include "components/viz/common/gpu/context_lost_observer.h"
+#include "components/viz/common/viz_common_export.h"
+#include "gpu/command_buffer/client/gles2_interface.h"
+#include "third_party/abseil-cpp/absl/types/optional.h"
+#include "ui/gfx/color_space.h"
+#include "ui/gfx/geometry/rect.h"
+#include "ui/gfx/geometry/rect_f.h"
+#include "ui/gfx/geometry/size.h"
+#include "ui/gfx/geometry/vector2d.h"
+
+namespace gfx {
+class ColorTransform;
+}  // namespace gfx
+
+namespace viz {
+
+class ContextProvider;
+
+// A high-performance texture scaler for use with an OpenGL ES 2.0 context. It
+// can be configured to operate at different quality levels, manages/converts
+// color spaces, and optionally re-arranges/formats data in output textures for
+// use with more-efficient texture readback pipelines.
+class VIZ_COMMON_EXPORT GLScaler final : public ContextLostObserver {
+ public:
+  struct VIZ_COMMON_EXPORT Parameters {
+    // Relative scale from/to factors. Both of these must be non-zero.
+    gfx::Vector2d scale_from = gfx::Vector2d(1, 1);
+    gfx::Vector2d scale_to = gfx::Vector2d(1, 1);
+
+    // The color space of the source texture and the desired color space of the
+    // output texture. If |source_color_space| is not set (or invalid), sRGB is
+    // assumed. If |output_color_space| is not set (or invalid), the source
+    // color space is assumed.
+    gfx::ColorSpace source_color_space;
+    gfx::ColorSpace output_color_space;
+
+    // Enable color management heuristics, using higher precision texture and
+    // gamma-aware scaling?
+    //
+    // When disabled, the gamma of the source color space and other concerns are
+    // ignored and 8-bit precision is used.
+    //
+    // When enabled, scaling occurs in a linear color space with 16-bit floats.
+    // This produces excellent results for virtually all color spaces while
+    // typically requiring twice the memory and execution resources. The caller
+    // must ensure the GL context supports the use of GL_RGBA16F format
+    // textures.
+    //
+    // Relevant reading: http://www.ericbrasseur.org/gamma.html
+    bool enable_precise_color_management = false;
+
+    // Selects the trade-off between quality and speed.
+    enum class Quality : int8_t {
+      // Bilinear single pass. Fastest possible. Do not use this unless the GL
+      // implementation is so slow that the other quality options won't work.
+      FAST,
+
+      // Bilinear upscale + N * 50% bilinear downscales. This is still fast
+      // enough for general-purpose use, and image quality is nearly as good as
+      // BEST when downscaling.
+      GOOD,
+
+      // Bicubic upscale + N * 50% bicubic downscales. Produces very good
+      // quality scaled images, but it's 2-8x slower than the "GOOD" quality.
+      BEST,
+    } quality = Quality::GOOD;
+
+    // Is the source texture Y-flipped (i.e., the origin is the lower-left
+    // corner and not the upper-left corner)? Most GL textures are Y-flipped.
+    // This information is required so that the scaler can correctly compute the
+    // sampling region.
+    bool is_flipped_source = true;
+
+    // Should the output be vertically flipped? Usually, this is used when the
+    // source is not Y-flipped, but the destination texture needs to be. Or, it
+    // can be used to draw the final output upside-down to avoid having to copy
+    // the rows in reverse order after a glReadPixels().
+    bool flip_output = false;
+
+    // Optionally rearrange the image data for export. Generally, this is used
+    // to make later readback steps more efficient (e.g., using glReadPixels()
+    // will produce the raw bytes in their correct locations).
+    //
+    // Output textures are assumed to be using one of the 4-channel RGBA
+    // formats. While it may be more "proper" to use a single-component texture
+    // format for the planar-oriented image data, not all GL implementations
+    // support the use of those formats. However, all must support at least
+    // GL_RGBA. Therefore, each RGBA pixel is treated as a generic "vec4" (a
+    // quad of values).
+    //
+    // When using this feature, it is usually necessary to adjust the
+    // |output_rect| passed to Scale() or ScaleToMultipleOutputs(). See notes
+    // below.
+    enum class ExportFormat : int8_t {
+      // Do not rearrange the image data:
+      //
+      //   (interleaved quads)     (interleaved quads)
+      //   RGBA RGBA RGBA RGBA     RGBA RGBA RGBA RGBA
+      //   RGBA RGBA RGBA RGBA --> RGBA RGBA RGBA RGBA
+      //   RGBA RGBA RGBA RGBA     RGBA RGBA RGBA RGBA
+      INTERLEAVED_QUADS,
+
+      // Select one color channel, packing each of 4 pixels' values into the 4
+      // elements of one output quad.
+      //
+      // For example, for CHANNEL_0:
+      //
+      //             (interleaved quads)              (channel 0)
+      //   RGBA RGBA RGBA RGBA RGBA RGBA RGBA RGBA     RRRR RRRR
+      //   RGBA RGBA RGBA RGBA RGBA RGBA RGBA RGBA --> RRRR RRRR
+      //   RGBA RGBA RGBA RGBA RGBA RGBA RGBA RGBA     RRRR RRRR
+      //
+      // Note: Because of this packing, the horizontal coordinates of the
+      // |output_rect| used with Scale() should be divided by 4.
+      CHANNEL_0,
+      CHANNEL_1,
+      CHANNEL_2,
+      CHANNEL_3,
+
+      // I422 sampling, delivered via two output textures (NV61 format): The
+      // first texture is produced the same as CHANNEL_0, while the second
+      // texture contains CHANNEL_1 and CHANNEL_2 at half-width interleaved and
+      // full-height. For example, if this is combined with RGB→YUV color space
+      // conversion:
+      //
+      //              (interleaved quads)
+      //    RGBA RGBA RGBA RGBA RGBA RGBA RGBA RGBA
+      //    RGBA RGBA RGBA RGBA RGBA RGBA RGBA RGBA
+      //    RGBA RGBA RGBA RGBA RGBA RGBA RGBA RGBA
+      //      |
+      //      |     (luma plane)  (chroma, interleaved)
+      //      |       YYYY YYYY      UVUV UVUV
+      //      +---> { YYYY YYYY  +   UVUV UVUV }
+      //              YYYY YYYY      UVUV UVUV
+      //
+      // Note: Because of this packing, the horizontal coordinates of the
+      // |output_rect| used with ScaleToMultipleOutputs() should be divided by
+      // 4.
+      // Note 2: This requires a GL context that supports multiple render
+      // targets with at least two draw buffers.
+      NV61,
+
+      // Deinterleave into two output textures.
+      //
+      //  UVUV UVUV       UUUU   VVVV
+      //  UVUV UVUV --> { UUUU + VVVV }
+      //  UVUV UVUV       UUUU   VVVV
+      //
+      // Note: Because of this packing, the horizontal coordinates of the
+      // |output_rect| used with ScaleToMultipleOutputs() should be divided by
+      // 2.
+      // Note 2: This requires a GL context that supports multiple render
+      // targets with at least two draw buffers.
+      DEINTERLEAVE_PAIRWISE,
+
+      // Select CHANNEL_1 and CHANNEL_2, packing each 2-channel pair from
+      // 4-pixel values into the 2 elements of one output quad. The channels
+      // will be selected at half-width and full height. This should be
+      // equivalent to the second texture produced by ExportFormat::NV61 (see
+      // above). If used on textures after they have gone through RGB→YUV color
+      // space conversion, the transformation is:
+      //
+      //             (interleaved quads)              (channels 1 & 2)
+      //   YUVx YUVx YUVx YUVx YUVx YUVx YUVx YUVx       UVUV UVUV
+      //   YUVx YUVx YUVx YUVx YUVx YUVx YUVx YUVx  -->  UVUV UVUV
+      //   YUVx YUVx YUVx YUVx YUVx YUVx YUVx YUVx       UVUV UVUV
+      //
+      // Note: Because of this packing, the horizontal coordinates of the
+      // |output_rect| used with Scale() should be divided by 4.
+      UV_CHANNELS,
+    } export_format = ExportFormat::INTERLEAVED_QUADS;
+
+    // Optionally swizzle the ordering of the values in each output quad. If the
+    // output of the scaler is not going to be read back (e.g., used with
+    // glReadPixels()), simply leave these unchanged. Otherwise, changing this
+    // allows a read-back pipeline to use the native format of the platform to
+    // avoid having to perform extra "BGRA⇄RGBA swizzle" memcpy's. Usually, this
+    // should match the format to be used with glReadPixels(), and that should
+    // match the GL_IMPLEMENTATION_COLOR_READ_FORMAT.
+    GLenum swizzle[2] = {
+        GL_RGBA,  // For |dest_texture_0|.
+        GL_RGBA,  // For |dest_texture_1|.
+    };
+
+    Parameters();
+    Parameters(const Parameters& other);
+    ~Parameters();
+  };
+
+  explicit GLScaler(ContextProvider* context_provider);
+
+  GLScaler(const GLScaler&) = delete;
+  GLScaler& operator=(const GLScaler&) = delete;
+
+  ~GLScaler() final;
+
+  // Returns true if the GL context provides the necessary support for enabling
+  // precise color management (see Parameters::enable_precise_color_management).
+  bool SupportsPreciseColorManagement() const;
+
+  // Returns the maximum number of simultaneous drawing buffers supported by the
+  // GL context. Certain Parameters can only be used when this is more than 1.
+  int GetMaxDrawBuffersSupported() const;
+
+  // [Re]Configure the scaler with the given |new_params|. Returns true on
+  // success, or false on failure.
+  [[nodiscard]] bool Configure(const Parameters& new_params);
+
+  // Returns the currently-configured and resolved Parameters. Note that these
+  // Parameters might not be exactly the same as those that were passed to
+  // Configure() because some properties (e.g., color spaces) are auto-resolved;
+  // however, ParametersAreEquivalent() will still return true. Results are
+  // undefined if Configure() has never been called successfully.
+  const Parameters& params() const { return params_; }
+
+  // Scales a portion of |src_texture| and draws the result into |dest_texture|
+  // at offset (0, 0). Returns true to indicate success, or false if this
+  // GLScaler is not valid.
+  //
+  // |src_texture_size| is the full, allocated size of the |src_texture|. This
+  // is required for computing texture coordinate transforms (and only because
+  // the OpenGL ES 2.0 API lacks the ability to query this info).
+  //
+  // |src_offset| is the offset in the source texture corresponding to point
+  // (0,0) in the source/output coordinate spaces. This prevents the need for
+  // extra texture copies just to re-position the source coordinate system.
+  //
+  // |output_rect| selects the region to draw (in the scaled, not the source,
+  // coordinate space). This is used to save work in cases where only a portion
+  // needs to be re-scaled. The implementation will back-compute, internally, to
+  // determine the region of the |src_texture| to sample.
+  //
+  // WARNING: The output will always be placed at (0, 0) in the |dest_texture|,
+  // and not at |output_rect.origin()|.
+  //
+  // Note that the |src_texture| will have the min/mag filter set to GL_LINEAR
+  // and wrap_s/t set to CLAMP_TO_EDGE in this call.
+  [[nodiscard]] bool Scale(GLuint src_texture,
+                           const gfx::Size& src_texture_size,
+                           const gfx::Vector2d& src_offset,
+                           GLuint dest_texture,
+                           const gfx::Rect& output_rect) {
+    return ScaleToMultipleOutputs(src_texture, src_texture_size, src_offset,
+                                  dest_texture, 0, output_rect);
+  }
+
+  // Same as above, but for use cases where there are two output textures drawn
+  // (see Parameters::ExportFormat).
+  [[nodiscard]] bool ScaleToMultipleOutputs(GLuint src_texture,
+                                            const gfx::Size& src_texture_size,
+                                            const gfx::Vector2d& src_offset,
+                                            GLuint dest_texture_0,
+                                            GLuint dest_texture_1,
+                                            const gfx::Rect& output_rect);
+
+  // Returns true if from:to represent the same scale ratio as that specified in
+  // |params|.
+  static bool ParametersHasSameScaleRatio(const Parameters& params,
+                                          const gfx::Vector2d& from,
+                                          const gfx::Vector2d& to);
+
+  // Returns true if configuring a GLScaler with either |a| or |b| will produce
+  // identical behaviors and results.
+  static bool ParametersAreEquivalent(const Parameters& a, const Parameters& b);
+
+ private:
+  friend class GLScalerOverscanPixelTest;
+  friend class GLScalerShaderPixelTest;
+  friend VIZ_COMMON_EXPORT std::ostream& operator<<(std::ostream&,
+                                                    const GLScaler&);
+
+  using GLES2Interface = gpu::gles2::GLES2Interface;
+
+  enum Axis { HORIZONTAL = 0, VERTICAL = 1 };
+
+  // The shaders used by each stage in the scaling pipeline.
+  enum class Shader : int8_t {
+    BILINEAR,
+    BILINEAR2,
+    BILINEAR3,
+    BILINEAR4,
+    BILINEAR2X2,
+    BICUBIC_UPSCALE,
+    BICUBIC_HALF_1D,
+    PLANAR_CHANNEL_0,
+    PLANAR_CHANNEL_1,
+    PLANAR_CHANNEL_2,
+    PLANAR_CHANNEL_3,
+    PLANAR_CHANNELS_1_2,
+    I422_NV61_MRT,
+    DEINTERLEAVE_PAIRWISE_MRT,
+  };
+
+  // A cached, re-usable shader program that performs one step in the scaling
+  // pipeline.
+  class VIZ_COMMON_EXPORT ShaderProgram {
+   public:
+    ShaderProgram(GLES2Interface* gl,
+                  Shader shader,
+                  GLenum texture_type,
+                  const gfx::ColorTransform* color_transform,
+                  const GLenum swizzle[2]);
+
+    ShaderProgram(const ShaderProgram&) = delete;
+    ShaderProgram& operator=(const ShaderProgram&) = delete;
+
+    ~ShaderProgram();
+
+    Shader shader() const { return shader_; }
+    GLenum texture_type() const { return texture_type_; }
+
+    // UseProgram must be called with GL_ARRAY_BUFFER bound to a vertex
+    // attribute buffer. |src_texture_size| is the size of the entire source
+    // texture, regardless of which region is to be sampled. |src_rect| is the
+    // source region, not including overscan pixels past the edges.
+    // |primary_axis| determines whether multiple texture samplings occur in one
+    // direction or the other (for some shaders). Note that this cannot
+    // necessarily be determined by just comparing the src and dst sizes.
+    // |flip_y| causes the |src_rect| to be scanned upside-down, to produce a
+    // vertically-flipped result.
+    void UseProgram(const gfx::Size& src_texture_size,
+                    const gfx::RectF& src_rect,
+                    const gfx::Size& dst_size,
+                    Axis primary_axis,
+                    bool flip_y);
+
+    // GL_ARRAY_BUFFER data that must be bound when drawing with a
+    // ShaderProgram. These are the vertex attributes that will sweep the entire
+    // source area when executing the program. They represent triangle strip
+    // coordinates: The first two columns are (x,y) values interpolated to
+    // produce the vertex coordinates in object space, while the latter two
+    // columns are (s,t) values interpolated to produce the texture coordinates
+    // that correspond to the vertex coordinates.
+    static const GLfloat kVertexAttributes[16];
+
+   private:
+    const raw_ptr<GLES2Interface> gl_;
+    const Shader shader_;
+    const GLenum texture_type_;
+
+    // A program for copying a source texture into a destination texture.
+    const GLuint program_;
+
+    // The location of the position in the program.
+    GLint position_location_ = -1;
+    // The location of the texture coordinate in the program.
+    GLint texcoord_location_ = -1;
+    // The location of the source texture in the program.
+    GLint texture_location_ = -1;
+    // The location of the texture coordinate of the source rectangle in the
+    // program.
+    GLint src_rect_location_ = -1;
+    // Location of size of source image in pixels.
+    GLint src_pixelsize_location_ = -1;
+    // Location of vector for scaling ratio between source and dest textures.
+    GLint scaling_vector_location_ = -1;
+  };
+
+  // One scaling stage in a chain of scaler pipeline stages. Each ScalerStage
+  // owns the previous ScalerStage in the chain: At execution time, a "working
+  // backwards" approach is used: The previous "input" stage renders an
+  // intermediate result that will be used as input for the current stage.
+  //
+  // Each ScalerStage caches textures and framebuffers to avoid reallocating
+  // them for each separate image scaling, which can be expensive on some
+  // platforms/drivers.
+  class VIZ_COMMON_EXPORT ScalerStage {
+   public:
+    ScalerStage(GLES2Interface* gl,
+                Shader shader,
+                Axis primary_axis,
+                const gfx::Vector2d& scale_from,
+                const gfx::Vector2d& scale_to);
+
+    ScalerStage(const ScalerStage&) = delete;
+    ScalerStage& operator=(const ScalerStage&) = delete;
+
+    ~ScalerStage();
+
+    Shader shader() const { return shader_; }
+    const gfx::Vector2d& scale_from() const { return scale_from_; }
+    const gfx::Vector2d& scale_to() const { return scale_to_; }
+
+    ScalerStage* input_stage() const { return input_stage_.get(); }
+    void set_input_stage(std::unique_ptr<ScalerStage> stage) {
+      input_stage_ = std::move(stage);
+    }
+    std::unique_ptr<ScalerStage> take_input_stage() {
+      return std::move(input_stage_);
+    }
+
+    ShaderProgram* shader_program() const { return program_; }
+    void set_shader_program(ShaderProgram* program) { program_ = program; }
+
+    bool is_flipped_source() const { return is_flipped_source_; }
+    void set_is_flipped_source(bool flipped) { is_flipped_source_ = flipped; }
+
+    bool flip_output() const { return flip_output_; }
+    void set_flip_output(bool flip) { flip_output_ = flip; }
+
+    void ScaleToMultipleOutputs(GLuint src_texture,
+                                gfx::Size src_texture_size,
+                                const gfx::Vector2d& src_offset,
+                                GLuint dest_texture_0,
+                                GLuint dest_texture_1,
+                                const gfx::Rect& output_rect);
+
+   private:
+    friend class GLScalerOverscanPixelTest;
+
+    // Returns the given |output_rect| mapped to the input stage's coordinate
+    // system.
+    gfx::RectF ToSourceRect(const gfx::Rect& output_rect) const;
+
+    // Returns the given |source_rect| padded to include the overscan pixels the
+    // shader program will access.
+    gfx::Rect ToInputRect(gfx::RectF source_rect) const;
+
+    // Generates the intermediate texture and/or re-defines it if its size has
+    // changed.
+    void EnsureIntermediateTextureDefined(const gfx::Size& size);
+
+    const raw_ptr<GLES2Interface> gl_;
+    const Shader shader_;
+    const Axis primary_axis_;
+    const gfx::Vector2d scale_from_;
+    const gfx::Vector2d scale_to_;
+
+    std::unique_ptr<ScalerStage> input_stage_;
+    raw_ptr<ShaderProgram> program_ = nullptr;
+    bool is_flipped_source_ = false;
+    bool flip_output_ = false;
+
+    GLuint intermediate_texture_ = 0;
+    gfx::Size intermediate_texture_size_;
+    GLuint dest_framebuffer_ = 0;
+  };
+
+  // ContextLostObserver implementation.
+  void OnContextLost() final;
+
+  // Returns a cached ShaderProgram, creating one on-demand if necessary.
+  ShaderProgram* GetShaderProgram(Shader shader,
+                                  GLenum texture_type,
+                                  const gfx::ColorTransform* color_transform,
+                                  const GLenum swizzle[2]);
+
+  // Create a scaling chain using the bilinear shaders.
+  static std::unique_ptr<ScalerStage> CreateAGoodScalingChain(
+      gpu::gles2::GLES2Interface* gl,
+      const gfx::Vector2d& scale_from,
+      const gfx::Vector2d& scale_to);
+
+  // Create a scaling chain using the bicubic shaders.
+  static std::unique_ptr<ScalerStage> CreateTheBestScalingChain(
+      gpu::gles2::GLES2Interface* gl,
+      const gfx::Vector2d& scale_from,
+      const gfx::Vector2d& scale_to);
+
+  // Modifies |chain| by appending an export stage, to rearrange the image data
+  // according to the requested |export_format|. In some cases, this will delete
+  // the final stage in |chain| before appending the export stage.
+  static std::unique_ptr<ScalerStage> MaybeAppendExportStage(
+      gpu::gles2::GLES2Interface* gl,
+      std::unique_ptr<ScalerStage> chain,
+      Parameters::ExportFormat export_format);
+
+  // Returns the other of the two axes.
+  static Axis TheOtherAxis(Axis axis);
+
+  // Returns the name of the |shader| in string form, for logging purposes.
+  static const char* GetShaderName(Shader shader);
+
+  // Returns true if the given |gl| context mentions all of |names| in its
+  // extensions string.
+  static bool AreAllGLExtensionsPresent(gpu::gles2::GLES2Interface* gl,
+                                        const std::vector<std::string>& names);
+
+  // The provider of the GL context. This is non-null while the GL context is
+  // valid and GLScaler is observing for context loss.
+  raw_ptr<ContextProvider> context_provider_;
+
+  // Set by Configure() to the resolved set of Parameters.
+  Parameters params_;
+
+  // If set to true, half-float textures are supported. This is lazy-initialized
+  // by SupportsPreciseColorManagement().
+  mutable absl::optional<bool> supports_half_floats_;
+
+  // The maximum number of simultaneous draw buffers, lazy-initialized by
+  // GetMaxDrawBuffersSupported(). -1 means "not yet known."
+  mutable int max_draw_buffers_ = -1;
+
+  // Cache of ShaderPrograms. The cache key consists of fields that correspond
+  // to the arguments of GetShaderProgram(): the shader, the texture format, the
+  // source and output color spaces (color transform), and the two swizzles.
+  using ShaderCacheKey = std::
+      tuple<Shader, GLenum, gfx::ColorSpace, gfx::ColorSpace, GLenum, GLenum>;
+  std::map<ShaderCacheKey, ShaderProgram> shader_programs_;
+
+  // The GL_ARRAY_BUFFER that holds the vertices and the texture coordinates
+  // data for sweeping the source area when a ScalerStage draws a quad (to
+  // execute its shader program).
+  GLuint vertex_attributes_buffer_ = 0;
+
+  // The chain of ScalerStages.
+  std::unique_ptr<ScalerStage> chain_;
+
+  // The color space in which the scaling stages operate.
+  gfx::ColorSpace scaling_color_space_;
+};
+
+// For logging.
+VIZ_COMMON_EXPORT std::ostream& operator<<(std::ostream& out,
+                                           const GLScaler& scaler);
+
+}  // namespace viz
+
+#endif  // COMPONENTS_VIZ_COMMON_GL_SCALER_H_
diff --git components/viz/common/resources/resource_format_utils.cc components/viz/common/resources/resource_format_utils.cc
index c1b9ab5102a39..8fec140903f59 100644
--- components/viz/common/resources/resource_format_utils.cc
+++ components/viz/common/resources/resource_format_utils.cc
@@ -273,6 +273,44 @@ unsigned int GLInternalFormat(ResourceFormat format) {
   }
 }
 
+unsigned int GLCopyTextureInternalFormat(ResourceFormat format) {
+  // In GLES2, valid formats for glCopyTexImage2D are: GL_ALPHA, GL_LUMINANCE,
+  // GL_LUMINANCE_ALPHA, GL_RGB, or GL_RGBA.
+  // Extensions typically used for glTexImage2D do not also work for
+  // glCopyTexImage2D. For instance GL_BGRA_EXT may not be used for
+  // anything but gl(Sub)TexImage2D:
+  // https://www.khronos.org/registry/gles/extensions/EXT/EXT_texture_format_BGRA8888.txt
+  DCHECK_LE(format, RESOURCE_FORMAT_MAX);
+  static const GLenum format_gl_data_format[] = {
+      GL_RGBA,       // RGBA_8888
+      GL_RGBA,       // RGBA_4444
+      GL_RGBA,       // BGRA_8888
+      GL_ALPHA,      // ALPHA_8
+      GL_LUMINANCE,  // LUMINANCE_8
+      GL_RGB,        // RGB_565
+      GL_RGB,        // BGR_565
+      GL_RGB,        // ETC1
+      GL_LUMINANCE,  // RED_8
+      GL_RGBA,       // RG_88
+      GL_LUMINANCE,  // LUMINANCE_F16
+      GL_RGBA,       // RGBA_F16
+      GL_LUMINANCE,  // R16_EXT
+      GL_RGBA,       // RG16_EXT
+      GL_RGB,        // RGBX_8888
+      GL_RGB,        // BGRX_8888
+      GL_ZERO,       // RGBA_1010102
+      GL_ZERO,       // BGRA_1010102
+      GL_ZERO,       // YVU_420
+      GL_ZERO,       // YUV_420_BIPLANAR
+      GL_ZERO,       // P010
+  };
+
+  static_assert(std::size(format_gl_data_format) == (RESOURCE_FORMAT_MAX + 1),
+                "format_gl_data_format does not handle all cases.");
+
+  return format_gl_data_format[format];
+}
+
 gfx::BufferFormat BufferFormat(ResourceFormat format) {
   switch (format) {
     case BGRA_8888:
diff --git components/viz/common/resources/resource_format_utils.h components/viz/common/resources/resource_format_utils.h
index 73131947dbb26..c5ec73b08f30e 100644
--- components/viz/common/resources/resource_format_utils.h
+++ components/viz/common/resources/resource_format_utils.h
@@ -38,6 +38,8 @@ SkColorTypeToResourceFormat(SkColorType color_type);
 VIZ_RESOURCE_FORMAT_EXPORT unsigned int GLDataType(ResourceFormat format);
 VIZ_RESOURCE_FORMAT_EXPORT unsigned int GLDataFormat(ResourceFormat format);
 VIZ_RESOURCE_FORMAT_EXPORT unsigned int GLInternalFormat(ResourceFormat format);
+VIZ_RESOURCE_FORMAT_EXPORT unsigned int GLCopyTextureInternalFormat(
+    ResourceFormat format);
 
 // Returns the pixel format of the resource when mapped into client-side memory.
 // Returns a default value when IsGpuMemoryBufferFormatSupported() returns false
diff --git components/viz/host/renderer_settings_creation.cc components/viz/host/renderer_settings_creation.cc
index 5ca2e3b7999fb..5d1e98c7b697e 100644
--- components/viz/host/renderer_settings_creation.cc
+++ components/viz/host/renderer_settings_creation.cc
@@ -66,6 +66,7 @@ RendererSettings CreateRendererSettings() {
 #endif
   renderer_settings.allow_antialiasing =
       !command_line->HasSwitch(switches::kDisableCompositedAntialiasing);
+  renderer_settings.use_skia_renderer = features::IsUsingSkiaRenderer();
 
   if (command_line->HasSwitch(switches::kSlowDownCompositingScaleFactor)) {
     const int kMinSlowDownScaleFactor = 1;
diff --git components/viz/service/BUILD.gn components/viz/service/BUILD.gn
index a7e4677d9a1c7..5cd38e9da7e24 100644
--- components/viz/service/BUILD.gn
+++ components/viz/service/BUILD.gn
@@ -45,6 +45,8 @@ viz_component("service") {
     "display/display_damage_tracker.h",
     "display/display_resource_provider.cc",
     "display/display_resource_provider.h",
+    "display/display_resource_provider_gl.cc",
+    "display/display_resource_provider_gl.h",
     "display/display_resource_provider_null.cc",
     "display/display_resource_provider_null.h",
     "display/display_resource_provider_skia.cc",
@@ -57,10 +59,22 @@ viz_component("service") {
     "display/display_scheduler_base.h",
     "display/draw_polygon.cc",
     "display/draw_polygon.h",
+    "display/dynamic_geometry_binding.cc",
+    "display/dynamic_geometry_binding.h",
     "display/external_use_client.cc",
     "display/external_use_client.h",
     "display/frame_rate_decider.cc",
     "display/frame_rate_decider.h",
+    "display/geometry_binding.cc",
+    "display/geometry_binding.h",
+    "display/gl_renderer.cc",
+    "display/gl_renderer.h",
+    "display/gl_renderer_copier.cc",
+    "display/gl_renderer_copier.h",
+    "display/gl_renderer_draw_cache.cc",
+    "display/gl_renderer_draw_cache.h",
+    "display/layer_quad.cc",
+    "display/layer_quad.h",
     "display/null_renderer.cc",
     "display/null_renderer.h",
     "display/output_surface.cc",
@@ -82,12 +96,20 @@ viz_component("service") {
     "display/overlay_processor_stub.h",
     "display/pending_swap_params.cc",
     "display/pending_swap_params.h",
+    "display/program_binding.cc",
+    "display/program_binding.h",
     "display/renderer_utils.cc",
     "display/renderer_utils.h",
     "display/resolved_frame_data.cc",
     "display/resolved_frame_data.h",
     "display/resource_fence.cc",
     "display/resource_fence.h",
+    "display/scoped_gpu_memory_buffer_texture.cc",
+    "display/scoped_gpu_memory_buffer_texture.h",
+    "display/scoped_render_pass_texture.cc",
+    "display/scoped_render_pass_texture.h",
+    "display/shader.cc",
+    "display/shader.h",
     "display/shared_bitmap_manager.h",
     "display/skia_output_surface.cc",
     "display/skia_output_surface.h",
@@ -97,12 +119,26 @@ viz_component("service") {
     "display/software_output_device.h",
     "display/software_renderer.cc",
     "display/software_renderer.h",
+    "display/static_geometry_binding.cc",
+    "display/static_geometry_binding.h",
     "display/surface_aggregator.cc",
     "display/surface_aggregator.h",
+    "display/sync_query_collection.cc",
+    "display/sync_query_collection.h",
+    "display/texture_deleter.cc",
+    "display/texture_deleter.h",
     "display_embedder/buffer_queue.cc",
     "display_embedder/buffer_queue.h",
     "display_embedder/compositor_gpu_thread.cc",
     "display_embedder/compositor_gpu_thread.h",
+    "display_embedder/image_context_impl.cc",
+    "display_embedder/image_context_impl.h",
+    "display_embedder/gl_output_surface.cc",
+    "display_embedder/gl_output_surface.h",
+    "display_embedder/gl_output_surface_buffer_queue.cc",
+    "display_embedder/gl_output_surface_buffer_queue.h",
+    "display_embedder/gl_output_surface_offscreen.cc",
+    "display_embedder/gl_output_surface_offscreen.h",
     "display_embedder/in_process_gpu_memory_buffer_manager.cc",
     "display_embedder/in_process_gpu_memory_buffer_manager.h",
     "display_embedder/output_surface_provider.h",
@@ -112,6 +148,8 @@ viz_component("service") {
     "display_embedder/server_shared_bitmap_manager.h",
     "display_embedder/software_output_surface.cc",
     "display_embedder/software_output_surface.h",
+    "display_embedder/viz_process_context_provider.cc",
+    "display_embedder/viz_process_context_provider.h",
     "display_embedder/vsync_parameter_listener.cc",
     "display_embedder/vsync_parameter_listener.h",
     "frame_sinks/begin_frame_tracker.cc",
@@ -245,6 +283,18 @@ viz_component("service") {
   ]
 
   if (is_chromeos_ash) {
+    sources += [
+      "display_embedder/gl_output_surface_chromeos.cc",
+      "display_embedder/gl_output_surface_chromeos.h",
+    ]
+
+    deps += [
+      "//components/chromeos_camera:jpeg_encode_accelerator_service",
+      "//components/chromeos_camera:mjpeg_decode_accelerator_service",
+      "//gpu/command_buffer/service:gles2",
+      "//media/mojo/services",
+    ]
+
     if (use_v4l2_codec || use_vaapi) {
       deps += [ "//ash/components/arc/video_accelerator" ]
     }
@@ -298,6 +348,8 @@ viz_component("service") {
       "display/overlay_processor_android.h",
       "display/overlay_processor_surface_control.cc",
       "display/overlay_processor_surface_control.h",
+      "display_embedder/gl_output_surface_android.cc",
+      "display_embedder/gl_output_surface_android.h",
       "frame_sinks/external_begin_frame_source_android.cc",
       "frame_sinks/external_begin_frame_source_android.h",
       "gl/throw_uncaught_exception.cc",
@@ -515,6 +567,7 @@ viz_source_set("unit_tests") {
     "display/delegated_ink_point_pixel_test_helper.cc",
     "display/delegated_ink_point_pixel_test_helper.h",
     "display/display_damage_tracker_unittest.cc",
+    "display/display_resource_provider_gl_unittest.cc",
     "display/display_resource_provider_skia_unittest.cc",
     "display/display_resource_provider_software_unittest.cc",
     "display/display_scheduler_unittest.cc",
@@ -522,15 +575,19 @@ viz_source_set("unit_tests") {
     "display/draw_polygon_unittest.cc",
     "display/frame_rate_decider_unittest.cc",
     "display/overlay_candidate_factory_unittest.cc",
+    "display/layer_quad_unittest.cc",
     "display/renderer_pixeltest.cc",
     "display/resolved_frame_data_unittest.cc",
+    "display/shader_unittest.cc",
     "display/skia_readback_pixeltest.cc",
     "display/software_renderer_unittest.cc",
     "display/surface_aggregator_pixeltest.cc",
     "display/surface_aggregator_unittest.cc",
+    "display/texture_deleter_unittest.cc",
     "display/viz_pixel_test.cc",
     "display/viz_pixel_test.h",
     "display_embedder/buffer_queue_unittest.cc",
+    "display_embedder/gl_output_surface_buffer_queue_unittest.cc",
     "display_embedder/server_shared_bitmap_manager_unittest.cc",
     "display_embedder/skia_output_device_buffer_queue_unittest.cc",
     "display_embedder/skia_output_surface_impl_unittest.cc",
diff --git components/viz/service/compositor_frame_fuzzer/fuzzer_software_output_surface_provider.cc components/viz/service/compositor_frame_fuzzer/fuzzer_software_output_surface_provider.cc
index 30074e5e32f1d..04c66d6ff0cfc 100644
--- components/viz/service/compositor_frame_fuzzer/fuzzer_software_output_surface_provider.cc
+++ components/viz/service/compositor_frame_fuzzer/fuzzer_software_output_surface_provider.cc
@@ -89,7 +89,8 @@ FuzzerSoftwareOutputSurfaceProvider::~FuzzerSoftwareOutputSurfaceProvider() =
 std::unique_ptr<DisplayCompositorMemoryAndTaskController>
 FuzzerSoftwareOutputSurfaceProvider::CreateGpuDependency(
     bool gpu_compositing,
-    gpu::SurfaceHandle surface_handle) {
+    gpu::SurfaceHandle surface_handle,
+    const RendererSettings& renderer_settings) {
   return nullptr;
 }
 
diff --git components/viz/service/compositor_frame_fuzzer/fuzzer_software_output_surface_provider.h components/viz/service/compositor_frame_fuzzer/fuzzer_software_output_surface_provider.h
index 531fc64017bad..e4471fb22419b 100644
--- components/viz/service/compositor_frame_fuzzer/fuzzer_software_output_surface_provider.h
+++ components/viz/service/compositor_frame_fuzzer/fuzzer_software_output_surface_provider.h
@@ -30,7 +30,8 @@ class FuzzerSoftwareOutputSurfaceProvider : public OutputSurfaceProvider {
   // OutputSurfaceProvider implementation.
   std::unique_ptr<DisplayCompositorMemoryAndTaskController> CreateGpuDependency(
       bool gpu_compositing,
-      gpu::SurfaceHandle surface_handle) override;
+      gpu::SurfaceHandle surface_handle,
+      const RendererSettings& renderer_settings) override;
   std::unique_ptr<OutputSurface> CreateOutputSurface(
       gpu::SurfaceHandle surface_handle,
       bool gpu_compositing,
diff --git components/viz/service/display/direct_renderer.cc components/viz/service/display/direct_renderer.cc
index 4830d0ab4f48f..60c3c05fad2e4 100644
--- components/viz/service/display/direct_renderer.cc
+++ components/viz/service/display/direct_renderer.cc
@@ -98,10 +98,21 @@ DirectRenderer::DirectRenderer(const RendererSettings* settings,
 DirectRenderer::~DirectRenderer() = default;
 
 void DirectRenderer::Initialize() {
+  auto* context_provider = output_surface_->context_provider();
+
   use_partial_swap_ = settings_->partial_swap_enabled && CanPartialSwap();
-  allow_empty_swap_ =
-      use_partial_swap_ ||
-      output_surface_->capabilities().supports_commit_overlay_planes;
+  allow_empty_swap_ = use_partial_swap_;
+  if (context_provider) {
+    if (context_provider->ContextCapabilities().commit_overlay_planes)
+      allow_empty_swap_ = true;
+#if DCHECK_IS_ON()
+    supports_occlusion_query_ =
+        context_provider->ContextCapabilities().occlusion_query;
+#endif
+  } else {
+    allow_empty_swap_ |=
+        output_surface_->capabilities().supports_commit_overlay_planes;
+  }
 
   initialized_ = true;
 }
@@ -236,6 +247,16 @@ void DirectRenderer::DrawFrame(
   auto* root_render_pass = render_passes_in_draw_order->back().get();
   DCHECK(root_render_pass);
 
+#if DCHECK_IS_ON()
+  bool overdraw_tracing_enabled;
+  TRACE_EVENT_CATEGORY_GROUP_ENABLED(TRACE_DISABLED_BY_DEFAULT("viz.overdraw"),
+                                     &overdraw_tracing_enabled);
+  DLOG_IF(WARNING, !overdraw_tracing_support_missing_logged_once_ &&
+                       overdraw_tracing_enabled && !supports_occlusion_query_)
+      << "Overdraw tracing enabled on platform without support.";
+  overdraw_tracing_support_missing_logged_once_ = true;
+#endif
+
   bool overdraw_feedback = debug_settings_->show_overdraw_feedback;
   if (overdraw_feedback && !output_surface_->capabilities().supports_stencil) {
 #if DCHECK_IS_ON()
diff --git components/viz/service/display/direct_renderer.h components/viz/service/display/direct_renderer.h
index c9caac83c3a3f..288cb666634c6 100644
--- components/viz/service/display/direct_renderer.h
+++ components/viz/service/display/direct_renderer.h
@@ -408,8 +408,11 @@ class VIZ_SERVICE_EXPORT DirectRenderer {
   virtual void DrawDelegatedInkTrail();
 
   bool initialized_ = false;
+
 #if DCHECK_IS_ON()
   bool overdraw_feedback_support_missing_logged_once_ = false;
+  bool overdraw_tracing_support_missing_logged_once_ = false;
+  bool supports_occlusion_query_ = false;
 #endif
   gfx::Rect last_root_render_pass_scissor_rect_;
   gfx::Size enlarge_pass_texture_amount_;
diff --git components/viz/service/display/display.cc components/viz/service/display/display.cc
index cfb6002e58ee8..6d7149fef5c3a 100644
--- components/viz/service/display/display.cc
+++ components/viz/service/display/display.cc
@@ -26,7 +26,6 @@
 #include "components/viz/common/display/renderer_settings.h"
 #include "components/viz/common/features.h"
 #include "components/viz/common/frame_sinks/begin_frame_source.h"
-#include "components/viz/common/quads/aggregated_render_pass_draw_quad.h"
 #include "components/viz/common/quads/compositor_frame.h"
 #include "components/viz/common/quads/draw_quad.h"
 #include "components/viz/common/quads/shared_quad_state.h"
@@ -37,10 +36,12 @@
 #include "components/viz/service/display/delegated_ink_point_renderer_base.h"
 #include "components/viz/service/display/direct_renderer.h"
 #include "components/viz/service/display/display_client.h"
+#include "components/viz/service/display/display_resource_provider_gl.h"
 #include "components/viz/service/display/display_resource_provider_null.h"
 #include "components/viz/service/display/display_resource_provider_skia.h"
 #include "components/viz/service/display/display_resource_provider_software.h"
 #include "components/viz/service/display/display_scheduler.h"
+#include "components/viz/service/display/gl_renderer.h"
 #include "components/viz/service/display/null_renderer.h"
 #include "components/viz/service/display/output_surface.h"
 #include "components/viz/service/display/renderer_utils.h"
@@ -333,6 +334,15 @@ Display::~Display() {
   if (resource_provider_) {
     resource_provider_->SetAllowAccessToGPUThread(true);
   }
+#if BUILDFLAG(IS_ANDROID)
+  // In certain cases, drivers hang when tearing down the display. Finishing
+  // before teardown appears to address this. As we're during display teardown,
+  // an additional finish should have minimal impact.
+  // TODO(ericrk): Add a more robust workaround. crbug.com/899705
+  if (auto* context = output_surface_->context_provider()) {
+    context->ContextGL()->Finish();
+  }
+#endif
 
   if (no_pending_swaps_callback_)
     std::move(no_pending_swaps_callback_).Run();
@@ -347,6 +357,8 @@ Display::~Display() {
 
   // Only do this if Initialize() happened.
   if (client_) {
+    if (auto* context = output_surface_->context_provider())
+      context->RemoveObserver(this);
     if (skia_output_surface_)
       skia_output_surface_->RemoveContextLostObserver(this);
   }
@@ -388,6 +400,9 @@ void Display::Initialize(DisplayClient* client,
   // This depends on assumptions that Display::Initialize will happen on the
   // same callstack as the ContextProvider being created/initialized or else
   // it could miss a callback before setting this.
+  if (auto* context = output_surface_->context_provider())
+    context->AddObserver(this);
+
   if (skia_output_surface_)
     skia_output_surface_->AddContextLostObserver(this);
 }
@@ -467,7 +482,8 @@ void Display::DisableSwapUntilResize(
       scheduler_->ForceImmediateSwapIfPossible();
 
     if (no_pending_swaps_callback && pending_swaps_ > 0 &&
-        output_surface_->AsSkiaOutputSurface()) {
+        (output_surface_->context_provider() ||
+         output_surface_->AsSkiaOutputSurface())) {
       no_pending_swaps_callback_ = std::move(no_pending_swaps_callback);
     }
 
@@ -520,6 +536,14 @@ void Display::InitializeRenderer(bool enable_shared_images) {
         resource_provider.get(), overlay_processor_.get(),
         skia_output_surface_);
     resource_provider_ = std::move(resource_provider);
+  } else if (output_surface_->context_provider()) {
+    auto resource_provider = std::make_unique<DisplayResourceProviderGL>(
+        output_surface_->context_provider(), enable_shared_images);
+    renderer_ = std::make_unique<GLRenderer>(
+        &settings_, debug_settings_, output_surface_.get(),
+        resource_provider.get(), overlay_processor_.get(),
+        current_task_runner_);
+    resource_provider_ = std::move(resource_provider);
   } else if (output_surface_->capabilities().skips_draw) {
     auto resource_provider = std::make_unique<DisplayResourceProviderNull>();
     renderer_ = std::make_unique<NullRenderer>(
diff --git components/viz/service/display/display_resource_provider_gl.cc components/viz/service/display/display_resource_provider_gl.cc
new file mode 100644
index 0000000000000..6b8ed375fb43e
--- /dev/null
+++ components/viz/service/display/display_resource_provider_gl.cc
@@ -0,0 +1,427 @@
+// Copyright 2021 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "components/viz/service/display/display_resource_provider_gl.h"
+
+#include <utility>
+#include <vector>
+
+#include "base/dcheck_is_on.h"
+#include "base/memory/raw_ptr.h"
+#include "base/trace_event/trace_event.h"
+#include "build/build_config.h"
+#include "components/viz/common/gpu/context_provider.h"
+#include "gpu/GLES2/gl2extchromium.h"
+#include "gpu/command_buffer/client/gles2_interface.h"
+#include "ui/gfx/gpu_fence.h"
+#include "ui/gl/gl_fence.h"
+
+using gpu::gles2::GLES2Interface;
+
+namespace viz {
+namespace {
+
+class ScopedSetActiveTexture {
+ public:
+  ScopedSetActiveTexture(GLES2Interface* gl, GLenum unit)
+      : gl_(gl), unit_(unit) {
+#if DCHECK_IS_ON()
+    GLint active_unit = 0;
+    gl->GetIntegerv(GL_ACTIVE_TEXTURE, &active_unit);
+    DCHECK_EQ(GL_TEXTURE0, active_unit);
+#endif
+
+    if (unit_ != GL_TEXTURE0)
+      gl_->ActiveTexture(unit_);
+  }
+
+  ~ScopedSetActiveTexture() {
+    // Active unit being GL_TEXTURE0 is effectively the ground state.
+    if (unit_ != GL_TEXTURE0)
+      gl_->ActiveTexture(GL_TEXTURE0);
+  }
+
+ private:
+  raw_ptr<GLES2Interface> gl_;
+  GLenum unit_;
+};
+
+}  // namespace
+
+DisplayResourceProviderGL::DisplayResourceProviderGL(
+    ContextProvider* compositor_context_provider,
+    bool enable_shared_images)
+    : DisplayResourceProvider(DisplayResourceProvider::kGpu),
+      compositor_context_provider_(compositor_context_provider),
+      enable_shared_images_(enable_shared_images) {
+  DCHECK(compositor_context_provider_);
+}
+
+DisplayResourceProviderGL::~DisplayResourceProviderGL() {
+  Destroy();
+  GLES2Interface* gl = ContextGL();
+  if (gl)
+    gl->Finish();
+
+  while (!resources_.empty())
+    DeleteResourceInternal(resources_.begin());
+}
+
+void DisplayResourceProviderGL::DeleteResourceInternal(
+    ResourceMap::iterator it) {
+  TRACE_EVENT0("viz", "DisplayResourceProvider::DeleteResourceInternal");
+  ChildResource* resource = &it->second;
+
+  if (resource->gl_id) {
+    GLES2Interface* gl = ContextGL();
+    DCHECK(gl);
+    gl->DeleteTextures(1, &resource->gl_id);
+  }
+
+  resources_.erase(it);
+}
+
+GLES2Interface* DisplayResourceProviderGL::ContextGL() const {
+  DCHECK(compositor_context_provider_);
+  return compositor_context_provider_->ContextGL();
+}
+
+const DisplayResourceProvider::ChildResource*
+DisplayResourceProviderGL::LockForRead(ResourceId id, bool overlay_only) {
+  // TODO(ericrk): We should never fail TryGetResource, but we appear to be
+  // doing so on Android in rare cases. Handle this gracefully until a better
+  // solution can be found. https://crbug.com/811858
+  ChildResource* resource = TryGetResource(id);
+  if (!resource)
+    return nullptr;
+
+  // Mailbox sync_tokens must be processed by a call to WaitSyncToken() prior to
+  // calling LockForRead().
+  DCHECK_NE(NEEDS_WAIT, resource->synchronization_state());
+  DCHECK(resource->is_gpu_resource_type());
+
+  const gpu::Mailbox& mailbox = resource->transferable.mailbox_holder.mailbox;
+  GLES2Interface* gl = ContextGL();
+  DCHECK(gl);
+  if (!resource->gl_id) {
+    if (mailbox.IsSharedImage() && enable_shared_images_) {
+      resource->gl_id =
+          gl->CreateAndTexStorage2DSharedImageCHROMIUM(mailbox.name);
+    } else {
+      resource->gl_id = gl->CreateAndConsumeTextureCHROMIUM(
+          resource->transferable.mailbox_holder.mailbox.name);
+    }
+    resource->SetLocallyUsed();
+  }
+  if (mailbox.IsSharedImage() && enable_shared_images_) {
+    if (overlay_only) {
+      if (resource->lock_for_overlay_count == 0) {
+        // If |lock_for_read_count| > 0, then BeginSharedImageAccess has
+        // already been called with READ, so don't re-lock with OVERLAY.
+        if (resource->lock_for_read_count == 0) {
+          gl->BeginSharedImageAccessDirectCHROMIUM(
+              resource->gl_id, GL_SHARED_IMAGE_ACCESS_MODE_OVERLAY_CHROMIUM);
+        }
+      }
+    } else {
+      if (resource->lock_for_read_count == 0) {
+        // If |lock_for_overlay_count| > 0, then we have already begun access
+        // for OVERLAY. End this access and "upgrade" it to READ.
+        // See https://crbug.com/1113925 for how this can go wrong.
+        if (resource->lock_for_overlay_count > 0)
+          gl->EndSharedImageAccessDirectCHROMIUM(resource->gl_id);
+        gl->BeginSharedImageAccessDirectCHROMIUM(
+            resource->gl_id, GL_SHARED_IMAGE_ACCESS_MODE_READ_CHROMIUM);
+      }
+    }
+  }
+
+  if (overlay_only)
+    resource->lock_for_overlay_count++;
+  else
+    resource->lock_for_read_count++;
+  if (resource->transferable.synchronization_type ==
+      TransferableResource::SynchronizationType::kGpuCommandsCompleted) {
+    if (current_read_lock_fence_.get())
+      current_read_lock_fence_->Set();
+    resource->read_lock_fence = current_read_lock_fence_;
+  }
+
+  return resource;
+}
+
+void DisplayResourceProviderGL::UnlockForRead(ResourceId id,
+                                              bool overlay_only) {
+  DCHECK_CALLED_ON_VALID_THREAD(thread_checker_);
+  ChildResource* resource = TryGetResource(id);
+  // TODO(ericrk): We should never fail to find id, but we appear to be
+  // doing so on Android in rare cases. Handle this gracefully until a better
+  // solution can be found. https://crbug.com/811858
+  if (!resource)
+    return;
+
+  DCHECK(resource->is_gpu_resource_type());
+  if (resource->transferable.mailbox_holder.mailbox.IsSharedImage() &&
+      enable_shared_images_) {
+    // If this is the last READ or OVERLAY access, then end access.
+    if (resource->lock_for_read_count + resource->lock_for_overlay_count == 1) {
+      DCHECK(resource->gl_id);
+      GLES2Interface* gl = ContextGL();
+      DCHECK(gl);
+      if (!resource->release_fence.is_null()) {
+        auto fence = gfx::GpuFence(resource->release_fence.Clone());
+        if (gl::GLFence::IsGpuFenceSupported()) {
+          auto fence_id =
+              gl->CreateClientGpuFenceCHROMIUM(fence.AsClientGpuFence());
+          gl->WaitGpuFenceCHROMIUM(fence_id);
+          gl->DestroyGpuFenceCHROMIUM(fence_id);
+        } else {
+          fence.Wait();
+        }
+      }
+      gl->EndSharedImageAccessDirectCHROMIUM(resource->gl_id);
+    }
+  }
+  if (overlay_only) {
+    DCHECK_GT(resource->lock_for_overlay_count, 0);
+    resource->lock_for_overlay_count--;
+  } else {
+    DCHECK_GT(resource->lock_for_read_count, 0);
+    resource->lock_for_read_count--;
+  }
+  TryReleaseResource(id, resource);
+}
+
+std::vector<ReturnedResource>
+DisplayResourceProviderGL::DeleteAndReturnUnusedResourcesToChildImpl(
+    Child& child_info,
+    DeleteStyle style,
+    const std::vector<ResourceId>& unused) {
+  std::vector<ReturnedResource> to_return;
+  // Reserve enough space to avoid re-allocating, so we can keep item pointers
+  // for later using.
+  to_return.reserve(unused.size());
+  std::vector<ReturnedResource*> need_synchronization_resources;
+  std::vector<GLbyte*> unverified_sync_tokens;
+
+  GLES2Interface* gl = ContextGL();
+  DCHECK(gl);
+  DCHECK(can_access_gpu_thread_);
+  for (ResourceId local_id : unused) {
+    auto it = resources_.find(local_id);
+    CHECK(it != resources_.end());
+    ChildResource& resource = it->second;
+    DCHECK(resource.is_gpu_resource_type());
+
+    ResourceId child_id = resource.transferable.id;
+    DCHECK(child_info.child_to_parent_map.count(child_id));
+
+    auto can_delete = CanDeleteNow(child_info, resource, style);
+    if (can_delete == CanDeleteNowResult::kNo) {
+      // Defer this resource deletion.
+      resource.marked_for_deletion = true;
+      continue;
+    }
+
+    const bool is_lost = can_delete == CanDeleteNowResult::kYesButLoseResource;
+
+    if (resource.gl_id && resource.filter != resource.transferable.filter) {
+      DCHECK(resource.transferable.mailbox_holder.texture_target);
+      DCHECK(!resource.ShouldWaitSyncToken());
+      gl->BindTexture(resource.transferable.mailbox_holder.texture_target,
+                      resource.gl_id);
+      gl->TexParameteri(resource.transferable.mailbox_holder.texture_target,
+                        GL_TEXTURE_MIN_FILTER, resource.transferable.filter);
+      gl->TexParameteri(resource.transferable.mailbox_holder.texture_target,
+                        GL_TEXTURE_MAG_FILTER, resource.transferable.filter);
+      resource.SetLocallyUsed();
+    }
+
+    to_return.emplace_back(child_id, resource.sync_token(),
+                           std::move(resource.release_fence),
+                           resource.imported_count, is_lost);
+    auto& returned = to_return.back();
+
+    if (resource.needs_sync_token()) {
+      need_synchronization_resources.push_back(&returned);
+    } else if (returned.sync_token.HasData() &&
+               !returned.sync_token.verified_flush()) {
+      unverified_sync_tokens.push_back(returned.sync_token.GetData());
+    }
+
+    child_info.child_to_parent_map.erase(child_id);
+    resource.imported_count = 0;
+    DeleteResourceInternal(it);
+  }
+
+  gpu::SyncToken new_sync_token;
+  if (!need_synchronization_resources.empty()) {
+    gl->GenUnverifiedSyncTokenCHROMIUM(new_sync_token.GetData());
+    unverified_sync_tokens.push_back(new_sync_token.GetData());
+  }
+
+  if (!unverified_sync_tokens.empty()) {
+    gl->VerifySyncTokensCHROMIUM(unverified_sync_tokens.data(),
+                                 unverified_sync_tokens.size());
+  }
+
+  // Set sync token after verification.
+  for (ReturnedResource* returned : need_synchronization_resources)
+    returned->sync_token = new_sync_token;
+
+  return to_return;
+}
+
+GLenum DisplayResourceProviderGL::GetResourceTextureTarget(ResourceId id) {
+  return GetResource(id)->transferable.mailbox_holder.texture_target;
+}
+
+void DisplayResourceProviderGL::WaitSyncToken(ResourceId id) {
+  ChildResource* resource = TryGetResource(id);
+  // TODO(ericrk): We should never fail TryGetResource, but we appear to
+  // be doing so on Android in rare cases. Handle this gracefully until a
+  // better solution can be found. https://crbug.com/811858
+  if (!resource)
+    return;
+  WaitSyncTokenInternal(resource);
+}
+
+GLenum DisplayResourceProviderGL::BindForSampling(ResourceId resource_id,
+                                                  GLenum unit,
+                                                  GLenum filter) {
+  DCHECK_CALLED_ON_VALID_THREAD(thread_checker_);
+  GLES2Interface* gl = ContextGL();
+  auto it = resources_.find(resource_id);
+  // TODO(ericrk): We should never fail to find resource_id, but we appear to
+  // be doing so on Android in rare cases. Handle this gracefully until a
+  // better solution can be found. https://crbug.com/811858
+  if (it == resources_.end())
+    return GL_TEXTURE_2D;
+
+  ChildResource* resource = &it->second;
+  DCHECK(resource->lock_for_read_count);
+
+  ScopedSetActiveTexture scoped_active_tex(gl, unit);
+  GLenum target = resource->transferable.mailbox_holder.texture_target;
+  gl->BindTexture(target, resource->gl_id);
+
+  // Texture parameters can be modified by concurrent reads so reset them
+  // before binding the texture. See https://crbug.com/1092080.
+  gl->TexParameteri(target, GL_TEXTURE_MIN_FILTER, filter);
+  gl->TexParameteri(target, GL_TEXTURE_MAG_FILTER, filter);
+  resource->filter = filter;
+
+  return target;
+}
+
+void DisplayResourceProviderGL::WaitSyncTokenInternal(ChildResource* resource) {
+  DCHECK(resource);
+  if (!resource->ShouldWaitSyncToken())
+    return;
+  GLES2Interface* gl = ContextGL();
+  DCHECK(gl);
+  // In the case of context lost, this sync token may be empty (see comment in
+  // the UpdateSyncToken() function). The WaitSyncTokenCHROMIUM() function
+  // handles empty sync tokens properly so just wait anyways and update the
+  // state the synchronized.
+  gl->WaitSyncTokenCHROMIUM(resource->sync_token().GetConstData());
+  resource->SetSynchronized();
+}
+
+DisplayResourceProviderGL::ScopedReadLockGL::ScopedReadLockGL(
+    DisplayResourceProviderGL* resource_provider,
+    ResourceId resource_id)
+    : resource_provider_(resource_provider), resource_id_(resource_id) {
+  const ChildResource* resource =
+      resource_provider->LockForRead(resource_id, false /* overlay_only */);
+  // TODO(ericrk): We should never fail LockForRead, but we appear to be
+  // doing so on Android in rare cases. Handle this gracefully until a better
+  // solution can be found. https://crbug.com/811858
+  if (!resource)
+    return;
+
+  texture_id_ = resource->gl_id;
+  target_ = resource->transferable.mailbox_holder.texture_target;
+  size_ = resource->transferable.size;
+  color_space_ = resource->transferable.color_space;
+  hdr_metadata_ = resource->transferable.hdr_metadata;
+}
+
+DisplayResourceProviderGL::ScopedReadLockGL::~ScopedReadLockGL() {
+  resource_provider_->UnlockForRead(resource_id_, false /* overlay_only */);
+}
+
+DisplayResourceProviderGL::ScopedSamplerGL::ScopedSamplerGL(
+    DisplayResourceProviderGL* resource_provider,
+    ResourceId resource_id,
+    GLenum filter)
+    : resource_lock_(resource_provider, resource_id),
+      unit_(GL_TEXTURE0),
+      target_(resource_provider->BindForSampling(resource_id, unit_, filter)) {}
+
+DisplayResourceProviderGL::ScopedSamplerGL::ScopedSamplerGL(
+    DisplayResourceProviderGL* resource_provider,
+    ResourceId resource_id,
+    GLenum unit,
+    GLenum filter)
+    : resource_lock_(resource_provider, resource_id),
+      unit_(unit),
+      target_(resource_provider->BindForSampling(resource_id, unit_, filter)) {}
+
+DisplayResourceProviderGL::ScopedSamplerGL::~ScopedSamplerGL() = default;
+
+DisplayResourceProviderGL::ScopedOverlayLockGL::ScopedOverlayLockGL(
+    DisplayResourceProviderGL* resource_provider,
+    ResourceId resource_id)
+    : resource_provider_(resource_provider), resource_id_(resource_id) {
+  const ChildResource* resource =
+      resource_provider->LockForRead(resource_id, true /* overlay_only */);
+  if (!resource)
+    return;
+
+  texture_id_ = resource->gl_id;
+}
+
+DisplayResourceProviderGL::ScopedOverlayLockGL::~ScopedOverlayLockGL() {
+  resource_provider_->UnlockForRead(resource_id_, true /* overlay_only */);
+}
+
+void DisplayResourceProviderGL::ScopedOverlayLockGL::SetReleaseFence(
+    gfx::GpuFenceHandle release_fence) {
+  auto* resource = resource_provider_->GetResource(resource_id_);
+  DCHECK(resource);
+  resource->release_fence = std::move(release_fence);
+}
+
+bool DisplayResourceProviderGL::ScopedOverlayLockGL::HasReadLockFence() const {
+  auto* resource = resource_provider_->GetResource(resource_id_);
+  DCHECK(resource);
+  return resource->transferable.synchronization_type ==
+         TransferableResource::SynchronizationType::kGpuCommandsCompleted;
+}
+
+DisplayResourceProviderGL::SynchronousFence::SynchronousFence(
+    gpu::gles2::GLES2Interface* gl)
+    : gl_(gl), has_synchronized_(true) {}
+
+DisplayResourceProviderGL::SynchronousFence::~SynchronousFence() = default;
+
+void DisplayResourceProviderGL::SynchronousFence::Set() {
+  has_synchronized_ = false;
+}
+
+bool DisplayResourceProviderGL::SynchronousFence::HasPassed() {
+  if (!has_synchronized_) {
+    has_synchronized_ = true;
+    Synchronize();
+  }
+  return true;
+}
+
+void DisplayResourceProviderGL::SynchronousFence::Synchronize() {
+  TRACE_EVENT0("viz", "DisplayResourceProvider::SynchronousFence::Synchronize");
+  gl_->Finish();
+}
+
+}  // namespace viz
diff --git components/viz/service/display/display_resource_provider_gl.h components/viz/service/display/display_resource_provider_gl.h
new file mode 100644
index 0000000000000..8a75cf568a81d
--- /dev/null
+++ components/viz/service/display/display_resource_provider_gl.h
@@ -0,0 +1,165 @@
+// Copyright 2021 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef COMPONENTS_VIZ_SERVICE_DISPLAY_DISPLAY_RESOURCE_PROVIDER_GL_H_
+#define COMPONENTS_VIZ_SERVICE_DISPLAY_DISPLAY_RESOURCE_PROVIDER_GL_H_
+
+#include <vector>
+
+#include "base/memory/raw_ptr.h"
+#include "components/viz/service/display/display_resource_provider.h"
+#include "components/viz/service/viz_service_export.h"
+
+namespace gpu {
+namespace gles2 {
+class GLES2Interface;
+}  // namespace gles2
+}  // namespace gpu
+
+namespace viz {
+
+class ContextProvider;
+
+// DisplayResourceProvider implementation used with GLRenderer.
+class VIZ_SERVICE_EXPORT DisplayResourceProviderGL
+    : public DisplayResourceProvider {
+ public:
+  // Android with GLRenderer doesn't support overlays with shared images
+  // enabled. For everything else |enable_shared_images| is true.
+  DisplayResourceProviderGL(ContextProvider* compositor_context_provider,
+                            bool enable_shared_images = true);
+  ~DisplayResourceProviderGL() override;
+
+  GLenum GetResourceTextureTarget(ResourceId id);
+  void WaitSyncToken(ResourceId id);
+
+  // The following lock classes are part of the DisplayResourceProvider API and
+  // are needed to read the resource contents. The user must ensure that they
+  // only use GL locks on GL resources, etc, and this is enforced by assertions.
+  class VIZ_SERVICE_EXPORT ScopedReadLockGL {
+   public:
+    ScopedReadLockGL(DisplayResourceProviderGL* resource_provider,
+                     ResourceId resource_id);
+    ~ScopedReadLockGL();
+
+    ScopedReadLockGL(const ScopedReadLockGL&) = delete;
+    ScopedReadLockGL& operator=(const ScopedReadLockGL&) = delete;
+
+    GLuint texture_id() const { return texture_id_; }
+    GLenum target() const { return target_; }
+    const gfx::Size& size() const { return size_; }
+    const gfx::ColorSpace& color_space() const { return color_space_; }
+    const absl::optional<gfx::HDRMetadata>& hdr_metadata() const {
+      return hdr_metadata_;
+    }
+
+   private:
+    const raw_ptr<DisplayResourceProviderGL> resource_provider_;
+    const ResourceId resource_id_;
+
+    GLuint texture_id_ = 0;
+    GLenum target_ = GL_TEXTURE_2D;
+    gfx::Size size_;
+    gfx::ColorSpace color_space_;
+    absl::optional<gfx::HDRMetadata> hdr_metadata_;
+  };
+
+  class VIZ_SERVICE_EXPORT ScopedSamplerGL {
+   public:
+    ScopedSamplerGL(DisplayResourceProviderGL* resource_provider,
+                    ResourceId resource_id,
+                    GLenum filter);
+    ScopedSamplerGL(DisplayResourceProviderGL* resource_provider,
+                    ResourceId resource_id,
+                    GLenum unit,
+                    GLenum filter);
+    ~ScopedSamplerGL();
+
+    ScopedSamplerGL(const ScopedSamplerGL&) = delete;
+    ScopedSamplerGL& operator=(const ScopedSamplerGL&) = delete;
+
+    GLuint texture_id() const { return resource_lock_.texture_id(); }
+    GLenum target() const { return target_; }
+    const gfx::ColorSpace& color_space() const {
+      return resource_lock_.color_space();
+    }
+    const absl::optional<gfx::HDRMetadata>& hdr_metadata() const {
+      return resource_lock_.hdr_metadata();
+    }
+
+   private:
+    const ScopedReadLockGL resource_lock_;
+    const GLenum unit_;
+    const GLenum target_;
+  };
+
+  class VIZ_SERVICE_EXPORT ScopedOverlayLockGL {
+   public:
+    ScopedOverlayLockGL(DisplayResourceProviderGL* resource_provider,
+                        ResourceId resource_id);
+    ~ScopedOverlayLockGL();
+
+    ScopedOverlayLockGL(const ScopedOverlayLockGL&) = delete;
+    ScopedOverlayLockGL& operator=(const ScopedOverlayLockGL&) = delete;
+
+    GLuint texture_id() const { return texture_id_; }
+
+    // Sets the given |release_fence| onto this resource.
+    // This is propagated to ReturnedResource when the resource is freed.
+    void SetReleaseFence(gfx::GpuFenceHandle release_fence);
+
+    // Returns true iff this resource has a read lock fence set.
+    bool HasReadLockFence() const;
+
+   private:
+    const raw_ptr<DisplayResourceProviderGL> resource_provider_;
+    const ResourceId resource_id_;
+    GLuint texture_id_ = 0;
+  };
+
+  class VIZ_SERVICE_EXPORT SynchronousFence : public ResourceFence {
+   public:
+    explicit SynchronousFence(gpu::gles2::GLES2Interface* gl);
+
+    SynchronousFence(const SynchronousFence&) = delete;
+    SynchronousFence& operator=(const SynchronousFence&) = delete;
+
+    // ResourceFence implementation.
+    void Set() override;
+    bool HasPassed() override;
+
+    // Returns true if fence has been set but not yet synchornized.
+    bool has_synchronized() const { return has_synchronized_; }
+
+   private:
+    ~SynchronousFence() override;
+
+    void Synchronize();
+
+    raw_ptr<gpu::gles2::GLES2Interface> gl_;
+    bool has_synchronized_;
+  };
+
+ private:
+  const ChildResource* LockForRead(ResourceId id, bool overlay_only);
+  void UnlockForRead(ResourceId id, bool overlay_only);
+
+  // DisplayResourceProvider overrides:
+  std::vector<ReturnedResource> DeleteAndReturnUnusedResourcesToChildImpl(
+      Child& child_info,
+      DeleteStyle style,
+      const std::vector<ResourceId>& unused) override;
+
+  gpu::gles2::GLES2Interface* ContextGL() const;
+  void DeleteResourceInternal(ResourceMap::iterator it);
+  GLenum BindForSampling(ResourceId resource_id, GLenum unit, GLenum filter);
+  void WaitSyncTokenInternal(ChildResource* resource);
+
+  const raw_ptr<ContextProvider> compositor_context_provider_;
+  const bool enable_shared_images_;
+};
+
+}  // namespace viz
+
+#endif  // COMPONENTS_VIZ_SERVICE_DISPLAY_DISPLAY_RESOURCE_PROVIDER_GL_H_
diff --git components/viz/service/display/display_resource_provider_gl_unittest.cc components/viz/service/display/display_resource_provider_gl_unittest.cc
new file mode 100644
index 0000000000000..a71ac8d9e75fa
--- /dev/null
+++ components/viz/service/display/display_resource_provider_gl_unittest.cc
@@ -0,0 +1,722 @@
+// Copyright 2021 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "components/viz/service/display/display_resource_provider_gl.h"
+
+#include <stddef.h>
+#include <stdint.h>
+
+#include <memory>
+#include <set>
+#include <unordered_map>
+#include <utility>
+#include <vector>
+
+#include "base/bind.h"
+#include "base/callback_helpers.h"
+#include "base/check.h"
+#include "base/memory/raw_ptr.h"
+#include "base/memory/ref_counted.h"
+#include "build/build_config.h"
+#include "components/viz/client/client_resource_provider.h"
+#include "components/viz/common/resources/release_callback.h"
+#include "components/viz/common/resources/resource_format_utils.h"
+#include "components/viz/common/resources/returned_resource.h"
+#include "components/viz/test/test_context_provider.h"
+#include "components/viz/test/test_gles2_interface.h"
+#include "gpu/GLES2/gl2extchromium.h"
+#include "testing/gmock/include/gmock/gmock.h"
+#include "testing/gtest/include/gtest/gtest.h"
+#include "third_party/khronos/GLES2/gl2.h"
+#include "third_party/khronos/GLES2/gl2ext.h"
+#include "ui/gfx/geometry/rect.h"
+
+using testing::_;
+using testing::ByMove;
+using testing::DoAll;
+using testing::Return;
+using testing::SaveArg;
+
+namespace viz {
+namespace {
+
+class MockReleaseCallback {
+ public:
+  MOCK_METHOD2(Released, void(const gpu::SyncToken& token, bool lost));
+};
+
+MATCHER_P(MatchesSyncToken, sync_token, "") {
+  gpu::SyncToken other;
+  memcpy(&other, arg, sizeof(other));
+  return other == sync_token;
+}
+
+static void CollectResources(std::vector<ReturnedResource>* array,
+                             std::vector<ReturnedResource> returned) {
+  array->insert(array->end(), std::make_move_iterator(returned.begin()),
+                std::make_move_iterator(returned.end()));
+}
+
+class ResourceProviderGLES2Interface : public TestGLES2Interface {
+ public:
+  ResourceProviderGLES2Interface() = default;
+
+  void WaitSyncTokenCHROMIUM(const GLbyte* sync_token) override {
+    gpu::SyncToken sync_token_data;
+    if (sync_token)
+      memcpy(&sync_token_data, sync_token, sizeof(sync_token_data));
+
+    if (sync_token_data.release_count() >
+        last_waited_sync_token_.release_count()) {
+      last_waited_sync_token_ = sync_token_data;
+    }
+  }
+
+  const gpu::SyncToken& last_waited_sync_token() const {
+    return last_waited_sync_token_;
+  }
+
+ private:
+  gpu::SyncToken last_waited_sync_token_;
+};
+
+class DisplayResourceProviderGLTest : public testing::Test {
+ public:
+  DisplayResourceProviderGLTest() {
+    auto gl_owned = std::make_unique<ResourceProviderGLES2Interface>();
+    gl_ = gl_owned.get();
+    context_provider_ = TestContextProvider::Create(std::move(gl_owned));
+    context_provider_->UnboundTestContextGL()
+        ->set_support_texture_format_bgra8888(true);
+    context_provider_->BindToCurrentThread();
+
+    child_context_provider_ = TestContextProvider::Create();
+    child_context_provider_->UnboundTestContextGL()
+        ->set_support_texture_format_bgra8888(true);
+    child_context_provider_->BindToCurrentThread();
+
+    resource_provider_ =
+        std::make_unique<DisplayResourceProviderGL>(context_provider_.get());
+
+    child_resource_provider_ = std::make_unique<ClientResourceProvider>();
+  }
+
+  ~DisplayResourceProviderGLTest() override {
+    child_resource_provider_->ShutdownAndReleaseAllResources();
+  }
+
+  static ReturnCallback GetReturnCallback(
+      std::vector<ReturnedResource>* array) {
+    return base::BindRepeating(&CollectResources, array);
+  }
+
+  static void SetResourceFilter(DisplayResourceProviderGL* resource_provider,
+                                ResourceId id,
+                                GLenum filter) {
+    DisplayResourceProviderGL::ScopedSamplerGL sampler(resource_provider, id,
+                                                       GL_TEXTURE_2D, filter);
+  }
+
+  TransferableResource CreateResource(ResourceFormat format) {
+    constexpr gfx::Size size(64, 64);
+    gpu::Mailbox gpu_mailbox = gpu::Mailbox::Generate();
+    gpu::SyncToken sync_token = GenSyncToken();
+    EXPECT_TRUE(sync_token.HasData());
+
+    TransferableResource gl_resource = TransferableResource::MakeGL(
+        gpu_mailbox, GL_LINEAR, GL_TEXTURE_2D, sync_token, size,
+        false /* is_overlay_candidate */);
+    gl_resource.format = format;
+    return gl_resource;
+  }
+
+  ResourceId MakeGpuResourceAndSendToDisplay(
+      GLuint filter,
+      GLuint target,
+      const gpu::SyncToken& sync_token,
+      DisplayResourceProvider* resource_provider) {
+    ReturnCallback return_callback = base::DoNothing();
+
+    int child = resource_provider->CreateChild(return_callback, SurfaceId());
+
+    gpu::Mailbox gpu_mailbox = gpu::Mailbox::Generate();
+    constexpr gfx::Size size(64, 64);
+    auto resource =
+        TransferableResource::MakeGL(gpu_mailbox, GL_LINEAR, target, sync_token,
+                                     size, false /* is_overlay_candidate */);
+    resource.id = ResourceId(11);
+    resource_provider->ReceiveFromChild(child, {resource});
+    auto& map = resource_provider->GetChildToParentMap(child);
+    return map.find(resource.id)->second;
+  }
+
+  gpu::SyncToken GenSyncToken() {
+    gpu::SyncToken sync_token(gpu::CommandBufferNamespace::GPU_IO,
+                              gpu::CommandBufferId::FromUnsafeValue(0x123),
+                              next_fence_sync_++);
+    sync_token.SetVerifyFlush();
+    return sync_token;
+  }
+
+ protected:
+  raw_ptr<ResourceProviderGLES2Interface> gl_ = nullptr;
+  uint64_t next_fence_sync_ = 1;
+  scoped_refptr<TestContextProvider> context_provider_;
+  scoped_refptr<TestContextProvider> child_context_provider_;
+  std::unique_ptr<DisplayResourceProviderGL> resource_provider_;
+  std::unique_ptr<ClientResourceProvider> child_resource_provider_;
+};
+
+TEST_F(DisplayResourceProviderGLTest, ReadLockCountStopsReturnToChildOrDelete) {
+  MockReleaseCallback release;
+  TransferableResource tran = CreateResource(RGBA_8888);
+  ResourceId id1 = child_resource_provider_->ImportResource(
+      tran, base::BindOnce(&MockReleaseCallback::Released,
+                           base::Unretained(&release)));
+
+  std::vector<ReturnedResource> returned_to_child;
+  int child_id = resource_provider_->CreateChild(
+      GetReturnCallback(&returned_to_child), SurfaceId());
+  {
+    // Transfer some resources to the parent.
+    std::vector<TransferableResource> list;
+    child_resource_provider_->PrepareSendToParent(
+        {id1}, &list,
+        static_cast<RasterContextProvider*>(child_context_provider_.get()));
+    ASSERT_EQ(1u, list.size());
+    EXPECT_TRUE(child_resource_provider_->InUseByConsumer(id1));
+
+    resource_provider_->ReceiveFromChild(child_id, list);
+
+    // In DisplayResourceProvider's namespace, use the mapped resource id.
+    std::unordered_map<ResourceId, ResourceId, ResourceIdHasher> resource_map =
+        resource_provider_->GetChildToParentMap(child_id);
+    ResourceId mapped_resource_id = resource_map[list[0].id];
+    resource_provider_->WaitSyncToken(mapped_resource_id);
+    DisplayResourceProviderGL::ScopedReadLockGL lock(resource_provider_.get(),
+                                                     mapped_resource_id);
+
+    resource_provider_->DeclareUsedResourcesFromChild(child_id,
+                                                      ResourceIdSet());
+    EXPECT_EQ(0u, returned_to_child.size());
+  }
+
+  EXPECT_EQ(1u, returned_to_child.size());
+  child_resource_provider_->ReceiveReturnsFromParent(
+      std::move(returned_to_child));
+
+  // No need to wait for the sync token here -- it will be returned to the
+  // client on delete.
+  {
+    EXPECT_CALL(release, Released(_, _));
+    child_resource_provider_->RemoveImportedResource(id1);
+  }
+
+  resource_provider_->DestroyChild(child_id);
+}
+
+class TestFence : public ResourceFence {
+ public:
+  TestFence() = default;
+
+  // ResourceFence implementation.
+  void Set() override {}
+  bool HasPassed() override { return passed; }
+
+  bool passed = false;
+
+ private:
+  ~TestFence() override = default;
+};
+
+TEST_F(DisplayResourceProviderGLTest, ReadLockFenceStopsReturnToChildOrDelete) {
+  MockReleaseCallback release;
+  TransferableResource tran1 = CreateResource(RGBA_8888);
+  tran1.synchronization_type =
+      TransferableResource::SynchronizationType::kGpuCommandsCompleted;
+  ResourceId id1 = child_resource_provider_->ImportResource(
+      tran1, base::BindOnce(&MockReleaseCallback::Released,
+                            base::Unretained(&release)));
+
+  std::vector<ReturnedResource> returned_to_child;
+  int child_id = resource_provider_->CreateChild(
+      GetReturnCallback(&returned_to_child), SurfaceId());
+
+  // Transfer some resources to the parent.
+  std::vector<TransferableResource> list;
+  child_resource_provider_->PrepareSendToParent(
+      {id1}, &list,
+      static_cast<RasterContextProvider*>(child_context_provider_.get()));
+  ASSERT_EQ(1u, list.size());
+  EXPECT_TRUE(child_resource_provider_->InUseByConsumer(id1));
+  EXPECT_EQ(list[0].synchronization_type,
+            TransferableResource::SynchronizationType::kGpuCommandsCompleted);
+
+  resource_provider_->ReceiveFromChild(child_id, list);
+
+  // In DisplayResourceProvider's namespace, use the mapped resource id.
+  std::unordered_map<ResourceId, ResourceId, ResourceIdHasher> resource_map =
+      resource_provider_->GetChildToParentMap(child_id);
+
+  scoped_refptr<TestFence> fence(new TestFence);
+  resource_provider_->SetReadLockFence(fence.get());
+  {
+    ResourceId parent_id = resource_map[list.front().id];
+    resource_provider_->WaitSyncToken(parent_id);
+    DisplayResourceProviderGL::ScopedReadLockGL lock(resource_provider_.get(),
+                                                     parent_id);
+  }
+  resource_provider_->DeclareUsedResourcesFromChild(child_id, ResourceIdSet());
+  EXPECT_EQ(0u, returned_to_child.size());
+
+  resource_provider_->DeclareUsedResourcesFromChild(child_id, ResourceIdSet());
+  EXPECT_EQ(0u, returned_to_child.size());
+  fence->passed = true;
+
+  resource_provider_->DeclareUsedResourcesFromChild(child_id, ResourceIdSet());
+  EXPECT_EQ(1u, returned_to_child.size());
+
+  child_resource_provider_->ReceiveReturnsFromParent(
+      std::move(returned_to_child));
+  EXPECT_CALL(release, Released(_, _));
+  child_resource_provider_->RemoveImportedResource(id1);
+}
+
+TEST_F(DisplayResourceProviderGLTest, ReadLockFenceDestroyChild) {
+  MockReleaseCallback release;
+
+  TransferableResource tran1 = CreateResource(RGBA_8888);
+  tran1.synchronization_type =
+      TransferableResource::SynchronizationType::kGpuCommandsCompleted;
+  ResourceId id1 = child_resource_provider_->ImportResource(
+      tran1, base::BindOnce(&MockReleaseCallback::Released,
+                            base::Unretained(&release)));
+
+  TransferableResource tran2 = CreateResource(RGBA_8888);
+  ASSERT_EQ(tran2.synchronization_type,
+            TransferableResource::SynchronizationType::kSyncToken);
+  ResourceId id2 = child_resource_provider_->ImportResource(
+      tran2, base::BindOnce(&MockReleaseCallback::Released,
+                            base::Unretained(&release)));
+
+  std::vector<ReturnedResource> returned_to_child;
+  int child_id = resource_provider_->CreateChild(
+      GetReturnCallback(&returned_to_child), SurfaceId());
+
+  // Transfer resources to the parent.
+  std::vector<TransferableResource> list;
+  child_resource_provider_->PrepareSendToParent(
+      {id1, id2}, &list,
+      static_cast<RasterContextProvider*>(child_context_provider_.get()));
+  ASSERT_EQ(2u, list.size());
+  EXPECT_TRUE(child_resource_provider_->InUseByConsumer(id1));
+  EXPECT_TRUE(child_resource_provider_->InUseByConsumer(id2));
+
+  resource_provider_->ReceiveFromChild(child_id, list);
+
+  // In DisplayResourceProvider's namespace, use the mapped resource id.
+  std::unordered_map<ResourceId, ResourceId, ResourceIdHasher> resource_map =
+      resource_provider_->GetChildToParentMap(child_id);
+
+  scoped_refptr<TestFence> fence(new TestFence);
+  resource_provider_->SetReadLockFence(fence.get());
+  {
+    for (auto& resource : list) {
+      ResourceId parent_id = resource_map[resource.id];
+      resource_provider_->WaitSyncToken(parent_id);
+      DisplayResourceProviderGL::ScopedReadLockGL lock(resource_provider_.get(),
+                                                       parent_id);
+    }
+  }
+  EXPECT_EQ(0u, returned_to_child.size());
+
+  EXPECT_EQ(2u, resource_provider_->num_resources());
+
+  resource_provider_->DestroyChild(child_id);
+
+  EXPECT_EQ(0u, resource_provider_->num_resources());
+  EXPECT_EQ(2u, returned_to_child.size());
+
+  // id1 should be lost and id2 should not.
+  EXPECT_EQ(returned_to_child[0].lost, returned_to_child[0].id == id1);
+  EXPECT_EQ(returned_to_child[1].lost, returned_to_child[1].id == id1);
+
+  child_resource_provider_->ReceiveReturnsFromParent(
+      std::move(returned_to_child));
+  EXPECT_CALL(release, Released(_, _)).Times(2);
+  child_resource_provider_->RemoveImportedResource(id1);
+  child_resource_provider_->RemoveImportedResource(id2);
+}
+
+// Test that ScopedBatchReturnResources batching works.
+TEST_F(DisplayResourceProviderGLTest,
+       ScopedBatchReturnResourcesPreventsReturn) {
+  MockReleaseCallback release;
+
+  std::vector<ReturnedResource> returned_to_child;
+  int child_id = resource_provider_->CreateChild(
+      GetReturnCallback(&returned_to_child), SurfaceId());
+
+  // Transfer some resources to the parent.
+  constexpr size_t kTotalResources = 5;
+  constexpr size_t kLockedResources = 3;
+  constexpr size_t kUsedResources = 4;
+  ResourceId ids[kTotalResources];
+  for (auto& id : ids) {
+    TransferableResource tran = CreateResource(RGBA_8888);
+    id = child_resource_provider_->ImportResource(
+        tran, base::BindOnce(&MockReleaseCallback::Released,
+                             base::Unretained(&release)));
+  }
+  std::vector<ResourceId> resource_ids_to_transfer(ids, ids + kTotalResources);
+
+  std::vector<TransferableResource> list;
+  child_resource_provider_->PrepareSendToParent(
+      resource_ids_to_transfer, &list,
+      static_cast<RasterContextProvider*>(child_context_provider_.get()));
+  ASSERT_EQ(kTotalResources, list.size());
+  for (const auto& id : ids)
+    EXPECT_TRUE(child_resource_provider_->InUseByConsumer(id));
+
+  resource_provider_->ReceiveFromChild(child_id, list);
+
+  // In DisplayResourceProvider's namespace, use the mapped resource id.
+  std::unordered_map<ResourceId, ResourceId, ResourceIdHasher> resource_map =
+      resource_provider_->GetChildToParentMap(child_id);
+  std::vector<std::unique_ptr<DisplayResourceProviderGL::ScopedReadLockGL>>
+      read_locks;
+  for (size_t i = 0; i < kLockedResources; i++) {
+    ResourceId mapped_resource_id = resource_map[ids[i]];
+    resource_provider_->WaitSyncToken(mapped_resource_id);
+    read_locks.push_back(
+        std::make_unique<DisplayResourceProviderGL::ScopedReadLockGL>(
+            resource_provider_.get(), mapped_resource_id));
+  }
+
+  // Mark all locked resources, and one unlocked resource as used for first
+  // batch.
+  {
+    DisplayResourceProviderGL::ScopedBatchReturnResources returner(
+        resource_provider_.get());
+    resource_provider_->DeclareUsedResourcesFromChild(
+        child_id, ResourceIdSet(ids, ids + kUsedResources));
+    EXPECT_EQ(0u, returned_to_child.size());
+  }
+  EXPECT_EQ(1u, returned_to_child.size());
+  child_resource_provider_->ReceiveReturnsFromParent(
+      std::move(returned_to_child));
+  returned_to_child.clear();
+
+  // Return all locked resources.
+  {
+    DisplayResourceProviderGL::ScopedBatchReturnResources returner(
+        resource_provider_.get());
+    resource_provider_->DeclareUsedResourcesFromChild(
+        child_id, ResourceIdSet(ids + kLockedResources, ids + kUsedResources));
+    // Can be called multiple times while batching is enabled.  This happens in
+    // practice when the same surface is visited using different paths during
+    // surface aggregation.
+    resource_provider_->DeclareUsedResourcesFromChild(
+        child_id, ResourceIdSet(ids + kLockedResources, ids + kUsedResources));
+    read_locks.clear();
+    EXPECT_EQ(0u, returned_to_child.size());
+  }
+  EXPECT_EQ(kLockedResources, returned_to_child.size());
+  // Returned resources that were locked share the same sync token.
+  for (const auto& resource : returned_to_child)
+    EXPECT_EQ(resource.sync_token, returned_to_child[0].sync_token);
+
+  child_resource_provider_->ReceiveReturnsFromParent(
+      std::move(returned_to_child));
+  returned_to_child.clear();
+
+  // Returns from destroying the child is also batched.
+  {
+    DisplayResourceProviderGL::ScopedBatchReturnResources returner(
+        resource_provider_.get());
+    resource_provider_->DestroyChild(child_id);
+    EXPECT_EQ(0u, returned_to_child.size());
+  }
+  EXPECT_EQ(1u, returned_to_child.size());
+  child_resource_provider_->ReceiveReturnsFromParent(
+      std::move(returned_to_child));
+  returned_to_child.clear();
+
+  EXPECT_CALL(release, Released(_, _)).Times(kTotalResources);
+  for (const auto& id : ids)
+    child_resource_provider_->RemoveImportedResource(id);
+}
+
+class TextureStateTrackingGLES2Interface : public TestGLES2Interface {
+ public:
+  MOCK_METHOD2(BindTexture, void(GLenum target, GLuint texture));
+  MOCK_METHOD3(TexParameteri, void(GLenum target, GLenum pname, GLint param));
+  MOCK_METHOD1(WaitSyncTokenCHROMIUM, void(const GLbyte* sync_token));
+  MOCK_METHOD1(CreateAndConsumeTextureCHROMIUM,
+               unsigned(const GLbyte* mailbox));
+
+  // Force all textures to be consecutive numbers starting at "1",
+  // so we easily can test for them.
+  GLuint NextTextureId() override { return next_texture_id_++; }
+
+  void RetireTextureId(GLuint) override {}
+};
+
+class ResourceProviderTestImportedResourceGLFilters {
+ public:
+  static void RunTest(bool mailbox_nearest_neighbor, GLenum sampler_filter) {
+    auto gl_owned = std::make_unique<TextureStateTrackingGLES2Interface>();
+    TextureStateTrackingGLES2Interface* gl = gl_owned.get();
+    auto context_provider = TestContextProvider::Create(std::move(gl_owned));
+    context_provider->BindToCurrentThread();
+
+    auto resource_provider =
+        std::make_unique<DisplayResourceProviderGL>(context_provider.get());
+
+    auto child_gl_owned =
+        std::make_unique<TextureStateTrackingGLES2Interface>();
+    TextureStateTrackingGLES2Interface* child_gl = child_gl_owned.get();
+    auto child_context_provider =
+        TestContextProvider::Create(std::move(child_gl_owned));
+    child_context_provider->BindToCurrentThread();
+
+    auto child_resource_provider = std::make_unique<ClientResourceProvider>();
+
+    unsigned texture_id = 1;
+    gpu::SyncToken sync_token(gpu::CommandBufferNamespace::GPU_IO,
+                              gpu::CommandBufferId::FromUnsafeValue(0x12),
+                              0x34);
+
+    EXPECT_CALL(*child_gl, BindTexture(_, _)).Times(0);
+    EXPECT_CALL(*child_gl, WaitSyncTokenCHROMIUM(_)).Times(0);
+    EXPECT_CALL(*child_gl, CreateAndConsumeTextureCHROMIUM(_)).Times(0);
+
+    gpu::Mailbox gpu_mailbox = gpu::Mailbox::Generate();
+    GLuint filter = mailbox_nearest_neighbor ? GL_NEAREST : GL_LINEAR;
+    constexpr gfx::Size size(64, 64);
+    auto resource = TransferableResource::MakeGL(
+        gpu_mailbox, filter, GL_TEXTURE_2D, sync_token, size,
+        false /* is_overlay_candidate */);
+
+    MockReleaseCallback release;
+    ResourceId resource_id = child_resource_provider->ImportResource(
+        resource, base::BindOnce(&MockReleaseCallback::Released,
+                                 base::Unretained(&release)));
+    EXPECT_NE(kInvalidResourceId, resource_id);
+
+    testing::Mock::VerifyAndClearExpectations(child_gl);
+
+    // Transfer resources to the parent.
+    std::vector<TransferableResource> send_to_parent;
+    std::vector<ReturnedResource> returned_to_child;
+    int child_id = resource_provider->CreateChild(
+        base::BindRepeating(&CollectResources, &returned_to_child),
+        SurfaceId());
+    child_resource_provider->PrepareSendToParent(
+        {resource_id}, &send_to_parent,
+        static_cast<RasterContextProvider*>(child_context_provider.get()));
+    resource_provider->ReceiveFromChild(child_id, send_to_parent);
+
+    // In DisplayResourceProvider's namespace, use the mapped resource id.
+    std::unordered_map<ResourceId, ResourceId, ResourceIdHasher> resource_map =
+        resource_provider->GetChildToParentMap(child_id);
+    ResourceId mapped_resource_id = resource_map[resource_id];
+    {
+      // The verified flush flag will be set by
+      // ClientResourceProvider::PrepareSendToParent. Before checking if
+      // the gpu::SyncToken matches, set this flag first.
+      sync_token.SetVerifyFlush();
+
+      // Mailbox sync point WaitSyncToken before using the texture.
+      EXPECT_CALL(*gl, WaitSyncTokenCHROMIUM(MatchesSyncToken(sync_token)));
+      resource_provider->WaitSyncToken(mapped_resource_id);
+      testing::Mock::VerifyAndClearExpectations(gl);
+
+      EXPECT_CALL(*gl, CreateAndConsumeTextureCHROMIUM(_))
+          .WillOnce(Return(texture_id));
+      EXPECT_CALL(*gl, BindTexture(GL_TEXTURE_2D, texture_id));
+
+      // The sampler will reset these if |mailbox_nearest_neighbor| does not
+      // match |sampler_filter|.
+      if (mailbox_nearest_neighbor != (sampler_filter == GL_NEAREST)) {
+        EXPECT_CALL(*gl, TexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER,
+                                       sampler_filter));
+        EXPECT_CALL(*gl, TexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER,
+                                       sampler_filter));
+      }
+
+      DisplayResourceProviderGL::ScopedSamplerGL lock(
+          resource_provider.get(), mapped_resource_id, sampler_filter);
+      testing::Mock::VerifyAndClearExpectations(gl);
+
+      // When done with it, a sync point should be inserted, but no produce is
+      // necessary.
+      EXPECT_CALL(*child_gl, WaitSyncTokenCHROMIUM(_)).Times(0);
+      EXPECT_CALL(*child_gl, CreateAndConsumeTextureCHROMIUM(_)).Times(0);
+    }
+
+    EXPECT_EQ(0u, returned_to_child.size());
+    // Transfer resources back from the parent to the child. Set no resources as
+    // being in use.
+    resource_provider->DeclareUsedResourcesFromChild(child_id, ResourceIdSet());
+    EXPECT_EQ(1u, returned_to_child.size());
+    child_resource_provider->ReceiveReturnsFromParent(
+        std::move(returned_to_child));
+
+    gpu::SyncToken released_sync_token;
+    {
+      EXPECT_CALL(release, Released(_, false))
+          .WillOnce(SaveArg<0>(&released_sync_token));
+      child_resource_provider->RemoveImportedResource(resource_id);
+    }
+    EXPECT_TRUE(released_sync_token.HasData());
+  }
+};
+
+TEST_F(DisplayResourceProviderGLTest, ReceiveGLTexture2D_LinearToLinear) {
+  ResourceProviderTestImportedResourceGLFilters::RunTest(false, GL_LINEAR);
+}
+
+TEST_F(DisplayResourceProviderGLTest, ReceiveGLTexture2D_NearestToNearest) {
+  ResourceProviderTestImportedResourceGLFilters::RunTest(true, GL_NEAREST);
+}
+
+TEST_F(DisplayResourceProviderGLTest, ReceiveGLTexture2D_NearestToLinear) {
+  ResourceProviderTestImportedResourceGLFilters::RunTest(true, GL_LINEAR);
+}
+
+TEST_F(DisplayResourceProviderGLTest, ReceiveGLTexture2D_LinearToNearest) {
+  ResourceProviderTestImportedResourceGLFilters::RunTest(false, GL_NEAREST);
+}
+
+TEST_F(DisplayResourceProviderGLTest, ReceiveGLTextureExternalOES) {
+  auto gl_owned = std::make_unique<TextureStateTrackingGLES2Interface>();
+  TextureStateTrackingGLES2Interface* gl = gl_owned.get();
+  auto context_provider = TestContextProvider::Create(std::move(gl_owned));
+  context_provider->BindToCurrentThread();
+
+  auto resource_provider =
+      std::make_unique<DisplayResourceProviderGL>(context_provider.get());
+
+  auto child_gl_owned = std::make_unique<TextureStateTrackingGLES2Interface>();
+  TextureStateTrackingGLES2Interface* child_gl = child_gl_owned.get();
+  auto child_context_provider =
+      TestContextProvider::Create(std::move(child_gl_owned));
+  child_context_provider->BindToCurrentThread();
+
+  auto child_resource_provider = std::make_unique<ClientResourceProvider>();
+
+  gpu::SyncToken sync_token(gpu::CommandBufferNamespace::GPU_IO,
+                            gpu::CommandBufferId::FromUnsafeValue(0x12), 0x34);
+
+  EXPECT_CALL(*child_gl, BindTexture(_, _)).Times(0);
+  EXPECT_CALL(*child_gl, WaitSyncTokenCHROMIUM(_)).Times(0);
+  EXPECT_CALL(*child_gl, CreateAndConsumeTextureCHROMIUM(_)).Times(0);
+
+  gpu::Mailbox gpu_mailbox = gpu::Mailbox::Generate();
+  ReleaseCallback callback = base::DoNothing();
+
+  constexpr gfx::Size size(64, 64);
+  auto resource = TransferableResource::MakeGL(
+      gpu_mailbox, GL_LINEAR, GL_TEXTURE_EXTERNAL_OES, sync_token, size,
+      false /* is_overlay_candidate */);
+
+  ResourceId resource_id =
+      child_resource_provider->ImportResource(resource, std::move(callback));
+  EXPECT_NE(kInvalidResourceId, resource_id);
+
+  testing::Mock::VerifyAndClearExpectations(child_gl);
+
+  // Transfer resources to the parent.
+  std::vector<TransferableResource> send_to_parent;
+  std::vector<ReturnedResource> returned_to_child;
+  int child_id = resource_provider->CreateChild(
+      base::BindRepeating(&CollectResources, &returned_to_child), SurfaceId());
+  child_resource_provider->PrepareSendToParent(
+      {resource_id}, &send_to_parent,
+      static_cast<RasterContextProvider*>(child_context_provider_.get()));
+  resource_provider->ReceiveFromChild(child_id, send_to_parent);
+
+  // Before create DrawQuad in DisplayResourceProvider's namespace, get the
+  // mapped resource id first.
+  std::unordered_map<ResourceId, ResourceId, ResourceIdHasher> resource_map =
+      resource_provider->GetChildToParentMap(child_id);
+  ResourceId mapped_resource_id = resource_map[resource_id];
+  {
+    // The verified flush flag will be set by
+    // ClientResourceProvider::PrepareSendToParent. Before checking if
+    // the gpu::SyncToken matches, set this flag first.
+    sync_token.SetVerifyFlush();
+
+    // Mailbox sync point WaitSyncToken before using the texture.
+    EXPECT_CALL(*gl, WaitSyncTokenCHROMIUM(MatchesSyncToken(sync_token)));
+    resource_provider->WaitSyncToken(mapped_resource_id);
+    testing::Mock::VerifyAndClearExpectations(gl);
+
+    unsigned texture_id = 1;
+
+    EXPECT_CALL(*gl, CreateAndConsumeTextureCHROMIUM(_))
+        .WillOnce(Return(texture_id));
+
+    DisplayResourceProviderGL::ScopedReadLockGL lock(resource_provider.get(),
+                                                     mapped_resource_id);
+    testing::Mock::VerifyAndClearExpectations(gl);
+
+    // When done with it, a sync point should be inserted, but no produce is
+    // necessary.
+    EXPECT_CALL(*gl, WaitSyncTokenCHROMIUM(_)).Times(0);
+    EXPECT_CALL(*gl, CreateAndConsumeTextureCHROMIUM(_)).Times(0);
+    testing::Mock::VerifyAndClearExpectations(gl);
+  }
+  EXPECT_EQ(0u, returned_to_child.size());
+  // Transfer resources back from the parent to the child. Set no resources as
+  // being in use.
+  resource_provider->DeclareUsedResourcesFromChild(child_id, ResourceIdSet());
+  EXPECT_EQ(1u, returned_to_child.size());
+  child_resource_provider->ReceiveReturnsFromParent(
+      std::move(returned_to_child));
+
+  child_resource_provider->RemoveImportedResource(resource_id);
+}
+
+TEST_F(DisplayResourceProviderGLTest, WaitSyncTokenIfNeeded) {
+  auto gl_owned = std::make_unique<TextureStateTrackingGLES2Interface>();
+  TextureStateTrackingGLES2Interface* gl = gl_owned.get();
+  auto context_provider = TestContextProvider::Create(std::move(gl_owned));
+  context_provider->BindToCurrentThread();
+
+  auto resource_provider =
+      std::make_unique<DisplayResourceProviderGL>(context_provider.get());
+
+  EXPECT_CALL(*gl, BindTexture(_, _)).Times(0);
+  EXPECT_CALL(*gl, WaitSyncTokenCHROMIUM(_)).Times(0);
+  EXPECT_CALL(*gl, CreateAndConsumeTextureCHROMIUM(_)).Times(0);
+
+  gpu::SyncToken sync_token(gpu::CommandBufferNamespace::GPU_IO,
+                            gpu::CommandBufferId::FromUnsafeValue(0x12), 0x34);
+  ResourceId id_with_sync = MakeGpuResourceAndSendToDisplay(
+      GL_LINEAR, GL_TEXTURE_2D, sync_token, resource_provider.get());
+  ResourceId id_without_sync = MakeGpuResourceAndSendToDisplay(
+      GL_LINEAR, GL_TEXTURE_2D, gpu::SyncToken(), resource_provider.get());
+
+  // First call to WaitSyncToken should call WaitSyncToken, but only if a
+  // SyncToken was present.
+  {
+    EXPECT_CALL(*gl, WaitSyncTokenCHROMIUM(MatchesSyncToken(sync_token)))
+        .Times(1);
+    resource_provider->WaitSyncToken(id_with_sync);
+    EXPECT_CALL(*gl, WaitSyncTokenCHROMIUM(_)).Times(0);
+    resource_provider->WaitSyncToken(id_without_sync);
+  }
+
+  {
+    // Subsequent calls to WaitSyncToken shouldn't call WaitSyncToken.
+    EXPECT_CALL(*gl, WaitSyncTokenCHROMIUM(_)).Times(0);
+    resource_provider->WaitSyncToken(id_with_sync);
+    resource_provider->WaitSyncToken(id_without_sync);
+  }
+}
+
+}  // namespace
+}  // namespace viz
diff --git components/viz/service/display/display_unittest.cc components/viz/service/display/display_unittest.cc
index b10314dd1d513..747265b3771a9 100644
--- components/viz/service/display/display_unittest.cc
+++ components/viz/service/display/display_unittest.cc
@@ -4541,7 +4541,10 @@ class SkiaDelegatedInkRendererTest : public DisplayTest {
   void SetUp() override { EnablePrediction(); }
 
   void SetUpRenderers() {
-    SetUpGpuDisplay(RendererSettings());
+    // First set up the display to use the Skia renderer.
+    RendererSettings settings;
+    settings.use_skia_renderer = true;
+    SetUpGpuDisplay(settings);
 
     // Initialize the renderer and create an ink renderer.
     display_->Initialize(&client_, manager_.surface_manager());
@@ -5065,7 +5068,9 @@ class DelegatedInkDisplayTest
           features::kUsePlatformDelegatedInk);
 
       // Set up the display to use the Skia renderer.
-      SetUpGpuDisplaySkiaWithPlatformInk(RendererSettings());
+      RendererSettings settings;
+      settings.use_skia_renderer = true;
+      SetUpGpuDisplaySkiaWithPlatformInk(settings);
 
       display_->Initialize(&client_, manager_.surface_manager());
     }
diff --git components/viz/service/display/dynamic_geometry_binding.cc components/viz/service/display/dynamic_geometry_binding.cc
new file mode 100644
index 0000000000000..bb47dba7320e8
--- /dev/null
+++ components/viz/service/display/dynamic_geometry_binding.cc
@@ -0,0 +1,68 @@
+// Copyright 2015 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "components/viz/service/display/dynamic_geometry_binding.h"
+
+#include <stdint.h>
+
+#include "gpu/command_buffer/client/gles2_interface.h"
+#include "ui/gfx/geometry/quad_f.h"
+#include "ui/gfx/geometry/rect_f.h"
+
+namespace viz {
+
+DynamicGeometryBinding::DynamicGeometryBinding(gpu::gles2::GLES2Interface* gl)
+    : gl_(gl), quad_vertices_vbo_(0), quad_elements_vbo_(0) {
+  GLuint buffers[2];
+  gl_->GenBuffers(2, buffers);
+  quad_vertices_vbo_ = buffers[0];
+  quad_elements_vbo_ = buffers[1];
+
+  gl_->BindBuffer(GL_ARRAY_BUFFER, quad_vertices_vbo_);
+  gl_->BufferData(GL_ARRAY_BUFFER, sizeof(GeometryBindingQuad), nullptr,
+                  GL_DYNAMIC_DRAW);
+
+  gl_->BindBuffer(GL_ELEMENT_ARRAY_BUFFER, quad_elements_vbo_);
+  gl_->BufferData(GL_ELEMENT_ARRAY_BUFFER, sizeof(GeometryBindingQuadIndex),
+                  nullptr, GL_DYNAMIC_DRAW);
+}
+
+DynamicGeometryBinding::~DynamicGeometryBinding() {
+  GLuint buffers[2] = {quad_vertices_vbo_, quad_elements_vbo_};
+  gl_->DeleteBuffers(2, buffers);
+}
+
+void DynamicGeometryBinding::InitializeCustomQuad(const gfx::QuadF& quad) {
+  float uv[] = {0.0f, 0.0f, 1.0f, 0.0f, 1.0f, 1.0f, 0.0f, 1.0f};
+  InitializeCustomQuadWithUVs(quad, uv);
+}
+
+void DynamicGeometryBinding::InitializeCustomQuadWithUVs(const gfx::QuadF& quad,
+                                                         const float uv[8]) {
+  GeometryBindingVertex v0 = {
+      {quad.p1().x(), quad.p1().y(), 0.0f}, {uv[0], uv[1]}, 0.0f};
+  GeometryBindingVertex v1 = {
+      {quad.p2().x(), quad.p2().y(), 0.0f}, {uv[2], uv[3]}, 1.0f};
+  GeometryBindingVertex v2 = {
+      {quad.p3().x(), quad.p3().y(), 0.0f}, {uv[4], uv[5]}, 2.0f};
+  GeometryBindingVertex v3 = {
+      {quad.p4().x(), quad.p4().y(), 0.0f}, {uv[6], uv[7]}, 3.0f};
+
+  GeometryBindingQuad local_quad = {v0, v1, v2, v3};
+  GeometryBindingQuadIndex quad_index(
+      static_cast<uint16_t>(0), static_cast<uint16_t>(1),
+      static_cast<uint16_t>(2), static_cast<uint16_t>(3),
+      static_cast<uint16_t>(0), static_cast<uint16_t>(2));
+
+  gl_->BufferSubData(GL_ARRAY_BUFFER, 0, sizeof(GeometryBindingQuad),
+                     &local_quad);
+  gl_->BufferSubData(GL_ELEMENT_ARRAY_BUFFER, 0,
+                     sizeof(GeometryBindingQuadIndex), &quad_index);
+}
+
+void DynamicGeometryBinding::PrepareForDraw() {
+  SetupGLContext(gl_, quad_elements_vbo_, quad_vertices_vbo_);
+}
+
+}  // namespace viz
diff --git components/viz/service/display/dynamic_geometry_binding.h components/viz/service/display/dynamic_geometry_binding.h
new file mode 100644
index 0000000000000..2d340962fadd4
--- /dev/null
+++ components/viz/service/display/dynamic_geometry_binding.h
@@ -0,0 +1,40 @@
+// Copyright 2015 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef COMPONENTS_VIZ_SERVICE_DISPLAY_DYNAMIC_GEOMETRY_BINDING_H_
+#define COMPONENTS_VIZ_SERVICE_DISPLAY_DYNAMIC_GEOMETRY_BINDING_H_
+
+#include "base/memory/raw_ptr.h"
+#include "components/viz/service/display/geometry_binding.h"
+#include "components/viz/service/viz_service_export.h"
+
+namespace gfx {
+class QuadF;
+}
+
+namespace viz {
+
+class VIZ_SERVICE_EXPORT DynamicGeometryBinding {
+ public:
+  explicit DynamicGeometryBinding(gpu::gles2::GLES2Interface* gl);
+
+  DynamicGeometryBinding(const DynamicGeometryBinding&) = delete;
+  DynamicGeometryBinding& operator=(const DynamicGeometryBinding&) = delete;
+
+  ~DynamicGeometryBinding();
+
+  void PrepareForDraw();
+  void InitializeCustomQuad(const gfx::QuadF& quad);
+  void InitializeCustomQuadWithUVs(const gfx::QuadF& quad, const float uv[8]);
+
+ private:
+  raw_ptr<gpu::gles2::GLES2Interface> gl_;
+
+  GLuint quad_vertices_vbo_;
+  GLuint quad_elements_vbo_;
+};
+
+}  // namespace viz
+
+#endif  // COMPONENTS_VIZ_SERVICE_DISPLAY_DYNAMIC_GEOMETRY_BINDING_H_
diff --git components/viz/service/display/geometry_binding.cc components/viz/service/display/geometry_binding.cc
new file mode 100644
index 0000000000000..e2013e1c02965
--- /dev/null
+++ components/viz/service/display/geometry_binding.cc
@@ -0,0 +1,75 @@
+// Copyright 2011 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "components/viz/service/display/geometry_binding.h"
+
+#include <stdint.h>
+#include <string.h>
+
+#include "gpu/command_buffer/client/gles2_interface.h"
+#include "ui/gfx/geometry/rect_f.h"
+
+namespace viz {
+
+void SetupGLContext(gpu::gles2::GLES2Interface* gl,
+                    GLuint quad_elements_vbo,
+                    GLuint quad_vertices_vbo) {
+  gl->BindBuffer(GL_ELEMENT_ARRAY_BUFFER, quad_elements_vbo);
+
+  gl->BindBuffer(GL_ARRAY_BUFFER, quad_vertices_vbo);
+  // OpenGL defines the last parameter to VertexAttribPointer as type
+  // "const GLvoid*" even though it is actually an offset into the buffer
+  // object's data store and not a pointer to the client's address space.
+  const void* offsets[3] = {
+      nullptr, reinterpret_cast<const void*>(3 * sizeof(float)),
+      reinterpret_cast<const void*>(5 * sizeof(float)),
+  };
+
+  gl->VertexAttribPointer(GeometryBinding::PositionAttribLocation(), 3,
+                          GL_FLOAT, false, 6 * sizeof(float), offsets[0]);
+  gl->VertexAttribPointer(GeometryBinding::TexCoordAttribLocation(), 2,
+                          GL_FLOAT, false, 6 * sizeof(float), offsets[1]);
+  gl->VertexAttribPointer(GeometryBinding::TriangleIndexAttribLocation(), 1,
+                          GL_FLOAT, false, 6 * sizeof(float), offsets[2]);
+  gl->EnableVertexAttribArray(GeometryBinding::PositionAttribLocation());
+  gl->EnableVertexAttribArray(GeometryBinding::TexCoordAttribLocation());
+  gl->EnableVertexAttribArray(GeometryBinding::TriangleIndexAttribLocation());
+}
+
+GeometryBindingQuad::GeometryBindingQuad() {
+  v0 = {{0, 0, 0}, {0, 0}, 0};
+  v1 = {{0, 0, 0}, {0, 0}, 0};
+  v2 = {{0, 0, 0}, {0, 0}, 0};
+  v3 = {{0, 0, 0}, {0, 0}, 0};
+}
+
+GeometryBindingQuad::GeometryBindingQuad(const GeometryBindingVertex& vert0,
+                                         const GeometryBindingVertex& vert1,
+                                         const GeometryBindingVertex& vert2,
+                                         const GeometryBindingVertex& vert3) {
+  v0 = vert0;
+  v1 = vert1;
+  v2 = vert2;
+  v3 = vert3;
+}
+
+GeometryBindingQuadIndex::GeometryBindingQuadIndex() {
+  memset(data, 0x0, sizeof(data));
+}
+
+GeometryBindingQuadIndex::GeometryBindingQuadIndex(uint16_t index0,
+                                                   uint16_t index1,
+                                                   uint16_t index2,
+                                                   uint16_t index3,
+                                                   uint16_t index4,
+                                                   uint16_t index5) {
+  data[0] = index0;
+  data[1] = index1;
+  data[2] = index2;
+  data[3] = index3;
+  data[4] = index4;
+  data[5] = index5;
+}
+
+}  // namespace viz
diff --git components/viz/service/display/geometry_binding.h components/viz/service/display/geometry_binding.h
new file mode 100644
index 0000000000000..64bdf0b9ae4d6
--- /dev/null
+++ components/viz/service/display/geometry_binding.h
@@ -0,0 +1,64 @@
+// Copyright 2011 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef COMPONENTS_VIZ_SERVICE_DISPLAY_GEOMETRY_BINDING_H_
+#define COMPONENTS_VIZ_SERVICE_DISPLAY_GEOMETRY_BINDING_H_
+
+#include <stdint.h>
+
+#include "gpu/command_buffer/client/gles2_interface.h"
+#include "third_party/khronos/GLES2/gl2.h"
+#include "third_party/khronos/GLES2/gl2ext.h"
+#include "ui/gfx/geometry/rect_f.h"
+
+namespace viz {
+
+struct GeometryBindingVertex {
+  float a_position[3];
+  float a_texCoord[2];
+  // Index of the vertex, divide by 4 to have the matrix for this quad.
+  float a_index;
+};
+
+struct GeometryBindingQuad {
+  GeometryBindingQuad();
+  GeometryBindingQuad(const GeometryBindingVertex& vert0,
+                      const GeometryBindingVertex& vert1,
+                      const GeometryBindingVertex& vert2,
+                      const GeometryBindingVertex& vert3);
+  GeometryBindingVertex v0, v1, v2, v3;
+};
+static_assert(sizeof(GeometryBindingQuad) == 24 * sizeof(float),
+              "struct Quad should be densely packed");
+
+struct GeometryBindingQuadIndex {
+  GeometryBindingQuadIndex();
+  GeometryBindingQuadIndex(uint16_t index0,
+                           uint16_t index1,
+                           uint16_t index2,
+                           uint16_t index3,
+                           uint16_t index4,
+                           uint16_t index5);
+
+  uint16_t data[6];
+};
+static_assert(sizeof(GeometryBindingQuadIndex) == 6 * sizeof(uint16_t),
+              "struct QuadIndex should be densely packed");
+
+struct GeometryBinding {
+  // All layer shaders share the same attribute locations for the vertex
+  // positions and texture coordinates. This allows switching shaders without
+  // rebinding attribute arrays.
+  static int PositionAttribLocation() { return 0; }
+  static int TexCoordAttribLocation() { return 1; }
+  static int TriangleIndexAttribLocation() { return 2; }
+};
+
+void SetupGLContext(gpu::gles2::GLES2Interface* gl,
+                    GLuint quad_elements_vbo,
+                    GLuint quad_vertices_vbo);
+
+}  // namespace viz
+
+#endif  // COMPONENTS_VIZ_SERVICE_DISPLAY_GEOMETRY_BINDING_H_
diff --git components/viz/service/display/gl_renderer.cc components/viz/service/display/gl_renderer.cc
new file mode 100644
index 0000000000000..e0a8510a9e1d1
--- /dev/null
+++ components/viz/service/display/gl_renderer.cc
@@ -0,0 +1,4505 @@
+// Copyright 2010 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "components/viz/service/display/gl_renderer.h"
+
+#include <stddef.h>
+#include <stdint.h>
+
+#include <algorithm>
+#include <limits>
+#include <memory>
+#include <numeric>
+#include <set>
+#include <vector>
+
+#include "base/bind.h"
+#include "base/callback_helpers.h"
+#include "base/check_op.h"
+#include "base/containers/cxx20_erase.h"
+#include "base/feature_list.h"
+#include "base/memory/ptr_util.h"
+#include "base/memory/raw_ptr.h"
+#include "base/notreached.h"
+#include "base/strings/string_split.h"
+#include "base/strings/string_util.h"
+#include "base/threading/thread_task_runner_handle.h"
+#include "base/time/time.h"
+#include "base/trace_event/trace_event.h"
+#include "build/build_config.h"
+#include "cc/base/math_util.h"
+#include "cc/debug/debug_colors.h"
+#include "cc/paint/render_surface_filters.h"
+#include "cc/raster/scoped_gpu_raster.h"
+#include "components/viz/common/display/renderer_settings.h"
+#include "components/viz/common/features.h"
+#include "components/viz/common/frame_sinks/copy_output_request.h"
+#include "components/viz/common/gpu/context_provider.h"
+#include "components/viz/common/quads/compositor_frame.h"
+#include "components/viz/common/quads/compositor_frame_metadata.h"
+#include "components/viz/common/quads/compositor_render_pass.h"
+#include "components/viz/common/quads/picture_draw_quad.h"
+#include "components/viz/common/quads/stream_video_draw_quad.h"
+#include "components/viz/common/quads/texture_draw_quad.h"
+#include "components/viz/common/resources/platform_color.h"
+#include "components/viz/common/resources/resource_format_utils.h"
+#include "components/viz/common/resources/resource_id.h"
+#include "components/viz/common/skia_helper.h"
+#include "components/viz/common/viz_utils.h"
+#include "components/viz/service/display/draw_polygon.h"
+#include "components/viz/service/display/dynamic_geometry_binding.h"
+#include "components/viz/service/display/layer_quad.h"
+#include "components/viz/service/display/output_surface.h"
+#include "components/viz/service/display/output_surface_frame.h"
+#include "components/viz/service/display/resource_fence.h"
+#include "components/viz/service/display/scoped_render_pass_texture.h"
+#include "components/viz/service/display/static_geometry_binding.h"
+#include "components/viz/service/display/texture_deleter.h"
+#include "gpu/GLES2/gl2extchromium.h"
+#include "gpu/command_buffer/client/context_support.h"
+#include "gpu/command_buffer/client/gles2_interface.h"
+#include "gpu/command_buffer/common/gpu_memory_allocation.h"
+#include "gpu/config/gpu_driver_bug_workaround_type.h"
+#include "gpu/config/gpu_feature_info.h"
+#include "third_party/abseil-cpp/absl/types/optional.h"
+#include "third_party/skia/include/core/SkBitmap.h"
+#include "third_party/skia/include/core/SkColor.h"
+#include "third_party/skia/include/core/SkColorFilter.h"
+#include "third_party/skia/include/core/SkImage.h"
+#include "third_party/skia/include/core/SkSurface.h"
+#include "third_party/skia/include/core/SkTypes.h"
+#include "third_party/skia/include/effects/SkShaderMaskFilter.h"
+#include "third_party/skia/include/gpu/GrBackendSurface.h"
+#include "third_party/skia/include/gpu/GrDirectContext.h"
+#include "third_party/skia/include/gpu/gl/GrGLInterface.h"
+#include "third_party/skia/include/gpu/gl/GrGLTypes.h"
+#include "ui/gfx/color_space.h"
+#include "ui/gfx/color_transform.h"
+#include "ui/gfx/geometry/quad_f.h"
+#include "ui/gfx/geometry/rect.h"
+#include "ui/gfx/geometry/rect_conversions.h"
+#include "ui/gfx/geometry/rrect_f.h"
+#include "ui/gfx/geometry/size_conversions.h"
+#include "ui/gfx/geometry/skia_conversions.h"
+#include "ui/gfx/geometry/vector2d.h"
+#include "ui/gfx/gpu_fence_handle.h"
+
+using gpu::gles2::GLES2Interface;
+
+namespace viz {
+namespace {
+
+Float4 UVTransform(const TextureDrawQuad* quad) {
+  gfx::RectF uv_rect =
+      gfx::BoundingRect(quad->uv_top_left, quad->uv_bottom_right);
+  gfx::RectF visible_uv_rect = cc::MathUtil::ScaleRectProportional(
+      uv_rect, gfx::RectF(quad->rect), gfx::RectF(quad->visible_rect));
+
+  gfx::PointF uv0 = visible_uv_rect.origin();
+  gfx::PointF uv1 = visible_uv_rect.bottom_right();
+  Float4 xform = {{uv0.x(), uv0.y(), uv1.x() - uv0.x(), uv1.y() - uv0.y()}};
+  if (quad->y_flipped) {
+    xform.data[1] = 1.0f - xform.data[1];
+    xform.data[3] = -xform.data[3];
+  }
+  return xform;
+}
+
+// To prevent sampling outside the visible rect.
+Float4 UVClampRect(gfx::RectF uv_visible_rect,
+                   const gfx::Size& texture_size,
+                   SamplerType sampler) {
+  gfx::SizeF half_texel(0.5f, 0.5f);
+  if (sampler != SAMPLER_TYPE_2D_RECT) {
+    half_texel.Scale(1.f / texture_size.width(), 1.f / texture_size.height());
+  } else {
+    uv_visible_rect.Scale(texture_size.width(), texture_size.height());
+  }
+  uv_visible_rect.Inset(
+      gfx::InsetsF::VH(half_texel.height(), half_texel.width()));
+  return {{uv_visible_rect.x(), uv_visible_rect.y(), uv_visible_rect.right(),
+           uv_visible_rect.bottom()}};
+}
+
+Float4 PremultipliedColor(SkColor color, float opacity) {
+  const U8CPU alpha255 = SkColorGetA(color);
+  const unsigned int alpha256 = alpha255 + 1;
+  const unsigned int premultiplied_red = (SkColorGetR(color) * alpha256) >> 8;
+  const unsigned int premultiplied_green = (SkColorGetG(color) * alpha256) >> 8;
+  const unsigned int premultiplied_blue = (SkColorGetB(color) * alpha256) >> 8;
+  const float factor = opacity / 255.0f;
+  return {{premultiplied_red * factor, premultiplied_green * factor,
+           premultiplied_blue * factor, alpha255 * factor}};
+}
+
+SamplerType SamplerTypeFromTextureTarget(GLenum target) {
+  switch (target) {
+    case GL_TEXTURE_2D:
+      return SAMPLER_TYPE_2D;
+    case GL_TEXTURE_RECTANGLE_ARB:
+      return SAMPLER_TYPE_2D_RECT;
+    case GL_TEXTURE_EXTERNAL_OES:
+      return SAMPLER_TYPE_EXTERNAL_OES;
+    default:
+      NOTREACHED();
+      return SAMPLER_TYPE_2D;
+  }
+}
+
+BlendMode BlendModeFromSkXfermode(SkBlendMode mode) {
+  switch (mode) {
+    case SkBlendMode::kSrcOver:
+      return BLEND_MODE_NORMAL;
+    case SkBlendMode::kDstIn:
+      return BLEND_MODE_DESTINATION_IN;
+    case SkBlendMode::kScreen:
+      return BLEND_MODE_SCREEN;
+    case SkBlendMode::kOverlay:
+      return BLEND_MODE_OVERLAY;
+    case SkBlendMode::kDarken:
+      return BLEND_MODE_DARKEN;
+    case SkBlendMode::kLighten:
+      return BLEND_MODE_LIGHTEN;
+    case SkBlendMode::kColorDodge:
+      return BLEND_MODE_COLOR_DODGE;
+    case SkBlendMode::kColorBurn:
+      return BLEND_MODE_COLOR_BURN;
+    case SkBlendMode::kHardLight:
+      return BLEND_MODE_HARD_LIGHT;
+    case SkBlendMode::kSoftLight:
+      return BLEND_MODE_SOFT_LIGHT;
+    case SkBlendMode::kDifference:
+      return BLEND_MODE_DIFFERENCE;
+    case SkBlendMode::kExclusion:
+      return BLEND_MODE_EXCLUSION;
+    case SkBlendMode::kMultiply:
+      return BLEND_MODE_MULTIPLY;
+    case SkBlendMode::kHue:
+      return BLEND_MODE_HUE;
+    case SkBlendMode::kSaturation:
+      return BLEND_MODE_SATURATION;
+    case SkBlendMode::kColor:
+      return BLEND_MODE_COLOR;
+    case SkBlendMode::kLuminosity:
+      return BLEND_MODE_LUMINOSITY;
+    case SkBlendMode::kSrc:
+      return BLEND_MODE_NONE;
+    default:
+      NOTREACHED();
+      return BLEND_MODE_NONE;
+  }
+}
+
+// Adds a timer query that spans all GL calls in its scope. |viz.composite_time|
+// trace category must be enabled for this to work.
+// Note:: Multiple timer queries cannot be nested.
+class ScopedTimerQuery {
+ public:
+  ScopedTimerQuery(bool tracing_enabled,
+                   gpu::gles2::GLES2Interface* gl,
+                   base::queue<std::pair<unsigned, std::string>>* timer_queries,
+                   const std::string& quad_type_str)
+      : gl_(gl) {
+    if (!tracing_enabled) {
+      gl_ = nullptr;
+      return;
+    }
+    unsigned timer_query;
+    gl_->GenQueriesEXT(1, &timer_query);
+    gl_->BeginQueryEXT(GL_TIME_ELAPSED_EXT, timer_query);
+    timer_queries->emplace(timer_query, quad_type_str);
+  }
+
+  ~ScopedTimerQuery() {
+    if (gl_)
+      gl_->EndQueryEXT(GL_TIME_ELAPSED_EXT);
+  }
+
+ private:
+  raw_ptr<gpu::gles2::GLES2Interface> gl_;
+};
+
+void AccumulateDrawRects(const gfx::Rect& quad_rect,
+                         const gfx::Transform& target_transform,
+                         std::vector<gfx::Rect>* drawn_rects) {
+  gfx::RectF quad_rect_f(quad_rect);
+
+  // If the transform is not axis aligned then assume the largest possible
+  // bounds the quad can take in the render target. In this case, we take the
+  // sum of 2 sides.
+  if (!target_transform.Preserves2dAxisAlignment()) {
+    // Increase the length of each side to |width + height|.
+    const int total_length = quad_rect.width() + quad_rect.height();
+    quad_rect_f.set_height(total_length);
+    quad_rect_f.set_width(total_length);
+
+    // Ensure that the increase is equally distributed on either sides of the
+    // quad such that the position of the center of the quad does not change.
+    const float delta_x = -(quad_rect.height() / 2.f);
+    const float delta_y = -(quad_rect.width() / 2.f);
+    quad_rect_f.Offset(gfx::Vector2d(delta_x, delta_y));
+
+    // Apply only the scale and translation component.
+    const gfx::Vector2dF& translate = target_transform.To2dTranslation();
+    const gfx::Vector2dF& scale = target_transform.To2dScale();
+    quad_rect_f.Scale(scale.x(), scale.y());
+    quad_rect_f.Offset(translate.x(), translate.y());
+  } else {
+    target_transform.TransformRect(&quad_rect_f);
+  }
+  drawn_rects->push_back(gfx::ToRoundedRect(quad_rect_f));
+}
+
+// Smallest unit that impact anti-aliasing output. We use this to
+// determine when anti-aliasing is unnecessary.
+const float kAntiAliasingEpsilon = 1.0f / 1024.0f;
+
+// A dummy timer query ID used to identify the beginning of a frame in the queue
+// of timer queries.
+const unsigned kTimerQueryDummy = 0;
+
+}  // anonymous namespace
+
+static GLint GetActiveTextureUnit(GLES2Interface* gl) {
+  GLint active_unit = 0;
+  gl->GetIntegerv(GL_ACTIVE_TEXTURE, &active_unit);
+  return active_unit;
+}
+
+// Parameters needed to draw a CompositorRenderPassDrawQuad.
+struct GLRenderer::DrawRenderPassDrawQuadParams {
+  DrawRenderPassDrawQuadParams() {}
+  ~DrawRenderPassDrawQuadParams() {
+    // Don't leak the texture.
+    DCHECK(!background_texture);
+  }
+
+  // Required inputs below.
+  raw_ptr<const AggregatedRenderPassDrawQuad> quad = nullptr;
+
+  // Either |contents_texture| or |bypass_quad_texture| is populated. The
+  // |contents_texture| will be valid if non-null, and when null the
+  // bypass_quad_texture will be valid instead.
+  raw_ptr<ScopedRenderPassTexture> contents_texture = nullptr;
+  struct {
+    ResourceId resource_id = kInvalidResourceId;
+    gfx::Size size;
+  } bypass_quad_texture;
+
+  raw_ptr<const gfx::QuadF> clip_region = nullptr;
+  bool flip_texture = false;
+
+  // |window_matrix| maps from [-1,-1]-[1,1] unit square coordinates to window
+  // pixel coordinates.
+  gfx::Transform window_matrix;
+  // |projection_matrix| maps texture coordinates (in pixels) to the 2D plane in
+  // [-1,-1]-[1,1] unit square coordinates. If FlippedFrameBuffer() is true,
+  // |projection_matrix| includes this flip.
+  gfx::Transform projection_matrix;
+  // |quad_to_target_transform| transforms from local quad pixel coordinates to
+  // target content space pixel coordinates, including scale, offset,
+  // perspective, and rotation.
+  gfx::Transform quad_to_target_transform;
+  raw_ptr<const cc::FilterOperations> filters = nullptr;
+  raw_ptr<const cc::FilterOperations> backdrop_filters = nullptr;
+  absl::optional<gfx::RRectF> backdrop_filter_bounds;
+
+  // Whether the texture to be sampled from needs to be flipped.
+  bool source_needs_flip = false;
+
+  float edge[24];
+  SkScalar color_matrix[20];
+
+  // Blending in the fragment shaders is used for modifications to the backdrop
+  // and for supporting advanced blending equation when not available by the
+  // underlying graphics API.
+  bool use_shaders_for_blending = false;
+  SkBlendMode blend_mode = SkBlendMode::kSrcOver;
+
+  bool use_aa = false;
+
+  // Some filters affect pixels outside the original contents bounds, in which
+  // case ApplyImageFilter will modify this rect.
+  gfx::RectF dst_rect;
+
+  // A Skia image that should be sampled from instead of the original
+  // contents.
+  sk_sp<SkImage> filter_image;
+
+  // The original contents, bound for sampling.
+  std::unique_ptr<DisplayResourceProviderGL::ScopedSamplerGL>
+      bypass_quad_resource_lock;
+
+  // A mask to be applied when drawing the RPDQ.
+  std::unique_ptr<DisplayResourceProviderGL::ScopedSamplerGL>
+      mask_resource_lock;
+
+  // Whether a color matrix needs to be applied by the shaders when drawing
+  // the RPDQ.
+  bool use_color_matrix = false;
+
+  gfx::QuadF surface_quad;
+
+  // |contents_device_transform| transforms from vertex geometry, which is often
+  // the unit quad [-0.5, 0.5], all the way to 2D window pixel coordinates,
+  // including 3D effects, frame buffer orientation, and window offset. The
+  // definition of the incoming vertex geometry comes from either
+  // shared_geometry_ or clipped_geometry_, which are initialized from
+  // DirectRenderer::QuadVertexRect or DynamicGeometryBinding, respectively.
+  // |contents_device_transform| is typically calculated as
+  //    |window_matrix| * |projection_matrix| * |quad_rect_matrix|
+  // and then flattened with FlattenTo2d(). Here, |quad_rect_matrix| is a
+  // combination of the geometry->quad transform as well as the quad->target
+  // space transform. The geometry->quad is the mapping from the bound geometry,
+  // often [-0.5, 0.5], to the quad, which is quad->rect.
+  gfx::Transform contents_device_transform;
+
+  gfx::RectF tex_coord_rect;
+
+  // The color space of the texture bound for sampling (from filter_image or
+  // bypass_quad_resource_lock, depending on the path taken).
+  gfx::ColorSpace contents_and_bypass_color_space;
+
+  // Background filters block.
+  // Original background texture.
+  uint32_t background_texture = 0;
+  GLenum background_texture_format = 0;
+  // Backdrop bounding box.
+  gfx::Rect background_rect;
+  // Filtered background texture.
+  sk_sp<SkImage> background_image;
+  GLuint background_image_id = 0;
+  // A multiplier for the temporary surface we create to apply the backdrop
+  // filter.
+  float backdrop_filter_quality = 1.0;
+  // Whether the original background texture is needed for the mask.
+  bool mask_for_background = false;
+
+  bool apply_shader_based_rounded_corner = true;
+};
+
+class GLRenderer::ScopedUseGrContext {
+ public:
+  static std::unique_ptr<ScopedUseGrContext> Create(GLRenderer* renderer) {
+    // GrContext for filters is created lazily, and may fail if the context
+    // is lost.
+    // TODO(vmiura,bsalomon): crbug.com/487850 Ensure that
+    // ContextProvider::GrContext() does not return NULL.
+    GrDirectContext* direct = GrAsDirectContext(
+        renderer->output_surface_->context_provider()->GrContext());
+    if (direct)
+      return base::WrapUnique(new ScopedUseGrContext(renderer));
+    return nullptr;
+  }
+
+  ScopedUseGrContext(const ScopedUseGrContext&) = delete;
+  ScopedUseGrContext& operator=(const ScopedUseGrContext&) = delete;
+
+  ~ScopedUseGrContext() {
+    // Pass context control back to GLrenderer.
+    scoped_gpu_raster_ = nullptr;
+    renderer_->RestoreGLStateAfterSkia();
+  }
+
+  GrDirectContext* context() const {
+    return renderer_->output_surface_->context_provider()->GrContext();
+  }
+
+ private:
+  explicit ScopedUseGrContext(GLRenderer* renderer)
+      : scoped_gpu_raster_(new cc::ScopedGpuRaster(
+            renderer->output_surface_->context_provider())),
+        renderer_(renderer) {
+    // scoped_gpu_raster_ passes context control to Skia.
+  }
+
+  std::unique_ptr<cc::ScopedGpuRaster> scoped_gpu_raster_;
+  raw_ptr<GLRenderer> renderer_;
+};
+
+GLRenderer::GLRenderer(
+    const RendererSettings* settings,
+    const DebugRendererSettings* debug_settings,
+    OutputSurface* output_surface,
+    DisplayResourceProviderGL* resource_provider,
+    OverlayProcessorInterface* overlay_processor,
+    scoped_refptr<base::SingleThreadTaskRunner> current_task_runner)
+    : DirectRenderer(settings,
+                     debug_settings,
+                     output_surface,
+                     resource_provider,
+                     overlay_processor),
+      shared_geometry_quad_(QuadVertexRect()),
+      gl_(output_surface->context_provider()->ContextGL()),
+      context_support_(output_surface->context_provider()->ContextSupport()),
+      texture_deleter_(current_task_runner),
+      copier_(output_surface->context_provider(), &texture_deleter_),
+      sync_queries_(gl_),
+      bound_geometry_(NO_BINDING),
+      current_task_runner_(std::move(current_task_runner)) {
+  DCHECK(gl_);
+  DCHECK(context_support_);
+
+  const auto& context_caps =
+      output_surface_->context_provider()->ContextCapabilities();
+
+  use_discard_framebuffer_ = context_caps.discard_framebuffer;
+  use_sync_query_ = context_caps.sync_query;
+  use_blend_equation_advanced_ = context_caps.blend_equation_advanced;
+  use_blend_equation_advanced_coherent_ =
+      context_caps.blend_equation_advanced_coherent;
+  use_occlusion_query_ = context_caps.occlusion_query;
+  use_timer_query_ = context_caps.timer_queries;
+  use_swap_with_bounds_ = context_caps.swap_buffers_with_bounds;
+  supports_multi_sampling_ = context_caps.max_samples > 0;
+  prefer_draw_to_copy_ = output_surface_->context_provider()
+                             ->GetGpuFeatureInfo()
+                             .IsWorkaroundEnabled(gpu::PREFER_DRAW_TO_COPY);
+  use_fast_path_solid_color_quad_ =
+      features::IsUsingFastPathForSolidColorQuad();
+  InitializeSharedObjects();
+}
+
+GLRenderer::~GLRenderer() {
+  CleanupSharedObjects();
+
+  auto* context_provider = output_surface_->context_provider();
+  auto* cache_controller = context_provider->CacheController();
+
+  if (context_busy_) {
+    cache_controller->ClientBecameNotBusy(std::move(context_busy_));
+  }
+  if (context_visibility_) {
+    cache_controller->ClientBecameNotVisibleDuringShutdown(
+        std::move(context_visibility_));
+  }
+}
+
+bool GLRenderer::CanPartialSwap() {
+  if (use_swap_with_bounds_)
+    return false;
+  auto* context_provider = output_surface_->context_provider();
+  return context_provider->ContextCapabilities().post_sub_buffer;
+}
+
+void GLRenderer::DidChangeVisibility() {
+  if (visible_) {
+    output_surface_->EnsureBackbuffer();
+  } else {
+    TRACE_EVENT0("viz", "GLRenderer::DidChangeVisibility dropping resources");
+    ReleaseRenderPassTextures();
+    output_surface_->DiscardBackbuffer();
+    gl_->ReleaseShaderCompiler();
+  }
+
+  PrepareGeometry(NO_BINDING);
+
+  auto* context_provider = output_surface_->context_provider();
+  auto* cache_controller = context_provider->CacheController();
+  if (visible_) {
+    DCHECK(!context_visibility_);
+    context_visibility_ = cache_controller->ClientBecameVisible();
+  } else {
+    DCHECK(context_visibility_);
+    cache_controller->ClientBecameNotVisible(std::move(context_visibility_));
+  }
+}
+
+void GLRenderer::ReleaseRenderPassTextures() {
+  render_pass_textures_.clear();
+  render_pass_backdrop_textures_.clear();
+}
+
+void GLRenderer::DiscardPixels() {
+  if (!use_discard_framebuffer_)
+    return;
+  bool using_default_framebuffer =
+      !current_framebuffer_texture_ &&
+      output_surface_->capabilities().uses_default_gl_framebuffer;
+  GLenum attachments[] = {static_cast<GLenum>(
+      using_default_framebuffer ? GL_COLOR_EXT : GL_COLOR_ATTACHMENT0_EXT)};
+  gl_->DiscardFramebufferEXT(GL_FRAMEBUFFER, std::size(attachments),
+                             attachments);
+}
+
+void GLRenderer::PrepareSurfaceForPass(
+    SurfaceInitializationMode initialization_mode,
+    const gfx::Rect& render_pass_scissor) {
+  SetViewport();
+
+  switch (initialization_mode) {
+    case SURFACE_INITIALIZATION_MODE_PRESERVE:
+      EnsureScissorTestDisabled();
+      return;
+    case SURFACE_INITIALIZATION_MODE_FULL_SURFACE_CLEAR:
+      EnsureScissorTestDisabled();
+      DiscardPixels();
+      ClearFramebuffer();
+      break;
+    case SURFACE_INITIALIZATION_MODE_SCISSORED_CLEAR:
+      SetScissorTestRect(render_pass_scissor);
+      ClearFramebuffer();
+      break;
+  }
+
+  if (OverdrawTracingEnabled()) {
+    gl_->GenQueriesEXT(1, &occlusion_query_);
+    gl_->BeginQueryEXT(GL_SAMPLES_PASSED_ARB, occlusion_query_);
+  }
+
+  // For each render pass, reset the drawn region.
+  drawn_rects_.clear();
+}
+
+void GLRenderer::ClearFramebuffer() {
+  // On DEBUG builds, opaque render passes are cleared to blue to easily see
+  // regions that were not drawn on the screen.
+  if (current_frame()->current_render_pass->has_transparent_background)
+    gl_->ClearColor(0, 0, 0, 0);
+  else
+    gl_->ClearColor(0, 0, 1, 1);
+
+  gl_->ClearStencil(0);
+
+  bool always_clear = overdraw_feedback_;
+#ifndef NDEBUG
+  always_clear = true;
+#endif
+  if (always_clear ||
+      current_frame()->current_render_pass->has_transparent_background) {
+    GLbitfield clear_bits = GL_COLOR_BUFFER_BIT;
+    if (always_clear)
+      clear_bits |= GL_STENCIL_BUFFER_BIT;
+    gl_->Clear(clear_bits);
+  }
+}
+
+void GLRenderer::BeginDrawingFrame() {
+  TRACE_EVENT0("viz", "GLRenderer::BeginDrawingFrame");
+
+  if (!context_busy_) {
+    context_busy_ = output_surface_->context_provider()
+                        ->CacheController()
+                        ->ClientBecameBusy();
+  }
+
+  // Begin batching read of shared images.
+  gl_->BeginBatchReadAccessSharedImageCHROMIUM();
+
+  scoped_refptr<ResourceFence> read_lock_fence;
+  if (use_sync_query_) {
+    read_lock_fence = sync_queries_.StartNewFrame();
+  } else {
+    read_lock_fence =
+        base::MakeRefCounted<DisplayResourceProviderGL::SynchronousFence>(gl_);
+  }
+  resource_provider()->SetReadLockFence(read_lock_fence.get());
+
+  // Insert WaitSyncTokenCHROMIUM on quad resources prior to drawing the frame,
+  // so that drawing can proceed without GL context switching interruptions.
+  for (const auto& pass : *current_frame()->render_passes_in_draw_order) {
+    for (auto* quad : pass->quad_list) {
+      for (ResourceId resource_id : quad->resources)
+        resource_provider()->WaitSyncToken(resource_id);
+    }
+  }
+
+  // TODO(enne): Do we need to reinitialize all of this state per frame?
+  ReinitializeGLState();
+
+  // Add a dummy timer query as a fence to identify the beginning of a frame in
+  // the circular queue.
+  if (CompositeTimeTracingEnabled())
+    timer_queries_.emplace(kTimerQueryDummy, "");
+
+  num_triangles_drawn_ = 0;
+}
+
+void GLRenderer::DoDrawQuad(const DrawQuad* quad,
+                            const gfx::QuadF* clip_region) {
+  DCHECK(quad->rect.Contains(quad->visible_rect));
+  if (quad->material != DrawQuad::Material::kTextureContent) {
+    FlushTextureQuadCache(SHARED_BINDING);
+  }
+
+  switch (quad->material) {
+    case DrawQuad::Material::kInvalid:
+      NOTREACHED();
+      break;
+    case DrawQuad::Material::kAggregatedRenderPass:
+      DrawRenderPassQuad(AggregatedRenderPassDrawQuad::MaterialCast(quad),
+                         clip_region);
+      break;
+    case DrawQuad::Material::kDebugBorder:
+      DrawDebugBorderQuad(DebugBorderDrawQuad::MaterialCast(quad));
+      break;
+    case DrawQuad::Material::kPictureContent:
+      // PictureDrawQuad should only be used for resourceless software draws.
+      NOTREACHED();
+      break;
+    case DrawQuad::Material::kCompositorRenderPass:
+      // At this point, RenderPassDrawQuads should be replaced by
+      // AggregatedRenderPassDrawQuad.
+      NOTREACHED();
+      break;
+    case DrawQuad::Material::kSolidColor:
+      DrawSolidColorQuad(SolidColorDrawQuad::MaterialCast(quad), clip_region);
+      break;
+    case DrawQuad::Material::kStreamVideoContent:
+      DrawStreamVideoQuad(StreamVideoDrawQuad::MaterialCast(quad), clip_region);
+      break;
+    case DrawQuad::Material::kSurfaceContent:
+      // Surface content should be fully resolved to other quad types before
+      // reaching a direct renderer.
+      NOTREACHED();
+      break;
+    case DrawQuad::Material::kSharedElement:
+      // Shared element should be fully resolved to other quad types before
+      // reaching a direct renderer.
+      NOTREACHED();
+      break;
+    case DrawQuad::Material::kTextureContent:
+      EnqueueTextureQuad(TextureDrawQuad::MaterialCast(quad), clip_region);
+      break;
+    case DrawQuad::Material::kTiledContent:
+      DrawTileQuad(TileDrawQuad::MaterialCast(quad), clip_region);
+      break;
+    case DrawQuad::Material::kYuvVideoContent:
+      DrawYUVVideoQuad(YUVVideoDrawQuad::MaterialCast(quad), clip_region);
+      break;
+    case DrawQuad::Material::kVideoHole:
+      // VideoHoleDrawQuad should only be used by Cast, and should
+      // have been replaced by cast-specific OverlayProcessor before
+      // reach here. In non-cast build, an untrusted render could send such
+      // Quad and the quad would then reach here unexpectedly. Therefore
+      // we should skip NOTREACHED() so an untrusted render is not capable
+      // of causing a crash.
+      break;
+  }
+}
+
+// This function does not handle 3D sorting right now, since the debug border
+// quads are just drawn as their original quads and not in split pieces. This
+// results in some debug border quads drawing over foreground quads.
+void GLRenderer::DrawDebugBorderQuad(const DebugBorderDrawQuad* quad) {
+  SetBlendEnabled(quad->ShouldDrawWithBlending());
+
+  SetUseProgram(ProgramKey::DebugBorder(), gfx::ColorSpace::CreateSRGB(),
+                CurrentRenderPassColorSpace());
+
+  // Use the full quad_rect for debug quads to not move the edges based on
+  // partial swaps.
+  gfx::Rect layer_rect = quad->rect;
+  gfx::Transform render_matrix;
+  QuadRectTransform(&render_matrix,
+                    quad->shared_quad_state->quad_to_target_transform,
+                    gfx::RectF(layer_rect));
+  SetShaderMatrix(current_frame()->projection_matrix * render_matrix);
+  SetShaderColor(quad->color, 1.f);
+
+  gl_->LineWidth(quad->width);
+
+  // The indices for the line are stored in the same array as the triangle
+  // indices.
+  gl_->DrawElements(GL_LINE_LOOP, 4, GL_UNSIGNED_SHORT, nullptr);
+}
+
+// This is a utility to convert from GrGLenum color format into the equivalent
+// skColorType format. Note: this only supports the limited set of values that
+// can get returned by GLRenderer::GetBackdropTexture().
+static SkColorType GlFormatToSkFormat(GrGLenum format) {
+  switch (format) {
+    case GL_RGB:
+      return kRGB_888x_SkColorType;
+    case GL_RGBA:
+      return kRGBA_8888_SkColorType;
+    case GL_BGRA_EXT:
+      return kBGRA_8888_SkColorType;
+    case GL_RGB10_A2_EXT:
+      return kRGBA_1010102_SkColorType;
+    default:
+      NOTREACHED() << std::hex << std::showbase << format;
+      return kN32_SkColorType;
+  }
+}
+
+static GrGLenum SkFormatToGlFormat(SkColorType format) {
+  switch (format) {
+    case kRGB_888x_SkColorType:
+      return GL_RGB8_OES;
+    case kRGBA_8888_SkColorType:
+      return GL_RGBA8_OES;
+    case kBGRA_8888_SkColorType:
+      return GL_BGRA8_EXT;
+    case kRGBA_1010102_SkColorType:
+      return GL_RGB10_A2_EXT;
+    default:
+      NOTREACHED();
+      return GL_RGBA8_OES;
+  }
+}
+
+// Wrap a given texture in a Ganesh backend texture.
+static sk_sp<SkImage> WrapTexture(uint32_t texture_id,
+                                  uint32_t target,
+                                  const gfx::Size& size,
+                                  GrDirectContext* context,
+                                  bool flip_texture,
+                                  SkColorType format,
+                                  bool adopt_texture) {
+  GrGLenum texture_format = SkFormatToGlFormat(format);
+  GrGLTextureInfo texture_info;
+  texture_info.fTarget = target;
+  texture_info.fID = texture_id;
+  texture_info.fFormat = texture_format;
+  GrBackendTexture backend_texture(size.width(), size.height(),
+                                   GrMipMapped::kNo, texture_info);
+  GrSurfaceOrigin origin =
+      flip_texture ? kBottomLeft_GrSurfaceOrigin : kTopLeft_GrSurfaceOrigin;
+  if (adopt_texture) {
+    return SkImage::MakeFromAdoptedTexture(
+        context, backend_texture, origin, format, kPremul_SkAlphaType, nullptr);
+  } else {
+    return SkImage::MakeFromTexture(context, backend_texture, origin, format,
+                                    kPremul_SkAlphaType, nullptr);
+  }
+}
+
+static gfx::RectF CenteredRect(const gfx::Rect& tile_rect) {
+  return gfx::RectF(
+      gfx::PointF(-0.5f * tile_rect.width(), -0.5f * tile_rect.height()),
+      gfx::SizeF(tile_rect.size()));
+}
+
+bool GLRenderer::CanApplyBlendModeUsingBlendFunc(SkBlendMode blend_mode) {
+  return use_blend_equation_advanced_ || blend_mode == SkBlendMode::kSrcOver ||
+         blend_mode == SkBlendMode::kDstIn ||
+         blend_mode == SkBlendMode::kScreen;
+}
+
+void GLRenderer::ApplyBlendModeUsingBlendFunc(SkBlendMode blend_mode) {
+  // Any modes set here must be reset in RestoreBlendFuncToDefault
+  if (blend_mode == SkBlendMode::kSrcOver) {
+    // Left no-op intentionally.
+  } else if (blend_mode == SkBlendMode::kDstIn) {
+    gl_->BlendFunc(GL_ZERO, GL_SRC_ALPHA);
+  } else if (blend_mode == SkBlendMode::kDstOut) {
+    gl_->BlendFunc(GL_ZERO, GL_ONE_MINUS_SRC_ALPHA);
+  } else if (blend_mode == SkBlendMode::kScreen) {
+    gl_->BlendFunc(GL_ONE_MINUS_DST_COLOR, GL_ONE);
+  } else {
+    DCHECK(use_blend_equation_advanced_);
+    GLenum equation = GL_FUNC_ADD;
+    switch (blend_mode) {
+      case SkBlendMode::kScreen:
+        equation = GL_SCREEN_KHR;
+        break;
+      case SkBlendMode::kOverlay:
+        equation = GL_OVERLAY_KHR;
+        break;
+      case SkBlendMode::kDarken:
+        equation = GL_DARKEN_KHR;
+        break;
+      case SkBlendMode::kLighten:
+        equation = GL_LIGHTEN_KHR;
+        break;
+      case SkBlendMode::kColorDodge:
+        equation = GL_COLORDODGE_KHR;
+        break;
+      case SkBlendMode::kColorBurn:
+        equation = GL_COLORBURN_KHR;
+        break;
+      case SkBlendMode::kHardLight:
+        equation = GL_HARDLIGHT_KHR;
+        break;
+      case SkBlendMode::kSoftLight:
+        equation = GL_SOFTLIGHT_KHR;
+        break;
+      case SkBlendMode::kDifference:
+        equation = GL_DIFFERENCE_KHR;
+        break;
+      case SkBlendMode::kExclusion:
+        equation = GL_EXCLUSION_KHR;
+        break;
+      case SkBlendMode::kMultiply:
+        equation = GL_MULTIPLY_KHR;
+        break;
+      case SkBlendMode::kHue:
+        equation = GL_HSL_HUE_KHR;
+        break;
+      case SkBlendMode::kSaturation:
+        equation = GL_HSL_SATURATION_KHR;
+        break;
+      case SkBlendMode::kColor:
+        equation = GL_HSL_COLOR_KHR;
+        break;
+      case SkBlendMode::kLuminosity:
+        equation = GL_HSL_LUMINOSITY_KHR;
+        break;
+      default:
+        NOTREACHED() << "Unexpected blend mode: SkBlendMode::k"
+                     << SkBlendMode_Name(blend_mode);
+        return;
+    }
+    gl_->BlendEquation(equation);
+  }
+}
+
+void GLRenderer::RestoreBlendFuncToDefault(SkBlendMode blend_mode) {
+  switch (blend_mode) {
+    case SkBlendMode::kSrcOver:
+      break;
+    case SkBlendMode::kDstIn:
+    case SkBlendMode::kDstOut:
+    case SkBlendMode::kScreen:
+      gl_->BlendFunc(GL_ONE, GL_ONE_MINUS_SRC_ALPHA);
+      break;
+    default:
+      DCHECK(use_blend_equation_advanced_);
+      gl_->BlendEquation(GL_FUNC_ADD);
+  }
+}
+
+bool GLRenderer::ShouldApplyBackdropFilters(
+    const DrawRenderPassDrawQuadParams* params) {
+  if (!params->backdrop_filters)
+    return false;
+  if (params->quad->shared_quad_state->opacity == 0.f)
+    return false;
+  DCHECK(!params->backdrop_filters->IsEmpty());
+  return true;
+}
+
+gfx::Rect GLRenderer::GetBackdropBoundingBoxForRenderPassQuad(
+    DrawRenderPassDrawQuadParams* params,
+    gfx::Transform* backdrop_filter_bounds_transform,
+    absl::optional<gfx::RRectF>* backdrop_filter_bounds,
+    gfx::Rect* unclipped_rect) const {
+  DCHECK(backdrop_filter_bounds_transform);
+  DCHECK(backdrop_filter_bounds);
+  DCHECK(unclipped_rect);
+
+  const auto* quad = params->quad.get();
+  gfx::QuadF scaled_region;
+  // |scaled_region| is a quad in [-0.5,0.5] space that represents |clip_region|
+  // as a fraction of the space defined by |quad->rect|. If |clip_region| is
+  // nullptr, then scaled_region is [-0.5,0.5].
+  if (!GetScaledRegion(quad->rect, params->clip_region, &scaled_region)) {
+    scaled_region = SharedGeometryQuad().BoundingBox();
+  }
+  // |backdrop_filter_bounds| is a rounded rect in [-0.5,0.5] space that
+  // represents |params->backdrop_filter_bounds| as a fraction of the space
+  // defined by |quad->rect|, not including its offset.
+  *backdrop_filter_bounds = gfx::RRectF();
+  if (!params->backdrop_filter_bounds ||
+      !GetScaledRRectF(quad->rect, params->backdrop_filter_bounds.value(),
+                       &backdrop_filter_bounds->value())) {
+    backdrop_filter_bounds->reset();
+  }
+
+  // |backdrop_rect| is now the bounding box of clip_region, in window pixel
+  // coordinates, and with flip applied.
+  gfx::Rect backdrop_rect = gfx::ToEnclosingRect(cc::MathUtil::MapClippedRect(
+      params->contents_device_transform, scaled_region.BoundingBox()));
+
+  if (!backdrop_rect.IsEmpty() && (params->filters || params->use_aa)) {
+    // If we have regular filters or antialiasing, grab an extra one-pixel
+    // border around the background, so texture edge clamping gives us a
+    // transparent border.
+    backdrop_rect.Inset(-1);
+  }
+
+  *unclipped_rect = backdrop_rect;
+  backdrop_rect.Intersect(MoveFromDrawToWindowSpace(
+      current_frame()->current_render_pass->output_rect));
+  if (ShouldApplyBackdropFilters(params)) {
+    float max_pixel_movement = params->backdrop_filters->MaximumPixelMovement();
+    gfx::Rect scissor_rect(current_window_space_viewport_);
+    scissor_rect.Inset(-max_pixel_movement);
+    backdrop_rect.Intersect(scissor_rect);
+  }
+
+  // The frame buffer flip is already included in the captured backdrop image,
+  // and it is included in |contents_device_transform| (through
+  // |projection_matrix|). Don't double-flip.
+  *backdrop_filter_bounds_transform = params->contents_device_transform;
+  float new_y = 2 * backdrop_filter_bounds_transform->To2dTranslation().y() +
+                backdrop_rect.bottom() - unclipped_rect->bottom() +
+                backdrop_rect.y() - unclipped_rect->y();
+  backdrop_filter_bounds_transform->PostScale(1, -1);
+  backdrop_filter_bounds_transform->PostTranslate(0, new_y);
+
+  // Shift to the space of the captured backdrop image.
+  backdrop_filter_bounds_transform->PostTranslate(-backdrop_rect.x(),
+                                                  -backdrop_rect.y());
+
+  return backdrop_rect;
+}
+
+GLenum GLRenderer::GetFramebufferCopyTextureFormat() {
+  // If copying a non-root renderpass then use the format of the bound
+  // texture. Otherwise, we use the format of the default framebuffer. But
+  // whatever the format is, convert it to a valid format for CopyTexSubImage2D.
+  GLenum format;
+  if (!current_framebuffer_texture_) {
+    format = output_surface_->GetFramebufferCopyTextureFormat();
+  } else {
+    ResourceFormat resource_format = CurrentRenderPassResourceFormat();
+    DCHECK(GLSupportsFormat(resource_format));
+    format = GLCopyTextureInternalFormat(resource_format);
+  }
+  // Verify the format is valid for GLES2's glCopyTexSubImage2D.
+  DCHECK(format == GL_ALPHA || format == GL_LUMINANCE ||
+         format == GL_LUMINANCE_ALPHA || format == GL_RGB ||
+         format == GL_RGBA ||
+         (output_surface_->context_provider()
+              ->ContextCapabilities()
+              .texture_format_bgra8888 &&
+          format == GL_BGRA_EXT) ||
+         format == GL_RGB10_A2_EXT)
+      << std::hex << std::showbase << format;
+  return format;
+}
+
+uint32_t GLRenderer::GetBackdropTexture(const gfx::Rect& window_rect,
+                                        float scale,
+                                        GLenum* internal_format) {
+  DCHECK(internal_format);
+  DCHECK_GE(window_rect.x(), 0);
+  DCHECK_GE(window_rect.y(), 0);
+  DCHECK_LE(window_rect.right(), current_surface_size_.width());
+  DCHECK_LE(window_rect.bottom(), current_surface_size_.height());
+
+  uint32_t texture_id;
+  gl_->GenTextures(1, &texture_id);
+  DCHECK(texture_id);
+  gl_->BindTexture(GL_TEXTURE_2D, texture_id);
+
+  gl_->TexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR);
+  gl_->TexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);
+  gl_->TexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);
+  gl_->TexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);
+  ResourceFormat resource_format = CurrentRenderPassResourceFormat();
+  // Get gl_format, gl_type and internal_format.
+  DCHECK(GLSupportsFormat(resource_format));
+  *internal_format = GLInternalFormat(resource_format);
+  GLenum gl_format = GLDataFormat(resource_format);
+  GLenum gl_type = GLDataType(resource_format);
+
+  if (supports_multi_sampling_ && scale != 1.0f) {
+    DCHECK(!prefer_draw_to_copy_ || !current_framebuffer_texture_);
+
+    gfx::Size target_size = window_rect.size();
+    target_size = gfx::ScaleToCeiledSize(target_size, scale);
+
+    gl_->TexImage2D(GL_TEXTURE_2D, 0, *internal_format, target_size.width(),
+                    target_size.height(), 0, gl_format, gl_type, nullptr);
+
+    unsigned fbo = 0;
+    gl_->GenFramebuffers(1, &fbo);
+    gl_->BindFramebuffer(GL_DRAW_FRAMEBUFFER, fbo);
+    gl_->FramebufferTexture2D(GL_DRAW_FRAMEBUFFER_EXT, GL_COLOR_ATTACHMENT0,
+                              GL_TEXTURE_2D, texture_id, 0);
+    DCHECK_EQ(static_cast<GLenum>(GL_FRAMEBUFFER_COMPLETE),
+              gl_->CheckFramebufferStatus(GL_DRAW_FRAMEBUFFER_EXT));
+
+    gl_->Scissor(0, 0, target_size.width(), target_size.height());
+
+    gl_->BlitFramebufferCHROMIUM(window_rect.x(), window_rect.y(),
+                                 window_rect.right(), window_rect.bottom(), 0,
+                                 0, target_size.width(), target_size.height(),
+                                 GL_COLOR_BUFFER_BIT, GL_LINEAR);
+
+    gl_->DeleteFramebuffers(1, &fbo);
+  } else if (prefer_draw_to_copy_ && current_framebuffer_texture_) {
+    // If there is a source texture |current_framebuffer_texture_| and the
+    // workaround |prefer_draw_to_copy_| is enabled, then do texture to texture
+    // copy via draw instead of glCopyTexImage2D.
+
+    // Size the destination texture with empty data. This is required since
+    // CopySubTextureCHROMIUM() does not sizes the texture but CopyTexImage2D
+    // does.
+    gl_->TexImage2D(GL_TEXTURE_2D, 0, *internal_format, window_rect.width(),
+                    window_rect.height(), 0, gl_format, gl_type, nullptr);
+    gl_->CopySubTextureCHROMIUM(
+        current_framebuffer_texture_->id(), 0, GL_TEXTURE_2D, texture_id, 0, 0,
+        0, window_rect.x(), window_rect.y(), window_rect.width(),
+        window_rect.height(), GL_FALSE, GL_FALSE, GL_FALSE);
+  } else {
+    *internal_format = GetFramebufferCopyTextureFormat();
+
+    // CopyTexImage2D requires inernalformat channels to be a subset of
+    // the channels of the source texture internalformat.
+    DCHECK(*internal_format == GL_RGB || *internal_format == GL_RGBA ||
+           *internal_format == GL_BGRA_EXT ||
+           *internal_format == GL_RGB10_A2_EXT);
+    if (*internal_format == GL_BGRA_EXT)
+      *internal_format = GL_RGBA;
+    gl_->CopyTexImage2D(GL_TEXTURE_2D, 0, *internal_format, window_rect.x(),
+                        window_rect.y(), window_rect.width(),
+                        window_rect.height(), 0);
+  }
+  gl_->BindTexture(GL_TEXTURE_2D, 0);
+  return texture_id;
+}
+
+static sk_sp<SkImage> FinalizeImage(sk_sp<SkSurface> surface) {
+  // Flush the drawing before source texture read lock goes out of scope.
+  // Skia API does not guarantee that when the SkImage goes out of scope,
+  // its externally referenced resources would force the rendering to be
+  // flushed.
+  surface->getCanvas()->flush();
+  sk_sp<SkImage> image = surface->makeImageSnapshot();
+  if (!image || !image->isTextureBacked()) {
+    return nullptr;
+  }
+  return image;
+}
+
+sk_sp<SkImage> GLRenderer::ApplyBackdropFilters(
+    DrawRenderPassDrawQuadParams* params,
+    const gfx::Rect& unclipped_rect,
+    const absl::optional<gfx::RRectF>& backdrop_filter_bounds,
+    const gfx::Transform& backdrop_filter_bounds_transform) {
+  DCHECK(ShouldApplyBackdropFilters(params));
+  DCHECK(params->backdrop_filter_quality > 0.0f &&
+         params->backdrop_filter_quality <= 1.0f);
+  DCHECK(!params->filters)
+      << "Filters should always be in a separate Effect node";
+  const auto* quad = params->quad.get();
+  auto use_gr_context = ScopedUseGrContext::Create(this);
+
+  // Check if cached result can be used
+  auto bg_texture_it =
+      render_pass_backdrop_textures_.find(quad->render_pass_id);
+  if (bg_texture_it != render_pass_backdrop_textures_.end()) {
+    if (!quad->intersects_damage_under)
+      return bg_texture_it->second;
+    else
+      render_pass_backdrop_textures_.erase(bg_texture_it);
+  }
+
+  gfx::Vector2d clipping_offset =
+      (params->background_rect.top_right() - unclipped_rect.top_right()) +
+      (params->background_rect.bottom_left() - unclipped_rect.bottom_left());
+
+  gfx::Rect quality_adjusted_rect = ScaleToEnclosingRect(
+      params->background_rect, params->backdrop_filter_quality);
+
+  // When backdrop_filter_quality is less than 1.0f, scale the blur amount
+  // accordingly.
+  cc::FilterOperations filter_operations;
+  if (params->backdrop_filter_quality < 1.0f) {
+    for (const cc::FilterOperation& op :
+         params->backdrop_filters->operations()) {
+      if (op.type() == cc::FilterOperation::BLUR) {
+        cc::FilterOperation blur_op(op);
+        blur_op.set_amount(op.amount() * params->backdrop_filter_quality);
+        filter_operations.Append(blur_op);
+      } else {
+        filter_operations.Append(op);
+      }
+    }
+  }
+  const cc::FilterOperations& filters = params->backdrop_filter_quality < 1.0f
+                                            ? filter_operations
+                                            : *params->backdrop_filters;
+
+  auto paint_filter = cc::RenderSurfaceFilters::BuildImageFilter(
+      filters, gfx::SizeF(quality_adjusted_rect.size()),
+      gfx::Vector2dF(clipping_offset));
+
+  // TODO(senorblanco): background filters should be moved to the
+  // makeWithFilter fast-path, and go back to calling ApplyImageFilter().
+  // See http://crbug.com/613233.
+  if (!paint_filter || !use_gr_context)
+    return nullptr;
+
+  auto filter = paint_filter->cached_sk_filter_;
+  sk_sp<SkImage> src_image = WrapTexture(
+      params->background_texture, GL_TEXTURE_2D, quality_adjusted_rect.size(),
+      use_gr_context->context(), /*flip_texture=*/true,
+      GlFormatToSkFormat(params->background_texture_format),
+      /*adopt_texture=*/false);
+  if (!src_image) {
+    TRACE_EVENT_INSTANT0("cc",
+                         "ApplyBackdropFilters wrap background texture failed",
+                         TRACE_EVENT_SCOPE_THREAD);
+    return nullptr;
+  }
+
+  // Create surface to draw into.
+  SkImageInfo dst_info = SkImageInfo::MakeN32Premul(
+      quality_adjusted_rect.width(), quality_adjusted_rect.height());
+  sk_sp<SkSurface> surface = SkSurface::MakeRenderTarget(
+      use_gr_context->context(), SkBudgeted::kYes, dst_info);
+  if (!surface) {
+    TRACE_EVENT_INSTANT0("viz",
+                         "ApplyBackdropFilters surface allocation failed",
+                         TRACE_EVENT_SCOPE_THREAD);
+    return nullptr;
+  }
+
+  // Big filters can sometimes fallback to CPU. Therefore, we need
+  // to disable subnormal floats for performance and security reasons.
+  cc::ScopedSubnormalFloatDisabler disabler;
+
+  gfx::RectF src_image_rect =
+      gfx::RectF(quality_adjusted_rect.width(), quality_adjusted_rect.height());
+  SkRect dest_rect = RectToSkRect(gfx::Rect(quality_adjusted_rect.size()));
+
+  // If the content underneath the backdrop filter can be exposed because of
+  // blending or bounds, paint the backdrop at full opacity first. The
+  // backdrop-filtered content will not be blended with the backdrop later, it
+  // will be rastered over the top. So we need to paint it here, unfiltered.
+  if (backdrop_filter_bounds.has_value() || quad->ShouldDrawWithBlending()) {
+    surface->getCanvas()->drawImageRect(
+        src_image, RectFToSkRect(src_image_rect), dest_rect,
+        SkSamplingOptions(), nullptr, SkCanvas::kStrict_SrcRectConstraint);
+  }
+
+  if (backdrop_filter_bounds.has_value()) {
+    // Crop the source image to the backdrop_filter_bounds.
+    gfx::Rect filter_clip = gfx::ToEnclosingRect(cc::MathUtil::MapClippedRect(
+        backdrop_filter_bounds_transform, backdrop_filter_bounds->rect()));
+    gfx::Rect src_rect(params->background_rect.width(),
+                       params->background_rect.height());
+    filter_clip.Intersect(src_rect);
+    if (filter_clip.IsEmpty())
+      return FinalizeImage(surface);
+    if (filter_clip != src_rect) {
+      filter_clip = gfx::ScaleToEnclosingRect(filter_clip,
+                                              params->backdrop_filter_quality);
+      src_image = src_image->makeSubset(RectToSkIRect(filter_clip),
+                                        use_gr_context->context());
+      src_image_rect = gfx::RectF(filter_clip.width(), filter_clip.height());
+      dest_rect = RectToSkRect(filter_clip);
+    }
+  }
+
+  SkIPoint offset;
+  SkIRect subset;
+  sk_sp<SkImage> filtered_image = SkiaHelper::ApplyImageFilter(
+      use_gr_context->context(), src_image, src_image_rect, src_image_rect,
+      quad->filters_scale, std::move(filter), &offset, &subset,
+      quad->filters_origin, true);
+
+  // Clip the filtered image to the (rounded) bounding box of the element.
+  if (backdrop_filter_bounds.has_value()) {
+    surface->getCanvas()->save();
+    gfx::RRectF clip_rect(backdrop_filter_bounds.value());
+    surface->getCanvas()->setMatrix(
+        backdrop_filter_bounds_transform.matrix().asM33());
+    surface->getCanvas()->clipRRect(SkRRect(clip_rect), SkClipOp::kIntersect,
+                                    true /* antialias */);
+    surface->getCanvas()->resetMatrix();
+  }
+
+  SkPaint paint;
+  // Paint the filtered backdrop image with opacity.
+  if (quad->shared_quad_state->opacity < 1.0) {
+    paint.setImageFilter(
+        SkiaHelper::BuildOpacityFilter(quad->shared_quad_state->opacity));
+  }
+  // Now paint the pre-filtered image onto the canvas (possibly with mask
+  // applied).
+  surface->getCanvas()->drawImageRect(filtered_image, SkRect::Make(subset),
+                                      dest_rect, SkSamplingOptions(), &paint,
+                                      SkCanvas::kStrict_SrcRectConstraint);
+
+  if (backdrop_filter_bounds.has_value()) {
+    surface->getCanvas()->restore();
+  }
+
+  sk_sp<SkImage> filtered_image_texture = FinalizeImage(surface);
+  if (!quad->intersects_damage_under) {
+    render_pass_backdrop_textures_[params->quad->render_pass_id] =
+        filtered_image_texture;
+  }
+  return filtered_image_texture;
+}
+
+const DrawQuad* GLRenderer::CanPassBeDrawnDirectly(
+    const AggregatedRenderPass* pass) {
+#if BUILDFLAG(IS_APPLE)
+  // On Macs, this path can sometimes lead to all black output.
+  // TODO(enne): investigate this and remove this hack.
+  return nullptr;
+#else
+  // Can only collapse a single tile quad.
+  if (pass->quad_list.size() != 1)
+    return nullptr;
+
+  const DrawQuad* quad = *pass->quad_list.BackToFrontBegin();
+  // Hack: this could be supported by concatenating transforms, but
+  // in practice if there is one quad, it is at the origin of the render pass
+  // and has the same size as the pass.
+  if (!quad->shared_quad_state->quad_to_target_transform.IsIdentity() ||
+      quad->rect != pass->output_rect)
+    return nullptr;
+  // The quad is expected to be the entire layer so that AA edges are correct.
+  if (quad->shared_quad_state->quad_layer_rect != quad->rect)
+    return nullptr;
+  if (quad->material != DrawQuad::Material::kTiledContent)
+    return nullptr;
+
+  // TODO(chrishtr): support could be added for opacity, but care needs
+  // to be taken to make sure it is correct w.r.t. non-commutative filters etc.
+  if (quad->shared_quad_state->opacity != 1.0f)
+    return nullptr;
+
+  if (quad->shared_quad_state->blend_mode != SkBlendMode::kSrcOver)
+    return nullptr;
+
+  const TileDrawQuad* tile_quad = TileDrawQuad::MaterialCast(quad);
+  // Hack: this could be supported by passing in a subrectangle to draw
+  // render pass, although in practice if there is only one quad there
+  // will be no border texels on the input.
+  if (tile_quad->tex_coord_rect != gfx::RectF(tile_quad->rect))
+    return nullptr;
+  // Tile quad features not supported in render pass shaders.
+  if (tile_quad->nearest_neighbor)
+    return nullptr;
+  // BUG=skia:3868, Skia currently doesn't support texture rectangle inputs.
+  // See also the DCHECKs about GL_TEXTURE_2D in DrawRenderPassQuad.
+  GLenum target =
+      resource_provider()->GetResourceTextureTarget(tile_quad->resource_id());
+  if (target != GL_TEXTURE_2D)
+    return nullptr;
+
+  return tile_quad;
+#endif
+}
+
+void GLRenderer::DrawRenderPassQuad(const AggregatedRenderPassDrawQuad* quad,
+                                    const gfx::QuadF* clip_region) {
+  auto bypass = render_pass_bypass_quads_.find(quad->render_pass_id);
+  DrawRenderPassDrawQuadParams params;
+  params.quad = quad;
+  params.clip_region = clip_region;
+  params.window_matrix = current_frame()->window_matrix;
+  params.projection_matrix = current_frame()->projection_matrix;
+  params.tex_coord_rect = quad->tex_coord_rect;
+  ScopedTimerQuery scoped_timer_query(CompositeTimeTracingEnabled(), gl_,
+                                      &timer_queries_, "kRenderPassDrawQuad");
+  if (bypass != render_pass_bypass_quads_.end()) {
+    DCHECK(bypass->second->material == DrawQuad::Material::kTiledContent);
+    const TileDrawQuad* tile_quad = TileDrawQuad::MaterialCast(bypass->second);
+    // The projection matrix used by GLRenderer has a flip.  As tile texture
+    // inputs are oriented opposite to framebuffer outputs, don't flip via
+    // texture coords and let the projection matrix naturallyd o it.
+    params.flip_texture = false;
+    params.bypass_quad_texture.resource_id = tile_quad->resource_id();
+    params.bypass_quad_texture.size = tile_quad->texture_size;
+    DrawRenderPassQuadInternal(&params);
+  } else {
+    auto contents_texture_it = render_pass_textures_.find(quad->render_pass_id);
+    DCHECK(contents_texture_it->second.id());
+    // See above comments about texture flipping.  When the input is a
+    // render pass, it needs to an extra flip to be oriented correctly.
+    params.flip_texture = true;
+    params.contents_texture = &contents_texture_it->second;
+    DrawRenderPassQuadInternal(&params);
+  }
+
+  if (params.background_texture) {
+    gl_->DeleteTextures(1, &params.background_texture);
+    params.background_texture = 0;
+  }
+}
+
+void GLRenderer::DrawRenderPassQuadInternal(
+    DrawRenderPassDrawQuadParams* params) {
+  params->quad_to_target_transform =
+      params->quad->shared_quad_state->quad_to_target_transform;
+  if (!InitializeRPDQParameters(params))
+    return;
+
+  UpdateRPDQShadersForBlending(params);
+  bool can_draw = UpdateRPDQWithSkiaFilters(params);
+  // The above calls use ScopedUseGrContext which can change the bound
+  // framebuffer, so we need to restore it for the current RenderPass.
+  UseRenderPass(current_frame()->current_render_pass);
+  // As part of restoring the framebuffer, we call SetViewport directly, rather
+  // than through PrepareSurfaceForPass. PrepareSurfaceForPass also clears the
+  // surface, which is not desired when restoring.
+  SetViewport();
+
+  if (!can_draw)
+    return;
+
+  UpdateRPDQTexturesForSampling(params);
+  UpdateRPDQBlendMode(params);
+  ChooseRPDQProgram(params, CurrentRenderPassColorSpace());
+  UpdateRPDQUniforms(params);
+  DrawRPDQ(*params);
+
+  AccumulateDrawRects(params->quad->visible_rect,
+                      params->quad->shared_quad_state->quad_to_target_transform,
+                      &drawn_rects_);
+}
+
+bool GLRenderer::InitializeRPDQParameters(
+    DrawRenderPassDrawQuadParams* params) {
+  DCHECK(params);
+  const auto* quad = params->quad.get();
+  SkMatrix local_matrix;
+  local_matrix.setTranslate(quad->filters_origin.x(), quad->filters_origin.y());
+  local_matrix.postScale(quad->filters_scale.x(), quad->filters_scale.y());
+  params->filters = FiltersForPass(quad->render_pass_id);
+  params->backdrop_filters = BackdropFiltersForPass(quad->render_pass_id);
+  if (ShouldApplyBackdropFilters(params)) {
+    params->backdrop_filter_bounds =
+        BackdropFilterBoundsForPass(quad->render_pass_id);
+    if (params->backdrop_filter_bounds.has_value()) {
+      params->backdrop_filter_bounds->Scale(quad->filters_scale.x(),
+                                            quad->filters_scale.y());
+    }
+  } else {
+    params->backdrop_filter_bounds.reset();
+  }
+  params->backdrop_filter_quality = quad->backdrop_filter_quality;
+  gfx::Rect dst_rect = params->filters
+                           ? params->filters->MapRect(quad->rect, local_matrix)
+                           : quad->rect;
+  params->dst_rect.SetRect(static_cast<float>(dst_rect.x()),
+                           static_cast<float>(dst_rect.y()),
+                           static_cast<float>(dst_rect.width()),
+                           static_cast<float>(dst_rect.height()));
+  gfx::Transform quad_rect_matrix;
+  gfx::Rect quad_layer_rect(quad->shared_quad_state->quad_layer_rect);
+  if (params->filters)
+    quad_layer_rect = params->filters->MapRect(quad_layer_rect, local_matrix);
+  QuadRectTransform(&quad_rect_matrix, params->quad_to_target_transform,
+                    gfx::RectF(quad_layer_rect));
+  params->contents_device_transform =
+      params->window_matrix * params->projection_matrix * quad_rect_matrix;
+  params->contents_device_transform.FlattenTo2d();
+
+  // Can only draw surface if device matrix is invertible.
+  if (!params->contents_device_transform.IsInvertible())
+    return false;
+
+  // TODO(sunxd): unify the anti-aliasing logic of RPDQ and TileDrawQuad.
+  params->surface_quad = SharedGeometryQuad();
+  gfx::QuadF device_layer_quad;
+  if (settings_->allow_antialiasing && !quad->force_anti_aliasing_off &&
+      quad->IsEdge()) {
+    bool clipped = false;
+    device_layer_quad = cc::MathUtil::MapQuad(params->contents_device_transform,
+                                              params->surface_quad, &clipped);
+    params->use_aa = ShouldAntialiasQuad(device_layer_quad, clipped,
+                                         settings_->force_antialiasing);
+  }
+
+  const gfx::QuadF* aa_quad = params->use_aa ? &device_layer_quad : nullptr;
+  SetupRenderPassQuadForClippingAndAntialiasing(
+      params->contents_device_transform, quad, aa_quad, params->clip_region,
+      &params->surface_quad, params->edge);
+
+  return true;
+}
+
+// Get a GL texture id from an SkImage. An optional origin pointer can be
+// passed in which will be filled out with the origin for the texture
+// backing the SkImage.
+static GLuint GetGLTextureIDFromSkImage(const SkImage* image,
+                                        GrSurfaceOrigin* origin = nullptr) {
+  GrBackendTexture backend_texture = image->getBackendTexture(true, origin);
+  if (!backend_texture.isValid()) {
+    return 0;
+  }
+  GrGLTextureInfo info;
+  bool result = backend_texture.getGLTextureInfo(&info);
+  DCHECK(result);
+  return info.fID;
+}
+
+void GLRenderer::UpdateRPDQShadersForBlending(
+    DrawRenderPassDrawQuadParams* params) {
+  const auto* quad = params->quad.get();
+  params->blend_mode = quad->shared_quad_state->blend_mode;
+  params->use_shaders_for_blending =
+      !CanApplyBlendModeUsingBlendFunc(params->blend_mode) ||
+      ShouldApplyBackdropFilters(params) ||
+      settings_->force_blending_with_shaders;
+
+  if (params->use_shaders_for_blending) {
+    // Compute a bounding box around the pixels that will be visible through
+    // the quad.
+    absl::optional<gfx::RRectF> backdrop_filter_bounds;
+    gfx::Transform backdrop_filter_bounds_transform;
+    gfx::Rect unclipped_rect;
+    params->background_rect = GetBackdropBoundingBoxForRenderPassQuad(
+        params, &backdrop_filter_bounds_transform, &backdrop_filter_bounds,
+        &unclipped_rect);
+
+    if (!params->background_rect.IsEmpty()) {
+      // The pixels from the filtered background should completely replace the
+      // current pixel values.
+      if (blend_enabled())
+        SetBlendEnabled(false);
+
+      // Read the pixels in the bounding box into a buffer R.
+      // This function allocates a texture, which should contribute to the
+      // amount of memory used by render surfaces:
+      // LayerTreeHost::CalculateMemoryForRenderSurfaces.
+      const auto& operations = params->backdrop_filters->operations();
+      DCHECK(params->backdrop_filter_quality == 1.0f ||
+             (operations.size() == 1 &&
+              operations.front().type() == cc::FilterOperation::BLUR));
+      params->background_texture = GetBackdropTexture(
+          params->background_rect, params->backdrop_filter_quality,
+          &params->background_texture_format);
+
+      if (ShouldApplyBackdropFilters(params)) {
+        // Apply the background filters to R, so that it is applied in the
+        // pixels' coordinate space.
+        params->background_image =
+            ApplyBackdropFilters(params, unclipped_rect, backdrop_filter_bounds,
+                                 backdrop_filter_bounds_transform);
+        if (params->background_image) {
+          params->background_image_id =
+              GetGLTextureIDFromSkImage(params->background_image.get());
+          DCHECK(params->background_image_id || IsContextLost());
+        }
+      }
+      if (params->background_image_id) {
+        // Reset original background texture if there is not any mask.
+        if (!quad->mask_resource_id()) {
+          gl_->DeleteTextures(1, &params->background_texture);
+          params->background_texture = 0;
+        }
+      } else if (CanApplyBlendModeUsingBlendFunc(params->blend_mode) &&
+                 ShouldApplyBackdropFilters(params)) {
+        // Something went wrong with applying backdrop filters to the
+        // backdrop.
+        params->use_shaders_for_blending = false;
+        gl_->DeleteTextures(1, &params->background_texture);
+        params->background_texture = 0;
+      }
+    } else {  // params->background_rect.IsEmpty()
+      DCHECK(!params->background_image_id);
+      params->use_shaders_for_blending = false;
+      params->blend_mode = SkBlendMode::kSrcOver;
+    }
+  }
+
+  // Need original background texture for mask?
+  params->mask_for_background =
+      params->background_texture &&  // Have original background texture
+      params->background_image_id;   // Have mask texture
+  // If we have background texture + background image, then we also have mask
+  // resource.
+  if (params->background_texture && params->background_image_id) {
+    DCHECK(params->mask_for_background);
+    DCHECK(quad->mask_resource_id());
+  }
+
+  DCHECK_EQ(params->background_texture || params->background_image_id,
+            params->use_shaders_for_blending);
+}
+
+bool GLRenderer::UpdateRPDQWithSkiaFilters(
+    DrawRenderPassDrawQuadParams* params) {
+  const auto* quad = params->quad.get();
+  // Apply filters to the contents texture.
+  if (params->filters) {
+    DCHECK(!params->filters->IsEmpty());
+    gfx::Size size = params->contents_texture
+                         ? params->contents_texture->size()
+                         : params->bypass_quad_texture.size;
+    auto paint_filter = cc::RenderSurfaceFilters::BuildImageFilter(
+        *params->filters, gfx::SizeF(size));
+    auto filter = paint_filter ? paint_filter->cached_sk_filter_ : nullptr;
+    if (filter) {
+      SkColorFilter* colorfilter_rawptr = nullptr;
+      filter->asColorFilter(&colorfilter_rawptr);
+      sk_sp<SkColorFilter> cf(colorfilter_rawptr);
+
+      if (cf && cf->asAColorMatrix(params->color_matrix)) {
+        // We have a color matrix at the root of the filter DAG; apply it
+        // locally in the compositor and process the rest of the DAG (if any)
+        // in Skia.
+        params->use_color_matrix = true;
+        filter = sk_ref_sp(filter->getInput(0));
+      }
+      if (filter) {
+        gfx::Rect clip_rect =
+            quad->shared_quad_state->clip_rect.value_or(current_draw_rect_);
+        gfx::Transform transform = params->quad_to_target_transform;
+        transform.FlattenTo2d();
+        if (!transform.IsInvertible()) {
+          return false;
+        }
+        // If the transform has perspective, there might be visible content
+        // outside of the bounds of the quad.
+        if (!transform.HasPerspective()) {
+          gfx::QuadF clip_quad = gfx::QuadF(gfx::RectF(clip_rect));
+          gfx::QuadF local_clip =
+              cc::MathUtil::InverseMapQuadToLocalSpace(transform, clip_quad);
+          params->dst_rect.Intersect(local_clip.BoundingBox());
+        }
+        // If we've been fully clipped out (by crop rect or clipping), there's
+        // nothing to draw.
+        if (params->dst_rect.IsEmpty()) {
+          return false;
+        }
+        SkIPoint offset;
+        SkIRect subset;
+        gfx::RectF src_rect(quad->rect);
+        auto use_gr_context = ScopedUseGrContext::Create(this);
+        if (!use_gr_context)
+          return false;
+
+        if (params->contents_texture) {
+          params->contents_and_bypass_color_space =
+              params->contents_texture->color_space();
+          sk_sp<SkImage> src_image = WrapTexture(
+              params->contents_texture->id(), GL_TEXTURE_2D,
+              params->contents_texture->size(), use_gr_context->context(),
+              params->flip_texture, kN32_SkColorType, /*adopt_texture=*/false);
+          params->filter_image = SkiaHelper::ApplyImageFilter(
+              use_gr_context->context(), src_image, src_rect, params->dst_rect,
+              quad->filters_scale, std::move(filter), &offset, &subset,
+              quad->filters_origin, true);
+        } else {
+          DisplayResourceProviderGL::ScopedReadLockGL
+              prefilter_bypass_quad_texture_lock(
+                  resource_provider(), params->bypass_quad_texture.resource_id);
+          params->contents_and_bypass_color_space =
+              prefilter_bypass_quad_texture_lock.color_space();
+          sk_sp<SkImage> src_image =
+              WrapTexture(prefilter_bypass_quad_texture_lock.texture_id(),
+                          prefilter_bypass_quad_texture_lock.target(),
+                          prefilter_bypass_quad_texture_lock.size(),
+                          use_gr_context->context(), params->flip_texture,
+                          kN32_SkColorType, /*adopt_texture=*/false);
+          params->filter_image = SkiaHelper::ApplyImageFilter(
+              use_gr_context->context(), src_image, src_rect, params->dst_rect,
+              quad->filters_scale, std::move(filter), &offset, &subset,
+              quad->filters_origin, true);
+        }
+
+        if (!params->filter_image)
+          return false;
+        params->dst_rect =
+            gfx::RectF(src_rect.x() + offset.fX, src_rect.y() + offset.fY,
+                       subset.width(), subset.height());
+        gfx::RectF tex_rect = gfx::RectF(gfx::PointF(subset.x(), subset.y()),
+                                         params->dst_rect.size());
+        params->tex_coord_rect = tex_rect;
+      }
+    }
+  }
+  return true;
+}
+
+void GLRenderer::UpdateRPDQTexturesForSampling(
+    DrawRenderPassDrawQuadParams* params) {
+  if (params->quad->mask_resource_id()) {
+    params->mask_resource_lock =
+        std::make_unique<DisplayResourceProviderGL::ScopedSamplerGL>(
+
+            resource_provider(), params->quad->mask_resource_id(), GL_TEXTURE1,
+            GL_LINEAR);
+  }
+
+  if (params->filter_image) {
+    GrSurfaceOrigin origin;
+    GLuint filter_image_id =
+        GetGLTextureIDFromSkImage(params->filter_image.get(), &origin);
+    DCHECK(filter_image_id || IsContextLost());
+    DCHECK_EQ(GL_TEXTURE0, GetActiveTextureUnit(gl_));
+    gl_->BindTexture(GL_TEXTURE_2D, filter_image_id);
+    gl_->TexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR);
+    gl_->TexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);
+    // |params->contents_and_bypass_color_space| was populated when
+    // |params->filter_image| was populated.
+    params->source_needs_flip = kBottomLeft_GrSurfaceOrigin == origin;
+  } else if (params->contents_texture) {
+    params->contents_texture->BindForSampling();
+    params->contents_and_bypass_color_space =
+        params->contents_texture->color_space();
+    params->source_needs_flip = params->flip_texture;
+  } else {
+    params->bypass_quad_resource_lock =
+        std::make_unique<DisplayResourceProviderGL::ScopedSamplerGL>(
+            resource_provider(), params->bypass_quad_texture.resource_id,
+            GL_LINEAR);
+    DCHECK_EQ(static_cast<GLenum>(GL_TEXTURE_2D),
+              params->bypass_quad_resource_lock->target());
+    params->contents_and_bypass_color_space =
+        params->bypass_quad_resource_lock->color_space();
+    params->source_needs_flip = params->flip_texture;
+  }
+}
+
+void GLRenderer::UpdateRPDQBlendMode(DrawRenderPassDrawQuadParams* params) {
+  SkBlendMode blend_mode = params->blend_mode;
+  SetBlendEnabled((!params->use_shaders_for_blending &&
+                   (params->quad->ShouldDrawWithBlending() ||
+                    !IsDefaultBlendMode(blend_mode))) ||
+                  ShouldApplyRoundedCorner(params->quad));
+  if (!params->use_shaders_for_blending) {
+    if (!use_blend_equation_advanced_coherent_ && use_blend_equation_advanced_)
+      gl_->BlendBarrierKHR();
+
+    ApplyBlendModeUsingBlendFunc(blend_mode);
+  }
+}
+
+void GLRenderer::ChooseRPDQProgram(DrawRenderPassDrawQuadParams* params,
+                                   const gfx::ColorSpace& target_color_space) {
+  TexCoordPrecision tex_coord_precision = TexCoordPrecisionRequired(
+      gl_, &highp_threshold_cache_, settings_->highp_threshold_min,
+      params->quad->shared_quad_state->visible_quad_layer_rect.size());
+
+  BlendMode shader_blend_mode =
+      params->use_shaders_for_blending
+          ? BlendModeFromSkXfermode(params->blend_mode)
+          : BLEND_MODE_NONE;
+
+  SamplerType sampler_type = SAMPLER_TYPE_2D;
+  MaskMode mask_mode = NO_MASK;
+  bool mask_for_background = params->mask_for_background;
+  if (params->mask_resource_lock) {
+    mask_mode = HAS_MASK;
+    sampler_type =
+        SamplerTypeFromTextureTarget(params->mask_resource_lock->target());
+  }
+  SetUseProgram(
+      ProgramKey::RenderPass(
+          tex_coord_precision, sampler_type, shader_blend_mode,
+          params->use_aa ? USE_AA : NO_AA, mask_mode, mask_for_background,
+          params->use_color_matrix, tint_gl_composited_content_,
+          params->apply_shader_based_rounded_corner &&
+              ShouldApplyRoundedCorner(params->quad)),
+      params->contents_and_bypass_color_space, target_color_space);
+}
+
+void GLRenderer::UpdateRPDQUniforms(DrawRenderPassDrawQuadParams* params) {
+  gfx::RectF tex_rect = params->tex_coord_rect;
+
+  gfx::Size texture_size;
+  if (params->filter_image) {
+    texture_size.set_width(params->filter_image->width());
+    texture_size.set_height(params->filter_image->height());
+  } else if (params->contents_texture) {
+    texture_size = params->contents_texture->size();
+  } else {
+    texture_size = params->bypass_quad_texture.size;
+  }
+
+  tex_rect.Scale(1.0f / texture_size.width(), 1.0f / texture_size.height());
+
+  DCHECK(current_program_->vertex_tex_transform_location() != -1 ||
+         IsContextLost());
+  if (params->source_needs_flip) {
+    // Flip the content vertically in the shader, as the RenderPass input
+    // texture is already oriented the same way as the framebuffer, but the
+    // projection transform does a flip.
+    gl_->Uniform4f(current_program_->vertex_tex_transform_location(),
+                   tex_rect.x(), 1.0f - tex_rect.y(), tex_rect.width(),
+                   -tex_rect.height());
+  } else {
+    // Tile textures are oriented opposite the framebuffer, so can use
+    // the projection transform to do the flip.
+    gl_->Uniform4f(current_program_->vertex_tex_transform_location(),
+                   tex_rect.x(), tex_rect.y(), tex_rect.width(),
+                   tex_rect.height());
+  }
+
+  GLint last_texture_unit = 0;
+  if (current_program_->mask_sampler_location() != -1) {
+    DCHECK(params->mask_resource_lock);
+    DCHECK_NE(current_program_->mask_tex_coord_scale_location(), 1);
+    DCHECK_NE(current_program_->mask_tex_coord_offset_location(), 1);
+    gl_->Uniform1i(current_program_->mask_sampler_location(), 1);
+
+    gfx::RectF mask_uv_rect = params->quad->mask_uv_rect;
+    if (SamplerTypeFromTextureTarget(params->mask_resource_lock->target()) !=
+        SAMPLER_TYPE_2D) {
+      mask_uv_rect.Scale(params->quad->mask_texture_size.width(),
+                         params->quad->mask_texture_size.height());
+    }
+
+    SkMatrix tex_to_mask = SkMatrix::RectToRect(RectFToSkRect(tex_rect),
+                                                RectFToSkRect(mask_uv_rect));
+
+    if (params->source_needs_flip) {
+      // Mask textures are oriented vertically flipped relative to the
+      // framebuffer and the RenderPass contents texture, so we flip the tex
+      // coords from the RenderPass texture to find the mask texture coords.
+      tex_to_mask.preTranslate(0, 1);
+      tex_to_mask.preScale(1, -1);
+    }
+
+    gl_->Uniform2f(current_program_->mask_tex_coord_offset_location(),
+                   tex_to_mask.getTranslateX(), tex_to_mask.getTranslateY());
+    gl_->Uniform2f(current_program_->mask_tex_coord_scale_location(),
+                   tex_to_mask.getScaleX(), tex_to_mask.getScaleY());
+    last_texture_unit = 1;
+  }
+
+  if (current_program_->edge_location() != -1)
+    gl_->Uniform3fv(current_program_->edge_location(), 8, params->edge);
+
+  if (current_program_->color_matrix_location() != -1) {
+    float matrix[16];
+    for (int i = 0; i < 4; ++i) {
+      for (int j = 0; j < 4; ++j)
+        matrix[i * 4 + j] = SkScalarToFloat(params->color_matrix[j * 5 + i]);
+    }
+    gl_->UniformMatrix4fv(current_program_->color_matrix_location(), 1, false,
+                          matrix);
+  }
+
+  if (current_program_->color_offset_location() != -1) {
+    float offset[4];
+    for (int i = 0; i < 4; ++i)
+      offset[i] = params->color_matrix[i * 5 + 4];
+
+    gl_->Uniform4fv(current_program_->color_offset_location(), 1, offset);
+  }
+
+  if (current_program_->tint_color_matrix_location() != -1) {
+    auto matrix = cc::DebugColors::TintCompositedContentColorTransformMatrix();
+    gl_->UniformMatrix4fv(current_program_->tint_color_matrix_location(), 1,
+                          false, matrix.data());
+  }
+
+  if (current_program_->backdrop_location() != -1) {
+    DCHECK(params->background_texture || params->background_image_id);
+    DCHECK_NE(current_program_->backdrop_location(), 0);
+    DCHECK_NE(current_program_->backdrop_rect_location(), 0);
+
+    ++last_texture_unit;
+    gl_->Uniform1i(current_program_->backdrop_location(), last_texture_unit);
+
+    gl_->Uniform4f(current_program_->backdrop_rect_location(),
+                   params->background_rect.x(), params->background_rect.y(),
+                   1.0f / params->background_rect.width(),
+                   1.0f / params->background_rect.height());
+
+    // Either |background_image_id| or |background_texture| will be the
+    // |backdrop_location| in the shader.
+    if (params->background_image_id) {
+      gl_->ActiveTexture(GL_TEXTURE0 + last_texture_unit);
+      gl_->BindTexture(GL_TEXTURE_2D, params->background_image_id);
+      if (params->backdrop_filter_quality != 1.0f)
+        gl_->TexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);
+      gl_->ActiveTexture(GL_TEXTURE0);
+    }
+    // If |mask_for_background| then we have both |background_image_id| and
+    // |background_texture|, and the latter will be the
+    // |original_backdrop_location| in the shader.
+    if (params->mask_for_background) {
+      DCHECK(params->background_image_id);
+      DCHECK(params->background_texture);
+      ++last_texture_unit;
+      gl_->Uniform1i(current_program_->original_backdrop_location(),
+                     last_texture_unit);
+    }
+    if (params->background_texture) {
+      gl_->ActiveTexture(GL_TEXTURE0 + last_texture_unit);
+      gl_->BindTexture(GL_TEXTURE_2D, params->background_texture);
+      gl_->ActiveTexture(GL_TEXTURE0);
+    }
+  }
+
+  SetShaderOpacity(params->quad->shared_quad_state->opacity);
+  if (current_program_->rounded_corner_rect_location() != -1) {
+    SetShaderRoundedCorner(params->quad->shared_quad_state->mask_filter_info
+                               .rounded_corner_bounds(),
+                           params->window_matrix * params->projection_matrix);
+  }
+  SetShaderQuadF(params->surface_quad);
+}
+
+void GLRenderer::DrawRPDQ(const DrawRenderPassDrawQuadParams& params) {
+  DrawQuadGeometry(params.projection_matrix, params.quad_to_target_transform,
+                   params.dst_rect);
+
+  // Flush the compositor context before the filter bitmap goes out of
+  // scope, so the draw gets processed before the filter texture gets deleted.
+  if (params.filter_image)
+    gl_->Flush();
+
+  if (!params.use_shaders_for_blending)
+    RestoreBlendFuncToDefault(params.blend_mode);
+}
+
+namespace {
+// These functions determine if a quad, clipped by a clip_region contains
+// the entire {top|bottom|left|right} edge.
+bool is_top(const gfx::QuadF* clip_region, const DrawQuad* quad) {
+  if (!quad->IsTopEdge())
+    return false;
+  if (!clip_region)
+    return true;
+
+  return std::abs(clip_region->p1().y()) < kAntiAliasingEpsilon &&
+         std::abs(clip_region->p2().y()) < kAntiAliasingEpsilon;
+}
+
+bool is_bottom(const gfx::QuadF* clip_region, const DrawQuad* quad) {
+  if (!quad->IsBottomEdge())
+    return false;
+  if (!clip_region)
+    return true;
+
+  return std::abs(clip_region->p3().y() -
+                  quad->shared_quad_state->quad_layer_rect.height()) <
+             kAntiAliasingEpsilon &&
+         std::abs(clip_region->p4().y() -
+                  quad->shared_quad_state->quad_layer_rect.height()) <
+             kAntiAliasingEpsilon;
+}
+
+bool is_left(const gfx::QuadF* clip_region, const DrawQuad* quad) {
+  if (!quad->IsLeftEdge())
+    return false;
+  if (!clip_region)
+    return true;
+
+  return std::abs(clip_region->p1().x()) < kAntiAliasingEpsilon &&
+         std::abs(clip_region->p4().x()) < kAntiAliasingEpsilon;
+}
+
+bool is_right(const gfx::QuadF* clip_region, const DrawQuad* quad) {
+  if (!quad->IsRightEdge())
+    return false;
+  if (!clip_region)
+    return true;
+
+  return std::abs(clip_region->p2().x() -
+                  quad->shared_quad_state->quad_layer_rect.width()) <
+             kAntiAliasingEpsilon &&
+         std::abs(clip_region->p3().x() -
+                  quad->shared_quad_state->quad_layer_rect.width()) <
+             kAntiAliasingEpsilon;
+}
+}  // anonymous namespace
+
+static gfx::QuadF GetDeviceQuadWithAntialiasingOnExteriorEdges(
+    const LayerQuad& device_layer_edges,
+    const gfx::Transform& device_transform,
+    const gfx::QuadF& tile_quad,
+    const gfx::QuadF* clip_region,
+    const DrawQuad* quad) {
+  auto tile_rect = gfx::RectF(quad->visible_rect);
+
+  gfx::PointF bottom_right = tile_quad.p3();
+  gfx::PointF bottom_left = tile_quad.p4();
+  gfx::PointF top_left = tile_quad.p1();
+  gfx::PointF top_right = tile_quad.p2();
+  bool clipped = false;
+
+  // Map points to device space. We ignore |clipped|, since the result of
+  // |MapPoint()| still produces a valid point to draw the quad with. When
+  // clipped, the point will be outside of the viewport. See crbug.com/416367.
+  bottom_right =
+      cc::MathUtil::MapPoint(device_transform, bottom_right, &clipped);
+  bottom_left = cc::MathUtil::MapPoint(device_transform, bottom_left, &clipped);
+  top_left = cc::MathUtil::MapPoint(device_transform, top_left, &clipped);
+  top_right = cc::MathUtil::MapPoint(device_transform, top_right, &clipped);
+
+  LayerQuad::Edge bottom_edge(bottom_right, bottom_left);
+  LayerQuad::Edge left_edge(bottom_left, top_left);
+  LayerQuad::Edge top_edge(top_left, top_right);
+  LayerQuad::Edge right_edge(top_right, bottom_right);
+
+  // Only apply anti-aliasing to edges not clipped by culling or scissoring.
+  // If an edge is degenerate we do not want to replace it with a "proper" edge
+  // as that will cause the quad to possibly expand in strange ways.
+  if (!top_edge.degenerate() && is_top(clip_region, quad) &&
+      tile_rect.y() == quad->rect.y()) {
+    top_edge = device_layer_edges.top();
+  }
+  if (!left_edge.degenerate() && is_left(clip_region, quad) &&
+      tile_rect.x() == quad->rect.x()) {
+    left_edge = device_layer_edges.left();
+  }
+  if (!right_edge.degenerate() && is_right(clip_region, quad) &&
+      tile_rect.right() == quad->rect.right()) {
+    right_edge = device_layer_edges.right();
+  }
+  if (!bottom_edge.degenerate() && is_bottom(clip_region, quad) &&
+      tile_rect.bottom() == quad->rect.bottom()) {
+    bottom_edge = device_layer_edges.bottom();
+  }
+
+  float sign = tile_quad.IsCounterClockwise() ? -1 : 1;
+  bottom_edge.scale(sign);
+  left_edge.scale(sign);
+  top_edge.scale(sign);
+  right_edge.scale(sign);
+
+  // Create device space quad.
+  return LayerQuad(left_edge, top_edge, right_edge, bottom_edge).ToQuadF();
+}
+
+float GetTotalQuadError(const gfx::QuadF* clipped_quad,
+                        const gfx::QuadF* ideal_rect) {
+  return (clipped_quad->p1() - ideal_rect->p1()).LengthSquared() +
+         (clipped_quad->p2() - ideal_rect->p2()).LengthSquared() +
+         (clipped_quad->p3() - ideal_rect->p3()).LengthSquared() +
+         (clipped_quad->p4() - ideal_rect->p4()).LengthSquared();
+}
+
+// Attempt to rotate the clipped quad until it lines up the most
+// correctly. This is necessary because we check the edges of this
+// quad against the expected left/right/top/bottom for anti-aliasing.
+void AlignQuadToBoundingBox(gfx::QuadF* clipped_quad) {
+  auto bounding_quad = gfx::QuadF(clipped_quad->BoundingBox());
+  gfx::QuadF best_rotation = *clipped_quad;
+  float least_error_amount = GetTotalQuadError(clipped_quad, &bounding_quad);
+  for (size_t i = 1; i < 4; ++i) {
+    clipped_quad->Realign(1);
+    float new_error = GetTotalQuadError(clipped_quad, &bounding_quad);
+    if (new_error < least_error_amount) {
+      least_error_amount = new_error;
+      best_rotation = *clipped_quad;
+    }
+  }
+  *clipped_quad = best_rotation;
+}
+
+void InflateAntiAliasingDistances(const gfx::QuadF& quad,
+                                  LayerQuad* device_layer_edges,
+                                  float edge[24]) {
+  DCHECK(!quad.BoundingBox().IsEmpty());
+  LayerQuad device_layer_bounds(gfx::QuadF(quad.BoundingBox()));
+
+  device_layer_edges->InflateAntiAliasingDistance();
+  device_layer_edges->ToFloatArray(edge);
+
+  device_layer_bounds.InflateAntiAliasingDistance();
+  device_layer_bounds.ToFloatArray(&edge[12]);
+}
+
+// static
+bool GLRenderer::ShouldAntialiasQuad(const gfx::QuadF& device_layer_quad,
+                                     bool clipped,
+                                     bool force_aa) {
+  // AAing clipped quads is not supported by the code yet.
+  if (clipped)
+    return false;
+  if (device_layer_quad.BoundingBox().IsEmpty())
+    return false;
+  if (force_aa)
+    return true;
+
+  bool is_axis_aligned_in_target = device_layer_quad.IsRectilinear();
+  bool is_nearest_rect_within_epsilon =
+      is_axis_aligned_in_target &&
+      gfx::IsNearestRectWithinDistance(device_layer_quad.BoundingBox(),
+                                       kAntiAliasingEpsilon);
+  return !is_nearest_rect_within_epsilon;
+}
+
+// static
+void GLRenderer::SetupQuadForClippingAndAntialiasing(
+    const gfx::Transform& device_transform,
+    const DrawQuad* quad,
+    const gfx::QuadF* aa_quad,
+    const gfx::QuadF* clip_region,
+    gfx::QuadF* local_quad,
+    float edge[24]) {
+  gfx::QuadF rotated_clip;
+  const gfx::QuadF* local_clip_region = clip_region;
+  if (local_clip_region) {
+    rotated_clip = *clip_region;
+    AlignQuadToBoundingBox(&rotated_clip);
+    local_clip_region = &rotated_clip;
+  }
+
+  if (!aa_quad) {
+    if (local_clip_region)
+      *local_quad = *local_clip_region;
+    return;
+  }
+
+  LayerQuad device_layer_edges(*aa_quad);
+  InflateAntiAliasingDistances(*aa_quad, &device_layer_edges, edge);
+
+  // If we have a clip region then we are split, and therefore
+  // by necessity, at least one of our edges is not an external
+  // one.
+  bool is_full_rect = quad->visible_rect == quad->rect;
+
+  bool region_contains_all_outside_edges =
+      is_full_rect &&
+      (is_top(local_clip_region, quad) && is_left(local_clip_region, quad) &&
+       is_bottom(local_clip_region, quad) && is_right(local_clip_region, quad));
+
+  bool use_aa_on_all_four_edges =
+      !local_clip_region && region_contains_all_outside_edges;
+
+  gfx::QuadF device_quad;
+  if (use_aa_on_all_four_edges) {
+    device_quad = device_layer_edges.ToQuadF();
+  } else {
+    gfx::QuadF tile_quad(local_clip_region
+                             ? *local_clip_region
+                             : gfx::QuadF(gfx::RectF(quad->visible_rect)));
+    device_quad = GetDeviceQuadWithAntialiasingOnExteriorEdges(
+        device_layer_edges, device_transform, tile_quad, local_clip_region,
+        quad);
+  }
+
+  *local_quad =
+      cc::MathUtil::InverseMapQuadToLocalSpace(device_transform, device_quad);
+}
+
+// static
+void GLRenderer::SetupRenderPassQuadForClippingAndAntialiasing(
+    const gfx::Transform& device_transform,
+    const AggregatedRenderPassDrawQuad* quad,
+    const gfx::QuadF* aa_quad,
+    const gfx::QuadF* clip_region,
+    gfx::QuadF* local_quad,
+    float edge[24]) {
+  gfx::QuadF rotated_clip;
+  const gfx::QuadF* local_clip_region = clip_region;
+  if (local_clip_region) {
+    rotated_clip = *clip_region;
+    AlignQuadToBoundingBox(&rotated_clip);
+    local_clip_region = &rotated_clip;
+  }
+
+  if (!aa_quad) {
+    GetScaledRegion(quad->rect, local_clip_region, local_quad);
+    return;
+  }
+
+  LayerQuad device_layer_edges(*aa_quad);
+  InflateAntiAliasingDistances(*aa_quad, &device_layer_edges, edge);
+
+  gfx::QuadF device_quad;
+
+  // Apply anti-aliasing only to the edges that are not being clipped
+  if (local_clip_region) {
+    gfx::QuadF tile_quad(gfx::RectF(quad->visible_rect));
+    GetScaledRegion(quad->rect, local_clip_region, &tile_quad);
+    device_quad = GetDeviceQuadWithAntialiasingOnExteriorEdges(
+        device_layer_edges, device_transform, tile_quad, local_clip_region,
+        quad);
+  } else {
+    device_quad = device_layer_edges.ToQuadF();
+  }
+
+  *local_quad =
+      cc::MathUtil::InverseMapQuadToLocalSpace(device_transform, device_quad);
+}
+
+void GLRenderer::DrawSolidColorQuad(const SolidColorDrawQuad* quad,
+                                    const gfx::QuadF* clip_region) {
+  gfx::Rect tile_rect = quad->visible_rect;
+
+  SkColor color = quad->color;
+  float opacity = quad->shared_quad_state->opacity;
+
+  // Early out if alpha is small enough that quad doesn't contribute to output,
+  // for kSrcOver blend mode.
+  if (quad->shared_quad_state->blend_mode == SkBlendMode::kSrcOver) {
+    float alpha = (SkColorGetA(color) * (1.0f / 255.0f)) * opacity;
+    if (alpha < std::numeric_limits<float>::epsilon() &&
+        quad->ShouldDrawWithBlending() &&
+        quad->shared_quad_state->blend_mode == SkBlendMode::kSrcOver)
+      return;
+  }
+
+  gfx::Transform device_transform =
+      current_frame()->window_matrix * current_frame()->projection_matrix *
+      quad->shared_quad_state->quad_to_target_transform;
+  device_transform.FlattenTo2d();
+  if (!device_transform.IsInvertible())
+    return;
+
+  auto local_quad = gfx::QuadF(gfx::RectF(tile_rect));
+
+  gfx::QuadF device_layer_quad;
+  bool use_aa = false;
+  bool allow_aa = settings_->allow_antialiasing &&
+                  !quad->force_anti_aliasing_off && quad->IsEdge();
+
+  if (allow_aa) {
+    bool clipped = false;
+    bool force_aa = false;
+    device_layer_quad = cc::MathUtil::MapQuad(
+        device_transform,
+        gfx::QuadF(
+            gfx::RectF(quad->shared_quad_state->visible_quad_layer_rect)),
+        &clipped);
+    use_aa = ShouldAntialiasQuad(device_layer_quad, clipped, force_aa);
+  }
+
+  ScopedTimerQuery scoped_timer_query(CompositeTimeTracingEnabled(), gl_,
+                                      &timer_queries_,
+                                      use_aa ? "kSolidColorAA" : "kSolidColor");
+
+  float edge[24];
+  const gfx::QuadF* aa_quad = use_aa ? &device_layer_quad : nullptr;
+  SetupQuadForClippingAndAntialiasing(device_transform, quad, aa_quad,
+                                      clip_region, &local_quad, edge);
+
+  SetUseProgram(ProgramKey::SolidColor(use_aa ? USE_AA : NO_AA,
+                                       tint_gl_composited_content_,
+                                       ShouldApplyRoundedCorner(quad)),
+                CurrentRenderPassColorSpace(), CurrentRenderPassColorSpace());
+
+  gfx::ColorSpace quad_color_space = gfx::ColorSpace::CreateSRGB();
+  SkColor4f color_f = SkColor4f::FromColor(color);
+
+  // Apply color transform if the color space or source and target do not match.
+  if (quad_color_space != CurrentRenderPassColorSpace()) {
+    const gfx::ColorTransform* color_transform =
+        GetColorTransform(quad_color_space, CurrentRenderPassColorSpace());
+    gfx::ColorTransform::TriStim col(color_f.fR, color_f.fG, color_f.fB);
+    color_transform->Transform(&col, 1);
+    color_f.fR = col.x();
+    color_f.fG = col.y();
+    color_f.fB = col.z();
+    color = color_f.toSkColor();
+  }
+
+  // Apply any color matrix that may be present.
+  if (HasOutputColorMatrix()) {
+    const SkM44& output_color_matrix = output_surface_->color_matrix();
+    const SkV4 color_v{color_f.fR, color_f.fG, color_f.fB, color_f.fA};
+    const SkV4 result = output_color_matrix * color_v;
+    std::copy(result.ptr(), result.ptr() + 4, color_f.vec());
+    color = color_f.toSkColor();
+  }
+
+  // Try using glClear to draw the solid color quad if possible. This is much
+  // more performant than executing the shader pipeline.
+  if (CanUseFastSolidColorDraw(quad) && !use_aa) {
+    // Pre-multiply the alpha and opacity to get the correct blending in case of
+    // transparent buffers. glClear does not have any alpha blending stage.
+    Float4 result = PremultipliedColor(color, opacity);
+    SkRGBA4f<kPremul_SkAlphaType> color_f_premul;
+    std::copy(result.data, result.data + 4, color_f_premul.vec());
+
+    gfx::RectF quad_rect_in_target_f(quad->visible_rect);
+
+    device_transform.TransformRect(&quad_rect_in_target_f);
+    gfx::Rect quad_rect_in_target = gfx::ToRoundedRect(quad_rect_in_target_f);
+
+    // If we are using partial swap, make sure the new scissor rect is within
+    // the partial swap bounds.
+    if (!scissor_rect_.IsEmpty() && is_scissor_enabled_)
+      quad_rect_in_target.Intersect(scissor_rect_);
+
+    gl_->Enable(GL_SCISSOR_TEST);
+    gl_->Scissor(quad_rect_in_target.x(), quad_rect_in_target.y(),
+                 quad_rect_in_target.width(), quad_rect_in_target.height());
+
+    gl_->ClearColor(color_f_premul.fR, color_f_premul.fG, color_f_premul.fB,
+                    color_f_premul.fA);
+    gl_->Clear(GL_COLOR_BUFFER_BIT);
+
+    // Restore GL scissor state.
+    if (is_scissor_enabled_)
+      gl_->Enable(GL_SCISSOR_TEST);
+    else
+      gl_->Disable(GL_SCISSOR_TEST);
+
+    gl_->Scissor(scissor_rect_.x(), scissor_rect_.y(), scissor_rect_.width(),
+                 scissor_rect_.height());
+  } else {
+    SetShaderColor(color, opacity);
+    if (current_program_->rounded_corner_rect_location() != -1) {
+      SetShaderRoundedCorner(
+          quad->shared_quad_state->mask_filter_info.rounded_corner_bounds(),
+          current_frame()->window_matrix * current_frame()->projection_matrix);
+    }
+
+    if (current_program_->tint_color_matrix_location() != -1) {
+      auto matrix =
+          cc::DebugColors::TintCompositedContentColorTransformMatrix();
+      gl_->UniformMatrix4fv(current_program_->tint_color_matrix_location(), 1,
+                            false, matrix.data());
+    }
+
+    if (use_aa) {
+      gl_->Uniform3fv(current_program_->edge_location(), 8, edge);
+    }
+
+    // Enable blending when the quad properties require it or if we decided
+    // to use antialiasing.
+    SetBlendEnabled(quad->ShouldDrawWithBlending() || use_aa);
+    ApplyBlendModeUsingBlendFunc(quad->shared_quad_state->blend_mode);
+
+    // Antialiasing requires a normalized quad, but this could lead to floating
+    // point precision errors, so only normalize when antialiasing is on.
+    if (use_aa) {
+      DrawQuadGeometryWithAA(quad, &local_quad, tile_rect);
+    } else {
+      PrepareGeometry(SHARED_BINDING);
+      SetShaderQuadF(local_quad);
+      SetShaderMatrix(current_frame()->projection_matrix *
+                      quad->shared_quad_state->quad_to_target_transform);
+      gl_->DrawElements(GL_TRIANGLES, 6, GL_UNSIGNED_SHORT, nullptr);
+      num_triangles_drawn_ += 2;
+    }
+    RestoreBlendFuncToDefault(quad->shared_quad_state->blend_mode);
+  }
+
+  // Add the quad to the region that has been drawn.
+  AccumulateDrawRects(quad->visible_rect,
+                      quad->shared_quad_state->quad_to_target_transform,
+                      &drawn_rects_);
+}
+
+void GLRenderer::DrawTileQuad(const TileDrawQuad* quad,
+                              const gfx::QuadF* clip_region) {
+  DrawContentQuad(quad, quad->resource_id(), clip_region);
+}
+
+void GLRenderer::DrawContentQuad(const ContentDrawQuadBase* quad,
+                                 ResourceId resource_id,
+                                 const gfx::QuadF* clip_region) {
+  gfx::Transform device_transform =
+      current_frame()->window_matrix * current_frame()->projection_matrix *
+      quad->shared_quad_state->quad_to_target_transform;
+  device_transform.FlattenTo2d();
+
+  gfx::QuadF device_layer_quad;
+  bool use_aa = false;
+  bool allow_aa = settings_->allow_antialiasing &&
+                  !quad->force_anti_aliasing_off && quad->IsEdge();
+  if (allow_aa) {
+    bool clipped = false;
+    bool force_aa = false;
+    device_layer_quad = cc::MathUtil::MapQuad(
+        device_transform,
+        gfx::QuadF(
+            gfx::RectF(quad->shared_quad_state->visible_quad_layer_rect)),
+        &clipped);
+    use_aa = ShouldAntialiasQuad(device_layer_quad, clipped, force_aa);
+  }
+
+  // TODO(timav): simplify coordinate transformations in DrawContentQuadAA
+  // similar to the way DrawContentQuadNoAA works and then consider
+  // combining DrawContentQuadAA and DrawContentQuadNoAA into one method.
+  if (use_aa)
+    DrawContentQuadAA(quad, resource_id, device_transform, device_layer_quad,
+                      clip_region);
+  else
+    DrawContentQuadNoAA(quad, resource_id, clip_region);
+
+  AccumulateDrawRects(quad->visible_rect,
+                      quad->shared_quad_state->quad_to_target_transform,
+                      &drawn_rects_);
+}
+
+void GLRenderer::DrawContentQuadAA(const ContentDrawQuadBase* quad,
+                                   ResourceId resource_id,
+                                   const gfx::Transform& device_transform,
+                                   const gfx::QuadF& aa_quad,
+                                   const gfx::QuadF* clip_region) {
+  if (!device_transform.IsInvertible())
+    return;
+
+  ScopedTimerQuery scoped_timer_query(CompositeTimeTracingEnabled(), gl_,
+                                      &timer_queries_, "kTiledContentAA");
+
+  gfx::Rect tile_rect = quad->visible_rect;
+
+  gfx::RectF tex_coord_rect = cc::MathUtil::ScaleRectProportional(
+      quad->tex_coord_rect, gfx::RectF(quad->rect), gfx::RectF(tile_rect));
+  float tex_to_geom_scale_x = quad->rect.width() / quad->tex_coord_rect.width();
+  float tex_to_geom_scale_y =
+      quad->rect.height() / quad->tex_coord_rect.height();
+
+  gfx::RectF clamp_geom_rect(tile_rect);
+  gfx::RectF clamp_tex_rect(tex_coord_rect);
+  // Clamp texture coordinates to avoid sampling outside the layer
+  // by deflating the tile region half a texel or half a texel
+  // minus epsilon for one pixel layers. The resulting clamp region
+  // is mapped to the unit square by the vertex shader and mapped
+  // back to normalized texture coordinates by the fragment shader
+  // after being clamped to 0-1 range.
+  float tex_clamp_x =
+      std::min(0.5f, 0.5f * clamp_tex_rect.width() - kAntiAliasingEpsilon);
+  float tex_clamp_y =
+      std::min(0.5f, 0.5f * clamp_tex_rect.height() - kAntiAliasingEpsilon);
+  float geom_clamp_x =
+      std::min(tex_clamp_x * tex_to_geom_scale_x,
+               0.5f * clamp_geom_rect.width() - kAntiAliasingEpsilon);
+  float geom_clamp_y =
+      std::min(tex_clamp_y * tex_to_geom_scale_y,
+               0.5f * clamp_geom_rect.height() - kAntiAliasingEpsilon);
+  clamp_geom_rect.Inset(gfx::InsetsF::VH(geom_clamp_y, geom_clamp_x));
+  clamp_tex_rect.Inset(gfx::InsetsF::VH(tex_clamp_y, tex_clamp_x));
+
+  // Map clamping rectangle to unit square.
+  float vertex_tex_translate_x = -clamp_geom_rect.x() / clamp_geom_rect.width();
+  float vertex_tex_translate_y =
+      -clamp_geom_rect.y() / clamp_geom_rect.height();
+  float vertex_tex_scale_x = tile_rect.width() / clamp_geom_rect.width();
+  float vertex_tex_scale_y = tile_rect.height() / clamp_geom_rect.height();
+
+  TexCoordPrecision tex_coord_precision = TexCoordPrecisionRequired(
+      gl_, &highp_threshold_cache_, settings_->highp_threshold_min,
+      quad->texture_size);
+
+  auto local_quad = gfx::QuadF(gfx::RectF(tile_rect));
+  float edge[24];
+  SetupQuadForClippingAndAntialiasing(device_transform, quad, &aa_quad,
+                                      clip_region, &local_quad, edge);
+  DisplayResourceProviderGL::ScopedSamplerGL quad_resource_lock(
+      resource_provider(), resource_id,
+      quad->nearest_neighbor ? GL_NEAREST : GL_LINEAR);
+  SamplerType sampler =
+      SamplerTypeFromTextureTarget(quad_resource_lock.target());
+
+  float fragment_tex_translate_x = clamp_tex_rect.x();
+  float fragment_tex_translate_y = clamp_tex_rect.y();
+  float fragment_tex_scale_x = clamp_tex_rect.width();
+  float fragment_tex_scale_y = clamp_tex_rect.height();
+
+  // Map to normalized texture coordinates.
+  if (sampler != SAMPLER_TYPE_2D_RECT) {
+    gfx::Size texture_size = quad->texture_size;
+    DCHECK(!texture_size.IsEmpty());
+    fragment_tex_translate_x /= texture_size.width();
+    fragment_tex_translate_y /= texture_size.height();
+    fragment_tex_scale_x /= texture_size.width();
+    fragment_tex_scale_y /= texture_size.height();
+  }
+
+  SetUseProgram(
+      ProgramKey::Tile(tex_coord_precision, sampler, USE_AA,
+                       quad->is_premultiplied ? PREMULTIPLIED_ALPHA
+                                              : NON_PREMULTIPLIED_ALPHA,
+                       false, false, tint_gl_composited_content_,
+                       ShouldApplyRoundedCorner(quad)),
+      quad_resource_lock.color_space(), CurrentRenderPassColorSpace());
+
+  if (current_program_->tint_color_matrix_location() != -1) {
+    auto matrix = cc::DebugColors::TintCompositedContentColorTransformMatrix();
+    gl_->UniformMatrix4fv(current_program_->tint_color_matrix_location(), 1,
+                          false, matrix.data());
+  }
+
+  gl_->Uniform3fv(current_program_->edge_location(), 8, edge);
+
+  gl_->Uniform4f(current_program_->vertex_tex_transform_location(),
+                 vertex_tex_translate_x, vertex_tex_translate_y,
+                 vertex_tex_scale_x, vertex_tex_scale_y);
+  gl_->Uniform4f(current_program_->fragment_tex_transform_location(),
+                 fragment_tex_translate_x, fragment_tex_translate_y,
+                 fragment_tex_scale_x, fragment_tex_scale_y);
+
+  // Blending is required for antialiasing.
+  SetBlendEnabled(true);
+  SetShaderOpacity(quad->shared_quad_state->opacity);
+  if (current_program_->rounded_corner_rect_location() != -1) {
+    SetShaderRoundedCorner(
+        quad->shared_quad_state->mask_filter_info.rounded_corner_bounds(),
+        current_frame()->window_matrix * current_frame()->projection_matrix);
+  }
+  DCHECK(CanApplyBlendModeUsingBlendFunc(quad->shared_quad_state->blend_mode));
+  ApplyBlendModeUsingBlendFunc(quad->shared_quad_state->blend_mode);
+
+  // Draw the quad with antialiasing.
+  DrawQuadGeometryWithAA(quad, &local_quad, tile_rect);
+  RestoreBlendFuncToDefault(quad->shared_quad_state->blend_mode);
+}
+
+void GLRenderer::DrawContentQuadNoAA(const ContentDrawQuadBase* quad,
+                                     ResourceId resource_id,
+                                     const gfx::QuadF* clip_region) {
+  gfx::RectF tex_coord_rect = cc::MathUtil::ScaleRectProportional(
+      quad->tex_coord_rect, gfx::RectF(quad->rect),
+      gfx::RectF(quad->visible_rect));
+  float tex_to_geom_scale_x = quad->rect.width() / quad->tex_coord_rect.width();
+  float tex_to_geom_scale_y =
+      quad->rect.height() / quad->tex_coord_rect.height();
+
+  ScopedTimerQuery scoped_timer_query(CompositeTimeTracingEnabled(), gl_,
+                                      &timer_queries_, "kTiledContent");
+
+  bool scaled = (tex_to_geom_scale_x != 1.f || tex_to_geom_scale_y != 1.f);
+  GLenum filter = (scaled || !quad->shared_quad_state->quad_to_target_transform
+                                  .IsIdentityOrIntegerTranslation()) &&
+                          !quad->nearest_neighbor
+                      ? GL_LINEAR
+                      : GL_NEAREST;
+
+  DisplayResourceProviderGL::ScopedSamplerGL quad_resource_lock(
+      resource_provider(), resource_id, filter);
+  SamplerType sampler =
+      SamplerTypeFromTextureTarget(quad_resource_lock.target());
+
+  // Tiles are guaranteed to have been entirely filled except for the
+  // bottom/right external edge tiles.  Because of border texels, any
+  // internal edge will have uvs that are offset from 0 and 1, so
+  // clamping to tex_coord_rect in all cases would cause these border
+  // texels to not be sampled.  Therefore, only clamp texture coordinates
+  // for external edge bottom/right tiles that don't have content all
+  // the way to the edge and are using bilinear filtering.
+  gfx::Size texture_size = quad->texture_size;
+  bool fills_right_edge =
+      !quad->IsRightEdge() || texture_size.width() == tex_coord_rect.right();
+  bool fills_bottom_edge =
+      !quad->IsBottomEdge() || texture_size.height() == tex_coord_rect.bottom();
+  bool has_tex_clamp_rect =
+      filter == GL_LINEAR && (!fills_right_edge || !fills_bottom_edge);
+  gfx::SizeF tex_clamp_size(texture_size);
+  // Clamp from the original tex coord rect, instead of the one that has
+  // been adjusted by the visible rect.
+  if (!fills_right_edge)
+    tex_clamp_size.set_width(quad->tex_coord_rect.right() - 0.5f);
+  if (!fills_bottom_edge)
+    tex_clamp_size.set_height(quad->tex_coord_rect.bottom() - 0.5f);
+
+  // Map to normalized texture coordinates.
+  if (sampler != SAMPLER_TYPE_2D_RECT) {
+    DCHECK(!texture_size.IsEmpty());
+    tex_coord_rect.Scale(1.f / texture_size.width(),
+                         1.f / texture_size.height());
+    tex_clamp_size.Scale(1.f / texture_size.width(),
+                         1.f / texture_size.height());
+  }
+
+  TexCoordPrecision tex_coord_precision =
+      TexCoordPrecisionRequired(gl_, &highp_threshold_cache_,
+                                settings_->highp_threshold_min, texture_size);
+  SetUseProgram(
+      ProgramKey::Tile(tex_coord_precision, sampler, NO_AA,
+                       quad->is_premultiplied ? PREMULTIPLIED_ALPHA
+                                              : NON_PREMULTIPLIED_ALPHA,
+                       !quad->ShouldDrawWithBlending(), has_tex_clamp_rect,
+                       tint_gl_composited_content_,
+                       ShouldApplyRoundedCorner(quad)),
+      quad_resource_lock.color_space(), CurrentRenderPassColorSpace());
+
+  if (current_program_->tint_color_matrix_location() != -1) {
+    auto matrix = cc::DebugColors::TintCompositedContentColorTransformMatrix();
+    gl_->UniformMatrix4fv(current_program_->tint_color_matrix_location(), 1,
+                          false, matrix.data());
+  }
+
+  if (has_tex_clamp_rect) {
+    gl_->Uniform4f(current_program_->tex_clamp_rect_location(), 0, 0,
+                   tex_clamp_size.width(), tex_clamp_size.height());
+  }
+  gl_->Uniform4f(current_program_->vertex_tex_transform_location(),
+                 tex_coord_rect.x(), tex_coord_rect.y(), tex_coord_rect.width(),
+                 tex_coord_rect.height());
+
+  DCHECK(CanApplyBlendModeUsingBlendFunc(quad->shared_quad_state->blend_mode));
+  SetBlendEnabled(quad->ShouldDrawWithBlending());
+  ApplyBlendModeUsingBlendFunc(quad->shared_quad_state->blend_mode);
+
+  SetShaderOpacity(quad->shared_quad_state->opacity);
+  if (current_program_->rounded_corner_rect_location() != -1) {
+    SetShaderRoundedCorner(
+        quad->shared_quad_state->mask_filter_info.rounded_corner_bounds(),
+        current_frame()->window_matrix * current_frame()->projection_matrix);
+  }
+
+  // Pass quad coordinates to the uniform in the same order as GeometryBinding
+  // does, then vertices will match the texture mapping in the vertex buffer.
+  // The method SetShaderQuadF() changes the order of vertices and so it's
+  // not used here.
+  auto tile_quad = gfx::QuadF(gfx::RectF(quad->visible_rect));
+  float width = quad->visible_rect.width();
+  float height = quad->visible_rect.height();
+  auto top_left = gfx::PointF(quad->visible_rect.origin());
+  if (clip_region) {
+    tile_quad = *clip_region;
+    float gl_uv[8] = {
+        (tile_quad.p4().x() - top_left.x()) / width,
+        (tile_quad.p4().y() - top_left.y()) / height,
+        (tile_quad.p1().x() - top_left.x()) / width,
+        (tile_quad.p1().y() - top_left.y()) / height,
+        (tile_quad.p2().x() - top_left.x()) / width,
+        (tile_quad.p2().y() - top_left.y()) / height,
+        (tile_quad.p3().x() - top_left.x()) / width,
+        (tile_quad.p3().y() - top_left.y()) / height,
+    };
+    PrepareGeometry(CLIPPED_BINDING);
+    clipped_geometry_->InitializeCustomQuadWithUVs(
+        gfx::QuadF(gfx::RectF(quad->visible_rect)), gl_uv);
+  } else {
+    PrepareGeometry(SHARED_BINDING);
+  }
+  float gl_quad[8] = {
+      tile_quad.p4().x(), tile_quad.p4().y(), tile_quad.p1().x(),
+      tile_quad.p1().y(), tile_quad.p2().x(), tile_quad.p2().y(),
+      tile_quad.p3().x(), tile_quad.p3().y(),
+  };
+  gl_->Uniform2fv(current_program_->quad_location(), 4, gl_quad);
+
+  SetShaderMatrix(current_frame()->projection_matrix *
+                  quad->shared_quad_state->quad_to_target_transform);
+
+  gl_->DrawElements(GL_TRIANGLES, 6, GL_UNSIGNED_SHORT, nullptr);
+  num_triangles_drawn_ += 2;
+  RestoreBlendFuncToDefault(quad->shared_quad_state->blend_mode);
+}
+
+void GLRenderer::DrawYUVVideoQuad(const YUVVideoDrawQuad* quad,
+                                  const gfx::QuadF* clip_region) {
+  std::string gpu_composite_time_string;
+  if (!clip_region && quad->rect == quad->visible_rect)
+    gpu_composite_time_string = "kYuvVideoContent";
+  else
+    gpu_composite_time_string = "kYuvVideoContentClipped";
+  ScopedTimerQuery scoped_timer_query(CompositeTimeTracingEnabled(), gl_,
+                                      &timer_queries_,
+                                      gpu_composite_time_string);
+
+  SetBlendEnabled(quad->ShouldDrawWithBlending());
+
+  TexCoordPrecision tex_coord_precision = TexCoordPrecisionRequired(
+      gl_, &highp_threshold_cache_, settings_->highp_threshold_min,
+      quad->shared_quad_state->visible_quad_layer_rect.size());
+  YUVAlphaTextureMode alpha_texture_mode = quad->a_plane_resource_id()
+                                               ? YUV_HAS_ALPHA_TEXTURE
+                                               : YUV_NO_ALPHA_TEXTURE;
+  UVTextureMode uv_texture_mode =
+      quad->v_plane_resource_id() == quad->u_plane_resource_id()
+          ? UV_TEXTURE_MODE_UV
+          : UV_TEXTURE_MODE_U_V;
+
+  DisplayResourceProviderGL::ScopedSamplerGL y_plane_lock(
+      resource_provider(), quad->y_plane_resource_id(), GL_TEXTURE1, GL_LINEAR);
+  DisplayResourceProviderGL::ScopedSamplerGL u_plane_lock(
+      resource_provider(), quad->u_plane_resource_id(), GL_TEXTURE2, GL_LINEAR);
+  DCHECK_EQ(y_plane_lock.target(), u_plane_lock.target());
+  DCHECK_EQ(y_plane_lock.color_space(), u_plane_lock.color_space());
+
+  // TODO(ccameron): There are currently two sources of the color space: the
+  // resource color space and quad->video_color_space. Remove one of them.
+  gfx::ColorSpace src_color_space = quad->video_color_space;
+  // Invalid or unspecified color spaces should be treated as REC709.
+  if (!src_color_space.IsValid())
+    src_color_space = gfx::ColorSpace::CreateREC709();
+  else
+    DCHECK_EQ(src_color_space, y_plane_lock.color_space());
+  // The source color space should never be RGB.
+  DCHECK_NE(src_color_space, src_color_space.GetAsFullRangeRGB());
+
+  gfx::ColorSpace dst_color_space = CurrentRenderPassColorSpace();
+
+#if BUILDFLAG(IS_WIN)
+  // Force sRGB output on Windows for overlay candidate video quads to match
+  // DirectComposition behavior in case these switch between overlays and
+  // compositing. See https://crbug.com/811118 for details.
+  // Currently if HDR is supported, OverlayProcessor doesn't promote HDR video
+  // frame as overlay candidate. So it's unnecessary to worry about the
+  // compositing-overlay switch here. In addition drawing a HDR video using sRGB
+  // can cancel the advantages of HDR.
+  const bool supports_dc_layers =
+      output_surface_->capabilities().supports_dc_layers;
+  if (supports_dc_layers && !src_color_space.IsHDR() &&
+      resource_provider()->IsOverlayCandidate(quad->y_plane_resource_id())) {
+    DCHECK(
+        resource_provider()->IsOverlayCandidate(quad->u_plane_resource_id()));
+    dst_color_space = gfx::ColorSpace::CreateSRGB();
+  }
+#endif
+
+  // TODO(jbauman): Use absl::optional when available.
+  std::unique_ptr<DisplayResourceProviderGL::ScopedSamplerGL> v_plane_lock;
+  if (uv_texture_mode == UV_TEXTURE_MODE_U_V) {
+    v_plane_lock = std::make_unique<DisplayResourceProviderGL::ScopedSamplerGL>(
+        resource_provider(), quad->v_plane_resource_id(), GL_TEXTURE3,
+        GL_LINEAR);
+    DCHECK_EQ(y_plane_lock.target(), v_plane_lock->target());
+    DCHECK_EQ(y_plane_lock.color_space(), v_plane_lock->color_space());
+  }
+  std::unique_ptr<DisplayResourceProviderGL::ScopedSamplerGL> a_plane_lock;
+  if (alpha_texture_mode == YUV_HAS_ALPHA_TEXTURE) {
+    a_plane_lock = std::make_unique<DisplayResourceProviderGL::ScopedSamplerGL>(
+        resource_provider(), quad->a_plane_resource_id(), GL_TEXTURE4,
+        GL_LINEAR);
+    DCHECK_EQ(y_plane_lock.target(), a_plane_lock->target());
+  }
+
+  // All planes must have the same sampler type.
+  SamplerType sampler = SamplerTypeFromTextureTarget(y_plane_lock.target());
+
+  SetUseProgram(
+      ProgramKey::YUVVideo(tex_coord_precision, sampler, alpha_texture_mode,
+                           uv_texture_mode, tint_gl_composited_content_,
+                           ShouldApplyRoundedCorner(quad)),
+      src_color_space, dst_color_space, /*adjust_src_white_level=*/true);
+
+  if (current_program_->tint_color_matrix_location() != -1) {
+    auto matrix = cc::DebugColors::TintCompositedContentColorTransformMatrix();
+    gl_->UniformMatrix4fv(current_program_->tint_color_matrix_location(), 1,
+                          false, matrix.data());
+  }
+
+  if (current_program_->rounded_corner_rect_location() != -1) {
+    SetShaderRoundedCorner(
+        quad->shared_quad_state->mask_filter_info.rounded_corner_bounds(),
+        current_frame()->window_matrix * current_frame()->projection_matrix);
+  }
+
+  gfx::SizeF ya_tex_scale(1.0f, 1.0f);
+  gfx::SizeF uv_tex_scale(1.0f, 1.0f);
+  if (sampler != SAMPLER_TYPE_2D_RECT) {
+    DCHECK(!quad->ya_tex_size.IsEmpty());
+    DCHECK(!quad->uv_tex_size.IsEmpty());
+    ya_tex_scale = gfx::SizeF(1.0f / quad->ya_tex_size.width(),
+                              1.0f / quad->ya_tex_size.height());
+    uv_tex_scale = gfx::SizeF(1.0f / quad->uv_tex_size.width(),
+                              1.0f / quad->uv_tex_size.height());
+  }
+
+  float ya_vertex_tex_translate_x =
+      quad->ya_tex_coord_rect.x() * ya_tex_scale.width();
+  float ya_vertex_tex_translate_y =
+      quad->ya_tex_coord_rect.y() * ya_tex_scale.height();
+  float ya_vertex_tex_scale_x =
+      quad->ya_tex_coord_rect.width() * ya_tex_scale.width();
+  float ya_vertex_tex_scale_y =
+      quad->ya_tex_coord_rect.height() * ya_tex_scale.height();
+
+  float uv_vertex_tex_translate_x =
+      quad->uv_tex_coord_rect.x() * uv_tex_scale.width();
+  float uv_vertex_tex_translate_y =
+      quad->uv_tex_coord_rect.y() * uv_tex_scale.height();
+  float uv_vertex_tex_scale_x =
+      quad->uv_tex_coord_rect.width() * uv_tex_scale.width();
+  float uv_vertex_tex_scale_y =
+      quad->uv_tex_coord_rect.height() * uv_tex_scale.height();
+
+  gl_->Uniform2f(current_program_->ya_tex_scale_location(),
+                 ya_vertex_tex_scale_x, ya_vertex_tex_scale_y);
+  gl_->Uniform2f(current_program_->ya_tex_offset_location(),
+                 ya_vertex_tex_translate_x, ya_vertex_tex_translate_y);
+  gl_->Uniform2f(current_program_->uv_tex_scale_location(),
+                 uv_vertex_tex_scale_x, uv_vertex_tex_scale_y);
+  gl_->Uniform2f(current_program_->uv_tex_offset_location(),
+                 uv_vertex_tex_translate_x, uv_vertex_tex_translate_y);
+
+  gfx::RectF ya_clamp_rect(ya_vertex_tex_translate_x, ya_vertex_tex_translate_y,
+                           ya_vertex_tex_scale_x, ya_vertex_tex_scale_y);
+  ya_clamp_rect.Inset(gfx::InsetsF::VH(0.5f * ya_tex_scale.height(),
+                                       0.5f * ya_tex_scale.width()));
+  gfx::RectF uv_clamp_rect(uv_vertex_tex_translate_x, uv_vertex_tex_translate_y,
+                           uv_vertex_tex_scale_x, uv_vertex_tex_scale_y);
+  uv_clamp_rect.Inset(gfx::InsetsF::VH(0.5f * uv_tex_scale.height(),
+                                       0.5f * uv_tex_scale.width()));
+  gl_->Uniform4f(current_program_->ya_clamp_rect_location(), ya_clamp_rect.x(),
+                 ya_clamp_rect.y(), ya_clamp_rect.right(),
+                 ya_clamp_rect.bottom());
+  gl_->Uniform4f(current_program_->uv_clamp_rect_location(), uv_clamp_rect.x(),
+                 uv_clamp_rect.y(), uv_clamp_rect.right(),
+                 uv_clamp_rect.bottom());
+
+  gl_->Uniform1i(current_program_->y_texture_location(), 1);
+  if (uv_texture_mode == UV_TEXTURE_MODE_UV) {
+    gl_->Uniform1i(current_program_->uv_texture_location(), 2);
+  } else {
+    gl_->Uniform1i(current_program_->u_texture_location(), 2);
+    gl_->Uniform1i(current_program_->v_texture_location(), 3);
+  }
+  if (alpha_texture_mode == YUV_HAS_ALPHA_TEXTURE)
+    gl_->Uniform1i(current_program_->a_texture_location(), 4);
+
+  gl_->Uniform1f(current_program_->resource_multiplier_location(),
+                 quad->resource_multiplier);
+  gl_->Uniform1f(current_program_->resource_offset_location(),
+                 quad->resource_offset);
+
+  // The transform and vertex data are used to figure out the extents that the
+  // un-antialiased quad should have and which vertex this is and the float
+  // quad passed in via uniform is the actual geometry that gets used to draw
+  // it. This is why this centered rect is used and not the original quad_rect.
+  auto tile_rect = gfx::RectF(quad->rect);
+
+  SetShaderOpacity(quad->shared_quad_state->opacity);
+  if (!clip_region && quad->rect == quad->visible_rect) {
+    DrawQuadGeometry(current_frame()->projection_matrix,
+                     quad->shared_quad_state->quad_to_target_transform,
+                     tile_rect);
+  } else {
+    gfx::QuadF region_quad =
+        clip_region ? *clip_region : gfx::QuadF(gfx::RectF(quad->visible_rect));
+    float uvs[8] = {0};
+    GetScaledUVs(quad->rect, &region_quad, uvs);
+    region_quad.Scale(1.0f / tile_rect.width(), 1.0f / tile_rect.height());
+    region_quad -= gfx::Vector2dF(0.5f, 0.5f);
+    DrawQuadGeometryClippedByQuadF(
+        quad->shared_quad_state->quad_to_target_transform, tile_rect,
+        region_quad, uvs);
+  }
+
+  // Track the region in the current target surface that has been drawn to.
+  AccumulateDrawRects(quad->visible_rect,
+                      quad->shared_quad_state->quad_to_target_transform,
+                      &drawn_rects_);
+}
+
+void GLRenderer::DrawStreamVideoQuad(const StreamVideoDrawQuad* quad,
+                                     const gfx::QuadF* clip_region) {
+  std::string gpu_composite_time_string;
+  if (!clip_region && quad->rect == quad->visible_rect) {
+    gpu_composite_time_string = "kStreamVideoContent";
+  } else {
+    gpu_composite_time_string = "kStreamVideoContentClipped";
+  }
+  ScopedTimerQuery scoped_timer_query(CompositeTimeTracingEnabled(), gl_,
+                                      &timer_queries_,
+                                      gpu_composite_time_string);
+  SetBlendEnabled(quad->ShouldDrawWithBlending());
+
+  DCHECK(output_surface_->context_provider()
+             ->ContextCapabilities()
+             .egl_image_external);
+
+  TexCoordPrecision tex_coord_precision = TexCoordPrecisionRequired(
+      gl_, &highp_threshold_cache_, settings_->highp_threshold_min,
+      quad->shared_quad_state->visible_quad_layer_rect.size());
+
+  DisplayResourceProviderGL::ScopedReadLockGL lock(resource_provider(),
+                                                   quad->resource_id());
+
+  SetUseProgram(ProgramKey::VideoStream(tex_coord_precision,
+                                        ShouldApplyRoundedCorner(quad)),
+                lock.color_space(), CurrentRenderPassColorSpace());
+
+  DCHECK_EQ(GL_TEXTURE0, GetActiveTextureUnit(gl_));
+  gl_->BindTexture(GL_TEXTURE_EXTERNAL_OES, lock.texture_id());
+
+  static float gl_matrix[16];
+  gfx::Transform matrix;
+  matrix.Scale(quad->uv_bottom_right.x() - quad->uv_top_left.x(),
+               quad->uv_bottom_right.y() - quad->uv_top_left.y());
+  matrix.Translate(quad->uv_top_left.x(), quad->uv_top_left.y());
+  ToGLMatrix(&gl_matrix[0], matrix);
+  gl_->UniformMatrix4fv(current_program_->tex_matrix_location(), 1, false,
+                        gl_matrix);
+
+  SetShaderOpacity(quad->shared_quad_state->opacity);
+  if (current_program_->rounded_corner_rect_location() != -1) {
+    SetShaderRoundedCorner(
+        quad->shared_quad_state->mask_filter_info.rounded_corner_bounds(),
+        current_frame()->window_matrix * current_frame()->projection_matrix);
+  }
+  gfx::Size texture_size = lock.size();
+  gfx::RectF uv_visible_rect(quad->uv_top_left.x(), quad->uv_top_left.y(),
+                             quad->uv_bottom_right.x() - quad->uv_top_left.x(),
+                             quad->uv_bottom_right.y() - quad->uv_top_left.y());
+  const SamplerType sampler = SamplerTypeFromTextureTarget(lock.target());
+  Float4 tex_clamp_rect = UVClampRect(uv_visible_rect, texture_size, sampler);
+  gl_->Uniform4f(current_program_->tex_clamp_rect_location(),
+                 tex_clamp_rect.data[0], tex_clamp_rect.data[1],
+                 tex_clamp_rect.data[2], tex_clamp_rect.data[3]);
+
+  auto tile_rect = gfx::RectF(quad->rect);
+
+  if (!clip_region && quad->rect == quad->visible_rect) {
+    DrawQuadGeometry(current_frame()->projection_matrix,
+                     quad->shared_quad_state->quad_to_target_transform,
+                     tile_rect);
+  } else {
+    gfx::QuadF region_quad =
+        clip_region ? *clip_region : gfx::QuadF(gfx::RectF(quad->visible_rect));
+    float uvs[8] = {0};
+    GetScaledUVs(quad->rect, &region_quad, uvs);
+    region_quad.Scale(1.0f / tile_rect.width(), 1.0f / tile_rect.height());
+    region_quad -= gfx::Vector2dF(0.5f, 0.5f);
+    DrawQuadGeometryClippedByQuadF(
+        quad->shared_quad_state->quad_to_target_transform, tile_rect,
+        region_quad, uvs);
+  }
+
+  AccumulateDrawRects(quad->visible_rect,
+                      quad->shared_quad_state->quad_to_target_transform,
+                      &drawn_rects_);
+}
+
+void GLRenderer::FlushTextureQuadCache(BoundGeometry flush_binding) {
+  // Check to see if we have anything to draw.
+  if (draw_cache_.is_empty)
+    return;
+  ScopedTimerQuery scoped_timer_query(CompositeTimeTracingEnabled(), gl_,
+                                      &timer_queries_, "kTextureContentFlush");
+
+  PrepareGeometry(flush_binding);
+
+  // Set the correct blending mode.
+  SetBlendEnabled(draw_cache_.needs_blending);
+
+  // Assume the current active textures is 0.
+  DisplayResourceProviderGL::ScopedSamplerGL locked_quad(
+      resource_provider(), draw_cache_.resource_id,
+      draw_cache_.nearest_neighbor ? GL_NEAREST : GL_LINEAR);
+
+  // Bind the program to the GL state.
+  SetUseProgram(draw_cache_.program_key, locked_quad.color_space(),
+                CurrentRenderPassColorSpace(),
+                /*adjust_src_white_level=*/draw_cache_.is_video_frame,
+                locked_quad.hdr_metadata());
+
+  if (current_program_->rounded_corner_rect_location() != -1) {
+    SetShaderRoundedCorner(
+        draw_cache_.mask_filter_info.rounded_corner_bounds(),
+        current_frame()->window_matrix * current_frame()->projection_matrix);
+  }
+
+  DCHECK_EQ(GL_TEXTURE0, GetActiveTextureUnit(gl_));
+  gl_->BindTexture(locked_quad.target(), locked_quad.texture_id());
+
+  static_assert(sizeof(Float4) == 4 * sizeof(float),
+                "Float4 struct should be densely packed");
+  static_assert(sizeof(Float16) == 16 * sizeof(float),
+                "Float16 struct should be densely packed");
+
+  // Upload the tranforms for both points and uvs.
+  gl_->UniformMatrix4fv(
+      current_program_->matrix_location(),
+      static_cast<int>(draw_cache_.matrix_data.size()), false,
+      reinterpret_cast<float*>(&draw_cache_.matrix_data.front()));
+  gl_->Uniform4fv(current_program_->vertex_tex_transform_location(),
+                  static_cast<int>(draw_cache_.uv_xform_data.size()),
+                  reinterpret_cast<float*>(&draw_cache_.uv_xform_data.front()));
+
+  if (current_program_->tint_color_matrix_location() != -1) {
+    auto matrix = cc::DebugColors::TintCompositedContentColorTransformMatrix();
+    gl_->UniformMatrix4fv(current_program_->tint_color_matrix_location(), 1,
+                          false, matrix.data());
+  }
+
+  if (current_program_->tex_clamp_rect_location() != -1) {
+    // Draw batching is not allowed with texture clamping.
+    DCHECK_EQ(1u, draw_cache_.matrix_data.size());
+    gl_->Uniform4f(current_program_->tex_clamp_rect_location(),
+                   draw_cache_.tex_clamp_rect_data.data[0],
+                   draw_cache_.tex_clamp_rect_data.data[1],
+                   draw_cache_.tex_clamp_rect_data.data[2],
+                   draw_cache_.tex_clamp_rect_data.data[3]);
+  }
+
+  if (draw_cache_.background_color != SK_ColorTRANSPARENT) {
+    Float4 background_color =
+        PremultipliedColor(draw_cache_.background_color, 1.f);
+    gl_->Uniform4fv(current_program_->background_color_location(), 1,
+                    background_color.data);
+  }
+
+  gl_->Uniform1fv(
+      current_program_->vertex_opacity_location(),
+      static_cast<int>(draw_cache_.vertex_opacity_data.size()),
+      static_cast<float*>(&draw_cache_.vertex_opacity_data.front()));
+
+  DCHECK_LE(draw_cache_.matrix_data.size(),
+            static_cast<size_t>(std::numeric_limits<int>::max()) / 6u);
+
+  // Draw the quads!
+  gl_->DrawElements(GL_TRIANGLES,
+                    6 * static_cast<int>(draw_cache_.matrix_data.size()),
+                    GL_UNSIGNED_SHORT, nullptr);
+  num_triangles_drawn_ += 2 * static_cast<int>(draw_cache_.matrix_data.size());
+
+  // Clear the cache.
+  draw_cache_.is_empty = true;
+  draw_cache_.resource_id = kInvalidResourceId;
+  draw_cache_.uv_xform_data.resize(0);
+  draw_cache_.vertex_opacity_data.resize(0);
+  draw_cache_.matrix_data.resize(0);
+  draw_cache_.tex_clamp_rect_data = Float4();
+  draw_cache_.is_video_frame = false;
+
+  // If we had a clipped binding, prepare the shared binding for the
+  // next inserts.
+  if (flush_binding == CLIPPED_BINDING) {
+    PrepareGeometry(SHARED_BINDING);
+  }
+}
+
+void GLRenderer::EnqueueTextureQuad(const TextureDrawQuad* quad,
+                                    const gfx::QuadF* clip_region) {
+  // If we have a clip_region then we have to render the next quad
+  // with dynamic geometry, therefore we must flush all pending
+  // texture quads.
+  if (clip_region) {
+    // We send in false here because we want to flush what's currently in the
+    // queue using the shared_geometry and not clipped_geometry
+    FlushTextureQuadCache(SHARED_BINDING);
+  }
+
+  DisplayResourceProviderGL::ScopedReadLockGL lock(resource_provider(),
+                                                   quad->resource_id());
+  // ScopedReadLockGL contains the correct texture size, even when
+  // quad->resource_size_in_pixels() is empty.
+  const gfx::Size texture_size = lock.size();
+  TexCoordPrecision tex_coord_precision =
+      TexCoordPrecisionRequired(gl_, &highp_threshold_cache_,
+                                settings_->highp_threshold_min, texture_size);
+
+  const SamplerType sampler = SamplerTypeFromTextureTarget(lock.target());
+
+  bool need_tex_clamp_rect = !quad->resource_size_in_pixels().IsEmpty() &&
+                             (quad->uv_top_left != gfx::PointF(0, 0) ||
+                              quad->uv_bottom_right != gfx::PointF(1, 1));
+
+  ProgramKey program_key = ProgramKey::Texture(
+      tex_coord_precision, sampler,
+      quad->premultiplied_alpha ? PREMULTIPLIED_ALPHA : NON_PREMULTIPLIED_ALPHA,
+      quad->background_color != SK_ColorTRANSPARENT, need_tex_clamp_rect,
+      tint_gl_composited_content_, ShouldApplyRoundedCorner(quad));
+  ResourceId resource_id = quad->resource_id();
+
+  size_t max_quads = StaticGeometryBinding::NUM_QUADS;
+  if (draw_cache_.is_empty || draw_cache_.program_key != program_key ||
+      draw_cache_.resource_id != resource_id ||
+      draw_cache_.needs_blending != quad->ShouldDrawWithBlending() ||
+      draw_cache_.nearest_neighbor != quad->nearest_neighbor ||
+      draw_cache_.background_color != quad->background_color ||
+      draw_cache_.mask_filter_info !=
+          quad->shared_quad_state->mask_filter_info ||
+      draw_cache_.matrix_data.size() >= max_quads ||
+      draw_cache_.is_video_frame != quad->is_video_frame) {
+    FlushTextureQuadCache(SHARED_BINDING);
+    draw_cache_.is_empty = false;
+    draw_cache_.program_key = program_key;
+    draw_cache_.resource_id = resource_id;
+    draw_cache_.needs_blending = quad->ShouldDrawWithBlending();
+    draw_cache_.nearest_neighbor = quad->nearest_neighbor;
+    draw_cache_.background_color = quad->background_color;
+    draw_cache_.mask_filter_info = quad->shared_quad_state->mask_filter_info;
+    draw_cache_.is_video_frame = quad->is_video_frame;
+  }
+
+  // Generate the uv-transform
+  auto uv_transform = UVTransform(quad);
+  if (sampler == SAMPLER_TYPE_2D_RECT) {
+    // Un-normalize the texture coordiantes for rectangle targets.
+    uv_transform.data[0] *= texture_size.width();
+    uv_transform.data[2] *= texture_size.width();
+    uv_transform.data[1] *= texture_size.height();
+    uv_transform.data[3] *= texture_size.height();
+  }
+  draw_cache_.uv_xform_data.push_back(uv_transform);
+
+  if (need_tex_clamp_rect) {
+    DCHECK_EQ(1u, draw_cache_.uv_xform_data.size());
+    DCHECK_EQ(texture_size.ToString(),
+              quad->resource_size_in_pixels().ToString());
+    DCHECK(!texture_size.IsEmpty());
+    gfx::RectF uv_visible_rect(
+        quad->uv_top_left.x(), quad->uv_top_left.y(),
+        quad->uv_bottom_right.x() - quad->uv_top_left.x(),
+        quad->uv_bottom_right.y() - quad->uv_top_left.y());
+    Float4 tex_clamp_rect = UVClampRect(uv_visible_rect, texture_size, sampler);
+    draw_cache_.tex_clamp_rect_data = tex_clamp_rect;
+  }
+
+  // Generate the vertex opacity
+  const float opacity = quad->shared_quad_state->opacity;
+  draw_cache_.vertex_opacity_data.push_back(quad->vertex_opacity[0] * opacity);
+  draw_cache_.vertex_opacity_data.push_back(quad->vertex_opacity[1] * opacity);
+  draw_cache_.vertex_opacity_data.push_back(quad->vertex_opacity[2] * opacity);
+  draw_cache_.vertex_opacity_data.push_back(quad->vertex_opacity[3] * opacity);
+
+  // Generate the transform matrix
+  gfx::Transform quad_rect_matrix;
+  QuadRectTransform(&quad_rect_matrix,
+                    quad->shared_quad_state->quad_to_target_transform,
+                    gfx::RectF(quad->visible_rect));
+  quad_rect_matrix = current_frame()->projection_matrix * quad_rect_matrix;
+
+  Float16 m;
+  quad_rect_matrix.matrix().getColMajor(m.data);
+  draw_cache_.matrix_data.push_back(m);
+
+  // Track the region in the current target surface that has been drawn to.
+  AccumulateDrawRects(quad->visible_rect,
+                      quad->shared_quad_state->quad_to_target_transform,
+                      &drawn_rects_);
+
+  if (clip_region) {
+    DCHECK_EQ(quad->rect, quad->visible_rect);
+    gfx::QuadF scaled_region;
+    if (!GetScaledRegion(quad->rect, clip_region, &scaled_region)) {
+      scaled_region = SharedGeometryQuad().BoundingBox();
+    }
+    // Both the scaled region and the SharedGeomtryQuad are in the space
+    // -0.5->0.5. We need to move that to the space 0->1.
+    float uv[8];
+    uv[0] = scaled_region.p1().x() + 0.5f;
+    uv[1] = scaled_region.p1().y() + 0.5f;
+    uv[2] = scaled_region.p2().x() + 0.5f;
+    uv[3] = scaled_region.p2().y() + 0.5f;
+    uv[4] = scaled_region.p3().x() + 0.5f;
+    uv[5] = scaled_region.p3().y() + 0.5f;
+    uv[6] = scaled_region.p4().x() + 0.5f;
+    uv[7] = scaled_region.p4().y() + 0.5f;
+    PrepareGeometry(CLIPPED_BINDING);
+    clipped_geometry_->InitializeCustomQuadWithUVs(scaled_region, uv);
+    FlushTextureQuadCache(CLIPPED_BINDING);
+  } else if (need_tex_clamp_rect) {
+    FlushTextureQuadCache(SHARED_BINDING);
+  }
+}
+
+void GLRenderer::FinishDrawingFrame() {
+  if (use_sync_query_) {
+    sync_queries_.EndCurrentFrame();
+  }
+
+  swap_buffer_rect_.Union(current_frame()->root_damage_rect);
+
+  if (use_swap_with_bounds_)
+    swap_content_bounds_ = current_frame()->root_content_bounds;
+
+  copier_.FreeUnusedCachedResources();
+
+  current_framebuffer_texture_ = nullptr;
+
+  gl_->Disable(GL_BLEND);
+  blend_shadow_ = false;
+
+  // Schedule output surface as overlay first to preserve existing ordering
+  // semantics during overlay refactoring.
+  ScheduleOutputSurfaceAsOverlay();
+
+#if BUILDFLAG(IS_ANDROID) || defined(USE_OZONE)
+  ScheduleOverlays();
+#elif BUILDFLAG(IS_APPLE)
+  ScheduleCALayers();
+#elif BUILDFLAG(IS_WIN)
+  ScheduleDCLayers();
+#endif
+
+  TRACE_COUNTER1(TRACE_DISABLED_BY_DEFAULT("viz.triangles"), "Triangles Drawn",
+                 num_triangles_drawn_);
+
+  // Mark the end of batched read of shared images.
+  gl_->EndBatchReadAccessSharedImageCHROMIUM();
+}
+
+bool GLRenderer::OverdrawTracingEnabled() {
+  // Only collect trace data if we select viz.overdraw.
+  bool tracing_enabled;
+  TRACE_EVENT_CATEGORY_GROUP_ENABLED(TRACE_DISABLED_BY_DEFAULT("viz.overdraw"),
+                                     &tracing_enabled);
+  // ARB_occlusion_query is required for tracing.
+  // Trace only the root render pass.
+  return tracing_enabled && use_occlusion_query_ &&
+         current_frame()->current_render_pass ==
+             current_frame()->root_render_pass;
+}
+
+bool GLRenderer::CompositeTimeTracingEnabled() {
+  bool tracing_enabled;
+  TRACE_EVENT_CATEGORY_GROUP_ENABLED(
+      TRACE_DISABLED_BY_DEFAULT("viz.gpu_composite_time"), &tracing_enabled);
+
+  return tracing_enabled && use_timer_query_;
+}
+
+void GLRenderer::AddCompositeTimeTraces(base::TimeTicks ready_timestamp) {
+  DCHECK(CompositeTimeTracingEnabled());
+  DCHECK_EQ(timer_queries_.front().first, kTimerQueryDummy);
+
+  std::size_t count = 0;
+  uint64_t duration = 0;
+
+  // List of queries to delete after their results are retrieved.
+  std::vector<unsigned> queries_to_delete;
+
+  // Queue of durations per draw call. The |second| in the pair represents the
+  // draw call type as string.
+  base::queue<std::pair<uint64_t, std::string>> durations;
+
+  // Pop the fence query as it does not represent a timer query.
+  timer_queries_.pop();
+
+  // Initialize |start_time_ticks| as the end timestamp and walk backwards to
+  // find the actual timestamp.
+  base::TimeTicks start_time_ticks = ready_timestamp;
+
+  while (timer_queries_.size() &&
+         timer_queries_.front().first != kTimerQueryDummy) {
+    count++;
+    gl_->GetQueryObjectui64vEXT(timer_queries_.front().first,
+                                GL_QUERY_RESULT_EXT, &duration);
+    durations.emplace(duration, timer_queries_.front().second);
+    queries_to_delete.push_back(timer_queries_.front().first);
+    timer_queries_.pop();
+    start_time_ticks -= base::Nanoseconds(duration);
+  }
+
+  // Delete all timer queries for which results have been retrieved.
+  gl_->DeleteQueriesEXT(count, queries_to_delete.data());
+
+  base::TimeDelta unique_id_delta = ready_timestamp - start_time_ticks;
+  const int trace_unique_id = unique_id_delta.InMilliseconds() * count;
+
+  TRACE_EVENT_ASYNC_BEGIN_WITH_TIMESTAMP0(
+      TRACE_DISABLED_BY_DEFAULT("viz.gpu_composite_time"), "Composite Time",
+      TRACE_ID_LOCAL(trace_unique_id), start_time_ticks);
+
+  while (!durations.empty()) {
+    duration = durations.front().first;
+
+    // |duration| may be set to 0 if the timer query result was unavailable in
+    // |GetQueryObjectui64vEXT| function call.
+    if (!duration) {
+      durations.pop();
+      continue;
+    }
+    TRACE_EVENT_ASYNC_STEP_INTO_WITH_TIMESTAMP0(
+        TRACE_DISABLED_BY_DEFAULT("viz.gpu_composite_time"), "Composite Time",
+        TRACE_ID_LOCAL(trace_unique_id), durations.front().second.c_str(),
+        start_time_ticks);
+    start_time_ticks += base::Nanoseconds(duration);
+    durations.pop();
+  }
+
+  TRACE_EVENT_ASYNC_END_WITH_TIMESTAMP0(
+      TRACE_DISABLED_BY_DEFAULT("viz.gpu_composite_time"), "Composite Time",
+      TRACE_ID_LOCAL(trace_unique_id), ready_timestamp);
+}
+
+void GLRenderer::FinishDrawingQuadList() {
+  FlushTextureQuadCache(SHARED_BINDING);
+  if (occlusion_query_) {
+    // Use the current surface area as max result. The effect is that overdraw
+    // is reported as a percentage of the output surface size. ie. 2x overdraw
+    // for the whole screen is reported as 200.
+    base::CheckedNumeric<int> surface_area =
+        current_surface_size_.GetCheckedArea();
+    DCHECK_GT(static_cast<int>(surface_area.ValueOrDefault(INT_MAX)), 0);
+
+    gl_->EndQueryEXT(GL_SAMPLES_PASSED_ARB);
+    context_support_->SignalQuery(
+        occlusion_query_, base::BindOnce(&GLRenderer::ProcessOverdrawFeedback,
+                                         weak_ptr_factory_.GetWeakPtr(),
+                                         surface_area, occlusion_query_));
+    occlusion_query_ = 0;
+  }
+}
+
+void GLRenderer::GenerateMipmap() {
+  DCHECK(current_framebuffer_texture_);
+  current_framebuffer_texture_->set_generate_mipmap();
+}
+
+bool GLRenderer::FlippedFramebuffer() const {
+#if BUILDFLAG(IS_APPLE)
+  if (force_drawing_frame_framebuffer_unflipped_)
+    return false;
+#endif
+  if (current_frame()->current_render_pass != current_frame()->root_render_pass)
+    return true;
+  return FlippedRootFramebuffer();
+}
+
+bool GLRenderer::FlippedRootFramebuffer() const {
+  // GL is normally flipped, so a flipped output results in an unflipping.
+  return output_surface_->capabilities().output_surface_origin ==
+         gfx::SurfaceOrigin::kBottomLeft;
+}
+
+void GLRenderer::EnsureScissorTestEnabled() {
+  if (is_scissor_enabled_)
+    return;
+
+  FlushTextureQuadCache(SHARED_BINDING);
+  gl_->Enable(GL_SCISSOR_TEST);
+  is_scissor_enabled_ = true;
+}
+
+void GLRenderer::EnsureScissorTestDisabled() {
+  if (!is_scissor_enabled_)
+    return;
+
+  FlushTextureQuadCache(SHARED_BINDING);
+  gl_->Disable(GL_SCISSOR_TEST);
+  is_scissor_enabled_ = false;
+}
+
+void GLRenderer::CopyDrawnRenderPass(
+    const copy_output::RenderPassGeometry& geometry,
+    std::unique_ptr<CopyOutputRequest> request) {
+  TRACE_EVENT0("viz", "GLRenderer::CopyDrawnRenderPass");
+
+  GLuint framebuffer_texture = 0;
+  gfx::Size framebuffer_texture_size;
+  if (current_framebuffer_texture_) {
+    framebuffer_texture = current_framebuffer_texture_->id();
+    framebuffer_texture_size = current_framebuffer_texture_->size();
+  }
+  copier_.CopyFromTextureOrFramebuffer(
+      std::move(request), geometry, GetFramebufferCopyTextureFormat(),
+      framebuffer_texture, framebuffer_texture_size, FlippedFramebuffer(),
+      CurrentRenderPassColorSpace());
+
+  // The copier modified texture/framebuffer bindings, shader programs, and
+  // other GL state; and so this must be restored before continuing.
+  RestoreGLState();
+
+  // CopyDrawnRenderPass() can change the binding of the framebuffer target as
+  // a part of its usual scaling and readback operations. It will break next
+  // CopyDrawnRenderPass() call for the root render pass. Therefore, make sure
+  // to restore the correct framebuffer between readbacks. (Even if it did
+  // not, a Mac-specific bug requires this workaround: http://crbug.com/99393)
+  const auto* render_pass = current_frame()->current_render_pass;
+  if (render_pass == current_frame()->root_render_pass)
+    BindFramebufferToOutputSurface();
+}
+
+void GLRenderer::ToGLMatrix(float* gl_matrix, const gfx::Transform& transform) {
+  transform.matrix().getColMajor(gl_matrix);
+}
+
+void GLRenderer::SetShaderQuadF(const gfx::QuadF& quad) {
+  if (!current_program_ || current_program_->quad_location() == -1)
+    return;
+  float gl_quad[8];
+  gl_quad[0] = quad.p1().x();
+  gl_quad[1] = quad.p1().y();
+  gl_quad[2] = quad.p2().x();
+  gl_quad[3] = quad.p2().y();
+  gl_quad[4] = quad.p3().x();
+  gl_quad[5] = quad.p3().y();
+  gl_quad[6] = quad.p4().x();
+  gl_quad[7] = quad.p4().y();
+  gl_->Uniform2fv(current_program_->quad_location(), 4, gl_quad);
+}
+
+void GLRenderer::SetShaderOpacity(float opacity) {
+  if (!current_program_ || current_program_->alpha_location() == -1)
+    return;
+  gl_->Uniform1f(current_program_->alpha_location(), opacity);
+}
+
+void GLRenderer::SetShaderMatrix(const gfx::Transform& transform) {
+  if (!current_program_ || current_program_->matrix_location() == -1)
+    return;
+  float gl_matrix[16];
+  ToGLMatrix(gl_matrix, transform);
+  gl_->UniformMatrix4fv(current_program_->matrix_location(), 1, false,
+                        gl_matrix);
+}
+
+void GLRenderer::SetShaderColor(SkColor color, float opacity) {
+  if (!current_program_ || current_program_->color_location() == -1)
+    return;
+  Float4 float_color = PremultipliedColor(color, opacity);
+  gl_->Uniform4fv(current_program_->color_location(), 1, float_color.data);
+}
+
+void GLRenderer::SetStencilEnabled(bool enabled) {
+  if (enabled == stencil_shadow_)
+    return;
+
+  if (enabled)
+    gl_->Enable(GL_STENCIL_TEST);
+  else
+    gl_->Disable(GL_STENCIL_TEST);
+  stencil_shadow_ = enabled;
+}
+
+void GLRenderer::SetBlendEnabled(bool enabled) {
+  if (enabled == blend_shadow_)
+    return;
+
+  if (enabled)
+    gl_->Enable(GL_BLEND);
+  else
+    gl_->Disable(GL_BLEND);
+  blend_shadow_ = enabled;
+}
+
+void GLRenderer::SetShaderRoundedCorner(
+    const gfx::RRectF& rounded_corner_bounds,
+    const gfx::Transform& screen_transform) {
+  DCHECK(current_program_);
+  DCHECK(!rounded_corner_bounds.IsEmpty());
+  DCHECK_NE(current_program_->rounded_corner_rect_location(), -1);
+  DCHECK_NE(current_program_->rounded_corner_radius_location(), -1);
+  DCHECK(screen_transform.IsScaleOrTranslation());
+
+  const gfx::Vector2dF& translate = screen_transform.To2dTranslation();
+  const gfx::Vector2dF& scale = screen_transform.To2dScale();
+  gfx::RRectF bounds_in_screen = rounded_corner_bounds;
+  bounds_in_screen.Scale(scale.x(), scale.y());
+  bounds_in_screen.Offset(translate.x(), translate.y());
+
+  gfx::RectF rect = bounds_in_screen.rect();
+
+  gl_->Uniform4f(current_program_->rounded_corner_rect_location(), rect.x(),
+                 rect.y(), rect.width(), rect.height());
+  gl_->Uniform4f(
+      current_program_->rounded_corner_radius_location(),
+      bounds_in_screen.GetCornerRadii(gfx::RRectF::Corner::kUpperLeft).x(),
+      bounds_in_screen.GetCornerRadii(gfx::RRectF::Corner::kUpperRight).x(),
+      bounds_in_screen.GetCornerRadii(gfx::RRectF::Corner::kLowerRight).x(),
+      bounds_in_screen.GetCornerRadii(gfx::RRectF::Corner::kLowerLeft).x());
+}
+
+void GLRenderer::DrawQuadGeometryClippedByQuadF(
+    const gfx::Transform& draw_transform,
+    const gfx::RectF& quad_rect,
+    const gfx::QuadF& clipping_region_quad,
+    const float* uvs) {
+  PrepareGeometry(CLIPPED_BINDING);
+  if (uvs) {
+    clipped_geometry_->InitializeCustomQuadWithUVs(clipping_region_quad, uvs);
+  } else {
+    clipped_geometry_->InitializeCustomQuad(clipping_region_quad);
+  }
+  gfx::Transform quad_rect_matrix;
+  QuadRectTransform(&quad_rect_matrix, draw_transform, quad_rect);
+  SetShaderMatrix(current_frame()->projection_matrix * quad_rect_matrix);
+
+  gl_->DrawElements(GL_TRIANGLES, 6, GL_UNSIGNED_SHORT,
+                    reinterpret_cast<const void*>(0));
+  num_triangles_drawn_ += 2;
+}
+
+void GLRenderer::DrawQuadGeometry(const gfx::Transform& projection_matrix,
+                                  const gfx::Transform& draw_transform,
+                                  const gfx::RectF& quad_rect) {
+  PrepareGeometry(SHARED_BINDING);
+  gfx::Transform quad_rect_matrix;
+  QuadRectTransform(&quad_rect_matrix, draw_transform, quad_rect);
+  SetShaderMatrix(projection_matrix * quad_rect_matrix);
+
+  gl_->DrawElements(GL_TRIANGLES, 6, GL_UNSIGNED_SHORT, nullptr);
+  num_triangles_drawn_ += 2;
+}
+
+void GLRenderer::DrawQuadGeometryWithAA(const DrawQuad* quad,
+                                        gfx::QuadF* local_quad,
+                                        const gfx::Rect& tile_rect) {
+  DCHECK(local_quad);
+  // Normalize to tile_rect.
+  local_quad->Scale(1.0f / tile_rect.width(), 1.0f / tile_rect.height());
+
+  SetShaderQuadF(*local_quad);
+
+  // The transform and vertex data are used to figure out the extents that the
+  // un-antialiased quad should have and which vertex this is and the float
+  // quad passed in via uniform is the actual geometry that gets used to draw
+  // it. This is why this centered rect is used and not the original quad_rect.
+  DrawQuadGeometry(current_frame()->projection_matrix,
+                   quad->shared_quad_state->quad_to_target_transform,
+                   CenteredRect(tile_rect));
+}
+
+void GLRenderer::SwapBuffers(SwapFrameData swap_frame_data) {
+  DCHECK(visible_);
+
+  TRACE_EVENT0("viz", "GLRenderer::SwapBuffers");
+  // We're done! Time to swapbuffers!
+
+  gfx::Size surface_size = surface_size_for_swap_buffers();
+
+  OutputSurfaceFrame output_frame;
+  output_frame.latency_info = std::move(swap_frame_data.latency_info);
+  output_frame.top_controls_visible_height_changed =
+      swap_frame_data.top_controls_visible_height_changed;
+  output_frame.size = surface_size;
+#if BUILDFLAG(IS_MAC)
+  output_frame.ca_layer_error_code = swap_frame_data.ca_layer_error_code;
+#endif
+
+  if (use_swap_with_bounds_) {
+    output_frame.content_bounds = std::move(swap_content_bounds_);
+  } else if (use_partial_swap_) {
+    // If supported, we can save significant bandwidth by only swapping the
+    // damaged/scissored region (clamped to the viewport).
+    swap_buffer_rect_.Intersect(gfx::Rect(surface_size));
+    int flipped_y_pos_of_rect_bottom = surface_size.height() -
+                                       swap_buffer_rect_.y() -
+                                       swap_buffer_rect_.height();
+    output_frame.sub_buffer_rect =
+        gfx::Rect(swap_buffer_rect_.x(),
+                  FlippedRootFramebuffer() ? flipped_y_pos_of_rect_bottom
+                                           : swap_buffer_rect_.y(),
+                  swap_buffer_rect_.width(), swap_buffer_rect_.height());
+  } else if (swap_buffer_rect_.IsEmpty() && allow_empty_swap_) {
+    output_frame.sub_buffer_rect = swap_buffer_rect_;
+  }
+
+  // Record resources from viz clients that have been shipped as overlays to the
+  // gpu together.
+  swapping_overlay_resources_.push_back(std::move(pending_overlay_resources_));
+  pending_overlay_resources_.clear();
+  if (settings_->release_overlay_resources_after_gpu_query) {
+    // Record RenderPass textures that have been shipped as overlays to the gpu
+    // together.
+    displayed_overlay_textures_.push_back(
+        std::move(awaiting_swap_overlay_textures_));
+    awaiting_swap_overlay_textures_.clear();
+  } else {
+    // If |displayed_overlay_textures_| is appended to in this case then
+    // SwapBuffersComplete needs to be extended to handle it.
+    DCHECK(awaiting_swap_overlay_textures_.empty());
+  }
+
+  output_surface_->SwapBuffers(std::move(output_frame));
+
+  swap_buffer_rect_ = gfx::Rect();
+
+  if (context_busy_) {
+    output_surface_->context_provider()->CacheController()->ClientBecameNotBusy(
+        std::move(context_busy_));
+  }
+}
+
+void GLRenderer::SwapBuffersSkipped() {
+  if (context_busy_) {
+    output_surface_->context_provider()->CacheController()->ClientBecameNotBusy(
+        std::move(context_busy_));
+  }
+}
+
+void GLRenderer::SwapBuffersComplete(gfx::GpuFenceHandle release_fence) {
+  // Returned release fence is signalled when the latest swap is presented,
+  // and tells us we can re-use the buffers from the /previous/ swap.
+  if (swapping_overlay_resources_.size() > 1) {
+    for (auto& lock : swapping_overlay_resources_[0]) {
+      lock->SetReleaseFence(release_fence.Clone());
+    }
+  }
+
+  if (settings_->release_overlay_resources_after_gpu_query) {
+    // Once a resource has been swap-ACKed, send a query to the GPU process to
+    // ask if the resource is no longer being consumed by the system compositor.
+    // The response will come with the next swap-ACK.
+    if (!swapping_overlay_resources_.empty()) {
+      for (OverlayResourceLock& lock : swapping_overlay_resources_.front()) {
+        unsigned texture = lock->texture_id();
+        if (swapped_and_acked_overlay_resources_.find(texture) ==
+            swapped_and_acked_overlay_resources_.end()) {
+          swapped_and_acked_overlay_resources_[texture] = std::move(lock);
+        }
+      }
+      swapping_overlay_resources_.pop_front();
+    }
+    if (!displayed_overlay_textures_.empty()) {
+      for (auto& overlay : displayed_overlay_textures_.front())
+        awaiting_release_overlay_textures_.push_back(std::move(overlay));
+      displayed_overlay_textures_.erase(displayed_overlay_textures_.begin());
+    }
+
+    size_t query_texture_count = swapped_and_acked_overlay_resources_.size() +
+                                 awaiting_release_overlay_textures_.size();
+    if (query_texture_count) {
+      std::vector<uint32_t> query_texture_ids;
+      query_texture_ids.reserve(query_texture_count);
+
+      for (auto& pair : swapped_and_acked_overlay_resources_)
+        query_texture_ids.push_back(pair.first);
+      for (auto& overlay : awaiting_release_overlay_textures_)
+        query_texture_ids.push_back(overlay->texture.id());
+
+      // We query for *all* outstanding texture ids, even if we previously
+      // queried, as we will not hear back about things becoming available
+      // until after we query again.
+      gl_->ScheduleCALayerInUseQueryCHROMIUM(query_texture_count,
+                                             query_texture_ids.data());
+    }
+  } else {
+    // If a query is not needed to release the overlay buffers, we can assume
+    // that once a swap buffer has completed we can remove the oldest buffers
+    // from the queue, but only once we've swapped another frame afterward.
+    if (swapping_overlay_resources_.size() > 1) {
+      auto& read_lock_release_fence_overlay_locks =
+          read_lock_release_fence_overlay_locks_.emplace_back();
+      if (!release_fence.is_null()) {
+        auto read_lock_iter = std::partition(
+            swapping_overlay_resources_.front().begin(),
+            swapping_overlay_resources_.front().end(),
+            [](auto& lock) { return !lock->HasReadLockFence(); });
+        read_lock_release_fence_overlay_locks.insert(
+            read_lock_release_fence_overlay_locks.end(),
+            std::make_move_iterator(read_lock_iter),
+            std::make_move_iterator(swapping_overlay_resources_.front().end()));
+      }
+
+      DisplayResourceProviderGL::ScopedBatchReturnResources returner(
+          resource_provider());
+      swapping_overlay_resources_.pop_front();
+    }
+    // If |displayed_overlay_textures_| has a non-empty member that means we're
+    // sending RenderPassDrawQuads as an overlay. This is only supported for
+    // CALayers now, where |release_overlay_resources_after_gpu_query| will be
+    // true. In order to support them here, the OverlayTextures would need to
+    // move to |awaiting_release_overlay_textures_| and stay there until the
+    // ResourceFence that was in use for the frame they were submitted is
+    // passed.
+    DCHECK(displayed_overlay_textures_.empty());
+  }
+}
+
+void GLRenderer::BuffersPresented() {
+  if (!read_lock_release_fence_overlay_locks_.empty())
+    read_lock_release_fence_overlay_locks_.pop_front();
+}
+
+void GLRenderer::DidReceiveTextureInUseResponses(
+    const gpu::TextureInUseResponses& responses) {
+  DCHECK(settings_->release_overlay_resources_after_gpu_query);
+  DisplayResourceProviderGL::ScopedBatchReturnResources returner(
+      resource_provider());
+  for (const gpu::TextureInUseResponse& response : responses) {
+    if (response.in_use)
+      continue;
+
+    // Returned texture ids may be for resources from clients of the
+    // display compositor, in |swapped_and_acked_overlay_resources_|. In that
+    // case we remove the lock from the map, allowing them to be returned to the
+    // client if the resource has been deleted from the
+    // DisplayResourceProviderGL.
+    if (swapped_and_acked_overlay_resources_.erase(response.texture))
+      continue;
+    // If not, then they would be a RenderPass copy texture, which is held in
+    // |awaiting_release_overlay_textures_|. We move it back to the available
+    // texture list to use it for the next frame.
+    auto it = std::find_if(
+        awaiting_release_overlay_textures_.begin(),
+        awaiting_release_overlay_textures_.end(),
+        [&response](const std::unique_ptr<OverlayTexture>& overlay) {
+          return overlay->texture.id() == response.texture;
+        });
+    if (it != awaiting_release_overlay_textures_.end()) {
+      // Mark the OverlayTexture as newly returned to the available set.
+      (*it)->frames_waiting_for_reuse = 0;
+      available_overlay_textures_.push_back(std::move(*it));
+      awaiting_release_overlay_textures_.erase(it);
+    }
+  }
+}
+
+void GLRenderer::BindFramebufferToOutputSurface() {
+  current_framebuffer_texture_ = nullptr;
+  output_surface_->BindFramebuffer();
+  tint_gl_composited_content_ = debug_settings_->tint_composited_content;
+  if (overdraw_feedback_) {
+    // Output surfaces that require an external stencil test should not allow
+    // overdraw feedback by setting |supports_stencil| to false.
+    DCHECK(!output_surface_->HasExternalStencilTest());
+    SetupOverdrawFeedback();
+    SetStencilEnabled(true);
+  } else if (output_surface_->HasExternalStencilTest()) {
+    output_surface_->ApplyExternalStencil();
+    SetStencilEnabled(true);
+  } else {
+    SetStencilEnabled(false);
+  }
+}
+
+void GLRenderer::BindFramebufferToTexture(
+    const AggregatedRenderPassId render_pass_id) {
+  tint_gl_composited_content_ = false;
+  gl_->BindFramebuffer(GL_FRAMEBUFFER, offscreen_framebuffer_id_);
+
+  auto contents_texture_it = render_pass_textures_.find(render_pass_id);
+  current_framebuffer_texture_ = &contents_texture_it->second;
+  GLuint texture_id = current_framebuffer_texture_->id();
+  DCHECK(texture_id);
+  gl_->FramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D,
+                            texture_id, 0);
+  if (overdraw_feedback_) {
+    if (!offscreen_stencil_renderbuffer_id_)
+      gl_->GenRenderbuffers(1, &offscreen_stencil_renderbuffer_id_);
+    if (current_framebuffer_texture_->size() !=
+        offscreen_stencil_renderbuffer_size_) {
+      gl_->BindRenderbuffer(GL_RENDERBUFFER,
+                            offscreen_stencil_renderbuffer_id_);
+      gl_->RenderbufferStorage(GL_RENDERBUFFER, GL_STENCIL_INDEX8,
+                               current_framebuffer_texture_->size().width(),
+                               current_framebuffer_texture_->size().height());
+      gl_->BindRenderbuffer(GL_RENDERBUFFER, 0);
+      offscreen_stencil_renderbuffer_size_ =
+          current_framebuffer_texture_->size();
+    }
+    gl_->FramebufferRenderbuffer(GL_FRAMEBUFFER, GL_STENCIL_ATTACHMENT,
+                                 GL_RENDERBUFFER,
+                                 offscreen_stencil_renderbuffer_id_);
+  }
+
+#if EXPENSIVE_DCHECKS_ARE_ON()
+  DCHECK(gl_->CheckFramebufferStatus(GL_FRAMEBUFFER) ==
+             GL_FRAMEBUFFER_COMPLETE ||
+         IsContextLost());
+#endif  // EXPENSIVE_DCHECKS_ARE_ON()
+
+  if (overdraw_feedback_) {
+    SetupOverdrawFeedback();
+    SetStencilEnabled(true);
+  } else {
+    SetStencilEnabled(false);
+  }
+}
+
+void GLRenderer::SetScissorTestRect(const gfx::Rect& scissor_rect) {
+  EnsureScissorTestEnabled();
+
+  // Don't unnecessarily ask the context to change the scissor, because it
+  // may cause undesired GPU pipeline flushes.
+  if (scissor_rect == scissor_rect_)
+    return;
+
+  scissor_rect_ = scissor_rect;
+  FlushTextureQuadCache(SHARED_BINDING);
+  gl_->Scissor(scissor_rect.x(), scissor_rect.y(), scissor_rect.width(),
+               scissor_rect.height());
+}
+
+void GLRenderer::SetViewport() {
+  gl_->Viewport(current_window_space_viewport_.x(),
+                current_window_space_viewport_.y(),
+                current_window_space_viewport_.width(),
+                current_window_space_viewport_.height());
+}
+
+void GLRenderer::InitializeSharedObjects() {
+  TRACE_EVENT0("viz", "GLRenderer::InitializeSharedObjects");
+
+  // Create an FBO for doing offscreen rendering.
+  gl_->GenFramebuffers(1, &offscreen_framebuffer_id_);
+
+  shared_geometry_ =
+      std::make_unique<StaticGeometryBinding>(gl_, QuadVertexRect());
+  clipped_geometry_ = std::make_unique<DynamicGeometryBinding>(gl_);
+}
+
+void GLRenderer::PrepareGeometry(BoundGeometry binding) {
+  if (binding == bound_geometry_) {
+    return;
+  }
+
+  switch (binding) {
+    case SHARED_BINDING:
+      shared_geometry_->PrepareForDraw();
+      break;
+    case CLIPPED_BINDING:
+      clipped_geometry_->PrepareForDraw();
+      break;
+    case NO_BINDING:
+      break;
+  }
+  bound_geometry_ = binding;
+}
+
+void GLRenderer::SetUseProgram(const ProgramKey& program_key_no_color,
+                               const gfx::ColorSpace& src_color_space,
+                               const gfx::ColorSpace& dst_color_space,
+                               bool adjust_src_white_level,
+                               absl::optional<gfx::HDRMetadata> hdr_metadata) {
+  DCHECK(dst_color_space.IsValid());
+  gfx::ColorSpace adjusted_src_color_space = src_color_space;
+
+  ProgramKey program_key = program_key_no_color;
+  const gfx::ColorTransform* color_transform =
+      GetColorTransform(adjusted_src_color_space, dst_color_space);
+  program_key.SetColorTransform(color_transform);
+
+  bool has_output_color_matrix = false;
+  if (program_key.type() != ProgramType::PROGRAM_TYPE_SOLID_COLOR)
+    has_output_color_matrix = HasOutputColorMatrix();
+  program_key.set_has_output_color_matrix(has_output_color_matrix);
+
+  // Create and set the program if needed.
+  std::unique_ptr<Program>& program = program_cache_[program_key];
+  if (!program) {
+    program = std::make_unique<Program>();
+    program->Initialize(output_surface_->context_provider(), program_key);
+  }
+  DCHECK(program);
+  if (current_program_ != program.get()) {
+    current_program_ = program.get();
+    gl_->UseProgram(current_program_->program());
+  }
+  if (!current_program_->initialized()) {
+    DCHECK(IsContextLost());
+    return;
+  }
+
+  // Set uniforms that are common to all programs.
+  if (current_program_->sampler_location() != -1)
+    gl_->Uniform1i(current_program_->sampler_location(), 0);
+  if (current_program_->viewport_location() != -1) {
+    float viewport[4] = {
+        static_cast<float>(current_window_space_viewport_.x()),
+        static_cast<float>(current_window_space_viewport_.y()),
+        static_cast<float>(current_window_space_viewport_.width()),
+        static_cast<float>(current_window_space_viewport_.height()),
+    };
+    gl_->Uniform4fv(current_program_->viewport_location(), 1, viewport);
+  }
+
+  if (has_output_color_matrix) {
+    DCHECK_NE(current_program_->output_color_matrix_location(), -1);
+    float matrix[16];
+    output_surface_->color_matrix().getColMajor(matrix);
+    gl_->UniformMatrix4fv(current_program_->output_color_matrix_location(), 1,
+                          false, matrix);
+  }
+}
+
+const Program* GLRenderer::GetProgramIfInitialized(
+    const ProgramKey& desc) const {
+  const auto found = program_cache_.find(desc);
+  if (found == program_cache_.end())
+    return nullptr;
+  return found->second.get();
+}
+
+const gfx::ColorTransform* GLRenderer::GetColorTransform(
+    const gfx::ColorSpace& src,
+    const gfx::ColorSpace& dst) {
+  ColorTransformKey key;
+  key.src = src;
+  key.dst = dst;
+  key.sdr_max_luminance_nits =
+      current_frame()->display_color_spaces.GetSDRMaxLuminanceNits();
+  std::unique_ptr<gfx::ColorTransform>& transform = color_transform_cache_[key];
+  if (!transform) {
+    gfx::ColorTransform::Options options;
+    options.tone_map_pq_and_hlg_to_sdr = !dst.IsHDR();
+    options.sdr_max_luminance_nits = key.sdr_max_luminance_nits;
+    transform = gfx::ColorTransform::NewColorTransform(src, dst, options);
+  }
+  return transform.get();
+}
+
+void GLRenderer::CleanupSharedObjects() {
+  shared_geometry_ = nullptr;
+
+  gl_->ReleaseShaderCompiler();
+  for (auto& iter : program_cache_)
+    iter.second->Cleanup(gl_);
+  program_cache_.clear();
+  color_transform_cache_.clear();
+
+  if (offscreen_framebuffer_id_)
+    gl_->DeleteFramebuffers(1, &offscreen_framebuffer_id_);
+
+  if (offscreen_stencil_renderbuffer_id_)
+    gl_->DeleteRenderbuffers(1, &offscreen_stencil_renderbuffer_id_);
+}
+
+void GLRenderer::ReinitializeGLState() {
+  is_scissor_enabled_ = false;
+  scissor_rect_ = gfx::Rect();
+  stencil_shadow_ = false;
+  blend_shadow_ = true;
+  current_program_ = nullptr;
+
+  RestoreGLState();
+}
+
+void GLRenderer::RestoreGLStateAfterSkia() {
+  // After using Skia we need to disable vertex attributes we don't use
+  int attribs_count = output_surface_->context_provider()
+                          ->ContextCapabilities()
+                          .max_vertex_attribs;
+  for (int i = 0; i < attribs_count; i++)
+    gl_->DisableVertexAttribArray(i);
+
+  RestoreGLState();
+}
+
+void GLRenderer::RestoreGLState() {
+  // This restores the current GLRenderer state to the GL context.
+  bound_geometry_ = NO_BINDING;
+  PrepareGeometry(SHARED_BINDING);
+
+  gl_->Disable(GL_DEPTH_TEST);
+  gl_->Disable(GL_CULL_FACE);
+  gl_->ColorMask(true, true, true, true);
+  gl_->BlendFunc(GL_ONE, GL_ONE_MINUS_SRC_ALPHA);
+  gl_->ActiveTexture(GL_TEXTURE0);
+
+  if (current_program_)
+    gl_->UseProgram(current_program_->program());
+
+  if (stencil_shadow_)
+    gl_->Enable(GL_STENCIL_TEST);
+  else
+    gl_->Disable(GL_STENCIL_TEST);
+
+  if (blend_shadow_)
+    gl_->Enable(GL_BLEND);
+  else
+    gl_->Disable(GL_BLEND);
+
+  if (is_scissor_enabled_)
+    gl_->Enable(GL_SCISSOR_TEST);
+  else
+    gl_->Disable(GL_SCISSOR_TEST);
+
+  gl_->Scissor(scissor_rect_.x(), scissor_rect_.y(), scissor_rect_.width(),
+               scissor_rect_.height());
+}
+
+bool GLRenderer::IsContextLost() {
+  return gl_->GetGraphicsResetStatusKHR() != GL_NO_ERROR;
+}
+
+#if BUILDFLAG(IS_APPLE)
+void GLRenderer::ScheduleCALayers() {
+  // The use of OverlayTextures for RenderPasses is only supported on the code
+  // paths for |release_overlay_resources_after_gpu_query| at the moment. See
+  // SwapBuffersComplete for notes on the missing support for other paths. This
+  // method uses ScheduleRenderPassDrawQuad to send RenderPass outputs as
+  // overlays, so it can only be used because this setting is true.
+  if (!settings_->release_overlay_resources_after_gpu_query)
+    return;
+
+  scoped_refptr<CALayerOverlaySharedState> shared_state;
+
+  for (const CALayerOverlay& ca_layer_overlay : current_frame()->overlay_list) {
+    if (ca_layer_overlay.rpdq) {
+      std::unique_ptr<OverlayTexture> overlay_texture =
+          ScheduleRenderPassDrawQuad(&ca_layer_overlay);
+      if (overlay_texture)
+        awaiting_swap_overlay_textures_.push_back(std::move(overlay_texture));
+      shared_state = nullptr;
+      continue;
+    }
+
+    ResourceId contents_resource_id = ca_layer_overlay.contents_resource_id;
+    unsigned texture_id = 0;
+    if (contents_resource_id) {
+      pending_overlay_resources_.push_back(
+          std::make_unique<DisplayResourceProviderGL::ScopedOverlayLockGL>(
+              resource_provider(), contents_resource_id));
+      texture_id = pending_overlay_resources_.back()->texture_id();
+    }
+    GLfloat contents_rect[4] = {
+        ca_layer_overlay.contents_rect.x(), ca_layer_overlay.contents_rect.y(),
+        ca_layer_overlay.contents_rect.width(),
+        ca_layer_overlay.contents_rect.height(),
+    };
+    GLfloat bounds_rect[4] = {
+        ca_layer_overlay.bounds_rect.x(), ca_layer_overlay.bounds_rect.y(),
+        ca_layer_overlay.bounds_rect.width(),
+        ca_layer_overlay.bounds_rect.height(),
+    };
+    GLboolean is_clipped = ca_layer_overlay.shared_state->is_clipped;
+    GLfloat clip_rect[4] = {ca_layer_overlay.shared_state->clip_rect.x(),
+                            ca_layer_overlay.shared_state->clip_rect.y(),
+                            ca_layer_overlay.shared_state->clip_rect.width(),
+                            ca_layer_overlay.shared_state->clip_rect.height()};
+
+    const gfx::RectF& rect =
+        ca_layer_overlay.shared_state->rounded_corner_bounds.rect();
+    GLfloat rounded_corner_bounds[5] = {
+        rect.x(), rect.y(), rect.width(), rect.height(),
+        ca_layer_overlay.shared_state->rounded_corner_bounds.GetSimpleRadius()};
+
+    GLint sorting_context_id =
+        ca_layer_overlay.shared_state->sorting_context_id;
+    GLfloat transform[16];
+    ca_layer_overlay.shared_state->transform.matrix().getColMajor(transform);
+    unsigned filter = ca_layer_overlay.filter;
+
+    if (ca_layer_overlay.shared_state != shared_state) {
+      shared_state = ca_layer_overlay.shared_state;
+      gl_->ScheduleCALayerSharedStateCHROMIUM(
+          ca_layer_overlay.shared_state->opacity, is_clipped, clip_rect,
+          rounded_corner_bounds, sorting_context_id, transform);
+    }
+    gl_->ScheduleCALayerCHROMIUM(
+        texture_id, contents_rect, ca_layer_overlay.background_color,
+        ca_layer_overlay.edge_aa_mask, bounds_rect, filter);
+  }
+
+  ReduceAvailableOverlayTextures();
+}
+#endif  // BUILDFLAG(IS_APPLE)
+
+#if BUILDFLAG(IS_WIN)
+void GLRenderer::ScheduleDCLayers() {
+  for (DCLayerOverlay& dc_layer_overlay : current_frame()->overlay_list) {
+    DCHECK_EQ(DCLayerOverlay::kNumResources, 2u);
+    GLuint texture_ids[DCLayerOverlay::kNumResources] = {};
+    for (size_t i = 0; i < DCLayerOverlay::kNumResources; i++) {
+      ResourceId resource_id = dc_layer_overlay.resources[i];
+      if (resource_id == kInvalidResourceId)
+        break;
+      pending_overlay_resources_.push_back(
+          std::make_unique<DisplayResourceProviderGL::ScopedOverlayLockGL>(
+              resource_provider(), resource_id));
+      texture_ids[i] = pending_overlay_resources_.back()->texture_id();
+    }
+    DCHECK(texture_ids[0]);
+    // TODO(sunnyps): Set color space in renderer like we do for tiles.
+    gl_->SetColorSpaceMetadataCHROMIUM(
+        texture_ids[0], dc_layer_overlay.color_space.AsGLColorSpace());
+
+    int z_order = dc_layer_overlay.z_order;
+    const gfx::Rect& content_rect = dc_layer_overlay.content_rect;
+    const gfx::Rect& quad_rect = dc_layer_overlay.quad_rect;
+    DCHECK(dc_layer_overlay.transform.IsFlat());
+    const auto& matrix = dc_layer_overlay.transform.matrix();
+    bool is_clipped = dc_layer_overlay.clip_rect.has_value();
+    const gfx::Rect& clip_rect =
+        dc_layer_overlay.clip_rect.value_or(gfx::Rect());
+    unsigned protected_video_type =
+        static_cast<unsigned>(dc_layer_overlay.protected_video_type);
+
+    gl_->ScheduleDCLayerCHROMIUM(
+        texture_ids[0], texture_ids[1], z_order, content_rect.x(),
+        content_rect.y(), content_rect.width(), content_rect.height(),
+        quad_rect.x(), quad_rect.y(), quad_rect.width(), quad_rect.height(),
+        matrix.rc(0, 0), matrix.rc(0, 1), matrix.rc(1, 0), matrix.rc(1, 1),
+        matrix.rc(0, 3), matrix.rc(1, 3), is_clipped, clip_rect.x(),
+        clip_rect.y(), clip_rect.width(), clip_rect.height(),
+        protected_video_type);
+  }
+}
+#endif  // BUILDFLAG(IS_WIN)
+
+#if BUILDFLAG(IS_ANDROID) || defined(USE_OZONE)
+void GLRenderer::ScheduleOverlays() {
+  if (current_frame()->overlay_list.empty())
+    return;
+
+  OverlayCandidateList& overlays = current_frame()->overlay_list;
+  for (const auto& overlay_candidate : overlays) {
+    pending_overlay_resources_.push_back(
+        std::make_unique<DisplayResourceProviderGL::ScopedOverlayLockGL>(
+            resource_provider(), overlay_candidate.resource_id));
+    unsigned texture_id = pending_overlay_resources_.back()->texture_id();
+
+    context_support_->ScheduleOverlayPlane(
+        overlay_candidate.plane_z_order, overlay_candidate.transform,
+        texture_id, ToNearestRect(overlay_candidate.display_rect),
+        overlay_candidate.uv_rect, !overlay_candidate.is_opaque,
+        overlay_candidate.gpu_fence_id);
+  }
+}
+#endif  // BUILDFLAG(IS_ANDROID) || defined(USE_OZONE)
+
+void GLRenderer::ScheduleOutputSurfaceAsOverlay() {
+  if (!current_frame()->output_surface_plane)
+    return;
+
+  // Initialize correct values to use an output surface as overlay candidate.
+  auto& overlay_candidate = *(current_frame()->output_surface_plane);
+  unsigned texture_id = output_surface_->GetOverlayTextureId();
+  DCHECK(texture_id || IsContextLost());
+  // Output surface is also z-order 0.
+  int plane_z_order = 0;
+
+  context_support_->ScheduleOverlayPlane(
+      plane_z_order, overlay_candidate.transform, texture_id,
+      ToNearestRect(overlay_candidate.display_rect), overlay_candidate.uv_rect,
+      overlay_candidate.enable_blending, overlay_candidate.gpu_fence_id);
+}
+
+#if BUILDFLAG(IS_APPLE)
+// This function draws the CompositorRenderPassDrawQuad into a temporary
+// texture/framebuffer, and then copies the result into an IOSurface. The
+// inefficient (but simple) way to do this would be to:
+//   1. Allocate a framebuffer the size of the screen.
+//   2. Draw using all the normal RPDQ draw logic.
+//
+// Instead, this method does the following:
+//   1. Configure parameters as if drawing to a framebuffer the size of the
+//   screen. This reuses most of the RPDQ draw logic.
+//   2. Update parameters to draw into a framebuffer only as large as needed.
+//   3. Fix shader uniforms that were broken by (2).
+//
+// Then:
+//   4. Allocate an IOSurface as the drawing destination.
+//   5. Draw the RPDQ.
+void GLRenderer::CopyRenderPassDrawQuadToOverlayResource(
+    const CALayerOverlay* ca_layer_overlay,
+    std::unique_ptr<OverlayTexture>* overlay_texture,
+    gfx::RectF* new_bounds) {
+  // Don't carry over any GL state from previous RenderPass draw operations.
+  ReinitializeGLState();
+  auto contents_texture_it =
+      render_pass_textures_.find(ca_layer_overlay->rpdq->render_pass_id);
+  DCHECK(contents_texture_it != render_pass_textures_.end());
+
+  // Configure parameters as if drawing to a framebuffer the size of the
+  // screen.
+  DrawRenderPassDrawQuadParams params;
+  params.quad = ca_layer_overlay->rpdq;
+  params.flip_texture = true;
+  params.contents_texture = &contents_texture_it->second;
+  params.quad_to_target_transform =
+      params.quad->shared_quad_state->quad_to_target_transform;
+  params.tex_coord_rect = params.quad->tex_coord_rect;
+
+  // Calculate projection and window matrices using InitializeViewport(). This
+  // requires creating a dummy DrawingFrame.
+  {
+    DrawingFrame dummy_frame;
+    gfx::Rect frame_rect(current_frame()->device_viewport_size);
+    force_drawing_frame_framebuffer_unflipped_ = true;
+    InitializeViewport(&dummy_frame, frame_rect, frame_rect, frame_rect.size());
+    force_drawing_frame_framebuffer_unflipped_ = false;
+    params.projection_matrix = dummy_frame.projection_matrix;
+    params.window_matrix = dummy_frame.window_matrix;
+  }
+
+  // Perform basic initialization with the screen-sized viewport.
+  if (!InitializeRPDQParameters(&params))
+    return;
+
+  if (!UpdateRPDQWithSkiaFilters(&params))
+    return;
+
+  // |params.dst_rect| now contain values that reflect a potentially increased
+  // size quad.
+  gfx::RectF updated_dst_rect = params.dst_rect;
+  gfx::Size dst_pixel_size = gfx::ToCeiledSize(updated_dst_rect.size());
+
+  int iosurface_width = dst_pixel_size.width();
+  int iosurface_height = dst_pixel_size.height();
+  if (!settings_->dont_round_texture_sizes_for_pixel_tests) {
+    // Round the size of the IOSurface to a multiple of 64 pixels. This reduces
+    // memory fragmentation. https://crbug.com/146070. This also allows
+    // IOSurfaces to be more easily reused during a resize operation.
+    int iosurface_multiple = 64;
+    iosurface_width =
+        cc::MathUtil::CheckedRoundUp(iosurface_width, iosurface_multiple);
+    iosurface_height =
+        cc::MathUtil::CheckedRoundUp(iosurface_height, iosurface_multiple);
+  }
+
+  *overlay_texture =
+      FindOrCreateOverlayTexture(params.quad->render_pass_id, iosurface_width,
+                                 iosurface_height, RootRenderPassColorSpace());
+  *new_bounds = gfx::RectF(updated_dst_rect.origin(),
+                           gfx::SizeF((*overlay_texture)->texture.size()));
+
+  // Calculate new projection and window matrices for a minimally sized viewport
+  // using InitializeViewport(). This requires creating a dummy DrawingFrame.
+  {
+    DrawingFrame dummy_frame;
+    force_drawing_frame_framebuffer_unflipped_ = true;
+    gfx::Rect frame_rect =
+        gfx::Rect(0, 0, updated_dst_rect.width(), updated_dst_rect.height());
+    InitializeViewport(&dummy_frame, frame_rect, frame_rect, frame_rect.size());
+    force_drawing_frame_framebuffer_unflipped_ = false;
+    params.projection_matrix = dummy_frame.projection_matrix;
+    params.window_matrix = dummy_frame.window_matrix;
+  }
+
+  // Calculate a new quad_to_target_transform.
+  params.quad_to_target_transform = gfx::Transform();
+  params.quad_to_target_transform.Translate(-updated_dst_rect.x(),
+                                            -updated_dst_rect.y());
+
+  // Antialiasing works by fading out content that is close to the edge of the
+  // viewport. All of these values need to be recalculated.
+  if (params.use_aa) {
+    current_window_space_viewport_ =
+        gfx::Rect(0, 0, updated_dst_rect.width(), updated_dst_rect.height());
+    gfx::Transform quad_rect_matrix;
+    QuadRectTransform(&quad_rect_matrix, params.quad_to_target_transform,
+                      updated_dst_rect);
+    params.contents_device_transform =
+        params.window_matrix * params.projection_matrix * quad_rect_matrix;
+    bool clipped = false;
+    params.contents_device_transform.FlattenTo2d();
+    gfx::QuadF device_layer_quad = cc::MathUtil::MapQuad(
+        params.contents_device_transform, SharedGeometryQuad(), &clipped);
+    LayerQuad device_layer_edges(device_layer_quad);
+    InflateAntiAliasingDistances(device_layer_quad, &device_layer_edges,
+                                 params.edge);
+  }
+
+  // Establish destination texture.
+  GLuint temp_fbo;
+  gl_->GenFramebuffers(1, &temp_fbo);
+  gl_->BindFramebuffer(GL_FRAMEBUFFER, temp_fbo);
+  gl_->FramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0,
+                            (*overlay_texture)->texture.target(),
+                            (*overlay_texture)->texture.id(), 0);
+  DCHECK(gl_->CheckFramebufferStatus(GL_FRAMEBUFFER) ==
+             GL_FRAMEBUFFER_COMPLETE ||
+         IsContextLost());
+
+  // Clear to 0 to ensure the background is transparent.
+  gl_->ClearColor(0, 0, 0, 0);
+  gl_->Clear(GL_COLOR_BUFFER_BIT);
+
+  UpdateRPDQTexturesForSampling(&params);
+  UpdateRPDQBlendMode(&params);
+  // The code in this method (CopyRenderPassDrawQuadToOverlayResource) is
+  // only called when we are drawing for the purpose of copying to
+  // a CALayerOverlay. In such cases, the CALayerOverlay applies rounded
+  // corners via CALayer parameters, so the shader-based rounded corners
+  // should be disabled here.
+  params.apply_shader_based_rounded_corner = false;
+  ChooseRPDQProgram(&params, (*overlay_texture)->texture.color_space());
+  UpdateRPDQUniforms(&params);
+
+  // Prior to drawing, set up the destination framebuffer and viewport.
+  gl_->BindFramebuffer(GL_FRAMEBUFFER, temp_fbo);
+  gl_->Viewport(0, 0, updated_dst_rect.width(), updated_dst_rect.height());
+
+  DrawRPDQ(params);
+  if (params.background_texture) {
+    gl_->DeleteTextures(1, &params.background_texture);
+    params.background_texture = 0;
+  }
+  gl_->DeleteFramebuffers(1, &temp_fbo);
+}
+
+std::unique_ptr<GLRenderer::OverlayTexture>
+GLRenderer::FindOrCreateOverlayTexture(
+    const AggregatedRenderPassId& render_pass_id,
+    int width,
+    int height,
+    const gfx::ColorSpace& color_space) {
+  // First try to use a texture for the same CompositorRenderPassId, to keep
+  // things more stable and less likely to clobber each others textures.
+  auto match_with_id = [&](const std::unique_ptr<OverlayTexture>& overlay) {
+    return overlay->render_pass_id == render_pass_id &&
+           overlay->texture.size().width() >= width &&
+           overlay->texture.size().height() >= height &&
+           overlay->texture.size().width() <= width * 2 &&
+           overlay->texture.size().height() <= height * 2;
+  };
+  auto it = std::find_if(available_overlay_textures_.begin(),
+                         available_overlay_textures_.end(), match_with_id);
+  if (it != available_overlay_textures_.end()) {
+    std::unique_ptr<OverlayTexture> result = std::move(*it);
+    available_overlay_textures_.erase(it);
+
+    result->render_pass_id = render_pass_id;
+    return result;
+  }
+
+  // Then fallback to trying other textures that still match.
+  auto match = [&](const std::unique_ptr<OverlayTexture>& overlay) {
+    return overlay->texture.size().width() >= width &&
+           overlay->texture.size().height() >= height &&
+           overlay->texture.size().width() <= width * 2 &&
+           overlay->texture.size().height() <= height * 2;
+  };
+  it = std::find_if(available_overlay_textures_.begin(),
+                    available_overlay_textures_.end(), match);
+  if (it != available_overlay_textures_.end()) {
+    std::unique_ptr<OverlayTexture> result = std::move(*it);
+    available_overlay_textures_.erase(it);
+
+    result->render_pass_id = render_pass_id;
+    return result;
+  }
+
+  // Make a new texture if we could not find a match. Sadtimes.
+  auto result = std::make_unique<OverlayTexture>();
+  result->texture = ScopedGpuMemoryBufferTexture(
+      output_surface_->context_provider(),
+      gfx::Size(width, height), color_space);
+  result->render_pass_id = render_pass_id;
+  return result;
+}
+
+void GLRenderer::ReduceAvailableOverlayTextures() {
+  // Overlay resources may get returned back to the compositor at varying rates,
+  // so we may get a number of resources returned at once, then none for a
+  // while. As such, we want to hold onto enough resources to not have to create
+  // any when none are released for a while. Emperical study by erikchen@ on
+  // crbug.com/636884 found that saving 5 spare textures per RenderPass was
+  // sufficient for important benchmarks. This seems to imply that the OS may
+  // hold up to 5 frames of textures before releasing them.
+  static const int kKeepCountPerRenderPass = 5;
+
+  // In order to accomodate the above requirements, we hold any released texture
+  // in the |available_overlay_textures_| set for up to 5 frames before
+  // discarding it.
+  for (const auto& overlay : available_overlay_textures_)
+    overlay->frames_waiting_for_reuse++;
+  base::EraseIf(available_overlay_textures_,
+                [](const std::unique_ptr<OverlayTexture>& overlay) {
+                  return overlay->frames_waiting_for_reuse >=
+                         kKeepCountPerRenderPass;
+                });
+}
+
+std::unique_ptr<GLRenderer::OverlayTexture>
+GLRenderer::ScheduleRenderPassDrawQuad(const CALayerOverlay* ca_layer_overlay) {
+  DCHECK(ca_layer_overlay->rpdq);
+
+  std::unique_ptr<OverlayTexture> overlay_texture;
+  gfx::RectF new_bounds;
+  CopyRenderPassDrawQuadToOverlayResource(ca_layer_overlay, &overlay_texture,
+                                          &new_bounds);
+  if (!overlay_texture)
+    return {};
+
+  GLfloat contents_rect[4] = {
+      ca_layer_overlay->contents_rect.x(), ca_layer_overlay->contents_rect.y(),
+      ca_layer_overlay->contents_rect.width(),
+      ca_layer_overlay->contents_rect.height(),
+  };
+  GLfloat bounds_rect[4] = {
+      new_bounds.x(), new_bounds.y(), new_bounds.width(), new_bounds.height(),
+  };
+  GLboolean is_clipped = ca_layer_overlay->shared_state->is_clipped;
+  GLfloat clip_rect[4] = {ca_layer_overlay->shared_state->clip_rect.x(),
+                          ca_layer_overlay->shared_state->clip_rect.y(),
+                          ca_layer_overlay->shared_state->clip_rect.width(),
+                          ca_layer_overlay->shared_state->clip_rect.height()};
+
+  const gfx::RectF& rect =
+      ca_layer_overlay->shared_state->rounded_corner_bounds.rect();
+  GLfloat rounded_corner_rect[5] = {
+      rect.x(), rect.y(), rect.width(), rect.height(),
+      ca_layer_overlay->shared_state->rounded_corner_bounds.GetSimpleRadius()};
+
+  GLint sorting_context_id = ca_layer_overlay->shared_state->sorting_context_id;
+  GLfloat gl_transform[16];
+  ca_layer_overlay->shared_state->transform.matrix().getColMajor(gl_transform);
+  unsigned filter = ca_layer_overlay->filter;
+
+  // The alpha has already been applied when copying the RPDQ to an IOSurface.
+  GLfloat alpha = 1;
+  gl_->ScheduleCALayerSharedStateCHROMIUM(alpha, is_clipped, clip_rect,
+                                          rounded_corner_rect,
+                                          sorting_context_id, gl_transform);
+  gl_->ScheduleCALayerCHROMIUM(overlay_texture->texture.id(), contents_rect,
+                               ca_layer_overlay->background_color,
+                               ca_layer_overlay->edge_aa_mask, bounds_rect,
+                               filter);
+  return overlay_texture;
+}
+#endif  // BUILDFLAG(IS_APPLE)
+
+void GLRenderer::SetupOverdrawFeedback() {
+  gl_->StencilFunc(GL_ALWAYS, 1, 0xffffffff);
+  // First two values are ignored as test always passes.
+  gl_->StencilOp(GL_KEEP, GL_KEEP, GL_INCR);
+  gl_->StencilMask(0xffffffff);
+}
+
+void GLRenderer::FlushOverdrawFeedback(const gfx::Rect& output_rect) {
+  DCHECK(stencil_shadow_);
+
+  // Test only, keep everything.
+  gl_->StencilOp(GL_KEEP, GL_KEEP, GL_KEEP);
+
+  EnsureScissorTestDisabled();
+  SetBlendEnabled(true);
+
+  PrepareGeometry(SHARED_BINDING);
+
+  SetUseProgram(ProgramKey::DebugBorder(), gfx::ColorSpace::CreateSRGB(),
+                CurrentRenderPassColorSpace());
+
+  gfx::Transform render_matrix;
+  render_matrix.Translate(0.5 * output_rect.width() + output_rect.x(),
+                          0.5 * output_rect.height() + output_rect.y());
+  render_matrix.Scale(output_rect.width(), output_rect.height());
+  SetShaderMatrix(current_frame()->projection_matrix * render_matrix);
+
+  // Produce hinting for the amount of overdraw on screen for each pixel by
+  // drawing hint colors to the framebuffer based on the current stencil value.
+  struct {
+    int multiplier;
+    GLenum func;
+    GLint ref;
+    SkColor color;
+  } stencil_tests[] = {
+      {1, GL_EQUAL, 2, 0x2f0000ff},  // Blue: Overdrawn once.
+      {2, GL_EQUAL, 3, 0x2f00ff00},  // Green: Overdrawn twice.
+      {3, GL_EQUAL, 4, 0x3fff0000},  // Pink: Overdrawn three times.
+      {4, GL_LESS, 4, 0x7fff0000},   // Red: Overdrawn four or more times.
+  };
+
+  for (const auto& test : stencil_tests) {
+    gl_->StencilFunc(test.func, test.ref, 0xffffffff);
+    // Transparent color unless color-coding of overdraw is enabled.
+    SetShaderColor(debug_settings_->show_overdraw_feedback ? test.color : 0,
+                   1.f);
+    gl_->DrawElements(GL_TRIANGLES, 6, GL_UNSIGNED_SHORT, nullptr);
+  }
+}
+
+void GLRenderer::ProcessOverdrawFeedback(base::CheckedNumeric<int> surface_area,
+                                         unsigned occlusion_query) {
+  unsigned result = 0;
+  DCHECK(occlusion_query);
+  gl_->GetQueryObjectuivEXT(occlusion_query, GL_QUERY_RESULT_EXT, &result);
+  gl_->DeleteQueriesEXT(1, &occlusion_query);
+
+  // Report GPU overdraw as a percentage of |surface_area|.
+  TRACE_COUNTER1(TRACE_DISABLED_BY_DEFAULT("viz.overdraw"), "GPU Overdraw",
+                 (result * 100.0 /
+                  static_cast<int>(surface_area.ValueOrDefault(INT_MAX))));
+}
+
+void GLRenderer::UpdateRenderPassTextures(
+    const AggregatedRenderPassList& render_passes_in_draw_order,
+    const base::flat_map<AggregatedRenderPassId, RenderPassRequirements>&
+        render_passes_in_frame) {
+  // Collect RenderPass textures that should be deleted.
+  std::vector<AggregatedRenderPassId> passes_to_delete;
+  for (const auto& pair : render_pass_textures_) {
+    auto render_pass_it = render_passes_in_frame.find(pair.first);
+    if (render_pass_it == render_passes_in_frame.end()) {
+      passes_to_delete.push_back(pair.first);
+      continue;
+    }
+    const RenderPassRequirements& requirements = render_pass_it->second;
+    const ScopedRenderPassTexture& texture = pair.second;
+    bool size_appropriate =
+        texture.size().width() >= requirements.size.width() &&
+        texture.size().height() >= requirements.size.height();
+    bool mipmap_appropriate = !requirements.generate_mipmap || texture.mipmap();
+    if (!size_appropriate || !mipmap_appropriate)
+      passes_to_delete.push_back(pair.first);
+  }
+  // Delete RenderPass textures from the previous frame that will not be used
+  // again.
+  for (auto& pass_to_delete : passes_to_delete) {
+    auto rp_backdrop_texture_it =
+        render_pass_backdrop_textures_.find(pass_to_delete);
+    if (rp_backdrop_texture_it != render_pass_backdrop_textures_.end())
+      render_pass_backdrop_textures_.erase(pass_to_delete);
+    render_pass_textures_.erase(pass_to_delete);
+  }
+}
+
+ResourceFormat GLRenderer::CurrentRenderPassResourceFormat() const {
+  const auto& caps = output_surface_->context_provider()->ContextCapabilities();
+  if (CurrentRenderPassColorSpace().IsHDR()) {
+    // If a platform does not support half-float renderbuffers then it should
+    // not should request HDR rendering.
+    DCHECK(caps.texture_half_float_linear);
+    DCHECK(caps.color_buffer_half_float_rgba);
+    return RGBA_F16;
+  }
+  return PlatformColor::BestSupportedTextureFormat(caps);
+}
+
+bool GLRenderer::HasOutputColorMatrix() const {
+  const bool is_root_render_pass =
+      current_frame()->current_render_pass == current_frame()->root_render_pass;
+  const SkM44& output_color_matrix = output_surface_->color_matrix();
+  return is_root_render_pass && output_color_matrix != SkM44();
+}
+
+bool GLRenderer::CanUseFastSolidColorDraw(
+    const SolidColorDrawQuad* quad) const {
+  const SharedQuadState* sqs = quad->shared_quad_state;
+
+  if (!use_fast_path_solid_color_quad_)
+    return false;
+
+  // Mask filters require blending with the background, which is not possible
+  // with the glClear draw method.
+  if (!sqs->mask_filter_info.IsEmpty())
+    return false;
+
+  // 3D transforms need vertex computation in 3D and cannot be handled using
+  // glClear().
+  if (!sqs->quad_to_target_transform.IsFlat())
+    return false;
+
+  // glClear ignores stencil buffer.
+  if (stencil_shadow_)
+    return false;
+
+  // Any non axis aligned transform cannot be handled by glClear.
+  if (!sqs->quad_to_target_transform.Preserves2dAxisAlignment())
+    return false;
+
+  // When no blending is needed, glClear can be used.
+  SkBlendMode blend_mode = quad->shared_quad_state->blend_mode;
+  if (blend_mode == SkBlendMode::kSrc)
+    return true;
+
+  if (blend_mode == SkBlendMode::kSrcOver) {
+    // Blending will replace destination color and alpha if the quad is opaque.
+    if (SkColorGetA(quad->color) == 255 &&
+        quad->shared_quad_state->opacity >= 1.0f) {
+      return true;
+    }
+
+    // It is safe to use glClearColor with alpha blending when the render
+    // pass has transparent background and nothing has drawn to the same rect
+    // area because the blending happens against (0, 0, 0, 0) which is the same
+    // as replacing the destination color & alpha.
+    if (!current_frame()->current_render_pass->has_transparent_background)
+      return false;
+
+    gfx::RectF quad_rect_in_target(quad->visible_rect);
+    sqs->quad_to_target_transform.TransformRect(&quad_rect_in_target);
+    const gfx::Rect quad_rect_in_target_rounded =
+        gfx::ToRoundedRect(quad_rect_in_target);
+
+    // If the quad does not intersect any region that has already been drawn
+    // to, then blending is not an issue and fast draw path can be used.
+    for (const auto& rect : drawn_rects_)
+      if (quad_rect_in_target_rounded.Intersects(rect))
+        return false;
+    return true;
+  }
+
+  return false;
+}
+
+void GLRenderer::AllocateRenderPassResourceIfNeeded(
+    const AggregatedRenderPassId& render_pass_id,
+    const RenderPassRequirements& requirements) {
+  auto contents_texture_it = render_pass_textures_.find(render_pass_id);
+  if (contents_texture_it != render_pass_textures_.end()) {
+    DCHECK(gfx::Rect(contents_texture_it->second.size())
+               .Contains(gfx::Rect(requirements.size)));
+    return;
+  }
+
+  ScopedRenderPassTexture contents_texture(
+      output_surface_->context_provider(), requirements.size,
+      CurrentRenderPassResourceFormat(), CurrentRenderPassColorSpace(),
+      requirements.generate_mipmap);
+  render_pass_textures_[render_pass_id] = std::move(contents_texture);
+}
+
+bool GLRenderer::IsRenderPassResourceAllocated(
+    const AggregatedRenderPassId& render_pass_id) const {
+  auto texture_it = render_pass_textures_.find(render_pass_id);
+  return texture_it != render_pass_textures_.end();
+}
+
+gfx::Size GLRenderer::GetRenderPassBackingPixelSize(
+    const AggregatedRenderPassId& render_pass_id) {
+  auto texture_it = render_pass_textures_.find(render_pass_id);
+  DCHECK(texture_it != render_pass_textures_.end());
+  return texture_it->second.size();
+}
+
+GLRenderer::OverlayTexture::OverlayTexture() = default;
+GLRenderer::OverlayTexture::~OverlayTexture() = default;
+
+bool GLRenderer::ColorTransformKey::operator==(
+    const ColorTransformKey& other) const {
+  return src == other.src && dst == other.dst &&
+         sdr_max_luminance_nits == other.sdr_max_luminance_nits;
+}
+
+bool GLRenderer::ColorTransformKey::operator!=(
+    const ColorTransformKey& other) const {
+  return !(*this == other);
+}
+
+bool GLRenderer::ColorTransformKey::operator<(
+    const ColorTransformKey& other) const {
+  return std::tie(src, dst, sdr_max_luminance_nits) <
+         std::tie(other.src, other.dst, other.sdr_max_luminance_nits);
+}
+
+}  // namespace viz
diff --git components/viz/service/display/gl_renderer.h components/viz/service/display/gl_renderer.h
new file mode 100644
index 0000000000000..f3106e13715dc
--- /dev/null
+++ components/viz/service/display/gl_renderer.h
@@ -0,0 +1,525 @@
+// Copyright 2010 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef COMPONENTS_VIZ_SERVICE_DISPLAY_GL_RENDERER_H_
+#define COMPONENTS_VIZ_SERVICE_DISPLAY_GL_RENDERER_H_
+
+#include <map>
+#include <memory>
+#include <string>
+#include <unordered_map>
+#include <utility>
+#include <vector>
+
+#include "base/cancelable_callback.h"
+#include "base/containers/circular_deque.h"
+#include "base/containers/queue.h"
+#include "base/memory/raw_ptr.h"
+#include "build/build_config.h"
+#include "components/viz/common/gpu/context_cache_controller.h"
+#include "components/viz/common/quads/aggregated_render_pass_draw_quad.h"
+#include "components/viz/common/quads/compositor_render_pass_draw_quad.h"
+#include "components/viz/common/quads/debug_border_draw_quad.h"
+#include "components/viz/common/quads/solid_color_draw_quad.h"
+#include "components/viz/common/quads/tile_draw_quad.h"
+#include "components/viz/common/quads/yuv_video_draw_quad.h"
+#include "components/viz/service/display/direct_renderer.h"
+#include "components/viz/service/display/display_resource_provider_gl.h"
+#include "components/viz/service/display/gl_renderer_copier.h"
+#include "components/viz/service/display/gl_renderer_draw_cache.h"
+#include "components/viz/service/display/program_binding.h"
+#include "components/viz/service/display/scoped_gpu_memory_buffer_texture.h"
+#include "components/viz/service/display/sync_query_collection.h"
+#include "components/viz/service/display/texture_deleter.h"
+#include "components/viz/service/viz_service_export.h"
+#include "ui/gfx/geometry/quad_f.h"
+#include "ui/gfx/gpu_fence_handle.h"
+#include "ui/latency/latency_info.h"
+
+#if BUILDFLAG(IS_APPLE)
+#include "components/viz/service/display/ca_layer_overlay.h"
+#endif
+
+#if BUILDFLAG(IS_WIN)
+#include "components/viz/service/display/dc_layer_overlay.h"
+#endif
+
+namespace base {
+class SingleThreadTaskRunner;
+}
+
+namespace gpu {
+namespace gles2 {
+class GLES2Interface;
+}
+}  // namespace gpu
+
+namespace gfx {
+class RRectF;
+}
+
+namespace viz {
+
+class DynamicGeometryBinding;
+class GLRendererShaderTest;
+class OutputSurface;
+class ScopedRenderPassTexture;
+class StaticGeometryBinding;
+class StreamVideoDrawQuad;
+class TextureDrawQuad;
+
+// Class that handles drawing of composited render layers using GL.
+class VIZ_SERVICE_EXPORT GLRenderer : public DirectRenderer {
+ public:
+  class ScopedUseGrContext;
+
+  GLRenderer(const RendererSettings* settings,
+             const DebugRendererSettings* debug_settings,
+             OutputSurface* output_surface,
+             DisplayResourceProviderGL* resource_provider,
+             OverlayProcessorInterface* overlay_processor,
+             scoped_refptr<base::SingleThreadTaskRunner> current_task_runner);
+
+  GLRenderer(const GLRenderer&) = delete;
+  GLRenderer& operator=(const GLRenderer&) = delete;
+
+  ~GLRenderer() override;
+
+  bool use_swap_with_bounds() const { return use_swap_with_bounds_; }
+
+  void SwapBuffers(SwapFrameData swap_frame_data) override;
+  void SwapBuffersSkipped() override;
+  void SwapBuffersComplete(gfx::GpuFenceHandle release_fence) override;
+  void BuffersPresented() override;
+
+  void DidReceiveTextureInUseResponses(
+      const gpu::TextureInUseResponses& responses) override;
+
+  virtual bool IsContextLost();
+
+ protected:
+  void DidChangeVisibility() override;
+
+  bool stencil_enabled() const { return stencil_shadow_; }
+
+  bool CanPartialSwap() override;
+  void UpdateRenderPassTextures(
+      const AggregatedRenderPassList& render_passes_in_draw_order,
+      const base::flat_map<AggregatedRenderPassId, RenderPassRequirements>&
+          render_passes_in_frame) override;
+  void AllocateRenderPassResourceIfNeeded(
+      const AggregatedRenderPassId& render_pass_id,
+      const RenderPassRequirements& requirements) override;
+  bool IsRenderPassResourceAllocated(
+      const AggregatedRenderPassId& render_pass_id) const override;
+  gfx::Size GetRenderPassBackingPixelSize(
+      const AggregatedRenderPassId& render_pass_id) override;
+  void BindFramebufferToOutputSurface() override;
+  void BindFramebufferToTexture(
+      const AggregatedRenderPassId render_pass_id) override;
+  void SetScissorTestRect(const gfx::Rect& scissor_rect) override;
+  void PrepareSurfaceForPass(SurfaceInitializationMode initialization_mode,
+                             const gfx::Rect& render_pass_scissor) override;
+  void DoDrawQuad(const class DrawQuad*,
+                  const gfx::QuadF* draw_region) override;
+  void BeginDrawingFrame() override;
+  void FlushOverdrawFeedback(const gfx::Rect& output_rect) override;
+  void FinishDrawingFrame() override;
+  bool FlippedFramebuffer() const override;
+  bool FlippedRootFramebuffer() const;
+  void EnsureScissorTestEnabled() override;
+  void EnsureScissorTestDisabled() override;
+  void CopyDrawnRenderPass(const copy_output::RenderPassGeometry& geometry,
+                           std::unique_ptr<CopyOutputRequest> request) override;
+  void FinishDrawingQuadList() override;
+  void GenerateMipmap() override;
+
+  // Returns true if quad requires antialiasing and false otherwise.
+  static bool ShouldAntialiasQuad(const gfx::QuadF& device_layer_quad,
+                                  bool clipped,
+                                  bool force_aa);
+
+  // Inflate the quad and fill edge array for fragment shader.
+  // |local_quad| is set to inflated quad. |edge| array is filled with
+  // inflated quad's edge data.
+  static void SetupQuadForClippingAndAntialiasing(
+      const gfx::Transform& device_transform,
+      const DrawQuad* quad,
+      const gfx::QuadF* device_layer_quad,
+      const gfx::QuadF* clip_region,
+      gfx::QuadF* local_quad,
+      float edge[24]);
+  static void SetupRenderPassQuadForClippingAndAntialiasing(
+      const gfx::Transform& device_transform,
+      const AggregatedRenderPassDrawQuad* quad,
+      const gfx::QuadF* device_layer_quad,
+      const gfx::QuadF* clip_region,
+      gfx::QuadF* local_quad,
+      float edge[24]);
+
+ private:
+  friend class GLRendererCopierPixelTest;
+  friend class GLRendererShaderPixelTest;
+  friend class GLRendererShaderTest;
+  friend class GLRendererTest;
+
+  using OverlayResourceLock =
+      std::unique_ptr<DisplayResourceProviderGL::ScopedOverlayLockGL>;
+  using OverlayResourceLockList = std::vector<OverlayResourceLock>;
+
+  // If a RenderPass is used as an overlay, we render the RenderPass with any
+  // effects into a texture for overlay use. We must keep the texture alive past
+  // the execution of SwapBuffers, and such textures are more expensive to make
+  // so we want to reuse them.
+  struct OverlayTexture {
+    OverlayTexture();
+    ~OverlayTexture();
+
+    AggregatedRenderPassId render_pass_id;
+    ScopedGpuMemoryBufferTexture texture;
+    int frames_waiting_for_reuse = 0;
+  };
+
+  struct DrawRenderPassDrawQuadParams;
+
+  // Returns the format to use for storage if copying from the current
+  // framebuffer. If the root renderpass is current, it uses the best matching
+  // format from the OutputSurface, otherwise it uses the best matching format
+  // from the texture being drawn to as the backbuffer.
+  GLenum GetFramebufferCopyTextureFormat();
+  void ReleaseRenderPassTextures();
+  enum BoundGeometry { NO_BINDING, SHARED_BINDING, CLIPPED_BINDING };
+  void PrepareGeometry(BoundGeometry geometry_to_bind);
+  void SetStencilEnabled(bool enabled);
+  void SetBlendEnabled(bool enabled);
+  bool blend_enabled() const { return blend_shadow_; }
+
+  // If any of the following functions returns false, then it means that drawing
+  // is not possible.
+  bool InitializeRPDQParameters(DrawRenderPassDrawQuadParams* params);
+  void UpdateRPDQShadersForBlending(DrawRenderPassDrawQuadParams* params);
+  bool UpdateRPDQWithSkiaFilters(DrawRenderPassDrawQuadParams* params);
+  void UpdateRPDQTexturesForSampling(DrawRenderPassDrawQuadParams* params);
+  void UpdateRPDQBlendMode(DrawRenderPassDrawQuadParams* params);
+  void ChooseRPDQProgram(DrawRenderPassDrawQuadParams* params,
+                         const gfx::ColorSpace& target_color_space);
+  void UpdateRPDQUniforms(DrawRenderPassDrawQuadParams* params);
+  void DrawRPDQ(const DrawRenderPassDrawQuadParams& params);
+
+  static void ToGLMatrix(float* gl_matrix, const gfx::Transform& transform);
+
+  void DiscardPixels();
+  void ClearFramebuffer();
+  void SetViewport();
+
+  void DrawDebugBorderQuad(const DebugBorderDrawQuad* quad);
+  static bool IsDefaultBlendMode(SkBlendMode blend_mode) {
+    return blend_mode == SkBlendMode::kSrcOver;
+  }
+  bool CanApplyBlendModeUsingBlendFunc(SkBlendMode blend_mode);
+  void ApplyBlendModeUsingBlendFunc(SkBlendMode blend_mode);
+  void RestoreBlendFuncToDefault(SkBlendMode blend_mode);
+
+  // Returns the rect that should be sampled from the backdrop texture to be
+  // backdrop filtered. This rect lives in window pixel space. The
+  // |backdrop_filter_bounds| output lives in the space of the output rect
+  // returned by this function. It will be used to clip the sampled backdrop
+  // texture. The |unclipped_rect| output is the unclipped (full) rect that the
+  // backdrop_filter should be applied to, in window pixel space.
+  gfx::Rect GetBackdropBoundingBoxForRenderPassQuad(
+      DrawRenderPassDrawQuadParams* params,
+      gfx::Transform* backdrop_filter_bounds_transform,
+      absl::optional<gfx::RRectF>* backdrop_filter_bounds,
+      gfx::Rect* unclipped_rect) const;
+
+  // Allocates and returns a texture id that contains a copy of the contents
+  // of the current RenderPass being drawn.
+  uint32_t GetBackdropTexture(const gfx::Rect& window_rect,
+                              float scale,
+                              GLenum* internal_format);
+
+  static bool ShouldApplyBackdropFilters(
+      const DrawRenderPassDrawQuadParams* params);
+
+  // Applies the backdrop filters to the backdrop that has been painted to this
+  // point, and returns it as an SkImage. Any opacity and/or "regular"
+  // (non-backdrop) filters will also be applied directly to the backdrop-
+  // filtered image at this point, so that the final result is as if the
+  // filtered backdrop image was painted as the starting point for this new
+  // stacking context, which would then be painted into its parent with opacity
+  // and filters applied. This is an approximation, but it should be close
+  // enough.
+  sk_sp<SkImage> ApplyBackdropFilters(
+      DrawRenderPassDrawQuadParams* params,
+      const gfx::Rect& unclipped_rect,
+      const absl::optional<gfx::RRectF>& backdrop_filter_bounds,
+      const gfx::Transform& backdrop_filter_bounds_transform);
+
+  // gl_renderer can bypass TileDrawQuads that fill the RenderPass
+  const DrawQuad* CanPassBeDrawnDirectly(
+      const AggregatedRenderPass* pass) override;
+
+  void DrawRenderPassQuad(const AggregatedRenderPassDrawQuad* quadi,
+                          const gfx::QuadF* clip_region);
+  void DrawRenderPassQuadInternal(DrawRenderPassDrawQuadParams* params);
+  void DrawSolidColorQuad(const SolidColorDrawQuad* quad,
+                          const gfx::QuadF* clip_region);
+  void DrawStreamVideoQuad(const StreamVideoDrawQuad* quad,
+                           const gfx::QuadF* clip_region);
+  void EnqueueTextureQuad(const TextureDrawQuad* quad,
+                          const gfx::QuadF* clip_region);
+  void FlushTextureQuadCache(BoundGeometry flush_binding);
+  void DrawTileQuad(const TileDrawQuad* quad, const gfx::QuadF* clip_region);
+  void DrawContentQuad(const ContentDrawQuadBase* quad,
+                       ResourceId resource_id,
+                       const gfx::QuadF* clip_region);
+  void DrawContentQuadAA(const ContentDrawQuadBase* quad,
+                         ResourceId resource_id,
+                         const gfx::Transform& device_transform,
+                         const gfx::QuadF& aa_quad,
+                         const gfx::QuadF* clip_region);
+  void DrawContentQuadNoAA(const ContentDrawQuadBase* quad,
+                           ResourceId resource_id,
+                           const gfx::QuadF* clip_region);
+  void DrawYUVVideoQuad(const YUVVideoDrawQuad* quad,
+                        const gfx::QuadF* clip_region);
+
+  void SetShaderOpacity(float opacity);
+  void SetShaderQuadF(const gfx::QuadF& quad);
+  void SetShaderMatrix(const gfx::Transform& transform);
+  void SetShaderColor(SkColor color, float opacity);
+  void SetShaderRoundedCorner(const gfx::RRectF& rounded_corner_bounds,
+                              const gfx::Transform& screen_transform);
+  void DrawQuadGeometryClippedByQuadF(const gfx::Transform& draw_transform,
+                                      const gfx::RectF& quad_rect,
+                                      const gfx::QuadF& clipping_region_quad,
+                                      const float uv[8]);
+  void DrawQuadGeometry(const gfx::Transform& projection_matrix,
+                        const gfx::Transform& draw_transform,
+                        const gfx::RectF& quad_rect);
+  void DrawQuadGeometryWithAA(const DrawQuad* quad,
+                              gfx::QuadF* local_quad,
+                              const gfx::Rect& tile_rect);
+
+  const gfx::QuadF& SharedGeometryQuad() const { return shared_geometry_quad_; }
+  const StaticGeometryBinding* SharedGeometry() const {
+    return shared_geometry_.get();
+  }
+
+  // If |dst_color_space| is invalid, then no color conversion (apart from YUV
+  // to RGB conversion) is performed. This explicit argument is available so
+  // that video color conversion can be enabled separately from general color
+  // conversion. If |adjust_src_white_level| is true, then the |src_color_space|
+  // white levels are adjusted to the display SDR white level so that no white
+  // level scaling happens. |src_hdr_metadata|, if available, is the mastering
+  // metadata associated to the source quad.
+  void SetUseProgram(
+      const ProgramKey& program_key,
+      const gfx::ColorSpace& src_color_space,
+      const gfx::ColorSpace& dst_color_space,
+      bool adjust_src_white_level = false,
+      absl::optional<gfx::HDRMetadata> src_hdr_metadata = absl::nullopt);
+
+  bool MakeContextCurrent();
+
+  void InitializeSharedObjects();
+  void CleanupSharedObjects();
+
+  void ReinitializeGLState();
+  void RestoreGLState();
+  void RestoreGLStateAfterSkia();
+
+  // TODO(weiliangc): Once the overlay processor could schedule overlays, remove
+  // these functions.
+  // Sends over output surface information as it is a overlay plane. This is
+  // used for BufferQueue. For non-BufferQueue cases, this function will do
+  // nothing.
+  void ScheduleOutputSurfaceAsOverlay();
+  // Schedule overlays sends overlay candidate to the GPU.
+#if BUILDFLAG(IS_ANDROID) || defined(USE_OZONE)
+  void ScheduleOverlays();
+#elif BUILDFLAG(IS_APPLE)
+  void ScheduleCALayers();
+
+  // Schedules the |ca_layer_overlay|, which is guaranteed to have a non-null
+  // |rpdq| parameter. Returns ownership of a GL texture that contains the
+  // output of the CompositorRenderPassDrawQuad.
+  std::unique_ptr<OverlayTexture> ScheduleRenderPassDrawQuad(
+      const CALayerOverlay* ca_layer_overlay);
+
+  // Copies the contents of the render pass draw quad, including filter effects,
+  // to a GL texture, returned in |overlay_texture|. The resulting texture may
+  // be larger than the CompositorRenderPassDrawQuad's output, in order to reuse
+  // existing textures. The new size and position is placed in |new_bounds|.
+  void CopyRenderPassDrawQuadToOverlayResource(
+      const CALayerOverlay* ca_layer_overlay,
+      std::unique_ptr<OverlayTexture>* overlay_texture,
+      gfx::RectF* new_bounds);
+  std::unique_ptr<OverlayTexture> FindOrCreateOverlayTexture(
+      const AggregatedRenderPassId& render_pass_id,
+      int width,
+      int height,
+      const gfx::ColorSpace& color_space);
+  void ReduceAvailableOverlayTextures();
+
+#elif BUILDFLAG(IS_WIN)
+  void ScheduleDCLayers();
+#endif
+
+  // Setup/flush all pending overdraw feedback to framebuffer.
+  void SetupOverdrawFeedback();
+
+  // Process overdraw feedback from query.
+  void ProcessOverdrawFeedback(base::CheckedNumeric<int> surface_area,
+                               unsigned query);
+  bool OverdrawTracingEnabled();
+
+  bool CompositeTimeTracingEnabled() override;
+  void AddCompositeTimeTraces(base::TimeTicks ready_timestamp) override;
+
+  ResourceFormat CurrentRenderPassResourceFormat() const;
+
+  bool HasOutputColorMatrix() const;
+
+  // Returns true if the given solid color draw quad can be safely drawn using
+  // the glClear function call.
+  bool CanUseFastSolidColorDraw(const SolidColorDrawQuad* quad) const;
+
+  DisplayResourceProviderGL* resource_provider() {
+    return static_cast<DisplayResourceProviderGL*>(resource_provider_);
+  }
+
+  // A map from RenderPass id to the texture used to draw the RenderPass from.
+  base::flat_map<AggregatedRenderPassId, ScopedRenderPassTexture>
+      render_pass_textures_;
+
+  // A map from RenderPass id to backdrop filter cache texture.
+  base::flat_map<AggregatedRenderPassId, sk_sp<SkImage>>
+      render_pass_backdrop_textures_;
+
+  // OverlayTextures that are free to be used in the next frame.
+  std::vector<std::unique_ptr<OverlayTexture>> available_overlay_textures_;
+  // OverlayTextures that have been set up for use but are waiting for
+  // SwapBuffers.
+  std::vector<std::unique_ptr<OverlayTexture>> awaiting_swap_overlay_textures_;
+  // OverlayTextures that have been swapped for display on the gpu. Each vector
+  // represents a single frame, and may be empty if none were used in that
+  // frame. Ordered from oldest to most recent frame.
+  std::vector<std::vector<std::unique_ptr<OverlayTexture>>>
+      displayed_overlay_textures_;
+  // OverlayTextures that we have replaced on the gpu but are awaiting
+  // confirmation that we can reuse them.
+  std::vector<std::unique_ptr<OverlayTexture>>
+      awaiting_release_overlay_textures_;
+
+  // Resources that have been sent to the GPU process, but not yet swapped.
+  OverlayResourceLockList pending_overlay_resources_;
+  // Resources that should be shortly swapped by the GPU process.
+  base::circular_deque<OverlayResourceLockList> swapping_overlay_resources_;
+
+  // Locks for overlays that have release fences and read lock fences.
+  base::circular_deque<OverlayResourceLockList>
+      read_lock_release_fence_overlay_locks_;
+
+  // Resources that the GPU process has finished swapping. The key is the
+  // texture id of the resource.
+  std::map<unsigned, OverlayResourceLock> swapped_and_acked_overlay_resources_;
+
+  // Query object, used to determine the number of sample drawn during a render
+  // pass.
+  unsigned occlusion_query_ = 0u;
+
+  unsigned offscreen_framebuffer_id_ = 0u;
+
+  std::unique_ptr<StaticGeometryBinding> shared_geometry_;
+  std::unique_ptr<DynamicGeometryBinding> clipped_geometry_;
+  gfx::QuadF shared_geometry_quad_;
+
+  // This will return nullptr if the requested program has not yet been
+  // initialized.
+  const Program* GetProgramIfInitialized(const ProgramKey& key) const;
+
+  std::unordered_map<ProgramKey, std::unique_ptr<Program>, ProgramKeyHash>
+      program_cache_;
+
+  const gfx::ColorTransform* GetColorTransform(const gfx::ColorSpace& src,
+                                               const gfx::ColorSpace& dst);
+  struct ColorTransformKey {
+    gfx::ColorSpace src;
+    gfx::ColorSpace dst;
+    float sdr_max_luminance_nits = 0.f;
+    bool operator==(const ColorTransformKey& other) const;
+    bool operator!=(const ColorTransformKey& other) const;
+    bool operator<(const ColorTransformKey& other) const;
+  };
+  std::map<ColorTransformKey, std::unique_ptr<gfx::ColorTransform>>
+      color_transform_cache_;
+
+  raw_ptr<gpu::gles2::GLES2Interface> gl_;
+  raw_ptr<gpu::ContextSupport> context_support_;
+  std::unique_ptr<ContextCacheController::ScopedVisibility> context_visibility_;
+  std::unique_ptr<ContextCacheController::ScopedBusy> context_busy_;
+
+  TextureDeleter texture_deleter_;
+  GLRendererCopier copier_;
+
+  gfx::Rect swap_buffer_rect_;
+  std::vector<gfx::Rect> swap_content_bounds_;
+  gfx::Rect scissor_rect_;
+  bool is_scissor_enabled_ = false;
+  bool stencil_shadow_ = false;
+  bool blend_shadow_ = false;
+  raw_ptr<const Program> current_program_ = nullptr;
+  TexturedQuadDrawCache draw_cache_;
+  int highp_threshold_cache_ = 0;
+
+  raw_ptr<ScopedRenderPassTexture> current_framebuffer_texture_;
+
+  SyncQueryCollection sync_queries_;
+  bool use_discard_framebuffer_ = false;
+  bool use_sync_query_ = false;
+  bool use_blend_equation_advanced_ = false;
+  bool use_blend_equation_advanced_coherent_ = false;
+  bool use_timer_query_ = false;
+  bool use_occlusion_query_ = false;
+  bool use_swap_with_bounds_ = false;
+  bool use_fast_path_solid_color_quad_ = false;
+  bool supports_multi_sampling_ = false;
+
+  // If true, tints all the composited content to red.
+  bool tint_gl_composited_content_ = true;
+
+#if BUILDFLAG(IS_APPLE)
+  // The method FlippedFramebuffer determines whether the framebuffer associated
+  // with a DrawingFrame is flipped. It makes the assumption that the
+  // DrawingFrame is being used as part of a render pass. If a DrawingFrame is
+  // not being used as part of a render pass, setting it here forces
+  // FlippedFramebuffer to return |true|.
+  bool force_drawing_frame_framebuffer_unflipped_ = false;
+#endif
+
+  BoundGeometry bound_geometry_;
+
+  unsigned offscreen_stencil_renderbuffer_id_ = 0;
+  gfx::Size offscreen_stencil_renderbuffer_size_;
+
+  unsigned num_triangles_drawn_ = 0;
+  bool prefer_draw_to_copy_ = false;
+
+  // A circular queue of to keep track of timer queries and their associated
+  // quad type as string.
+  base::queue<std::pair<unsigned, std::string>> timer_queries_;
+
+  // Keeps track of areas that have been drawn to in the current render pass.
+  std::vector<gfx::Rect> drawn_rects_;
+
+  // This may be null if the compositor is run on a thread without a
+  // MessageLoop.
+  scoped_refptr<base::SingleThreadTaskRunner> current_task_runner_;
+  base::WeakPtrFactory<GLRenderer> weak_ptr_factory_{this};
+};
+
+}  // namespace viz
+
+#endif  // COMPONENTS_VIZ_SERVICE_DISPLAY_GL_RENDERER_H_
diff --git components/viz/service/display/gl_renderer_copier.cc components/viz/service/display/gl_renderer_copier.cc
new file mode 100644
index 0000000000000..bbfe5a7515c83
--- /dev/null
+++ components/viz/service/display/gl_renderer_copier.cc
@@ -0,0 +1,1298 @@
+// Copyright 2017 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "components/viz/service/display/gl_renderer_copier.h"
+
+#include <cstring>
+#include <utility>
+
+#include "base/bind.h"
+#include "base/containers/cxx20_erase.h"
+#include "base/memory/raw_ptr.h"
+#include "base/process/memory.h"
+#include "base/threading/sequenced_task_runner_handle.h"
+#include "components/viz/common/frame_sinks/copy_output_request.h"
+#include "components/viz/common/frame_sinks/copy_output_result.h"
+#include "components/viz/common/frame_sinks/copy_output_util.h"
+#include "components/viz/common/gl_i420_converter.h"
+#include "components/viz/common/gl_nv12_converter.h"
+#include "components/viz/common/gl_scaler.h"
+#include "components/viz/common/gpu/context_provider.h"
+#include "components/viz/service/display/texture_deleter.h"
+#include "gpu/GLES2/gl2extchromium.h"
+#include "gpu/command_buffer/client/context_support.h"
+#include "gpu/command_buffer/client/gles2_interface.h"
+#include "gpu/command_buffer/client/shared_image_interface.h"
+#include "gpu/command_buffer/common/mailbox.h"
+#include "gpu/command_buffer/common/shared_image_usage.h"
+#include "gpu/command_buffer/common/sync_token.h"
+#include "third_party/libyuv/include/libyuv/planar_functions.h"
+#include "third_party/skia/include/core/SkBitmap.h"
+#include "third_party/skia/include/core/SkColorSpace.h"
+#include "third_party/skia/include/core/SkImageInfo.h"
+#include "ui/gfx/geometry/size.h"
+
+// Syntactic sugar to DCHECK that two sizes are equal.
+#define DCHECK_SIZE_EQ(a, b)                                \
+  DCHECK((a) == (b)) << #a " != " #b ": " << (a).ToString() \
+                     << " != " << (b).ToString()
+
+namespace viz {
+
+using ResultFormat = CopyOutputRequest::ResultFormat;
+using ResultDestination = CopyOutputRequest::ResultDestination;
+
+namespace {
+
+constexpr int kRGBABytesPerPixel = 4;
+
+// Returns the source property of the |request|, if it is set. Otherwise,
+// returns an empty token. This is needed because CopyOutputRequest will crash
+// if source() is called when !has_source().
+base::UnguessableToken SourceOf(const CopyOutputRequest& request) {
+  return request.has_source() ? request.source() : base::UnguessableToken();
+}
+
+// Creates a new texture, binds it to the GL_TEXTURE_2D target, and initializes
+// its default parameters.
+GLuint CreateDefaultTexture2D(gpu::gles2::GLES2Interface* gl) {
+  GLuint result = 0;
+  gl->GenTextures(1, &result);
+  gl->BindTexture(GL_TEXTURE_2D, result);
+  gl->TexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);
+  gl->TexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR);
+  gl->TexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);
+  gl->TexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);
+  return result;
+}
+
+// Creates or re-creates a texture, only if needed, to ensure a texture of the
+// given |required| size is defined. |texture| and |size| are I/O parameters,
+// read to determine what to do and updated if any changes are made.
+void EnsureTextureDefinedWithSize(gpu::gles2::GLES2Interface* gl,
+                                  const gfx::Size& required,
+                                  GLuint* texture,
+                                  gfx::Size* size) {
+  if (*texture != 0 && *size == required)
+    return;
+  if (*texture == 0) {
+    *texture = CreateDefaultTexture2D(gl);
+  } else {
+    gl->BindTexture(GL_TEXTURE_2D, *texture);
+  }
+  gl->TexImage2D(GL_TEXTURE_2D, 0, GL_RGBA, required.width(), required.height(),
+                 0, GL_RGBA, GL_UNSIGNED_BYTE, nullptr);
+  *size = required;
+}
+
+// Returns parameters for the scaler to scale/transform the image in the source
+// framebuffer to meet the requirements of the |request|.
+GLScaler::Parameters CreateScalerParameters(
+    const CopyOutputRequest& request,
+    const gfx::ColorSpace& source_color_space,
+    const gfx::ColorSpace& output_color_space,
+    bool flipped_source) {
+  GLScaler::Parameters params;
+
+  params.scale_from = request.scale_from();
+  params.scale_to = request.scale_to();
+  params.source_color_space = source_color_space;
+  params.output_color_space = output_color_space;
+  // For downscaling, use the GOOD quality setting (appropriate for
+  // thumbnailing); and, for upscaling, use the BEST quality.
+  const bool is_downscale_in_both_dimensions =
+      request.scale_to().x() < request.scale_from().x() &&
+      request.scale_to().y() < request.scale_from().y();
+  params.quality = is_downscale_in_both_dimensions
+                       ? GLScaler::Parameters::Quality::GOOD
+                       : GLScaler::Parameters::Quality::BEST;
+  params.is_flipped_source = flipped_source;
+
+  return params;
+}
+
+// Returns the specified offset in the form of a pointer for OpenGL's
+// `glReadPixels` call. This is not a valid memory address and the pointer
+// should never be dereferenced.
+uint8_t* GetOffsetPointer(int offset) {
+  uint8_t* result = reinterpret_cast<uint8_t*>(0);
+  result += offset;
+  return result;
+}
+
+}  // namespace
+
+GLRendererCopier::GLRendererCopier(ContextProvider* context_provider,
+                                   TextureDeleter* texture_deleter)
+    : context_provider_(context_provider), texture_deleter_(texture_deleter) {}
+
+GLRendererCopier::~GLRendererCopier() {
+  for (auto& entry : cache_)
+    entry.second->Free(context_provider_->ContextGL());
+}
+
+void GLRendererCopier::CopyFromTextureOrFramebuffer(
+    std::unique_ptr<CopyOutputRequest> request,
+    const copy_output::RenderPassGeometry& geometry,
+    GLenum internal_format,
+    GLuint framebuffer_texture,
+    const gfx::Size& framebuffer_texture_size,
+    bool flipped_source,
+    const gfx::ColorSpace& framebuffer_color_space) {
+  const gfx::Rect& result_rect = geometry.result_selection;
+
+  // If we can't convert |color_space| to a SkColorSpace for SkBitmap copy
+  // requests (e.g. PIECEWISE_HDR), fallback to a color transform to sRGB
+  // before returning the copy result.
+  gfx::ColorSpace dest_color_space = framebuffer_color_space;
+  if (!framebuffer_color_space.ToSkColorSpace() &&
+      request->result_format() == ResultFormat::RGBA &&
+      request->result_destination() == ResultDestination::kSystemMemory) {
+    dest_color_space = gfx::ColorSpace::CreateSRGB();
+  }
+  // Fast-Path: If no transformation is necessary and no new textures need to be
+  // generated, read-back directly from the currently-bound framebuffer.
+  if (request->result_format() == ResultFormat::RGBA &&
+      request->result_destination() == ResultDestination::kSystemMemory &&
+      framebuffer_color_space == dest_color_space && !request->is_scaled()) {
+    StartReadbackFromFramebuffer(std::move(request), geometry.readback_offset,
+                                 flipped_source, false, result_rect,
+                                 dest_color_space);
+    return;
+  }
+
+  gfx::Rect sampling_rect = geometry.sampling_bounds;
+
+  const base::UnguessableToken requester = SourceOf(*request);
+  std::unique_ptr<ReusableThings> things =
+      TakeReusableThingsOrCreate(requester);
+
+  // Determine the source texture: This is either the one attached to the
+  // framebuffer, or a copy made from the framebuffer. Its format will be the
+  // same as |internal_format|.
+  //
+  // TODO(crbug/767221): All of this (including some texture copies) wouldn't be
+  // necessary if we could query whether the currently-bound framebuffer has a
+  // texture attached to it, and just source from that texture directly (i.e.,
+  // using glGetFramebufferAttachmentParameteriv() and
+  // glGetTexLevelParameteriv(GL_TEXTURE_WIDTH/HEIGHT)).
+  GLuint source_texture;
+  gfx::Size source_texture_size;
+  if (framebuffer_texture != 0) {
+    source_texture = framebuffer_texture;
+    source_texture_size = framebuffer_texture_size;
+  } else {
+    auto* const gl = context_provider_->ContextGL();
+    if (things->fb_copy_texture == 0) {
+      things->fb_copy_texture = CreateDefaultTexture2D(gl);
+      things->fb_copy_texture_internal_format = static_cast<GLenum>(GL_NONE);
+      things->fb_copy_texture_size = gfx::Size();
+    } else {
+      gl->BindTexture(GL_TEXTURE_2D, things->fb_copy_texture);
+    }
+    if (things->fb_copy_texture_internal_format == internal_format &&
+        things->fb_copy_texture_size == sampling_rect.size()) {
+      // Copy the framebuffer pixels without redefining the texture.
+      gl->CopyTexSubImage2D(GL_TEXTURE_2D, 0, 0, 0, sampling_rect.x(),
+                            sampling_rect.y(), sampling_rect.width(),
+                            sampling_rect.height());
+    } else {
+      // Copy the framebuffer pixels into a newly-defined texture.
+      gl->CopyTexImage2D(GL_TEXTURE_2D, 0, internal_format, sampling_rect.x(),
+                         sampling_rect.y(), sampling_rect.width(),
+                         sampling_rect.height(), 0);
+      things->fb_copy_texture_internal_format = internal_format;
+      things->fb_copy_texture_size = sampling_rect.size();
+    }
+    source_texture = things->fb_copy_texture;
+    source_texture_size = sampling_rect.size();
+    sampling_rect.set_origin(gfx::Point());
+  }
+
+  // Revert the Y-flipping of the sampling rect coordinates for GLScaler, which
+  // always assumes the source offset is assuming a origin-at-top-left
+  // coordinate space.
+  if (flipped_source) {
+    sampling_rect.set_y(source_texture_size.height() - sampling_rect.bottom());
+  }
+
+  switch (request->result_format()) {
+    case ResultFormat::RGBA:
+
+      switch (request->result_destination()) {
+        case ResultDestination::kSystemMemory:
+          EnsureTextureDefinedWithSize(
+              context_provider_->ContextGL(), result_rect.size(),
+              &things->result_texture, &things->result_texture_size);
+          RenderResultTexture(*request, flipped_source, framebuffer_color_space,
+                              dest_color_space, source_texture,
+                              source_texture_size, sampling_rect, result_rect,
+                              things->result_texture, things.get());
+          StartReadbackFromTexture(std::move(request), result_rect,
+                                   dest_color_space, things.get());
+          break;
+        case ResultDestination::kNativeTextures:
+          RenderAndSendTextureResult(std::move(request), flipped_source,
+                                     framebuffer_color_space, dest_color_space,
+                                     source_texture, source_texture_size,
+                                     sampling_rect, result_rect, things.get());
+          break;
+      }
+
+      break;
+
+    case ResultFormat::I420_PLANES: {
+      // The optimized single-copy path, provided by GLPixelBufferI420Result,
+      // requires that the result be accessed via a task in the same task runner
+      // sequence as the GLRendererCopier. Since I420_PLANES requests are meant
+      // to be VIZ-internal, this is an acceptable limitation to enforce.
+      if (!request->SendsResultsInCurrentSequence()) {
+        request->set_result_task_runner(base::SequencedTaskRunnerHandle::Get());
+      }
+
+      const gfx::Rect aligned_rect = RenderI420Textures(
+          *request, flipped_source, framebuffer_color_space, source_texture,
+          source_texture_size, sampling_rect, result_rect, things.get());
+      StartI420ReadbackFromTextures(std::move(request), aligned_rect,
+                                    result_rect, things.get());
+      break;
+    }
+
+    case ResultFormat::NV12_PLANES: {
+      // The optimized single-copy path, provided by GLPixelBufferNV12Result,
+      // requires that the result be accessed via a task in the same task runner
+      // sequence as the GLRendererCopier. Since NV12_PLANES requests are meant
+      // to be VIZ-internal, this is an acceptable limitation to enforce.
+      if (!request->SendsResultsInCurrentSequence()) {
+        request->set_result_task_runner(base::SequencedTaskRunnerHandle::Get());
+      }
+
+      const gfx::Rect aligned_rect = RenderNV12Textures(
+          *request, flipped_source, framebuffer_color_space, source_texture,
+          source_texture_size, sampling_rect, result_rect, things.get());
+      StartNV12ReadbackFromTextures(std::move(request), aligned_rect,
+                                    result_rect, things.get());
+
+      break;
+    }
+  }
+
+  StashReusableThingsOrDelete(requester, std::move(things));
+}
+
+void GLRendererCopier::FreeUnusedCachedResources() {
+  ++purge_counter_;
+
+  // Purge all cache entries that should no longer be kept alive, freeing any
+  // resources they held.
+  const auto IsTooOld = [this](const decltype(cache_)::value_type& entry) {
+    return static_cast<int32_t>(purge_counter_ -
+                                entry.second->purge_count_at_last_use) >=
+           kKeepalivePeriod;
+  };
+  for (auto& entry : cache_) {
+    if (IsTooOld(entry))
+      entry.second->Free(context_provider_->ContextGL());
+  }
+  base::EraseIf(cache_, IsTooOld);
+}
+
+void GLRendererCopier::RenderResultTexture(
+    const CopyOutputRequest& request,
+    bool flipped_source,
+    const gfx::ColorSpace& source_color_space,
+    const gfx::ColorSpace& dest_color_space,
+    GLuint source_texture,
+    const gfx::Size& source_texture_size,
+    const gfx::Rect& sampling_rect,
+    const gfx::Rect& result_rect,
+    GLuint result_texture,
+    ReusableThings* things) {
+  DCHECK_EQ(request.result_format(), ResultFormat::RGBA);
+
+  GLScaler::Parameters params = CreateScalerParameters(
+      request, source_color_space, dest_color_space, flipped_source);
+
+  if (request.result_destination() == ResultDestination::kSystemMemory) {
+    // Render the result in top-down row order, and swizzle, within the GPU so
+    // these things don't have to be done, less efficiently, on the CPU later.
+    params.flip_output = flipped_source;
+    params.swizzle[0] =
+        ShouldSwapRedAndBlueForBitmapReadback() ? GL_BGRA_EXT : GL_RGBA;
+  } else {
+    // Texture results are always in bottom-up row order.
+    DCHECK_EQ(request.result_destination(), ResultDestination::kNativeTextures);
+    params.flip_output = !flipped_source;
+    DCHECK_EQ(params.swizzle[0], static_cast<GLenum>(GL_RGBA));
+  }
+
+  if (!things->scaler)
+    things->scaler = std::make_unique<GLScaler>(context_provider_);
+  if (!GLScaler::ParametersAreEquivalent(params, things->scaler->params())) {
+    const bool is_configured = things->scaler->Configure(params);
+    // GLRendererCopier should never use illegal or unsupported options, nor
+    // be using GLScaler with an invalid GL context.
+    DCHECK(is_configured);
+  }
+
+  const bool success = things->scaler->Scale(
+      source_texture, source_texture_size, sampling_rect.OffsetFromOrigin(),
+      result_texture, result_rect);
+  DCHECK(success);
+}
+
+gfx::Rect GLRendererCopier::RenderI420Textures(
+    const CopyOutputRequest& request,
+    bool flipped_source,
+    const gfx::ColorSpace& source_color_space,
+    GLuint source_texture,
+    const gfx::Size& source_texture_size,
+    const gfx::Rect& sampling_rect,
+    const gfx::Rect& result_rect,
+    ReusableThings* things) {
+  DCHECK_EQ(request.result_format(), ResultFormat::I420_PLANES);
+
+  auto* const gl = context_provider_->ContextGL();
+
+  // Compute required Y/U/V texture sizes and re-define them, if necessary. See
+  // class comments for GLI420Converter for an explanation of how planar data is
+  // packed into RGBA textures.
+  const gfx::Rect aligned_rect = GLI420Converter::ToAlignedRect(result_rect);
+  const gfx::Size required_luma_size(aligned_rect.width() / kRGBABytesPerPixel,
+                                     aligned_rect.height());
+  const gfx::Size required_chroma_size(required_luma_size.width() / 2,
+                                       required_luma_size.height() / 2);
+
+  EnsureTextureDefinedWithSize(gl, required_luma_size, &things->yuv_textures[0],
+                               &things->texture_sizes[0]);
+  EnsureTextureDefinedWithSize(gl, required_chroma_size,
+                               &things->yuv_textures[1],
+                               &things->texture_sizes[1]);
+  EnsureTextureDefinedWithSize(gl, required_chroma_size,
+                               &things->yuv_textures[2],
+                               &things->texture_sizes[2]);
+
+  GLI420Converter::Parameters params =
+      CreateScalerParameters(request, source_color_space,
+                             gfx::ColorSpace::CreateREC709(), flipped_source);
+  // I420 readback assumes content is in top-down row order. Also, set the
+  // output swizzle to match the readback format so that image bitmaps don't
+  // have to be byte-order-swizzled on the CPU later.
+  params.flip_output = flipped_source;
+  params.swizzle[0] = GetOptimalReadbackFormat();
+
+  if (!things->i420_converter) {
+    things->i420_converter =
+        std::make_unique<GLI420Converter>(context_provider_);
+  }
+  if (!GLI420Converter::ParametersAreEquivalent(
+          params, things->i420_converter->params())) {
+    const bool is_configured = things->i420_converter->Configure(params);
+    // GLRendererCopier should never use illegal or unsupported options, nor
+    // be using GLI420Converter with an invalid GL context.
+    DCHECK(is_configured);
+  }
+
+  const bool success = things->i420_converter->Convert(
+      source_texture, source_texture_size, sampling_rect.OffsetFromOrigin(),
+      aligned_rect, things->yuv_textures.data());
+  DCHECK(success);
+
+  return aligned_rect;
+}
+
+gfx::Rect GLRendererCopier::RenderNV12Textures(
+    const CopyOutputRequest& request,
+    bool flipped_source,
+    const gfx::ColorSpace& source_color_space,
+    GLuint source_texture,
+    const gfx::Size& source_texture_size,
+    const gfx::Rect& sampling_rect,
+    const gfx::Rect& result_rect,
+    ReusableThings* things) {
+  DCHECK_EQ(request.result_format(), ResultFormat::NV12_PLANES);
+
+  auto* const gl = context_provider_->ContextGL();
+
+  // Compute required Y/UV texture sizes and re-define them, if necessary. See
+  // class comments for GLNV12Converter for an explanation of how planar data is
+  // packed into RGBA textures.
+  const gfx::Rect aligned_rect = GLNV12Converter::ToAlignedRect(result_rect);
+
+  const gfx::Size required_luma_size(aligned_rect.width() / kRGBABytesPerPixel,
+                                     aligned_rect.height());
+  const gfx::Size required_chroma_size(required_luma_size.width(),
+                                       required_luma_size.height() / 2);
+
+  EnsureTextureDefinedWithSize(gl, required_luma_size, &things->yuv_textures[0],
+                               &things->texture_sizes[0]);
+
+  EnsureTextureDefinedWithSize(gl, required_chroma_size,
+                               &things->yuv_textures[1],
+                               &things->texture_sizes[1]);
+
+  GLNV12Converter::Parameters params =
+      CreateScalerParameters(request, source_color_space,
+                             gfx::ColorSpace::CreateREC709(), flipped_source);
+
+  // NV12 readback assumes content is in top-down row order. Also, set the
+  // output swizzle to match the readback format so that image bitmaps don't
+  // have to be byte-order-swizzled on the CPU later.
+  params.flip_output = flipped_source;
+  params.swizzle[0] = GetOptimalReadbackFormat();
+
+  if (!things->nv12_converter) {
+    things->nv12_converter =
+        std::make_unique<GLNV12Converter>(context_provider_);
+  }
+  if (!GLNV12Converter::ParametersAreEquivalent(
+          params, things->nv12_converter->params())) {
+    const bool is_configured = things->nv12_converter->Configure(params);
+    // GLRendererCopier should never use illegal or unsupported options, nor
+    // be using GLNV12Converter with an invalid GL context.
+    DCHECK(is_configured);
+  }
+
+  const bool success = things->nv12_converter->Convert(
+      source_texture, source_texture_size, sampling_rect.OffsetFromOrigin(),
+      aligned_rect, things->yuv_textures.data());
+  DCHECK(success);
+
+  return aligned_rect;
+}
+
+void GLRendererCopier::StartReadbackFromTexture(
+    std::unique_ptr<CopyOutputRequest> request,
+    const gfx::Rect& result_rect,
+    const gfx::ColorSpace& color_space,
+    ReusableThings* things) {
+  DCHECK_EQ(request->result_format(), ResultFormat::RGBA);
+  DCHECK_EQ(request->result_destination(), ResultDestination::kSystemMemory);
+
+  auto* const gl = context_provider_->ContextGL();
+  if (things->readback_framebuffer == 0) {
+    gl->GenFramebuffers(1, &things->readback_framebuffer);
+  }
+  gl->BindFramebuffer(GL_FRAMEBUFFER, things->readback_framebuffer);
+  gl->FramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D,
+                           things->result_texture, 0);
+  StartReadbackFromFramebuffer(std::move(request), gfx::Vector2d(), false,
+                               ShouldSwapRedAndBlueForBitmapReadback(),
+                               result_rect, color_space);
+}
+
+namespace {
+
+// This is the type of CopyOutputResult we send for RGBA readback. The
+// constructor is called during on GLRendererCopier::FinishReadPixelsWorkflow(),
+// thus it always have access to the GLContext. The ReadRGBAPlane and destructor
+// are called asynchronously, and thus might not have access to the GLContext if
+// it has been destroyed in the meantime. We use the WeakPtr to the
+// GLRendererCopier as an indicator that the GLContext is still alive. If the
+// access to the GLContext is lost, we treat the copy output as failed.
+class GLPixelBufferRGBAResult final : public CopyOutputResult {
+ public:
+  GLPixelBufferRGBAResult(const gfx::Rect& result_rect,
+                          const gfx::ColorSpace& color_space,
+                          base::WeakPtr<GLRendererCopier> copier_weak_ptr,
+                          ContextProvider* context_provider,
+                          GLuint transfer_buffer,
+                          bool is_upside_down,
+                          bool swap_red_and_blue)
+      : CopyOutputResult(CopyOutputResult::Format::RGBA,
+                         CopyOutputResult::Destination::kSystemMemory,
+                         result_rect,
+                         /*needs_lock_for_bitmap=*/false),
+        color_space_(color_space),
+        copier_weak_ptr_(std::move(copier_weak_ptr)),
+        context_provider_(std::move(context_provider)),
+        transfer_buffer_(transfer_buffer),
+        is_upside_down_(is_upside_down),
+        swap_red_and_blue_(swap_red_and_blue) {}
+
+  ~GLPixelBufferRGBAResult() final {
+    if (transfer_buffer_ && copier_weak_ptr_) {
+      context_provider_->ContextGL()->DeleteBuffers(1, &transfer_buffer_);
+    }
+  }
+
+  bool ReadRGBAPlane(uint8_t* dest, int stride) const final {
+    // If the GLRendererCopier is gone, this implies the display compositor
+    // which contains the GLContext is gone. Regard this copy output readback as
+    // failed.
+    if (!copier_weak_ptr_)
+      return false;
+
+    const int src_bytes_per_row = size().width() * kRGBABytesPerPixel;
+    DCHECK_GE(stride, src_bytes_per_row);
+
+    // No need to read from GPU memory if a cached bitmap already exists.
+    if (rect().IsEmpty() || cached_bitmap()->readyToDraw())
+      return CopyOutputResult::ReadRGBAPlane(dest, stride);
+
+    auto* const gl = context_provider_->ContextGL();
+    gl->BindBuffer(GL_PIXEL_PACK_TRANSFER_BUFFER_CHROMIUM, transfer_buffer_);
+    const uint8_t* pixels = static_cast<uint8_t*>(gl->MapBufferCHROMIUM(
+        GL_PIXEL_PACK_TRANSFER_BUFFER_CHROMIUM, GL_READ_ONLY));
+    if (pixels) {
+      if (is_upside_down_) {
+        dest += (size().height() - 1) * stride;
+        stride = -stride;
+      }
+      const uint8_t* src = pixels;
+      if (swap_red_and_blue_) {
+        for (int y = 0; y < size().height();
+             ++y, src += src_bytes_per_row, dest += stride) {
+          for (int x = 0; x < kRGBABytesPerPixel * size().width();
+               x += kRGBABytesPerPixel) {
+            dest[x + 2] = src[x + 0];
+            dest[x + 1] = src[x + 1];
+            dest[x + 0] = src[x + 2];
+            dest[x + 3] = src[x + 3];
+          }
+        }
+      } else {
+        libyuv::CopyPlane(src, src_bytes_per_row, dest, stride,
+                          src_bytes_per_row, size().height());
+      }
+      gl->UnmapBufferCHROMIUM(GL_PIXEL_PACK_TRANSFER_BUFFER_CHROMIUM);
+    }
+    gl->BindBuffer(GL_PIXEL_PACK_TRANSFER_BUFFER_CHROMIUM, 0);
+    return !!pixels;
+  }
+
+  gfx::ColorSpace GetRGBAColorSpace() const final { return color_space_; }
+
+  // This method is always called on the same sequence as the GLRendererCopier.
+  // This method will be inside Viz and has access to the WeakPtr of the
+  // GLRendererCopier to check whether we still have the access to an alive
+  // GLContext.
+  const SkBitmap& AsSkBitmap() const final {
+    if (rect().IsEmpty())
+      return *cached_bitmap();  // Return "null" bitmap for empty result.
+
+    if (cached_bitmap()->readyToDraw())
+      return *cached_bitmap();
+
+    if (!copier_weak_ptr_)
+      return *cached_bitmap();
+
+    SkBitmap result_bitmap;
+    // size() was clamped to render pass or framebuffer size. If we can't
+    // allocate it then OOM.
+    auto info = SkImageInfo::MakeN32Premul(
+        size().width(), size().height(), GetRGBAColorSpace().ToSkColorSpace());
+    if (!result_bitmap.tryAllocPixels(info, info.minRowBytes()))
+      base::TerminateBecauseOutOfMemory(info.computeMinByteSize());
+
+    ReadRGBAPlane(static_cast<uint8_t*>(result_bitmap.getPixels()),
+                  result_bitmap.rowBytes());
+    *cached_bitmap() = result_bitmap;
+    // Now that we have a cached bitmap, no need to read from GPU memory
+    // anymore.
+    context_provider_->ContextGL()->DeleteBuffers(1, &transfer_buffer_);
+    transfer_buffer_ = 0;
+
+    return *cached_bitmap();
+  }
+
+ private:
+  const gfx::ColorSpace color_space_;
+  base::WeakPtr<GLRendererCopier> copier_weak_ptr_;
+  raw_ptr<ContextProvider> context_provider_;
+  mutable GLuint transfer_buffer_;
+  const bool is_upside_down_;
+  const bool swap_red_and_blue_;
+};
+}  // namespace
+
+GLRendererCopier::ReadPixelsWorkflow::ReadPixelsWorkflow(
+    std::unique_ptr<CopyOutputRequest> copy_request,
+    const gfx::Vector2d& readback_offset,
+    bool flipped_source,
+    bool swap_red_and_blue,
+    const gfx::Rect& result_rect,
+    const gfx::ColorSpace& color_space,
+    ContextProvider* context_provider,
+    GLenum readback_format)
+    : copy_request(std::move(copy_request)),
+      flipped_source(flipped_source),
+      swap_red_and_blue(swap_red_and_blue),
+      result_rect(result_rect),
+      color_space(color_space),
+      context_provider_(context_provider) {
+  DCHECK(readback_format == GL_RGBA || readback_format == GL_BGRA_EXT);
+  DCHECK(context_provider_);
+  auto* const gl = context_provider_->ContextGL();
+
+  // Create a buffer for the pixel transfer.
+  gl->GenBuffers(1, &transfer_buffer);
+  gl->BindBuffer(GL_PIXEL_PACK_TRANSFER_BUFFER_CHROMIUM, transfer_buffer);
+  gl->BufferData(
+      GL_PIXEL_PACK_TRANSFER_BUFFER_CHROMIUM,
+      (result_rect.size().GetCheckedArea() * kRGBABytesPerPixel).ValueOrDie(),
+      nullptr, GL_STREAM_READ);
+
+  // Execute an asynchronous read-pixels operation, with a query that triggers
+  // when Finish() should be run.
+  gl->GenQueriesEXT(1, &query_);
+  gl->BeginQueryEXT(GL_ASYNC_PIXEL_PACK_COMPLETED_CHROMIUM, query_);
+  gl->ReadPixels(readback_offset.x(), readback_offset.y(), result_rect.width(),
+                 result_rect.height(), readback_format, GL_UNSIGNED_BYTE,
+                 nullptr);
+  gl->EndQueryEXT(GL_ASYNC_PIXEL_PACK_COMPLETED_CHROMIUM);
+  gl->BindBuffer(GL_PIXEL_PACK_TRANSFER_BUFFER_CHROMIUM, 0);
+}
+
+GLRendererCopier::ReadPixelsWorkflow::~ReadPixelsWorkflow() {
+  auto* const gl = context_provider_->ContextGL();
+  gl->DeleteQueriesEXT(1, &query_);
+  if (transfer_buffer)
+    gl->DeleteBuffers(1, &transfer_buffer);
+}
+
+// Callback for the asynchronous glReadPixels(). The pixels are read from the
+// transfer buffer, and a CopyOutputResult is sent to the requestor. This would
+// mark this workflow as finished, and the workflow will be cleared later.
+void GLRendererCopier::FinishReadPixelsWorkflow(ReadPixelsWorkflow* workflow) {
+  auto result = std::make_unique<GLPixelBufferRGBAResult>(
+      workflow->result_rect, workflow->color_space, weak_factory_.GetWeakPtr(),
+      context_provider_, workflow->transfer_buffer, workflow->flipped_source,
+      workflow->swap_red_and_blue);
+  workflow->transfer_buffer = 0;  // Ownerhip was transferred to the result.
+  if (!workflow->copy_request->SendsResultsInCurrentSequence()) {
+    // Force readback into a SkBitmap now, because after PostTask we don't
+    // have access to |context_provider_|.
+    auto scoped_bitmap = result->ScopedAccessSkBitmap();
+    auto bitmap = scoped_bitmap.bitmap();
+  }
+  workflow->copy_request->SendResult(std::move(result));
+  const auto it =
+      std::find_if(read_pixels_workflows_.begin(), read_pixels_workflows_.end(),
+                   [workflow](auto& ptr) { return ptr.get() == workflow; });
+  DCHECK(it != read_pixels_workflows_.end());
+  read_pixels_workflows_.erase(it);
+}
+
+void GLRendererCopier::StartReadbackFromFramebuffer(
+    std::unique_ptr<CopyOutputRequest> request,
+    const gfx::Vector2d& readback_offset,
+    bool flipped_source,
+    bool swapped_red_and_blue,
+    const gfx::Rect& result_rect,
+    const gfx::ColorSpace& color_space) {
+  DCHECK_EQ(request->result_format(), ResultFormat::RGBA);
+  DCHECK_EQ(request->result_destination(), ResultDestination::kSystemMemory);
+
+  read_pixels_workflows_.emplace_back(std::make_unique<ReadPixelsWorkflow>(
+      std::move(request), readback_offset, flipped_source,
+      ShouldSwapRedAndBlueForBitmapReadback() != swapped_red_and_blue,
+      result_rect, color_space, context_provider_, GetOptimalReadbackFormat()));
+  context_provider_->ContextSupport()->SignalQuery(
+      read_pixels_workflows_.back()->query(),
+      base::BindOnce(&GLRendererCopier::FinishReadPixelsWorkflow,
+                     weak_factory_.GetWeakPtr(),
+                     read_pixels_workflows_.back().get()));
+}
+
+void GLRendererCopier::RenderAndSendTextureResult(
+    std::unique_ptr<CopyOutputRequest> request,
+    bool flipped_source,
+    const gfx::ColorSpace& source_color_space,
+    const gfx::ColorSpace& dest_color_space,
+    GLuint source_texture,
+    const gfx::Size& source_texture_size,
+    const gfx::Rect& sampling_rect,
+    const gfx::Rect& result_rect,
+    ReusableThings* things) {
+  DCHECK_EQ(request->result_format(), ResultFormat::RGBA);
+  DCHECK_EQ(request->result_destination(), ResultDestination::kNativeTextures);
+
+  auto* sii = context_provider_->SharedImageInterface();
+  gpu::Mailbox mailbox = sii->CreateSharedImage(
+      ResourceFormat::RGBA_8888, result_rect.size(), dest_color_space,
+      kTopLeft_GrSurfaceOrigin, kPremul_SkAlphaType,
+      gpu::SHARED_IMAGE_USAGE_GLES2, gpu::kNullSurfaceHandle);
+  auto* gl = context_provider_->ContextGL();
+  gl->WaitSyncTokenCHROMIUM(sii->GenUnverifiedSyncToken().GetConstData());
+  GLuint texture = gl->CreateAndTexStorage2DSharedImageCHROMIUM(mailbox.name);
+  gl->BeginSharedImageAccessDirectCHROMIUM(
+      texture, GL_SHARED_IMAGE_ACCESS_MODE_READWRITE_CHROMIUM);
+  RenderResultTexture(*request, flipped_source, source_color_space,
+                      dest_color_space, source_texture, source_texture_size,
+                      sampling_rect, result_rect, texture, things);
+  gl->EndSharedImageAccessDirectCHROMIUM(texture);
+  gl->DeleteTextures(1, &texture);
+  gpu::SyncToken sync_token;
+  gl->GenSyncTokenCHROMIUM(sync_token.GetData());
+
+  // Create a callback that deletes what was created in this GL context.
+  // Note: There's no need to try to pool/re-use the result texture from here,
+  // since only clients that are trying to re-invent video capture would see any
+  // significant performance benefit. Instead, such clients should use the video
+  // capture services provided by VIZ.
+  CopyOutputResult::ReleaseCallbacks release_callbacks;
+  release_callbacks.push_back(
+      texture_deleter_->GetReleaseCallback(context_provider_.get(), mailbox));
+
+  request->SendResult(std::make_unique<CopyOutputTextureResult>(
+      CopyOutputResult::Format::RGBA, result_rect,
+      CopyOutputResult::TextureResult(mailbox, sync_token, dest_color_space),
+      std::move(release_callbacks)));
+}
+
+namespace {
+
+// Specialization of CopyOutputResult which reads I420 plane data from a GL
+// pixel buffer object, and automatically deletes the pixel buffer object at
+// destruction time. This provides an optimal one-copy data flow, from the pixel
+// buffer into client-provided memory.
+class GLPixelBufferI420Result final : public CopyOutputResult {
+ public:
+  // |aligned_rect| identifies the region of result pixels in the pixel buffer,
+  // while the |result_rect| is the subregion that is exposed to the client.
+  GLPixelBufferI420Result(const gfx::Rect& aligned_rect,
+                          const gfx::Rect& result_rect,
+                          base::WeakPtr<GLRendererCopier> copier_weak_ptr,
+                          ContextProvider* context_provider,
+                          GLuint transfer_buffer)
+      : CopyOutputResult(CopyOutputResult::Format::I420_PLANES,
+                         CopyOutputResult::Destination::kSystemMemory,
+                         result_rect,
+                         /*needs_lock_for_bitmap=*/false),
+        aligned_rect_(aligned_rect),
+        copier_weak_ptr_(copier_weak_ptr),
+        context_provider_(context_provider),
+        transfer_buffer_(transfer_buffer) {
+    auto* const gl = context_provider_->ContextGL();
+    gl->BindBuffer(GL_PIXEL_PACK_TRANSFER_BUFFER_CHROMIUM, transfer_buffer_);
+    pixels_ = static_cast<uint8_t*>(gl->MapBufferCHROMIUM(
+        GL_PIXEL_PACK_TRANSFER_BUFFER_CHROMIUM, GL_READ_ONLY));
+    gl->BindBuffer(GL_PIXEL_PACK_TRANSFER_BUFFER_CHROMIUM, 0);
+  }
+
+  ~GLPixelBufferI420Result() final {
+    if (copier_weak_ptr_) {
+      auto* const gl = context_provider_->ContextGL();
+      gl->BindBuffer(GL_PIXEL_PACK_TRANSFER_BUFFER_CHROMIUM, transfer_buffer_);
+      gl->UnmapBufferCHROMIUM(GL_PIXEL_PACK_TRANSFER_BUFFER_CHROMIUM);
+      gl->BindBuffer(GL_PIXEL_PACK_TRANSFER_BUFFER_CHROMIUM, 0);
+      gl->DeleteBuffers(1, &transfer_buffer_);
+    }
+  }
+
+  bool ReadI420Planes(uint8_t* y_out,
+                      int y_out_stride,
+                      uint8_t* u_out,
+                      int u_out_stride,
+                      uint8_t* v_out,
+                      int v_out_stride) const final {
+    DCHECK_GE(y_out_stride, size().width());
+    const int chroma_row_bytes = (size().width() + 1) / 2;
+
+    DCHECK_GE(u_out_stride, chroma_row_bytes);
+    DCHECK_GE(v_out_stride, chroma_row_bytes);
+    if (!copier_weak_ptr_)
+      return false;
+
+    uint8_t* pixels = pixels_;
+    if (pixels) {
+      const int y_stride = aligned_rect_.width();
+      const gfx::Vector2d result_offset =
+          rect().OffsetFromOrigin() - aligned_rect_.OffsetFromOrigin();
+      const int y_start_offset =
+          result_offset.y() * y_stride + result_offset.x();
+      libyuv::CopyPlane(pixels + y_start_offset, y_stride, y_out, y_out_stride,
+                        size().width(), size().height());
+      pixels += y_stride * aligned_rect_.height();
+      const int chroma_stride = aligned_rect_.width() / 2;
+      const int chroma_start_offset =
+          ((result_offset.y() / 2) * chroma_stride) + (result_offset.x() / 2);
+      const int chroma_height = (size().height() + 1) / 2;
+      libyuv::CopyPlane(pixels + chroma_start_offset, chroma_stride, u_out,
+                        u_out_stride, chroma_row_bytes, chroma_height);
+      pixels += chroma_stride * (aligned_rect_.height() / 2);
+      libyuv::CopyPlane(pixels + chroma_start_offset, chroma_stride, v_out,
+                        v_out_stride, chroma_row_bytes, chroma_height);
+    }
+    return !!pixels;
+  }
+
+ private:
+  const gfx::Rect aligned_rect_;
+  base::WeakPtr<GLRendererCopier> copier_weak_ptr_;
+  const raw_ptr<ContextProvider> context_provider_;
+  const GLuint transfer_buffer_;
+  raw_ptr<uint8_t> pixels_;
+};
+
+// Specialization of CopyOutputResult which reads NV12 plane data from a GL
+// pixel buffer object, and automatically deletes the pixel buffer object at
+// destruction time. This provides an optimal one-copy data flow, from the pixel
+// buffer into client-provided memory.
+class GLPixelBufferNV12Result final : public CopyOutputResult {
+ public:
+  // |aligned_rect| identifies the region of result pixels in the pixel buffer,
+  // while the |result_rect| is the subregion that is exposed to the client.
+  GLPixelBufferNV12Result(const gfx::Rect& aligned_rect,
+                          const gfx::Rect& result_rect,
+                          base::WeakPtr<GLRendererCopier> copier_weak_ptr,
+                          ContextProvider* context_provider,
+                          GLuint transfer_buffer)
+      : CopyOutputResult(CopyOutputResult::Format::NV12_PLANES,
+                         CopyOutputResult::Destination::kSystemMemory,
+                         result_rect,
+                         /*needs_lock_for_bitmap=*/false),
+        aligned_rect_(aligned_rect),
+        copier_weak_ptr_(copier_weak_ptr),
+        context_provider_(context_provider),
+        transfer_buffer_(transfer_buffer) {
+    auto* const gl = context_provider_->ContextGL();
+    gl->BindBuffer(GL_PIXEL_PACK_TRANSFER_BUFFER_CHROMIUM, transfer_buffer_);
+    pixels_ = static_cast<uint8_t*>(gl->MapBufferCHROMIUM(
+        GL_PIXEL_PACK_TRANSFER_BUFFER_CHROMIUM, GL_READ_ONLY));
+    gl->BindBuffer(GL_PIXEL_PACK_TRANSFER_BUFFER_CHROMIUM, 0);
+  }
+
+  ~GLPixelBufferNV12Result() final {
+    if (copier_weak_ptr_) {
+      auto* const gl = context_provider_->ContextGL();
+      gl->BindBuffer(GL_PIXEL_PACK_TRANSFER_BUFFER_CHROMIUM, transfer_buffer_);
+      gl->UnmapBufferCHROMIUM(GL_PIXEL_PACK_TRANSFER_BUFFER_CHROMIUM);
+      gl->BindBuffer(GL_PIXEL_PACK_TRANSFER_BUFFER_CHROMIUM, 0);
+      gl->DeleteBuffers(1, &transfer_buffer_);
+    }
+  }
+
+  bool ReadNV12Planes(uint8_t* y_out,
+                      int y_out_stride,
+                      uint8_t* uv_out,
+                      int uv_out_stride) const final {
+    DCHECK_GE(y_out_stride, size().width());
+    const int chroma_row_bytes = 2 * ((size().width() + 1) / 2);
+    DCHECK_GE(uv_out_stride, chroma_row_bytes);
+    if (!copier_weak_ptr_)
+      return false;
+
+    uint8_t* pixels = pixels_;
+
+    if (pixels) {
+      const int y_stride = aligned_rect_.width();
+      const gfx::Vector2d result_offset =
+          rect().OffsetFromOrigin() - aligned_rect_.OffsetFromOrigin();
+      const int y_start_offset =
+          result_offset.y() * y_stride + result_offset.x();
+      libyuv::CopyPlane(pixels + y_start_offset, y_stride, y_out, y_out_stride,
+                        size().width(), size().height());
+      pixels += y_stride * aligned_rect_.height();
+      const int chroma_stride = aligned_rect_.width();
+      const int chroma_start_offset =
+          ((result_offset.y() / 2) * chroma_stride) +
+          2 * (result_offset.x() / 2);
+      const int chroma_height = (size().height() + 1) / 2;
+      libyuv::CopyPlane(pixels + chroma_start_offset, chroma_stride, uv_out,
+                        uv_out_stride, chroma_row_bytes, chroma_height);
+    }
+    return !!pixels;
+  }
+
+ private:
+  const gfx::Rect aligned_rect_;
+  base::WeakPtr<GLRendererCopier> copier_weak_ptr_;
+  const raw_ptr<ContextProvider> context_provider_;
+  const GLuint transfer_buffer_;
+  raw_ptr<uint8_t> pixels_ = nullptr;
+};
+
+}  // namespace
+
+GLRendererCopier::ReadI420PlanesWorkflow::ReadI420PlanesWorkflow(
+    std::unique_ptr<CopyOutputRequest> copy_request,
+    const gfx::Rect& aligned_rect,
+    const gfx::Rect& result_rect,
+    base::WeakPtr<GLRendererCopier> copier_weak_ptr,
+    ContextProvider* context_provider)
+    : copy_request(std::move(copy_request)),
+      aligned_rect(aligned_rect),
+      result_rect(result_rect),
+      copier_weak_ptr_(copier_weak_ptr),
+      context_provider_(context_provider) {
+  // Create a buffer for the pixel transfer: A single buffer is used and will
+  // contain the Y plane, then the U plane, then the V plane.
+  auto* const gl = context_provider_->ContextGL();
+  gl->GenBuffers(1, &transfer_buffer);
+  gl->BindBuffer(GL_PIXEL_PACK_TRANSFER_BUFFER_CHROMIUM, transfer_buffer);
+  base::CheckedNumeric<int> y_plane_bytes =
+      y_texture_size().GetCheckedArea() * kRGBABytesPerPixel;
+  base::CheckedNumeric<int> chroma_plane_bytes =
+      chroma_texture_size().GetCheckedArea() * kRGBABytesPerPixel;
+  gl->BufferData(GL_PIXEL_PACK_TRANSFER_BUFFER_CHROMIUM,
+                 (y_plane_bytes + chroma_plane_bytes * 2).ValueOrDie(), nullptr,
+                 GL_STREAM_READ);
+  data_offsets_ = {0, y_plane_bytes.ValueOrDie(),
+                   (y_plane_bytes + chroma_plane_bytes).ValueOrDie()};
+  gl->BindBuffer(GL_PIXEL_PACK_TRANSFER_BUFFER_CHROMIUM, 0);
+
+  // Generate the three queries used for determining when each of the plane
+  // readbacks has completed.
+  gl->GenQueriesEXT(3, queries.data());
+}
+
+void GLRendererCopier::ReadI420PlanesWorkflow::BindTransferBuffer() {
+  DCHECK_NE(transfer_buffer, 0u);
+  context_provider_->ContextGL()->BindBuffer(
+      GL_PIXEL_PACK_TRANSFER_BUFFER_CHROMIUM, transfer_buffer);
+}
+
+void GLRendererCopier::ReadI420PlanesWorkflow::StartPlaneReadback(
+    int plane,
+    GLenum readback_format) {
+  DCHECK_NE(queries[plane], 0u);
+  auto* const gl = context_provider_->ContextGL();
+  gl->BeginQueryEXT(GL_ASYNC_PIXEL_PACK_COMPLETED_CHROMIUM, queries[plane]);
+  const gfx::Size& size = plane == 0 ? y_texture_size() : chroma_texture_size();
+  // Note: While a PIXEL_PACK_BUFFER is bound, OpenGL interprets the last
+  // argument to ReadPixels() as a byte offset within the buffer instead of
+  // an actual pointer in system memory.
+  uint8_t* offset_in_buffer = GetOffsetPointer(data_offsets_[plane]);
+  gl->ReadPixels(0, 0, size.width(), size.height(), readback_format,
+                 GL_UNSIGNED_BYTE, offset_in_buffer);
+  gl->EndQueryEXT(GL_ASYNC_PIXEL_PACK_COMPLETED_CHROMIUM);
+  context_provider_->ContextSupport()->SignalQuery(
+      queries[plane],
+      base::BindOnce(&GLRendererCopier::FinishReadI420PlanesWorkflow,
+                     copier_weak_ptr_, this, plane));
+}
+
+void GLRendererCopier::ReadI420PlanesWorkflow::UnbindTransferBuffer() {
+  context_provider_->ContextGL()->BindBuffer(
+      GL_PIXEL_PACK_TRANSFER_BUFFER_CHROMIUM, 0);
+}
+
+GLRendererCopier::ReadI420PlanesWorkflow::~ReadI420PlanesWorkflow() {
+  auto* const gl = context_provider_->ContextGL();
+  if (transfer_buffer != 0)
+    gl->DeleteBuffers(1, &transfer_buffer);
+  for (GLuint& query : queries) {
+    if (query != 0)
+      gl->DeleteQueriesEXT(1, &query);
+  }
+}
+
+gfx::Size GLRendererCopier::ReadI420PlanesWorkflow::y_texture_size() const {
+  return gfx::Size(aligned_rect.width() / kRGBABytesPerPixel,
+                   aligned_rect.height());
+}
+
+gfx::Size GLRendererCopier::ReadI420PlanesWorkflow::chroma_texture_size()
+    const {
+  return gfx::Size(aligned_rect.width() / kRGBABytesPerPixel / 2,
+                   aligned_rect.height() / 2);
+}
+
+GLRendererCopier::ReadNV12PlanesWorkflow::ReadNV12PlanesWorkflow(
+    std::unique_ptr<CopyOutputRequest> copy_request,
+    const gfx::Rect& aligned_rect,
+    const gfx::Rect& result_rect,
+    base::WeakPtr<GLRendererCopier> copier_weak_ptr,
+    ContextProvider* context_provider)
+    : copy_request_(std::move(copy_request)),
+      aligned_rect_(aligned_rect),
+      result_rect_(result_rect),
+      copier_weak_ptr_(copier_weak_ptr),
+      context_provider_(context_provider) {
+  // Create a buffer for the pixel transfer: A single buffer is used and will
+  // contain the Y plane, then the UV plane.
+  auto* const gl = context_provider_->ContextGL();
+  gl->GenBuffers(1, &transfer_buffer_);
+  gl->BindBuffer(GL_PIXEL_PACK_TRANSFER_BUFFER_CHROMIUM, transfer_buffer_);
+  base::CheckedNumeric<int> y_plane_bytes =
+      y_texture_size().GetCheckedArea() * kRGBABytesPerPixel;
+  base::CheckedNumeric<int> chroma_plane_bytes =
+      chroma_texture_size().GetCheckedArea() * kRGBABytesPerPixel;
+  gl->BufferData(GL_PIXEL_PACK_TRANSFER_BUFFER_CHROMIUM,
+                 (y_plane_bytes + chroma_plane_bytes).ValueOrDie(), nullptr,
+                 GL_STREAM_READ);
+  data_offsets_ = {0, y_plane_bytes.ValueOrDie()};
+  gl->BindBuffer(GL_PIXEL_PACK_TRANSFER_BUFFER_CHROMIUM, 0);
+
+  // Generate the two queries used for determining when each of the plane
+  // readbacks has completed.
+  gl->GenQueriesEXT(2, queries_.data());
+}
+
+void GLRendererCopier::ReadNV12PlanesWorkflow::BindTransferBuffer() {
+  DCHECK_NE(transfer_buffer_, 0u);
+  context_provider_->ContextGL()->BindBuffer(
+      GL_PIXEL_PACK_TRANSFER_BUFFER_CHROMIUM, transfer_buffer_);
+}
+
+void GLRendererCopier::ReadNV12PlanesWorkflow::StartPlaneReadback(
+    int plane,
+    GLenum readback_format) {
+  DCHECK_NE(queries_[plane], 0u);
+  auto* const gl = context_provider_->ContextGL();
+  gl->BeginQueryEXT(GL_ASYNC_PIXEL_PACK_COMPLETED_CHROMIUM, queries_[plane]);
+  const gfx::Size& size = plane == 0 ? y_texture_size() : chroma_texture_size();
+  // Note: While a PIXEL_PACK_BUFFER is bound, OpenGL interprets the last
+  // argument to ReadPixels() as a byte offset within the buffer instead of
+  // an actual pointer in system memory.
+  uint8_t* offset_in_buffer = GetOffsetPointer(data_offsets_[plane]);
+  gl->ReadPixels(0, 0, size.width(), size.height(), readback_format,
+                 GL_UNSIGNED_BYTE, offset_in_buffer);
+  gl->EndQueryEXT(GL_ASYNC_PIXEL_PACK_COMPLETED_CHROMIUM);
+  context_provider_->ContextSupport()->SignalQuery(
+      queries_[plane],
+      base::BindOnce(&GLRendererCopier::FinishReadNV12PlanesWorkflow,
+                     copier_weak_ptr_, this, plane));
+}
+
+void GLRendererCopier::ReadNV12PlanesWorkflow::UnbindTransferBuffer() {
+  context_provider_->ContextGL()->BindBuffer(
+      GL_PIXEL_PACK_TRANSFER_BUFFER_CHROMIUM, 0);
+}
+
+GLRendererCopier::ReadNV12PlanesWorkflow::~ReadNV12PlanesWorkflow() {
+  auto* const gl = context_provider_->ContextGL();
+  if (transfer_buffer_ != 0)
+    gl->DeleteBuffers(1, &transfer_buffer_);
+  for (GLuint& query : queries_) {
+    if (query != 0)
+      gl->DeleteQueriesEXT(1, &query);
+  }
+}
+
+gfx::Size GLRendererCopier::ReadNV12PlanesWorkflow::y_texture_size() const {
+  return gfx::Size(aligned_rect_.width() / kRGBABytesPerPixel,
+                   aligned_rect_.height());
+}
+
+gfx::Size GLRendererCopier::ReadNV12PlanesWorkflow::chroma_texture_size()
+    const {
+  return gfx::Size(aligned_rect_.width() / kRGBABytesPerPixel,
+                   aligned_rect_.height() / 2);
+}
+
+void GLRendererCopier::StartI420ReadbackFromTextures(
+    std::unique_ptr<CopyOutputRequest> request,
+    const gfx::Rect& aligned_rect,
+    const gfx::Rect& result_rect,
+    ReusableThings* things) {
+  DCHECK_EQ(request->result_format(), ResultFormat::I420_PLANES);
+
+  auto* const gl = context_provider_->ContextGL();
+  if (things->yuv_readback_framebuffers[0] == 0) {
+    gl->GenFramebuffers(3, things->yuv_readback_framebuffers.data());
+  } else if (things->yuv_readback_framebuffers[2] == 0) {
+    gl->GenFramebuffers(1, &things->yuv_readback_framebuffers[2]);
+  }
+
+  // Execute three asynchronous read-pixels operations, one for each plane. The
+  // CopyOutputRequest is passed to the ReadI420PlanesWorkflow, which will send
+  // the CopyOutputResult once all readback operations are complete.
+  read_i420_workflows_.emplace_back(std::make_unique<ReadI420PlanesWorkflow>(
+      std::move(request), aligned_rect, result_rect, weak_factory_.GetWeakPtr(),
+      context_provider_));
+  ReadI420PlanesWorkflow* workflow = read_i420_workflows_.back().get();
+  workflow->BindTransferBuffer();
+  for (int plane = 0; plane < 3; ++plane) {
+    gl->BindFramebuffer(GL_FRAMEBUFFER,
+                        things->yuv_readback_framebuffers[plane]);
+    gl->FramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0,
+                             GL_TEXTURE_2D, things->yuv_textures[plane], 0);
+    workflow->StartPlaneReadback(plane, GetOptimalReadbackFormat());
+  }
+  workflow->UnbindTransferBuffer();
+}
+
+void GLRendererCopier::FinishReadI420PlanesWorkflow(
+    ReadI420PlanesWorkflow* workflow,
+    int plane) {
+  context_provider_->ContextGL()->DeleteQueriesEXT(1,
+                                                   &workflow->queries[plane]);
+  workflow->queries[plane] = 0;
+
+  // If all three readbacks have completed, send the result.
+  if (workflow->queries == std::array<GLuint, 3>{{0, 0, 0}}) {
+    workflow->copy_request->SendResult(
+        std::make_unique<GLPixelBufferI420Result>(
+            workflow->aligned_rect, workflow->result_rect,
+            weak_factory_.GetWeakPtr(), context_provider_,
+            workflow->transfer_buffer));
+    workflow->transfer_buffer = 0;  // Ownership was transferred to the result.
+    const auto it =
+        std::find_if(read_i420_workflows_.begin(), read_i420_workflows_.end(),
+                     [workflow](auto& ptr) { return ptr.get() == workflow; });
+    DCHECK(it != read_i420_workflows_.end());
+    read_i420_workflows_.erase(it);
+  }
+}
+
+void GLRendererCopier::StartNV12ReadbackFromTextures(
+    std::unique_ptr<CopyOutputRequest> request,
+    const gfx::Rect& aligned_rect,
+    const gfx::Rect& result_rect,
+    ReusableThings* things) {
+  DCHECK_EQ(request->result_format(), ResultFormat::NV12_PLANES);
+
+  auto* const gl = context_provider_->ContextGL();
+  if (things->yuv_readback_framebuffers[0] == 0)
+    gl->GenFramebuffers(2, things->yuv_readback_framebuffers.data());
+
+  // Execute two asynchronous read-pixels operations, one for each plane. The
+  // CopyOutputRequest is passed to the ReadNV12PlanesWorkflow, which will send
+  // the CopyOutputResult once all readback operations are complete.
+  read_nv12_workflows_.push_back(std::make_unique<ReadNV12PlanesWorkflow>(
+      std::move(request), aligned_rect, result_rect, weak_factory_.GetWeakPtr(),
+      context_provider_));
+  ReadNV12PlanesWorkflow* workflow = read_nv12_workflows_.back().get();
+  workflow->BindTransferBuffer();
+  for (int plane = 0; plane < 2; ++plane) {
+    gl->BindFramebuffer(GL_FRAMEBUFFER,
+                        things->yuv_readback_framebuffers[plane]);
+    gl->FramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0,
+                             GL_TEXTURE_2D, things->yuv_textures[plane], 0);
+    workflow->StartPlaneReadback(plane, GetOptimalReadbackFormat());
+  }
+  workflow->UnbindTransferBuffer();
+}
+
+void GLRendererCopier::FinishReadNV12PlanesWorkflow(
+    ReadNV12PlanesWorkflow* workflow,
+    int plane) {
+  GLuint query = workflow->query(plane);
+  context_provider_->ContextGL()->DeleteQueriesEXT(1, &query);
+  workflow->MarkQueryCompleted(plane);
+
+  // If both readbacks have completed, send the result.
+  if (workflow->IsCompleted()) {
+    workflow->TakeRequest()->SendResult(
+        std::make_unique<GLPixelBufferNV12Result>(
+            workflow->aligned_rect(), workflow->result_rect(),
+            weak_factory_.GetWeakPtr(), context_provider_,
+            workflow->TakeTransferBuffer()));
+    const auto it =
+        std::find_if(read_nv12_workflows_.begin(), read_nv12_workflows_.end(),
+                     [workflow](auto& ptr) { return ptr.get() == workflow; });
+    DCHECK(it != read_nv12_workflows_.end());
+    read_nv12_workflows_.erase(it);
+  }
+}
+
+std::unique_ptr<GLRendererCopier::ReusableThings>
+GLRendererCopier::TakeReusableThingsOrCreate(
+    const base::UnguessableToken& requester) {
+  if (!requester.is_empty()) {
+    const auto it = cache_.find(requester);
+    if (it != cache_.end()) {
+      auto things = std::move(it->second);
+      cache_.erase(it);
+      return things;
+    }
+  }
+
+  return std::make_unique<ReusableThings>();
+}
+
+void GLRendererCopier::StashReusableThingsOrDelete(
+    const base::UnguessableToken& requester,
+    std::unique_ptr<ReusableThings> things) {
+  if (requester.is_empty()) {
+    things->Free(context_provider_->ContextGL());
+  } else {
+    things->purge_count_at_last_use = purge_counter_;
+    cache_[requester] = std::move(things);
+  }
+}
+
+GLenum GLRendererCopier::GetOptimalReadbackFormat() {
+  if (optimal_readback_format_ != GL_NONE)
+    return optimal_readback_format_;
+
+  // Preconditions: GetOptimalReadbackFormat() requires a valid context and a
+  // complete framebuffer set up. The latter must be guaranteed by all possible
+  // callers of this method.
+  auto* const gl = context_provider_->ContextGL();
+  if (gl->GetGraphicsResetStatusKHR() != GL_NO_ERROR)
+    return GL_RGBA;  // No context: Just return a sane default.
+  DCHECK(gl->CheckFramebufferStatus(GL_FRAMEBUFFER) == GL_FRAMEBUFFER_COMPLETE);
+
+  // If the GL implementation internally uses the GL_BGRA_EXT+GL_UNSIGNED_BYTE
+  // format+type combination, then consider that the optimal readback
+  // format+type. Otherwise, use GL_RGBA+GL_UNSIGNED_BYTE, which all platforms
+  // must support, per the GLES 2.0 spec.
+  GLint type = 0;
+  GLint readback_format = 0;
+  gl->GetIntegerv(GL_IMPLEMENTATION_COLOR_READ_TYPE, &type);
+  if (type == GL_UNSIGNED_BYTE)
+    gl->GetIntegerv(GL_IMPLEMENTATION_COLOR_READ_FORMAT, &readback_format);
+  if (readback_format != GL_BGRA_EXT)
+    readback_format = GL_RGBA;
+
+  optimal_readback_format_ = static_cast<GLenum>(readback_format);
+  return optimal_readback_format_;
+}
+
+bool GLRendererCopier::ShouldSwapRedAndBlueForBitmapReadback() {
+  const bool skbitmap_is_bgra = (kN32_SkColorType == kBGRA_8888_SkColorType);
+  const bool readback_will_be_bgra =
+      (GetOptimalReadbackFormat() == GL_BGRA_EXT);
+  return skbitmap_is_bgra != readback_will_be_bgra;
+}
+
+GLRendererCopier::ReusableThings::ReusableThings() = default;
+
+GLRendererCopier::ReusableThings::~ReusableThings() {
+  // Ensure all resources were freed by this point. Resources aren't explicity
+  // freed here, in the destructor, because some require access to the GL
+  // context. See Free().
+  DCHECK_EQ(fb_copy_texture, 0u);
+  DCHECK(!scaler);
+  DCHECK_EQ(result_texture, 0u);
+  DCHECK_EQ(readback_framebuffer, 0u);
+  DCHECK(!i420_converter);
+  constexpr std::array<GLuint, 3> kAllZeros = {0, 0, 0};
+  DCHECK(yuv_textures == kAllZeros);
+  DCHECK(yuv_readback_framebuffers == kAllZeros);
+}
+
+void GLRendererCopier::ReusableThings::Free(gpu::gles2::GLES2Interface* gl) {
+  if (fb_copy_texture != 0) {
+    gl->DeleteTextures(1, &fb_copy_texture);
+    fb_copy_texture = 0;
+    fb_copy_texture_internal_format = static_cast<GLenum>(GL_NONE);
+    fb_copy_texture_size = gfx::Size();
+  }
+  scaler.reset();
+  if (result_texture != 0) {
+    gl->DeleteTextures(1, &result_texture);
+    result_texture = 0;
+    result_texture_size = gfx::Size();
+  }
+  if (readback_framebuffer != 0) {
+    gl->DeleteFramebuffers(1, &readback_framebuffer);
+    readback_framebuffer = 0;
+  }
+
+  i420_converter.reset();
+  nv12_converter.reset();
+
+  if (yuv_textures[0] != 0) {
+    // We have some cached textures, check if there's 2 or 3 & delete them:
+    int num_textures = yuv_textures[2] != 0 ? 3 : 2;
+    gl->DeleteTextures(num_textures, yuv_textures.data());
+    yuv_textures = {0, 0, 0};
+    texture_sizes = {};
+  }
+  if (yuv_readback_framebuffers[0] != 0) {
+    // We have some cached readback buffers, check if there's 2 or 3 & delete
+    // them:
+    int num_readback_buffers = yuv_readback_framebuffers[2] != 0 ? 3 : 2;
+    gl->DeleteFramebuffers(num_readback_buffers,
+                           yuv_readback_framebuffers.data());
+    yuv_readback_framebuffers = {0, 0, 0};
+  }
+}
+
+}  // namespace viz
diff --git components/viz/service/display/gl_renderer_copier.h components/viz/service/display/gl_renderer_copier.h
new file mode 100644
index 0000000000000..e0952de31f38b
--- /dev/null
+++ components/viz/service/display/gl_renderer_copier.h
@@ -0,0 +1,485 @@
+// Copyright 2017 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef COMPONENTS_VIZ_SERVICE_DISPLAY_GL_RENDERER_COPIER_H_
+#define COMPONENTS_VIZ_SERVICE_DISPLAY_GL_RENDERER_COPIER_H_
+
+#include <stdint.h>
+
+#include <array>
+#include <memory>
+#include <utility>
+#include <vector>
+
+#include "base/callback.h"
+#include "base/containers/flat_map.h"
+#include "base/memory/raw_ptr.h"
+#include "base/memory/ref_counted.h"
+#include "base/task/task_runner.h"
+#include "base/unguessable_token.h"
+#include "components/viz/service/viz_service_export.h"
+#include "ui/gfx/color_space.h"
+#include "ui/gfx/geometry/rect.h"
+#include "ui/gfx/geometry/size.h"
+
+namespace gfx {
+class ColorSpace;
+class Rect;
+class Vector2d;
+}  // namespace gfx
+
+namespace gpu {
+namespace gles2 {
+class GLES2Interface;
+}
+}  // namespace gpu
+
+namespace viz {
+
+class ContextProvider;
+class CopyOutputRequest;
+class GLI420Converter;
+class GLNV12Converter;
+class GLScaler;
+class TextureDeleter;
+
+namespace copy_output {
+struct RenderPassGeometry;
+}  // namespace copy_output
+
+// Helper class for GLRenderer that executes CopyOutputRequests using GL, to
+// perform texture copies/transformations and read back bitmaps. Also manages
+// the caching of resources needed to ensure efficient video performance.
+//
+// GLRenderer calls CopyFromTextureOrFramebuffer() to execute a
+// CopyOutputRequest. GLRendererCopier will examine the request and determine
+// the minimal amount of work needed to satisfy all the requirements of the
+// request.
+//
+// In many cases, interim GL objects (textures, framebuffers, etc.) must be
+// created as part of a multi-step process. When considering video performance
+// (i.e., a series of CopyOutputRequests from the same "source"), these interim
+// objects must be cached to prevent a significant performance penalty on some
+// GPU/drivers. GLRendererCopier manages such a cache and automatically frees
+// the objects when it detects that a stream of CopyOutputRequests from a given
+// "source" has ended.
+class VIZ_SERVICE_EXPORT GLRendererCopier {
+ public:
+  // Define types to avoid pulling in command buffer GL headers, which conflict
+  // the ui/gl/gl_bindings.h
+  using GLuint = unsigned int;
+  using GLenum = unsigned int;
+
+  // |context_provider| and |texture_deleter| must outlive this instance.
+  GLRendererCopier(ContextProvider* context_provider,
+                   TextureDeleter* texture_deleter);
+
+  GLRendererCopier(const GLRendererCopier&) = delete;
+  GLRendererCopier& operator=(const GLRendererCopier&) = delete;
+
+  ~GLRendererCopier();
+
+  // Executes the |request|, copying from the currently-bound framebuffer of the
+  // given |internal_format|. |output_rect| is the RenderPass's output Rect in
+  // draw space, and is used to translate and clip the result selection Rect in
+  // the request. |framebuffer_texture| and |framebuffer_texture_size| are
+  // optional, but desired for performance: If provided, the texture might be
+  // used as the source, to avoid having to make a copy of the framebuffer.
+  // |flipped_source| is true (common case) if the framebuffer content is
+  // vertically flipped (bottom-up row order). |framebuffer_color_space|
+  // specifies the color space of the pixels in the framebuffer.
+  //
+  // This implementation may change a wide variety of GL state, such as texture
+  // and framebuffer bindings, shader programs, and related attributes; and so
+  // the caller must not make any assumptions about the state of the GL context
+  // after this call.
+  void CopyFromTextureOrFramebuffer(
+      std::unique_ptr<CopyOutputRequest> request,
+      const copy_output::RenderPassGeometry& geometry,
+      GLenum internal_format,
+      GLuint framebuffer_texture,
+      const gfx::Size& framebuffer_texture_size,
+      bool flipped_source,
+      const gfx::ColorSpace& framebuffer_color_space);
+
+  // Checks whether cached resources should be freed because recent copy
+  // activity is no longer using them. This should be called after a frame has
+  // finished drawing (after all copy requests have been executed).
+  void FreeUnusedCachedResources();
+
+ private:
+  friend class GLRendererCopierTest;
+
+  // The collection of resources that might be cached over multiple copy
+  // requests from the same source. While executing a CopyOutputRequest, this
+  // struct is also used to pass around intermediate objects between operations.
+  struct VIZ_SERVICE_EXPORT ReusableThings {
+    // This is used to determine whether these things aren't being used anymore.
+    uint32_t purge_count_at_last_use = 0;
+
+    // Texture containing a copy of the source framebuffer, if the source
+    // framebuffer cannot be used directly.
+    GLuint fb_copy_texture = 0;
+    GLenum fb_copy_texture_internal_format = static_cast<GLenum>(0 /*GL_NONE*/);
+    gfx::Size fb_copy_texture_size;
+
+    // RGBA requests: Scaling, and texture/framebuffer for readback.
+    std::unique_ptr<GLScaler> scaler;
+    GLuint result_texture = 0;
+    gfx::Size result_texture_size;
+    GLuint readback_framebuffer = 0;
+
+    // I420_PLANES & NV12_PLANES requests: I420, NV12 scaling and format
+    // conversion, and textures+framebuffers for readback.
+    std::unique_ptr<GLI420Converter> i420_converter;
+    std::unique_ptr<GLNV12Converter> nv12_converter;
+    std::array<GLuint, 3> yuv_textures = {0, 0, 0};
+    std::array<gfx::Size, 3> texture_sizes;
+    std::array<GLuint, 3> yuv_readback_framebuffers = {0, 0, 0};
+
+    ReusableThings();
+
+    ReusableThings(const ReusableThings&) = delete;
+    ReusableThings& operator=(const ReusableThings&) = delete;
+
+    ~ReusableThings();
+
+    // Frees all the GL objects and scalers. This is in-lieu of a ReusableThings
+    // destructor because a valid GL context is required to free some of the
+    // objects.
+    void Free(gpu::gles2::GLES2Interface* gl);
+  };
+
+  // Manages the execution of one asynchronous framebuffer readback and contains
+  // all the relevant state needed to complete a copy request. The constructor
+  // initiates the operation, and the destructor cleans up all the GL objects
+  // created for this workflow. This class is owned by the GLRendererCopier, and
+  // GLRendererCopier is responsible for deleting this either after the workflow
+  // is finished, or when the GLRendererCopier is being destroyed.
+  struct ReadPixelsWorkflow {
+   public:
+    // Saves all revelant state and initiates the GL asynchronous read-pixels
+    // workflow.
+    ReadPixelsWorkflow(std::unique_ptr<CopyOutputRequest> copy_request,
+                       const gfx::Vector2d& readback_offset,
+                       bool flipped_source,
+                       bool swap_red_and_blue,
+                       const gfx::Rect& result_rect,
+                       const gfx::ColorSpace& color_space,
+                       ContextProvider* context_provider,
+                       GLenum readback_format);
+    ReadPixelsWorkflow(const ReadPixelsWorkflow&) = delete;
+
+    // The destructor is by the GLRendererCopier, either called after the
+    // workflow is finished or when GLRendererCopier is being destoryed.
+    ~ReadPixelsWorkflow();
+
+    GLuint query() const { return query_; }
+
+    const std::unique_ptr<CopyOutputRequest> copy_request;
+    const bool flipped_source;
+    const bool swap_red_and_blue;
+    const gfx::Rect result_rect;
+    const gfx::ColorSpace color_space;
+    GLuint transfer_buffer = 0;
+
+   private:
+    const raw_ptr<ContextProvider> context_provider_;
+    GLuint query_ = 0;
+  };
+
+  // Renders a scaled/transformed copy of a source texture according to the
+  // |request| parameters and other source characteristics. |result_texture|
+  // must be allocated/sized by the caller. For RGBA requests with destination
+  // set to system memory, the image content will be rendered in top-down row
+  // order and maybe red-blue swapped, to support efficient readback later on.
+  // For RGBA requests with ResultDestination::kNativeTextures set, the image
+  // content is always rendered Y-flipped (bottom-up row order).
+  void RenderResultTexture(const CopyOutputRequest& request,
+                           bool flipped_source,
+                           const gfx::ColorSpace& source_color_space,
+                           const gfx::ColorSpace& dest_color_space,
+                           GLuint source_texture,
+                           const gfx::Size& source_texture_size,
+                           const gfx::Rect& sampling_rect,
+                           const gfx::Rect& result_rect,
+                           GLuint result_texture,
+                           ReusableThings* things);
+
+  // Like the ReadPixelsWorkflow, except for I420 planes readback. Because there
+  // are three separate glReadPixels operations that may complete in any order,
+  // a ReadI420PlanesWorkflow will receive notifications from three separate "GL
+  // query" callbacks. It is only after all three operations have completed that
+  // a fully-assembled CopyOutputResult can be sent.
+  //
+  // See class comments for GLI420Converter for an explanation of how
+  // planar data is packed into RGBA textures.
+  struct ReadI420PlanesWorkflow {
+   public:
+    ReadI420PlanesWorkflow(std::unique_ptr<CopyOutputRequest> copy_request,
+                           const gfx::Rect& aligned_rect,
+                           const gfx::Rect& result_rect,
+                           base::WeakPtr<GLRendererCopier> copier_weak_ptr,
+                           ContextProvider* context_provider);
+
+    void BindTransferBuffer();
+    void StartPlaneReadback(int plane, GLenum readback_format);
+    void UnbindTransferBuffer();
+
+    ~ReadI420PlanesWorkflow();
+
+    const std::unique_ptr<CopyOutputRequest> copy_request;
+    const gfx::Rect aligned_rect;
+    const gfx::Rect result_rect;
+    GLuint transfer_buffer;
+    std::array<GLuint, 3> queries;
+
+   private:
+    gfx::Size y_texture_size() const;
+    gfx::Size chroma_texture_size() const;
+
+    base::WeakPtr<GLRendererCopier> copier_weak_ptr_;
+    const raw_ptr<ContextProvider> context_provider_;
+    std::array<int, 3> data_offsets_;
+  };
+
+  // Like the ReadPixelsWorkflow, except for NV12 planes readback. Because there
+  // are two separate glReadPixels operations that may complete in any order,
+  // a ReadNV12PlanesWorkflow will receive notifications from two separate "GL
+  // query" callbacks. It is only after all two operations have completed that
+  // a fully-assembled CopyOutputResult can be sent.
+  //
+  // See class comments for GLNV12Converter for an explanation of how planar
+  // data is packed into RGBA textures.
+  class ReadNV12PlanesWorkflow {
+   public:
+    ReadNV12PlanesWorkflow(std::unique_ptr<CopyOutputRequest> copy_request,
+                           const gfx::Rect& aligned_rect,
+                           const gfx::Rect& result_rect,
+                           base::WeakPtr<GLRendererCopier> copier_weak_ptr,
+                           ContextProvider* context_provider);
+    ~ReadNV12PlanesWorkflow();
+
+    void BindTransferBuffer();
+    void StartPlaneReadback(int plane, GLenum readback_format);
+    void UnbindTransferBuffer();
+
+    gfx::Rect aligned_rect() const { return aligned_rect_; }
+
+    gfx::Rect result_rect() const { return result_rect_; }
+
+    std::unique_ptr<CopyOutputRequest> TakeRequest() {
+      DCHECK(copy_request_);
+
+      return std::move(copy_request_);
+    }
+
+    GLuint TakeTransferBuffer() {
+      DCHECK(transfer_buffer_);
+
+      GLuint result = transfer_buffer_;
+      transfer_buffer_ = 0;
+      return result;
+    }
+
+    // Returns true if the workflow has completed (i.e. readback requests for
+    // all planes have finished).
+    bool IsCompleted() const {
+      return queries_ == std::array<GLuint, 2>{{0, 0}};
+    }
+
+    GLuint query(int plane) { return queries_[plane]; }
+
+    // Marks that a readback has completed for a given plane.
+    void MarkQueryCompleted(int plane) { queries_[plane] = 0; }
+
+   private:
+    gfx::Size y_texture_size() const;
+    gfx::Size chroma_texture_size() const;
+
+    std::unique_ptr<CopyOutputRequest> copy_request_;
+    const gfx::Rect aligned_rect_;
+    const gfx::Rect result_rect_;
+    GLuint transfer_buffer_;
+    std::array<GLuint, 2> queries_;
+
+    base::WeakPtr<GLRendererCopier> copier_weak_ptr_;
+    const raw_ptr<ContextProvider> context_provider_;
+    std::array<int, 2> data_offsets_;
+  };
+
+  // Similar to RenderResultTexture(), except also transform the image into I420
+  // format (a popular video format). Three textures, representing each of the
+  // Y/U/V planes (as described in GLI420Converter), are populated and their GL
+  // references placed in |things|. The image content is always rendered in
+  // top-down row order and swizzled (if needed), to support efficient readback
+  // later on.
+  //
+  // For alignment reasons, sometimes a slightly larger result will be provided,
+  // and the return Rect will indicate the actual bounds that were rendered
+  // (|result_rect|'s coordinate system). See StartI420ReadbackFromTextures()
+  // for more details.
+  gfx::Rect RenderI420Textures(const CopyOutputRequest& request,
+                               bool flipped_source,
+                               const gfx::ColorSpace& source_color_space,
+                               GLuint source_texture,
+                               const gfx::Size& source_texture_size,
+                               const gfx::Rect& sampling_rect,
+                               const gfx::Rect& result_rect,
+                               ReusableThings* things);
+
+  // Similar to RenderResultTexture(), except also transform the image into NV12
+  // format (a popular video format). Two textures, representing each of the
+  // Y/UV planes (as described in GLNV12Converter), are populated and their GL
+  // references placed in |things|. The image content is always rendered in
+  // top-down row order and swizzled (if needed), to support efficient readback
+  // later on.
+  //
+  // For alignment reasons, sometimes a slightly larger result will be provided,
+  // and the return Rect will indicate the actual bounds that were rendered
+  // (|result_rect|'s coordinate system). See StartNV12ReadbackFromTextures()
+  // for more details.
+  gfx::Rect RenderNV12Textures(const CopyOutputRequest& request,
+                               bool flipped_source,
+                               const gfx::ColorSpace& source_color_space,
+                               GLuint source_texture,
+                               const gfx::Size& source_texture_size,
+                               const gfx::Rect& sampling_rect,
+                               const gfx::Rect& result_rect,
+                               ReusableThings* things);
+
+  // Binds the |things->result_texture| to a framebuffer and calls
+  // StartReadbackFromFramebuffer(). This is only for RGBA requests with
+  // destination set to kSystemMemory.
+  // Assumes the image content is in top-down row order (and is red-blue swapped
+  // iff RenderResultTexture() would have done that).
+  void StartReadbackFromTexture(std::unique_ptr<CopyOutputRequest> request,
+                                const gfx::Rect& result_rect,
+                                const gfx::ColorSpace& color_space,
+                                ReusableThings* things);
+
+  // Processes the next phase of the copy request by starting readback from the
+  // currently-bound framebuffer into a pixel transfer buffer. |readback_offset|
+  // is the origin of the readback rect within the framebuffer, with
+  // |result_rect| providing the size of the readback rect. |flipped_source| is
+  // true if the framebuffer content is in bottom-up row order, and
+  // |swapped_red_and_blue| specifies whether the red and blue channels have
+  // been swapped. This method kicks-off an asynchronous glReadPixels()
+  // workflow.
+  void StartReadbackFromFramebuffer(std::unique_ptr<CopyOutputRequest> request,
+                                    const gfx::Vector2d& readback_offset,
+                                    bool flipped_source,
+                                    bool swapped_red_and_blue,
+                                    const gfx::Rect& result_rect,
+                                    const gfx::ColorSpace& color_space);
+
+  // Renders a scaled/transformed copy of a source texture similarly to
+  // RenderResultTexture, but packages up the result in a mailbox and sends it
+  // as the result to the CopyOutputRequest.
+  void RenderAndSendTextureResult(std::unique_ptr<CopyOutputRequest> request,
+                                  bool flipped_source,
+                                  const gfx::ColorSpace& source_color_space,
+                                  const gfx::ColorSpace& dest_color_space,
+                                  GLuint source_texture,
+                                  const gfx::Size& source_texture_size,
+                                  const gfx::Rect& sampling_rect,
+                                  const gfx::Rect& result_rect,
+                                  ReusableThings* things);
+
+  // Like StartReadbackFromTexture(), except that this processes the three Y/U/V
+  // result textures in |things| by using three framebuffers and three
+  // asynchronous readback operations. A single pixel transfer buffer is used to
+  // hold the results of all three readbacks (i.e., each plane starts at a
+  // different offset in the transfer buffer).
+  //
+  // |aligned_rect| is the Rect returned from the RenderI420Textures() call, and
+  // is required so that the CopyOutputResult sent at the end of this workflow
+  // will access the correct region of pixels.
+  void StartI420ReadbackFromTextures(std::unique_ptr<CopyOutputRequest> request,
+                                     const gfx::Rect& aligned_rect,
+                                     const gfx::Rect& result_rect,
+                                     ReusableThings* things);
+
+  // Like StartReadbackFromTexture(), except that this processes the two Y/UV
+  // result textures in |things| by using two framebuffers and two asynchronous
+  // readback operations. A single pixel transfer buffer is used to hold the
+  // results of both readbacks (i.e., each plane starts at a different offset in
+  // the transfer buffer).
+  //
+  // |aligned_rect| is the Rect returned from the RenderNV12Textures() call, and
+  // is required so that the CopyOutputResult sent at the end of this workflow
+  // will access the correct region of pixels.
+  void StartNV12ReadbackFromTextures(std::unique_ptr<CopyOutputRequest> request,
+                                     const gfx::Rect& aligned_rect,
+                                     const gfx::Rect& result_rect,
+                                     ReusableThings* things);
+
+  // Retrieves a cached ReusableThings instance for the given CopyOutputRequest
+  // source, or creates a new instance.
+  std::unique_ptr<ReusableThings> TakeReusableThingsOrCreate(
+      const base::UnguessableToken& requester);
+
+  // If |requester| is a valid UnguessableToken, this stashes the given
+  // ReusableThings instance in the cache for use in future CopyOutputRequests
+  // from the same requester. Otherwise, |things| is freed.
+  void StashReusableThingsOrDelete(const base::UnguessableToken& requester,
+                                   std::unique_ptr<ReusableThings> things);
+
+  // Queries the GL implementation to determine which is the more performance-
+  // optimal supported readback format: GL_RGBA or GL_BGRA_EXT, and memoizes the
+  // result for all future calls.
+  //
+  // Precondition: The GL context has a complete, bound framebuffer ready for
+  // readback.
+  GLenum GetOptimalReadbackFormat();
+
+  // Returns true if the red and blue channels should be swapped within the GPU,
+  // where such an operation has negligible cost, so that later the red-blue
+  // swap does not need to happen on the CPU (non-negligible cost).
+  bool ShouldSwapRedAndBlueForBitmapReadback();
+
+  void FinishReadPixelsWorkflow(ReadPixelsWorkflow*);
+  void FinishReadI420PlanesWorkflow(ReadI420PlanesWorkflow*, int plane);
+  void FinishReadNV12PlanesWorkflow(ReadNV12PlanesWorkflow* workflow,
+                                    int plane);
+
+  // Injected dependencies.
+  const raw_ptr<ContextProvider> context_provider_;
+  const raw_ptr<TextureDeleter> texture_deleter_;
+
+  // This increments by one for every call to FreeUnusedCachedResources(). It
+  // is meant to determine when cached resources should be freed because they
+  // are unlikely to see further use.
+  uint32_t purge_counter_ = 0;
+
+  // A cache of resources recently used in the execution of a stream of copy
+  // requests from the same source. Since this reflects the number of active
+  // video captures, it is expected to almost always be zero or one entry in
+  // size.
+  base::flat_map<base::UnguessableToken, std::unique_ptr<ReusableThings>>
+      cache_;
+
+  // This specifies whether the GPU+driver combination executes readback more
+  // efficiently using GL_RGBA or GL_BGRA_EXT format. This starts out as
+  // GL_NONE, which means "unknown," and will be determined at the time the
+  // first readback request is made.
+  GLenum optimal_readback_format_ = static_cast<GLenum>(0 /*GL_NONE*/);
+
+  // Purge cache entries that have not been used after this many calls to
+  // FreeUnusedCachedResources(). The choice of 60 is arbitrary, but on most
+  // platforms means that a somewhat-to-fully active compositor will cause
+  // things to be auto-purged after approx. 1-2 seconds of not being used.
+  static constexpr int kKeepalivePeriod = 60;
+
+  std::vector<std::unique_ptr<ReadPixelsWorkflow>> read_pixels_workflows_;
+  std::vector<std::unique_ptr<ReadI420PlanesWorkflow>> read_i420_workflows_;
+  std::vector<std::unique_ptr<ReadNV12PlanesWorkflow>> read_nv12_workflows_;
+
+  // Weak ptr to this class.
+  base::WeakPtrFactory<GLRendererCopier> weak_factory_{this};
+};
+
+}  // namespace viz
+
+#endif  // COMPONENTS_VIZ_SERVICE_DISPLAY_GL_RENDERER_COPIER_H_
diff --git components/viz/service/display/gl_renderer_draw_cache.cc components/viz/service/display/gl_renderer_draw_cache.cc
new file mode 100644
index 0000000000000..887eec8c2af43
--- /dev/null
+++ components/viz/service/display/gl_renderer_draw_cache.cc
@@ -0,0 +1,13 @@
+// Copyright 2012 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "components/viz/service/display/gl_renderer_draw_cache.h"
+
+namespace viz {
+
+TexturedQuadDrawCache::TexturedQuadDrawCache() = default;
+
+TexturedQuadDrawCache::~TexturedQuadDrawCache() = default;
+
+}  // namespace viz
diff --git components/viz/service/display/gl_renderer_draw_cache.h components/viz/service/display/gl_renderer_draw_cache.h
new file mode 100644
index 0000000000000..eb85528501dc1
--- /dev/null
+++ components/viz/service/display/gl_renderer_draw_cache.h
@@ -0,0 +1,62 @@
+// Copyright 2012 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef COMPONENTS_VIZ_SERVICE_DISPLAY_GL_RENDERER_DRAW_CACHE_H_
+#define COMPONENTS_VIZ_SERVICE_DISPLAY_GL_RENDERER_DRAW_CACHE_H_
+
+#include <vector>
+
+#include "components/viz/common/resources/resource_id.h"
+#include "components/viz/service/display/program_binding.h"
+#include "third_party/skia/include/core/SkColor.h"
+#include "ui/gfx/geometry/mask_filter_info.h"
+
+namespace viz {
+
+// Collects 4 floats at a time for easy upload to GL.
+struct Float4 {
+  float data[4];
+};
+
+// Collects 16 floats at a time for easy upload to GL.
+struct Float16 {
+  float data[16];
+};
+
+// A cache for storing textured quads to be drawn.  Stores the minimum required
+// data to tell if two back to back draws only differ in their transform. Quads
+// that only differ by transform may be coalesced into a single draw call.
+struct TexturedQuadDrawCache {
+  TexturedQuadDrawCache();
+
+  TexturedQuadDrawCache(const TexturedQuadDrawCache&) = delete;
+  TexturedQuadDrawCache& operator=(const TexturedQuadDrawCache&) = delete;
+
+  ~TexturedQuadDrawCache();
+
+  bool is_empty = true;
+
+  // Values tracked to determine if textured quads may be coalesced.
+  ProgramKey program_key;
+  ResourceId resource_id = kInvalidResourceId;
+  bool needs_blending = false;
+  bool nearest_neighbor = false;
+  SkColor background_color = 0;
+  gfx::MaskFilterInfo mask_filter_info;
+
+  // A cache for the coalesced quad data.
+  std::vector<Float4> uv_xform_data;
+  std::vector<float> vertex_opacity_data;
+  std::vector<Float16> matrix_data;
+
+  // Don't batch if tex clamp rect is given.
+  Float4 tex_clamp_rect_data;
+
+  // Video frames need special white level adjustment.
+  bool is_video_frame = false;
+};
+
+}  // namespace viz
+
+#endif  // COMPONENTS_VIZ_SERVICE_DISPLAY_GL_RENDERER_DRAW_CACHE_H_
diff --git components/viz/service/display/layer_quad.cc components/viz/service/display/layer_quad.cc
new file mode 100644
index 0000000000000..d7349d86d7922
--- /dev/null
+++ components/viz/service/display/layer_quad.cc
@@ -0,0 +1,121 @@
+// Copyright 2011 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "components/viz/service/display/layer_quad.h"
+
+#include <stddef.h>
+
+#include "base/check.h"
+#include "ui/gfx/geometry/quad_f.h"
+
+namespace viz {
+
+LayerQuad::Edge::Edge(const gfx::PointF& p, const gfx::PointF& q) {
+  if (p == q) {
+    degenerate_ = true;
+    return;
+  }
+  degenerate_ = false;
+  gfx::Vector2dF tangent(p.y() - q.y(), q.x() - p.x());
+  float cross2 = p.x() * q.y() - q.x() * p.y();
+
+  set(tangent.x(), tangent.y(), cross2);
+  scale(1.0f / tangent.Length());
+}
+
+gfx::PointF LayerQuad::Edge::Intersect(const LayerQuad::Edge& e) const {
+  DCHECK(!degenerate());
+  DCHECK(!e.degenerate());
+
+  return gfx::PointF((y() * e.z() - e.y() * z()) / (x() * e.y() - e.x() * y()),
+                     (x() * e.z() - e.x() * z()) / (e.x() * y() - x() * e.y()));
+}
+
+LayerQuad::LayerQuad(const gfx::QuadF& quad) {
+  // Create edges.
+  left_ = Edge(quad.p4(), quad.p1());
+  right_ = Edge(quad.p2(), quad.p3());
+  top_ = Edge(quad.p1(), quad.p2());
+  bottom_ = Edge(quad.p3(), quad.p4());
+
+  float sign = quad.IsCounterClockwise() ? -1 : 1;
+  left_.scale(sign);
+  right_.scale(sign);
+  top_.scale(sign);
+  bottom_.scale(sign);
+}
+
+LayerQuad::LayerQuad(const Edge& left,
+                     const Edge& top,
+                     const Edge& right,
+                     const Edge& bottom)
+    : left_(left), top_(top), right_(right), bottom_(bottom) {}
+
+gfx::QuadF LayerQuad::ToQuadF() const {
+  size_t num_degenerate_edges = left_.degenerate() + right_.degenerate() +
+                                top_.degenerate() + bottom_.degenerate();
+  if (num_degenerate_edges > 1) {
+    return gfx::QuadF();
+  }
+
+  if (left_.degenerate()) {
+    return gfx::QuadF(top_.Intersect(bottom_), top_.Intersect(right_),
+                      right_.Intersect(bottom_), bottom_.Intersect(top_));
+  }
+  if (right_.degenerate()) {
+    return gfx::QuadF(left_.Intersect(top_), top_.Intersect(bottom_),
+                      bottom_.Intersect(top_), bottom_.Intersect(left_));
+  }
+  if (top_.degenerate()) {
+    return gfx::QuadF(left_.Intersect(right_), right_.Intersect(left_),
+                      right_.Intersect(bottom_), bottom_.Intersect(left_));
+  }
+  if (bottom_.degenerate()) {
+    return gfx::QuadF(left_.Intersect(top_), top_.Intersect(right_),
+                      right_.Intersect(left_), left_.Intersect(right_));
+  }
+  return gfx::QuadF(left_.Intersect(top_), top_.Intersect(right_),
+                    right_.Intersect(bottom_), bottom_.Intersect(left_));
+}
+
+void LayerQuad::ToFloatArray(float flattened[12]) const {
+  if (left_.degenerate()) {
+    flattened[0] = bottom_.x();
+    flattened[1] = bottom_.y();
+    flattened[2] = bottom_.z();
+  } else {
+    flattened[0] = left_.x();
+    flattened[1] = left_.y();
+    flattened[2] = left_.z();
+  }
+  if (top_.degenerate()) {
+    flattened[3] = left_.x();
+    flattened[4] = left_.y();
+    flattened[5] = left_.z();
+  } else {
+    flattened[3] = top_.x();
+    flattened[4] = top_.y();
+    flattened[5] = top_.z();
+  }
+  if (right_.degenerate()) {
+    flattened[6] = top_.x();
+    flattened[7] = top_.y();
+    flattened[8] = top_.z();
+  } else {
+    flattened[6] = right_.x();
+    flattened[7] = right_.y();
+    flattened[8] = right_.z();
+  }
+  if (bottom_.degenerate()) {
+    flattened[9] = right_.x();
+    flattened[10] = right_.y();
+    flattened[11] = right_.z();
+  } else {
+    flattened[9] = bottom_.x();
+    flattened[10] = bottom_.y();
+    flattened[11] = bottom_.z();
+  }
+}
+
+}  // namespace viz
diff --git components/viz/service/display/layer_quad.h components/viz/service/display/layer_quad.h
new file mode 100644
index 0000000000000..e6cd61fa457bc
--- /dev/null
+++ components/viz/service/display/layer_quad.h
@@ -0,0 +1,110 @@
+// Copyright 2011 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef COMPONENTS_VIZ_SERVICE_DISPLAY_LAYER_QUAD_H_
+#define COMPONENTS_VIZ_SERVICE_DISPLAY_LAYER_QUAD_H_
+
+#include "components/viz/service/viz_service_export.h"
+#include "ui/gfx/geometry/point_f.h"
+
+namespace gfx {
+class QuadF;
+}
+
+namespace viz {
+
+constexpr float kAntiAliasingInflateDistance = 0.5f;
+
+class VIZ_SERVICE_EXPORT LayerQuad {
+ public:
+  class VIZ_SERVICE_EXPORT Edge {
+   public:
+    Edge() : x_(0), y_(0), z_(0), degenerate_(false) {}
+    Edge(const gfx::PointF& p, const gfx::PointF& q);
+
+    float x() const { return x_; }
+    float y() const { return y_; }
+    float z() const { return z_; }
+
+    void set_x(float x) { x_ = x; }
+    void set_y(float y) { y_ = y; }
+    void set_z(float z) { z_ = z; }
+    void set(float x, float y, float z) {
+      x_ = x;
+      y_ = y;
+      z_ = z;
+    }
+
+    void move_x(float dx) { x_ += dx; }
+    void move_y(float dy) { y_ += dy; }
+    void move_z(float dz) { z_ += dz; }
+    void move(float dx, float dy, float dz) {
+      x_ += dx;
+      y_ += dy;
+      z_ += dz;
+    }
+
+    void scale_x(float sx) { x_ *= sx; }
+    void scale_y(float sy) { y_ *= sy; }
+    void scale_z(float sz) { z_ *= sz; }
+    void scale(float sx, float sy, float sz) {
+      x_ *= sx;
+      y_ *= sy;
+      z_ *= sz;
+    }
+    void scale(float s) { scale(s, s, s); }
+
+    bool degenerate() const { return degenerate_; }
+
+    gfx::PointF Intersect(const Edge& e) const;
+
+   private:
+    float x_;
+    float y_;
+    float z_;
+    bool degenerate_;
+  };
+
+  LayerQuad(const Edge& left,
+            const Edge& top,
+            const Edge& right,
+            const Edge& bottom);
+  explicit LayerQuad(const gfx::QuadF& quad);
+
+  LayerQuad(const LayerQuad&) = delete;
+  LayerQuad& operator=(const LayerQuad&) = delete;
+
+  Edge left() const { return left_; }
+  Edge top() const { return top_; }
+  Edge right() const { return right_; }
+  Edge bottom() const { return bottom_; }
+
+  void InflateX(float dx) {
+    left_.move_z(dx);
+    right_.move_z(dx);
+  }
+  void InflateY(float dy) {
+    top_.move_z(dy);
+    bottom_.move_z(dy);
+  }
+  void Inflate(float d) {
+    InflateX(d);
+    InflateY(d);
+  }
+  void InflateAntiAliasingDistance() { Inflate(kAntiAliasingInflateDistance); }
+
+  gfx::QuadF ToQuadF() const;
+
+  void ToFloatArray(float flattened[12]) const;
+
+ private:
+  Edge left_;
+  Edge top_;
+  Edge right_;
+  Edge bottom_;
+};
+
+}  // namespace viz
+
+#endif  // COMPONENTS_VIZ_SERVICE_DISPLAY_LAYER_QUAD_H_
diff --git components/viz/service/display/layer_quad_unittest.cc components/viz/service/display/layer_quad_unittest.cc
new file mode 100644
index 0000000000000..6de10f5b62ae4
--- /dev/null
+++ components/viz/service/display/layer_quad_unittest.cc
@@ -0,0 +1,69 @@
+// Copyright 2011 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "components/viz/service/display/layer_quad.h"
+
+#include "testing/gtest/include/gtest/gtest.h"
+#include "ui/gfx/geometry/quad_f.h"
+
+namespace viz {
+namespace {
+
+TEST(LayerQuadTest, QuadFConversion) {
+  gfx::PointF p1(-0.5f, -0.5f);
+  gfx::PointF p2(0.5f, -0.5f);
+  gfx::PointF p3(0.5f, 0.5f);
+  gfx::PointF p4(-0.5f, 0.5f);
+
+  gfx::QuadF quad_cw(p1, p2, p3, p4);
+  LayerQuad layer_quad_cw(quad_cw);
+  EXPECT_EQ(layer_quad_cw.ToQuadF(), quad_cw);
+
+  gfx::QuadF quad_ccw(p1, p4, p3, p2);
+  LayerQuad layer_quad_ccw(quad_ccw);
+  EXPECT_EQ(layer_quad_ccw.ToQuadF(), quad_ccw);
+}
+
+TEST(LayerQuadTest, Inflate) {
+  gfx::PointF p1(-0.5f, -0.5f);
+  gfx::PointF p2(0.5f, -0.5f);
+  gfx::PointF p3(0.5f, 0.5f);
+  gfx::PointF p4(-0.5f, 0.5f);
+
+  gfx::QuadF quad(p1, p2, p3, p4);
+  LayerQuad layer_quad(quad);
+  quad.Scale(2.f, 2.f);
+  layer_quad.Inflate(0.5f);
+  EXPECT_EQ(layer_quad.ToQuadF(), quad);
+}
+
+TEST(LayerQuadTest, Degenerate) {
+  gfx::QuadF quad;
+  gfx::PointF p1(1.0f, 1.0f);
+  gfx::PointF p2(0.0f, 1.0f);
+  gfx::PointF p3(1.0f, 0.0f);
+  gfx::QuadF triangle(p1, p2, p3, p1);
+
+  LayerQuad::Edge e1d(p1, p1);
+  LayerQuad::Edge e2d(p2, p2);
+  LayerQuad::Edge e2(p1, p2);
+  LayerQuad::Edge e3(p2, p3);
+  LayerQuad::Edge e4(p3, p1);
+  EXPECT_TRUE(e1d.degenerate());
+  EXPECT_TRUE(e2d.degenerate());
+  EXPECT_FALSE(e2.degenerate());
+  EXPECT_FALSE(e3.degenerate());
+  EXPECT_FALSE(e4.degenerate());
+
+  LayerQuad degenerate_quad(e1d, e2d, e2, e3);
+  // With more than one degenerate edge, we expect the quad to be zero.
+  EXPECT_EQ(quad, degenerate_quad.ToQuadF());
+
+  LayerQuad triangle_quad(e1d, e2, e3, e4);
+  // With only one degenerate edge, we expect the quad to be a triangle.
+  EXPECT_EQ(triangle, triangle_quad.ToQuadF());
+}
+
+}  // namespace
+}  // namespace viz
diff --git components/viz/service/display/program_binding.cc components/viz/service/display/program_binding.cc
new file mode 100644
index 0000000000000..488151c358783
--- /dev/null
+++ components/viz/service/display/program_binding.cc
@@ -0,0 +1,301 @@
+// Copyright 2011 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "components/viz/service/display/program_binding.h"
+
+#include "base/logging.h"
+#include "base/trace_event/trace_event.h"
+#include "components/viz/service/display/geometry_binding.h"
+#include "gpu/GLES2/gl2extchromium.h"
+#include "gpu/command_buffer/client/gles2_interface.h"
+#include "ui/gfx/color_transform.h"
+
+using gpu::gles2::GLES2Interface;
+
+namespace viz {
+
+ProgramKey::ProgramKey() = default;
+
+ProgramKey::ProgramKey(const ProgramKey& other) = default;
+
+ProgramKey::~ProgramKey() = default;
+
+bool ProgramKey::operator==(const ProgramKey& other) const {
+  return type_ == other.type_ && precision_ == other.precision_ &&
+         sampler_ == other.sampler_ && blend_mode_ == other.blend_mode_ &&
+         aa_mode_ == other.aa_mode_ && is_opaque_ == other.is_opaque_ &&
+         premultiplied_alpha_ == other.premultiplied_alpha_ &&
+         has_background_color_ == other.has_background_color_ &&
+         has_tex_clamp_rect_ == other.has_tex_clamp_rect_ &&
+         mask_mode_ == other.mask_mode_ &&
+         mask_for_background_ == other.mask_for_background_ &&
+         has_color_matrix_ == other.has_color_matrix_ &&
+         yuv_alpha_texture_mode_ == other.yuv_alpha_texture_mode_ &&
+         uv_texture_mode_ == other.uv_texture_mode_ &&
+         color_conversion_mode_ == other.color_conversion_mode_ &&
+         color_transform_ == other.color_transform_ &&
+         has_output_color_matrix_ == other.has_output_color_matrix_ &&
+         has_rounded_corner_ == other.has_rounded_corner_;
+}
+
+bool ProgramKey::operator!=(const ProgramKey& other) const {
+  return !(*this == other);
+}
+
+// static
+ProgramKey ProgramKey::DebugBorder() {
+  ProgramKey result;
+  result.type_ = PROGRAM_TYPE_DEBUG_BORDER;
+  return result;
+}
+
+// static
+ProgramKey ProgramKey::SolidColor(AAMode aa_mode,
+                                  bool tint_color,
+                                  bool rounded_corner) {
+  ProgramKey result;
+  result.type_ = PROGRAM_TYPE_SOLID_COLOR;
+  result.aa_mode_ = aa_mode;
+  result.has_tint_color_matrix_ = tint_color;
+  result.has_rounded_corner_ = rounded_corner;
+  return result;
+}
+
+// static
+ProgramKey ProgramKey::Tile(TexCoordPrecision precision,
+                            SamplerType sampler,
+                            AAMode aa_mode,
+                            PremultipliedAlphaMode premultiplied_alpha,
+                            bool is_opaque,
+                            bool has_tex_clamp_rect,
+                            bool tint_color,
+                            bool rounded_corner) {
+  ProgramKey result;
+  result.type_ = PROGRAM_TYPE_TILE;
+  result.precision_ = precision;
+  result.sampler_ = sampler;
+  result.aa_mode_ = aa_mode;
+  result.is_opaque_ = is_opaque;
+  result.has_tex_clamp_rect_ = has_tex_clamp_rect;
+  result.has_tint_color_matrix_ = tint_color;
+  result.premultiplied_alpha_ = premultiplied_alpha;
+  result.has_rounded_corner_ = rounded_corner;
+  return result;
+}
+
+// static
+ProgramKey ProgramKey::Texture(TexCoordPrecision precision,
+                               SamplerType sampler,
+                               PremultipliedAlphaMode premultiplied_alpha,
+                               bool has_background_color,
+                               bool has_tex_clamp_rect,
+                               bool tint_color,
+                               bool rounded_corner) {
+  ProgramKey result;
+  result.type_ = PROGRAM_TYPE_TEXTURE;
+  result.precision_ = precision;
+  result.sampler_ = sampler;
+  result.premultiplied_alpha_ = premultiplied_alpha;
+  result.has_background_color_ = has_background_color;
+  result.has_tex_clamp_rect_ = has_tex_clamp_rect;
+  result.has_tint_color_matrix_ = tint_color;
+  result.has_rounded_corner_ = rounded_corner;
+  return result;
+}
+
+// static
+ProgramKey ProgramKey::RenderPass(TexCoordPrecision precision,
+                                  SamplerType sampler,
+                                  BlendMode blend_mode,
+                                  AAMode aa_mode,
+                                  MaskMode mask_mode,
+                                  bool mask_for_background,
+                                  bool has_color_matrix,
+                                  bool tint_color,
+                                  bool rounded_corner) {
+  ProgramKey result;
+  result.type_ = PROGRAM_TYPE_RENDER_PASS;
+  result.precision_ = precision;
+  result.sampler_ = sampler;
+  result.blend_mode_ = blend_mode;
+  result.aa_mode_ = aa_mode;
+  result.mask_mode_ = mask_mode;
+  result.mask_for_background_ = mask_for_background;
+  result.has_color_matrix_ = has_color_matrix;
+  result.has_tint_color_matrix_ = tint_color;
+  result.has_rounded_corner_ = rounded_corner;
+  return result;
+}
+
+// static
+ProgramKey ProgramKey::VideoStream(TexCoordPrecision precision,
+                                   bool rounded_corner) {
+  ProgramKey result;
+  result.type_ = PROGRAM_TYPE_VIDEO_STREAM;
+  result.precision_ = precision;
+  result.sampler_ = SAMPLER_TYPE_EXTERNAL_OES;
+  result.has_rounded_corner_ = rounded_corner;
+  return result;
+}
+
+// static
+ProgramKey ProgramKey::YUVVideo(TexCoordPrecision precision,
+                                SamplerType sampler,
+                                YUVAlphaTextureMode yuv_alpha_texture_mode,
+                                UVTextureMode uv_texture_mode,
+                                bool tint_color,
+                                bool rounded_corner) {
+  ProgramKey result;
+  result.type_ = PROGRAM_TYPE_YUV_VIDEO;
+  result.precision_ = precision;
+  result.sampler_ = sampler;
+  result.yuv_alpha_texture_mode_ = yuv_alpha_texture_mode;
+  DCHECK(yuv_alpha_texture_mode == YUV_NO_ALPHA_TEXTURE ||
+         yuv_alpha_texture_mode == YUV_HAS_ALPHA_TEXTURE);
+  result.uv_texture_mode_ = uv_texture_mode;
+  DCHECK(uv_texture_mode == UV_TEXTURE_MODE_UV ||
+         uv_texture_mode == UV_TEXTURE_MODE_U_V);
+  result.has_tint_color_matrix_ = tint_color;
+  result.has_rounded_corner_ = rounded_corner;
+  return result;
+}
+
+void ProgramKey::SetColorTransform(const gfx::ColorTransform* transform) {
+  color_transform_ = nullptr;
+  if (transform->IsIdentity()) {
+    color_conversion_mode_ = COLOR_CONVERSION_MODE_NONE;
+  } else {
+    color_conversion_mode_ = COLOR_CONVERSION_MODE_SHADER;
+    color_transform_ = transform;
+  }
+}
+
+ProgramBindingBase::ProgramBindingBase()
+    : program_(0),
+      vertex_shader_id_(0),
+      fragment_shader_id_(0),
+      initialized_(false) {}
+
+ProgramBindingBase::~ProgramBindingBase() {
+  // If you hit these asserts, you initialized but forgot to call Cleanup().
+  DCHECK(!program_);
+  DCHECK(!vertex_shader_id_);
+  DCHECK(!fragment_shader_id_);
+  DCHECK(!initialized_);
+}
+
+bool ProgramBindingBase::Init(GLES2Interface* context,
+                              const std::string& vertex_shader,
+                              const std::string& fragment_shader) {
+  TRACE_EVENT0("viz", "ProgramBindingBase::init");
+  vertex_shader_id_ = LoadShader(context, GL_VERTEX_SHADER, vertex_shader);
+  if (!vertex_shader_id_)
+    return false;
+
+  fragment_shader_id_ =
+      LoadShader(context, GL_FRAGMENT_SHADER, fragment_shader);
+  if (!fragment_shader_id_) {
+    context->DeleteShader(vertex_shader_id_);
+    vertex_shader_id_ = 0;
+    return false;
+  }
+
+  program_ =
+      CreateShaderProgram(context, vertex_shader_id_, fragment_shader_id_);
+  return !!program_;
+}
+
+bool ProgramBindingBase::Link(GLES2Interface* context) {
+  context->LinkProgram(program_);
+  CleanupShaders(context);
+  if (!program_)
+    return false;
+#ifndef NDEBUG
+  int linked = 0;
+  context->GetProgramiv(program_, GL_LINK_STATUS, &linked);
+  if (!linked) {
+    char buffer[1024] = "";
+    context->GetProgramInfoLog(program_, sizeof(buffer), nullptr, buffer);
+    DLOG(ERROR) << "Error compiling shader: " << buffer;
+    return false;
+  }
+#endif
+  return true;
+}
+
+void ProgramBindingBase::Cleanup(GLES2Interface* context) {
+  initialized_ = false;
+  if (!program_)
+    return;
+
+  DCHECK(context);
+  context->DeleteProgram(program_);
+  program_ = 0;
+
+  CleanupShaders(context);
+}
+
+unsigned ProgramBindingBase::LoadShader(GLES2Interface* context,
+                                        unsigned type,
+                                        const std::string& shader_source) {
+  unsigned shader = context->CreateShader(type);
+  if (!shader)
+    return 0u;
+
+  const char* shader_source_str[] = {shader_source.data()};
+  int shader_length[] = {static_cast<int>(shader_source.length())};
+  context->ShaderSource(shader, 1, shader_source_str, shader_length);
+  context->CompileShader(shader);
+#if EXPENSIVE_DCHECKS_ARE_ON()
+  int compiled = 0;
+  context->GetShaderiv(shader, GL_COMPILE_STATUS, &compiled);
+  if (!compiled) {
+    char buffer[1024] = "";
+    context->GetShaderInfoLog(shader, sizeof(buffer), nullptr, buffer);
+    DLOG(ERROR) << "Error compiling shader: " << buffer
+                << "\n shader program: " << shader_source;
+    return 0u;
+  }
+#endif  // EXPENSIVE_DCHECKS_ARE_ON()
+  return shader;
+}
+
+unsigned ProgramBindingBase::CreateShaderProgram(GLES2Interface* context,
+                                                 unsigned vertex_shader,
+                                                 unsigned fragment_shader) {
+  unsigned program_object = context->CreateProgram();
+  if (!program_object)
+    return 0;
+
+  context->AttachShader(program_object, vertex_shader);
+  context->AttachShader(program_object, fragment_shader);
+
+  // Bind the common attrib locations.
+  context->BindAttribLocation(
+      program_object, GeometryBinding::PositionAttribLocation(), "a_position");
+  context->BindAttribLocation(
+      program_object, GeometryBinding::TexCoordAttribLocation(), "a_texCoord");
+  context->BindAttribLocation(program_object,
+                              GeometryBinding::TriangleIndexAttribLocation(),
+                              "a_index");
+
+  return program_object;
+}
+
+void ProgramBindingBase::CleanupShaders(GLES2Interface* context) {
+  if (vertex_shader_id_) {
+    context->DeleteShader(vertex_shader_id_);
+    vertex_shader_id_ = 0;
+  }
+  if (fragment_shader_id_) {
+    context->DeleteShader(fragment_shader_id_);
+    fragment_shader_id_ = 0;
+  }
+}
+
+bool ProgramBindingBase::IsContextLost(GLES2Interface* context) {
+  return context->GetGraphicsResetStatusKHR() != GL_NO_ERROR;
+}
+
+}  // namespace viz
diff --git components/viz/service/display/program_binding.h components/viz/service/display/program_binding.h
new file mode 100644
index 0000000000000..b03673f9266e8
--- /dev/null
+++ components/viz/service/display/program_binding.h
@@ -0,0 +1,480 @@
+// Copyright 2011 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef COMPONENTS_VIZ_SERVICE_DISPLAY_PROGRAM_BINDING_H_
+#define COMPONENTS_VIZ_SERVICE_DISPLAY_PROGRAM_BINDING_H_
+
+#include <string>
+
+#include "base/check_op.h"
+#include "base/memory/raw_ptr.h"
+#include "build/build_config.h"
+#include "components/viz/common/gpu/context_provider.h"
+#include "components/viz/service/display/shader.h"
+#include "components/viz/service/viz_service_export.h"
+
+namespace gfx {
+class ColorTransform;
+}
+
+namespace gpu {
+namespace gles2 {
+class GLES2Interface;
+}
+}  // namespace gpu
+
+namespace viz {
+
+class VIZ_SERVICE_EXPORT ProgramBindingBase {
+ public:
+  ProgramBindingBase();
+
+  ProgramBindingBase(const ProgramBindingBase&) = delete;
+  ProgramBindingBase& operator=(const ProgramBindingBase&) = delete;
+
+  ~ProgramBindingBase();
+
+  bool Init(gpu::gles2::GLES2Interface* context,
+            const std::string& vertex_shader,
+            const std::string& fragment_shader);
+  bool Link(gpu::gles2::GLES2Interface* context);
+  void Cleanup(gpu::gles2::GLES2Interface* context);
+
+  unsigned program() const { return program_; }
+  bool initialized() const { return initialized_; }
+
+ protected:
+  unsigned LoadShader(gpu::gles2::GLES2Interface* context,
+                      unsigned type,
+                      const std::string& shader_source);
+  unsigned CreateShaderProgram(gpu::gles2::GLES2Interface* context,
+                               unsigned vertex_shader,
+                               unsigned fragment_shader);
+  void CleanupShaders(gpu::gles2::GLES2Interface* context);
+
+  bool IsContextLost(gpu::gles2::GLES2Interface* context);
+
+  unsigned program_;
+  unsigned vertex_shader_id_;
+  unsigned fragment_shader_id_;
+  bool initialized_;
+};
+
+enum ProgramType {
+  PROGRAM_TYPE_DEBUG_BORDER,
+  PROGRAM_TYPE_SOLID_COLOR,
+  PROGRAM_TYPE_TILE,
+  PROGRAM_TYPE_TEXTURE,
+  PROGRAM_TYPE_RENDER_PASS,
+  PROGRAM_TYPE_VIDEO_STREAM,
+  PROGRAM_TYPE_YUV_VIDEO,
+};
+
+class VIZ_SERVICE_EXPORT ProgramKey {
+ public:
+  ProgramKey();
+  ProgramKey(const ProgramKey& other);
+  ~ProgramKey();
+
+  static ProgramKey DebugBorder();
+  static ProgramKey SolidColor(AAMode aa_mode,
+                               bool tint_color,
+                               bool rounded_corner);
+  static ProgramKey Tile(TexCoordPrecision precision,
+                         SamplerType sampler,
+                         AAMode aa_mode,
+                         PremultipliedAlphaMode premultiplied_alpha,
+                         bool is_opaque,
+                         bool has_tex_clamp_rect,
+                         bool tint_color,
+                         bool rounded_corner);
+  static ProgramKey Texture(TexCoordPrecision precision,
+                            SamplerType sampler,
+                            PremultipliedAlphaMode premultiplied_alpha,
+                            bool has_background_color,
+                            bool has_tex_clamp_rect,
+                            bool tint_color,
+                            bool rounded_corner);
+
+  // TODO(ccameron): Merge |mask_for_background| into MaskMode.
+  static ProgramKey RenderPass(TexCoordPrecision precision,
+                               SamplerType sampler,
+                               BlendMode blend_mode,
+                               AAMode aa_mode,
+                               MaskMode mask_mode,
+                               bool mask_for_background,
+                               bool has_color_matrix,
+                               bool tint_color,
+                               bool rounded_corner);
+  static ProgramKey VideoStream(TexCoordPrecision precision,
+                                bool rounded_corner);
+  static ProgramKey YUVVideo(TexCoordPrecision precision,
+                             SamplerType sampler,
+                             YUVAlphaTextureMode yuv_alpha_texture_mode,
+                             UVTextureMode uv_texture_mode,
+                             bool tint_color,
+                             bool rounded_corner);
+
+  bool operator==(const ProgramKey& other) const;
+  bool operator!=(const ProgramKey& other) const;
+
+  void SetColorTransform(const gfx::ColorTransform* transform);
+
+  bool has_output_color_matrix() const { return has_output_color_matrix_; }
+  void set_has_output_color_matrix(bool value) {
+    has_output_color_matrix_ = value;
+  }
+  TexCoordPrecision tex_coord_precision() const { return precision_; }
+
+  ProgramType type() const { return type_; }
+
+ private:
+  friend struct ProgramKeyHash;
+  friend class Program;
+
+  ProgramType type_ = PROGRAM_TYPE_DEBUG_BORDER;
+  TexCoordPrecision precision_ = TEX_COORD_PRECISION_NA;
+  SamplerType sampler_ = SAMPLER_TYPE_NA;
+  BlendMode blend_mode_ = BLEND_MODE_NONE;
+  AAMode aa_mode_ = NO_AA;
+  bool is_opaque_ = false;
+
+  PremultipliedAlphaMode premultiplied_alpha_ = PREMULTIPLIED_ALPHA;
+  bool has_background_color_ = false;
+
+  MaskMode mask_mode_ = NO_MASK;
+  bool mask_for_background_ = false;
+  bool has_color_matrix_ = false;
+
+  YUVAlphaTextureMode yuv_alpha_texture_mode_ = YUV_NO_ALPHA_TEXTURE;
+  UVTextureMode uv_texture_mode_ = UV_TEXTURE_MODE_NA;
+
+  ColorConversionMode color_conversion_mode_ = COLOR_CONVERSION_MODE_NONE;
+  raw_ptr<const gfx::ColorTransform> color_transform_ = nullptr;
+
+  bool has_tex_clamp_rect_ = false;
+
+  bool has_output_color_matrix_ = false;
+  bool has_tint_color_matrix_ = false;
+  bool has_rounded_corner_ = false;
+};
+
+struct ProgramKeyHash {
+  size_t operator()(const ProgramKey& key) const {
+    return (static_cast<size_t>(key.type_) << 0) ^
+           (static_cast<size_t>(key.precision_) << 3) ^
+           (static_cast<size_t>(key.sampler_) << 6) ^
+           (static_cast<size_t>(key.blend_mode_) << 9) ^
+           (static_cast<size_t>(key.aa_mode_) << 15) ^
+           (static_cast<size_t>(key.is_opaque_) << 17) ^
+           (static_cast<size_t>(key.premultiplied_alpha_) << 19) ^
+           (static_cast<size_t>(key.has_background_color_) << 20) ^
+           (static_cast<size_t>(key.mask_mode_) << 21) ^
+           (static_cast<size_t>(key.mask_for_background_) << 22) ^
+           (static_cast<size_t>(key.has_color_matrix_) << 23) ^
+           (static_cast<size_t>(key.yuv_alpha_texture_mode_) << 24) ^
+           (static_cast<size_t>(key.uv_texture_mode_) << 25) ^
+           (static_cast<size_t>(key.color_conversion_mode_) << 26) ^
+           (static_cast<size_t>(key.has_tex_clamp_rect_) << 28) ^
+           (static_cast<size_t>(key.has_output_color_matrix_) << 29) ^
+           (static_cast<size_t>(key.has_tint_color_matrix_) << 30) ^
+           (static_cast<size_t>(key.has_rounded_corner_) << 31);
+  }
+};
+
+class VIZ_SERVICE_EXPORT Program : public ProgramBindingBase {
+ public:
+  Program() {}
+
+  Program(const Program&) = delete;
+  Program& operator=(const Program&) = delete;
+
+  void Initialize(ContextProvider* context_provider, const ProgramKey& key) {
+    // Set parameters that are common to all sub-classes.
+    vertex_shader_.aa_mode_ = key.aa_mode_;
+    fragment_shader_.aa_mode_ = key.aa_mode_;
+    fragment_shader_.blend_mode_ = key.blend_mode_;
+    fragment_shader_.tex_coord_precision_ = key.precision_;
+    fragment_shader_.sampler_type_ = key.sampler_;
+    fragment_shader_.premultiply_alpha_mode_ = key.premultiplied_alpha_;
+    fragment_shader_.mask_mode_ = key.mask_mode_;
+    fragment_shader_.mask_for_background_ = key.mask_for_background_;
+    fragment_shader_.color_conversion_mode_ = key.color_conversion_mode_;
+    fragment_shader_.color_transform_ = key.color_transform_;
+    fragment_shader_.has_output_color_matrix_ = key.has_output_color_matrix_;
+    fragment_shader_.has_tint_color_matrix_ = key.has_tint_color_matrix_;
+    fragment_shader_.has_rounded_corner_ = key.has_rounded_corner_;
+
+    switch (key.type_) {
+      case PROGRAM_TYPE_DEBUG_BORDER:
+        InitializeDebugBorderProgram();
+        break;
+      case PROGRAM_TYPE_SOLID_COLOR:
+        InitializeSolidColorProgram(key);
+        break;
+      case PROGRAM_TYPE_TILE:
+        InitializeTileProgram(key);
+        break;
+      case PROGRAM_TYPE_TEXTURE:
+        InitializeTextureProgram(key);
+        break;
+      case PROGRAM_TYPE_RENDER_PASS:
+        InitializeRenderPassProgram(key);
+        break;
+      case PROGRAM_TYPE_VIDEO_STREAM:
+        InitializeVideoStreamProgram(key);
+        break;
+      case PROGRAM_TYPE_YUV_VIDEO:
+        InitializeYUVVideo(key);
+        break;
+    }
+    InitializeInternal(context_provider);
+  }
+
+  const VertexShader& vertex_shader() const { return vertex_shader_; }
+  const FragmentShader& fragment_shader() const { return fragment_shader_; }
+
+  // Functions for querying uniform locations.
+  int vertex_tex_transform_location() const {
+    return vertex_shader_.vertex_tex_transform_location_;
+  }
+  int tex_matrix_location() const {
+    return vertex_shader_.tex_matrix_location_;
+  }
+  int ya_tex_scale_location() const {
+    return vertex_shader_.ya_tex_scale_location_;
+  }
+  int ya_tex_offset_location() const {
+    return vertex_shader_.ya_tex_offset_location_;
+  }
+  int uv_tex_scale_location() const {
+    return vertex_shader_.uv_tex_scale_location_;
+  }
+  int uv_tex_offset_location() const {
+    return vertex_shader_.uv_tex_offset_location_;
+  }
+  int matrix_location() const { return vertex_shader_.matrix_location_; }
+  int vertex_opacity_location() const {
+    return vertex_shader_.vertex_opacity_location_;
+  }
+  int viewport_location() const { return vertex_shader_.viewport_location_; }
+  int edge_location() const { return vertex_shader_.edge_location_; }
+  int quad_location() const { return vertex_shader_.quad_location_; }
+
+  int sampler_location() const { return fragment_shader_.sampler_location_; }
+  int alpha_location() const { return fragment_shader_.alpha_location_; }
+  int color_location() const { return fragment_shader_.color_location_; }
+  int background_color_location() const {
+    return fragment_shader_.background_color_location_;
+  }
+  int fragment_tex_transform_location() const {
+    return fragment_shader_.fragment_tex_transform_location_;
+  }
+  int backdrop_location() const { return fragment_shader_.backdrop_location_; }
+  int backdrop_rect_location() const {
+    return fragment_shader_.backdrop_rect_location_;
+  }
+  int original_backdrop_location() const {
+    return fragment_shader_.original_backdrop_location_;
+  }
+  int mask_sampler_location() const {
+    return fragment_shader_.mask_sampler_location_;
+  }
+  int mask_tex_coord_scale_location() const {
+    return fragment_shader_.mask_tex_coord_scale_location_;
+  }
+  int mask_tex_coord_offset_location() const {
+    return fragment_shader_.mask_tex_coord_offset_location_;
+  }
+  int color_matrix_location() const {
+    return fragment_shader_.color_matrix_location_;
+  }
+  int color_offset_location() const {
+    return fragment_shader_.color_offset_location_;
+  }
+  int tex_clamp_rect_location() const {
+    return fragment_shader_.tex_clamp_rect_location_;
+  }
+  int y_texture_location() const {
+    return fragment_shader_.y_texture_location_;
+  }
+  int u_texture_location() const {
+    return fragment_shader_.u_texture_location_;
+  }
+  int v_texture_location() const {
+    return fragment_shader_.v_texture_location_;
+  }
+  int uv_texture_location() const {
+    return fragment_shader_.uv_texture_location_;
+  }
+  int a_texture_location() const {
+    return fragment_shader_.a_texture_location_;
+  }
+  int resource_multiplier_location() const {
+    return fragment_shader_.resource_multiplier_location_;
+  }
+  int resource_offset_location() const {
+    return fragment_shader_.resource_offset_location_;
+  }
+  int ya_clamp_rect_location() const {
+    return fragment_shader_.ya_clamp_rect_location_;
+  }
+  int uv_clamp_rect_location() const {
+    return fragment_shader_.uv_clamp_rect_location_;
+  }
+  int output_color_matrix_location() const {
+    return fragment_shader_.output_color_matrix_location_;
+  }
+  int tint_color_matrix_location() const {
+    return fragment_shader_.tint_color_matrix_location_;
+  }
+  int rounded_corner_rect_location() const {
+    return fragment_shader_.rounded_corner_rect_location_;
+  }
+  int rounded_corner_radius_location() const {
+    return fragment_shader_.rounded_corner_radius_location_;
+  }
+
+  const gfx::ColorTransform* color_transform_for_testing() const {
+    return fragment_shader_.color_transform_;
+  }
+
+ private:
+  void InitializeDebugBorderProgram() {
+    // Initialize fragment program.
+    fragment_shader_.input_color_type_ = INPUT_COLOR_SOURCE_UNIFORM;
+    fragment_shader_.frag_color_mode_ = FRAG_COLOR_MODE_DEFAULT;
+  }
+
+  void InitializeSolidColorProgram(const ProgramKey& key) {
+    // Initialize vertex program.
+    vertex_shader_.position_source_ = POSITION_SOURCE_ATTRIBUTE_INDEXED_UNIFORM;
+#if BUILDFLAG(IS_ANDROID)
+    if (key.aa_mode_ == NO_AA)
+      vertex_shader_.has_dummy_variables_ = true;
+#endif
+
+    // Initialize fragment program.
+    fragment_shader_.input_color_type_ = INPUT_COLOR_SOURCE_UNIFORM;
+    fragment_shader_.frag_color_mode_ = FRAG_COLOR_MODE_DEFAULT;
+  }
+
+  void InitializeTileProgram(const ProgramKey& key) {
+    // Initialize vertex program.
+    vertex_shader_.position_source_ = POSITION_SOURCE_ATTRIBUTE_INDEXED_UNIFORM;
+    vertex_shader_.tex_coord_transform_ = TEX_COORD_TRANSFORM_VEC4;
+    vertex_shader_.tex_coord_source_ = TEX_COORD_SOURCE_ATTRIBUTE;
+
+    // Initialize fragment program.
+    fragment_shader_.has_tex_clamp_rect_ = key.has_tex_clamp_rect_;
+    if (key.is_opaque_) {
+      DCHECK_EQ(key.aa_mode_, NO_AA);
+      fragment_shader_.frag_color_mode_ = FRAG_COLOR_MODE_OPAQUE;
+    } else {
+      // TODO(ccameron): This branch shouldn't be needed (this is always
+      // BLEND_MODE_NONE).
+      if (key.aa_mode_ == NO_AA)
+        fragment_shader_.frag_color_mode_ = FRAG_COLOR_MODE_APPLY_BLEND_MODE;
+      fragment_shader_.has_uniform_alpha_ = true;
+    }
+    // AA changes the texture coordinate mode (affecting both shaders).
+    if (key.aa_mode_ == USE_AA) {
+      vertex_shader_.tex_coord_source_ = TEX_COORD_SOURCE_POSITION;
+      vertex_shader_.aa_mode_ = USE_AA;
+      fragment_shader_.has_rgba_fragment_tex_transform_ = true;
+      // Tiles that have AA do their own clamping.
+      DCHECK(!fragment_shader_.has_tex_clamp_rect_);
+    }
+  }
+
+  void InitializeTextureProgram(const ProgramKey& key) {
+    // Initialize vertex program.
+    vertex_shader_.tex_coord_source_ = TEX_COORD_SOURCE_ATTRIBUTE;
+    vertex_shader_.tex_coord_transform_ = TEX_COORD_TRANSFORM_VEC4;
+    vertex_shader_.has_vertex_opacity_ = true;
+    vertex_shader_.use_uniform_arrays_ = !key.has_tex_clamp_rect_;
+
+    // Initialize fragment program.
+    fragment_shader_.has_varying_alpha_ = true;
+    fragment_shader_.has_background_color_ = key.has_background_color_;
+    fragment_shader_.has_tex_clamp_rect_ = key.has_tex_clamp_rect_;
+  }
+
+  void InitializeRenderPassProgram(const ProgramKey& key) {
+    // Initialize vertex program.
+    if (key.aa_mode_ == NO_AA) {
+      vertex_shader_.tex_coord_source_ = TEX_COORD_SOURCE_ATTRIBUTE;
+      vertex_shader_.tex_coord_transform_ = TEX_COORD_TRANSFORM_VEC4;
+      vertex_shader_.has_vertex_opacity_ = true;
+      vertex_shader_.use_uniform_arrays_ = true;
+    } else {
+      vertex_shader_.position_source_ =
+          POSITION_SOURCE_ATTRIBUTE_INDEXED_UNIFORM;
+      vertex_shader_.tex_coord_source_ = TEX_COORD_SOURCE_POSITION;
+      vertex_shader_.tex_coord_transform_ = TEX_COORD_TRANSFORM_TRANSLATED_VEC4;
+    }
+
+    // Initialize fragment program.
+    fragment_shader_.frag_color_mode_ = FRAG_COLOR_MODE_APPLY_BLEND_MODE;
+    fragment_shader_.has_uniform_alpha_ = true;
+    fragment_shader_.has_color_matrix_ = key.has_color_matrix_;
+    if (key.mask_mode_ == HAS_MASK) {
+      fragment_shader_.ignore_sampler_type_ = true;
+    } else {
+      DCHECK(!key.mask_for_background_);
+    }
+  }
+
+  void InitializeVideoStreamProgram(const ProgramKey& key) {
+    vertex_shader_.tex_coord_source_ = TEX_COORD_SOURCE_ATTRIBUTE;
+    vertex_shader_.tex_coord_transform_ = TEX_COORD_TRANSFORM_MATRIX;
+    DCHECK_EQ(key.sampler_, SAMPLER_TYPE_EXTERNAL_OES);
+  }
+
+  void InitializeYUVVideo(const ProgramKey& key) {
+    vertex_shader_.tex_coord_source_ = TEX_COORD_SOURCE_ATTRIBUTE;
+    vertex_shader_.is_ya_uv_ = true;
+
+    fragment_shader_.input_color_type_ = INPUT_COLOR_SOURCE_YUV_TEXTURES;
+    fragment_shader_.has_uniform_alpha_ = true;
+    fragment_shader_.yuv_alpha_texture_mode_ = key.yuv_alpha_texture_mode_;
+    fragment_shader_.uv_texture_mode_ = key.uv_texture_mode_;
+  }
+
+  void InitializeInternal(ContextProvider* context_provider) {
+    DCHECK(context_provider);
+    DCHECK(!initialized_);
+
+    if (IsContextLost(context_provider->ContextGL()))
+      return;
+
+    if (!ProgramBindingBase::Init(context_provider->ContextGL(),
+                                  vertex_shader_.GetShaderString(),
+                                  fragment_shader_.GetShaderString())) {
+      DCHECK(IsContextLost(context_provider->ContextGL()));
+      return;
+    }
+
+    int base_uniform_index = 0;
+    vertex_shader_.Init(context_provider->ContextGL(), program_,
+                        &base_uniform_index);
+    fragment_shader_.Init(context_provider->ContextGL(), program_,
+                          &base_uniform_index);
+
+    // Link after binding uniforms
+    if (!Link(context_provider->ContextGL())) {
+      DCHECK(IsContextLost(context_provider->ContextGL()));
+      return;
+    }
+
+    initialized_ = true;
+  }
+
+  VertexShader vertex_shader_;
+  FragmentShader fragment_shader_;
+};
+
+}  // namespace viz
+
+#endif  // COMPONENTS_VIZ_SERVICE_DISPLAY_PROGRAM_BINDING_H_
diff --git components/viz/service/display/scoped_gpu_memory_buffer_texture.cc components/viz/service/display/scoped_gpu_memory_buffer_texture.cc
new file mode 100644
index 0000000000000..e7968ed7377b8
--- /dev/null
+++ components/viz/service/display/scoped_gpu_memory_buffer_texture.cc
@@ -0,0 +1,96 @@
+// Copyright 2017 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "components/viz/service/display/scoped_gpu_memory_buffer_texture.h"
+
+#include "base/check.h"
+#include "components/viz/common/gpu/context_provider.h"
+#include "components/viz/common/resources/resource_format.h"
+#include "components/viz/common/resources/resource_format_utils.h"
+#include "gpu/GLES2/gl2extchromium.h"
+#include "gpu/command_buffer/client/gles2_interface.h"
+#include "gpu/command_buffer/common/gpu_memory_buffer_support.h"
+
+namespace viz {
+
+ScopedGpuMemoryBufferTexture::ScopedGpuMemoryBufferTexture(
+    ContextProvider* context_provider,
+    const gfx::Size& size,
+    const gfx::ColorSpace& color_space)
+    : context_provider_(context_provider),
+      size_(size),
+      color_space_(color_space) {
+  DCHECK(context_provider_);
+
+  const auto& caps = context_provider->ContextCapabilities();
+  // This capability is needed to use TexStorage2DImageCHROMIUM, and should be
+  // known to be enabled before using an object of this type.
+  DCHECK(caps.texture_storage_image);
+
+  gpu::gles2::GLES2Interface* gl = context_provider_->ContextGL();
+  gl->GenTextures(1, &gl_id_);
+
+  gfx::BufferUsage usage = gfx::BufferUsage::SCANOUT;
+  ResourceFormat format = RGBA_8888;
+  gfx::BufferFormat buffer_format = BufferFormat(format);
+
+  target_ = gpu::GetBufferTextureTarget(usage, buffer_format, caps);
+
+  gl->BindTexture(target_, gl_id_);
+  gl->TexParameteri(target_, GL_TEXTURE_MIN_FILTER, GL_LINEAR);
+  gl->TexParameteri(target_, GL_TEXTURE_MAG_FILTER, GL_LINEAR);
+  gl->TexParameteri(target_, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);
+  gl->TexParameteri(target_, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);
+
+  gl->TexStorage2DImageCHROMIUM(
+      target_, TextureStorageFormat(format, caps.angle_rgbx_internal_format),
+      GL_SCANOUT_CHROMIUM, size_.width(), size_.height());
+  if (color_space_.IsValid()) {
+    gl->SetColorSpaceMetadataCHROMIUM(gl_id_, color_space_.AsGLColorSpace());
+  }
+  gl->BindTexture(target_, 0);
+}
+
+ScopedGpuMemoryBufferTexture::ScopedGpuMemoryBufferTexture() = default;
+
+ScopedGpuMemoryBufferTexture::~ScopedGpuMemoryBufferTexture() {
+  Free();
+}
+
+ScopedGpuMemoryBufferTexture::ScopedGpuMemoryBufferTexture(
+    ScopedGpuMemoryBufferTexture&& other)
+    : context_provider_(other.context_provider_),
+      gl_id_(other.gl_id_),
+      target_(other.target_),
+      size_(other.size_),
+      color_space_(other.color_space_) {
+  other.gl_id_ = 0;
+}
+
+ScopedGpuMemoryBufferTexture& ScopedGpuMemoryBufferTexture::operator=(
+    ScopedGpuMemoryBufferTexture&& other) {
+  DCHECK(!context_provider_ || !other.context_provider_ ||
+         context_provider_ == other.context_provider_);
+  if (this != &other) {
+    Free();
+    context_provider_ = other.context_provider_;
+    gl_id_ = other.gl_id_;
+    target_ = other.target_;
+    size_ = other.size_;
+    color_space_ = other.color_space_;
+
+    other.gl_id_ = 0;
+  }
+  return *this;
+}
+
+void ScopedGpuMemoryBufferTexture::Free() {
+  if (!gl_id_)
+    return;
+  gpu::gles2::GLES2Interface* gl = context_provider_->ContextGL();
+  gl->DeleteTextures(1, &gl_id_);
+  gl_id_ = 0;
+}
+
+}  // namespace viz
diff --git components/viz/service/display/scoped_gpu_memory_buffer_texture.h components/viz/service/display/scoped_gpu_memory_buffer_texture.h
new file mode 100644
index 0000000000000..1711224bcb135
--- /dev/null
+++ components/viz/service/display/scoped_gpu_memory_buffer_texture.h
@@ -0,0 +1,49 @@
+// Copyright 2017 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef COMPONENTS_VIZ_SERVICE_DISPLAY_SCOPED_GPU_MEMORY_BUFFER_TEXTURE_H_
+#define COMPONENTS_VIZ_SERVICE_DISPLAY_SCOPED_GPU_MEMORY_BUFFER_TEXTURE_H_
+
+#include "base/memory/raw_ptr.h"
+#include "components/viz/service/viz_service_export.h"
+#include "ui/gfx/color_space.h"
+#include "ui/gfx/geometry/size.h"
+
+namespace viz {
+class ContextProvider;
+
+// ScopedGpuMemoryBufferTexture is a GL texture backed by a GL image and a
+// GpuMemoryBuffer, so that it can be used as an overlay.
+class VIZ_SERVICE_EXPORT ScopedGpuMemoryBufferTexture {
+ public:
+  explicit ScopedGpuMemoryBufferTexture(ContextProvider* context_provider,
+                                        const gfx::Size& size,
+                                        const gfx::ColorSpace& color_space);
+
+  ScopedGpuMemoryBufferTexture();
+  ~ScopedGpuMemoryBufferTexture();
+
+  ScopedGpuMemoryBufferTexture(ScopedGpuMemoryBufferTexture&& other);
+  ScopedGpuMemoryBufferTexture& operator=(ScopedGpuMemoryBufferTexture&& other);
+
+  uint32_t id() const { return gl_id_; }
+  uint32_t target() const { return target_; }
+  const gfx::Size& size() const { return size_; }
+  const gfx::ColorSpace& color_space() const { return color_space_; }
+
+ private:
+  void Free();
+
+  // The ContextProvider used to free the texture when this object is destroyed,
+  // so it must outlive this object.
+  raw_ptr<ContextProvider> context_provider_ = nullptr;
+  uint32_t gl_id_ = 0;
+  uint32_t target_ = 0;
+  gfx::Size size_;
+  gfx::ColorSpace color_space_;
+};
+
+}  // namespace viz
+
+#endif  // COMPONENTS_VIZ_SERVICE_DISPLAY_SCOPED_GPU_MEMORY_BUFFER_TEXTURE_H_
diff --git components/viz/service/display/scoped_render_pass_texture.cc components/viz/service/display/scoped_render_pass_texture.cc
new file mode 100644
index 0000000000000..9a668018e08e7
--- /dev/null
+++ components/viz/service/display/scoped_render_pass_texture.cc
@@ -0,0 +1,127 @@
+// Copyright 2017 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "components/viz/service/display/scoped_render_pass_texture.h"
+
+#include <algorithm>
+
+#include "base/bits.h"
+#include "base/check.h"
+#include "components/viz/common/gpu/context_provider.h"
+#include "components/viz/common/resources/resource_format_utils.h"
+#include "gpu/GLES2/gl2extchromium.h"
+#include "gpu/command_buffer/client/gles2_interface.h"
+
+namespace viz {
+
+ScopedRenderPassTexture::ScopedRenderPassTexture() = default;
+
+ScopedRenderPassTexture::ScopedRenderPassTexture(
+    ContextProvider* context_provider,
+    const gfx::Size& size,
+    ResourceFormat format,
+    const gfx::ColorSpace& color_space,
+    bool mipmap)
+    : context_provider_(context_provider),
+      size_(size),
+      mipmap_(mipmap),
+      color_space_(color_space) {
+  DCHECK(context_provider_);
+  gpu::gles2::GLES2Interface* gl = context_provider_->ContextGL();
+  const gpu::Capabilities& caps = context_provider_->ContextCapabilities();
+  gl->GenTextures(1, &gl_id_);
+
+  gl->BindTexture(GL_TEXTURE_2D, gl_id_);
+  gl->TexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR);
+  gl->TexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);
+  gl->TexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);
+  gl->TexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);
+
+  // This texture will be bound as a framebuffer, so optimize for that.
+  if (caps.texture_usage) {
+    gl->TexParameteri(GL_TEXTURE_2D, GL_TEXTURE_USAGE_ANGLE,
+                      GL_FRAMEBUFFER_ATTACHMENT_ANGLE);
+  }
+
+  if (caps.texture_storage) {
+    GLint levels = 1;
+    if (caps.texture_npot && mipmap_)
+      levels += base::bits::Log2Floor(std::max(size_.width(), size_.height()));
+
+    gl->TexStorage2DEXT(
+        GL_TEXTURE_2D, levels,
+        TextureStorageFormat(format, context_provider_->ContextCapabilities()
+                                         .angle_rgbx_internal_format),
+        size_.width(), size_.height());
+  } else {
+    DCHECK(GLSupportsFormat(format));
+    gl->TexImage2D(GL_TEXTURE_2D, 0, GLInternalFormat(format), size_.width(),
+                   size_.height(), 0, GLDataFormat(format), GLDataType(format),
+                   nullptr);
+  }
+}
+
+ScopedRenderPassTexture::~ScopedRenderPassTexture() {
+  Free();
+}
+
+ScopedRenderPassTexture::ScopedRenderPassTexture(
+    ScopedRenderPassTexture&& other) {
+  context_provider_ = other.context_provider_;
+  size_ = other.size_;
+  mipmap_ = other.mipmap_;
+  color_space_ = other.color_space_;
+  gl_id_ = other.gl_id_;
+  mipmap_state_ = other.mipmap_state_;
+
+  // When being moved, other will no longer hold this gl_id_.
+  other.gl_id_ = 0;
+}
+
+ScopedRenderPassTexture& ScopedRenderPassTexture::operator=(
+    ScopedRenderPassTexture&& other) {
+  if (this != &other) {
+    Free();
+    context_provider_ = other.context_provider_;
+    size_ = other.size_;
+    mipmap_ = other.mipmap_;
+    color_space_ = other.color_space_;
+    gl_id_ = other.gl_id_;
+    mipmap_state_ = other.mipmap_state_;
+
+    // When being moved, other will no longer hold this gl_id_.
+    other.gl_id_ = 0;
+  }
+  return *this;
+}
+
+void ScopedRenderPassTexture::Free() {
+  if (!gl_id_)
+    return;
+  gpu::gles2::GLES2Interface* gl = context_provider_->ContextGL();
+  gl->DeleteTextures(1, &gl_id_);
+  gl_id_ = 0;
+}
+
+void ScopedRenderPassTexture::BindForSampling() {
+  gpu::gles2::GLES2Interface* gl = context_provider_->ContextGL();
+  gl->BindTexture(GL_TEXTURE_2D, gl_id_);
+  switch (mipmap_state_) {
+    case INVALID:
+      break;
+    case GENERATE:
+      // TODO(crbug.com/803286): npot texture always return false on ubuntu
+      // desktop. The npot texture check is probably failing on desktop GL.
+      DCHECK(context_provider_->ContextCapabilities().texture_npot);
+      gl->GenerateMipmap(GL_TEXTURE_2D);
+      mipmap_state_ = VALID;
+      [[fallthrough]];
+    case VALID:
+      gl->TexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER,
+                        GL_LINEAR_MIPMAP_LINEAR);
+      break;
+  }
+}
+
+}  // namespace viz
diff --git components/viz/service/display/scoped_render_pass_texture.h components/viz/service/display/scoped_render_pass_texture.h
new file mode 100644
index 0000000000000..da29d49b70b77
--- /dev/null
+++ components/viz/service/display/scoped_render_pass_texture.h
@@ -0,0 +1,61 @@
+// Copyright 2017 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef COMPONENTS_VIZ_SERVICE_DISPLAY_SCOPED_RENDER_PASS_TEXTURE_H_
+#define COMPONENTS_VIZ_SERVICE_DISPLAY_SCOPED_RENDER_PASS_TEXTURE_H_
+
+#include "base/memory/raw_ptr.h"
+#include "components/viz/common/resources/resource_format.h"
+#include "components/viz/service/viz_service_export.h"
+#include "third_party/khronos/GLES2/gl2.h"
+#include "ui/gfx/color_space.h"
+#include "ui/gfx/geometry/size.h"
+
+namespace viz {
+class ContextProvider;
+
+// ScopedRenderPassTexture is resource used inside the same GL context and will
+// not being sent into another process. So no need to create fence and mailbox
+// for these resources.
+class VIZ_SERVICE_EXPORT ScopedRenderPassTexture {
+ public:
+  ScopedRenderPassTexture();
+  ScopedRenderPassTexture(ContextProvider* context_provider,
+                          const gfx::Size& size,
+                          ResourceFormat format,
+                          const gfx::ColorSpace& color_space,
+                          bool mipmap);
+  ~ScopedRenderPassTexture();
+
+  ScopedRenderPassTexture(ScopedRenderPassTexture&& other);
+  ScopedRenderPassTexture& operator=(ScopedRenderPassTexture&& other);
+  void BindForSampling();
+
+  GLuint id() const { return gl_id_; }
+  const gfx::Size& size() const { return size_; }
+  bool mipmap() const { return mipmap_; }
+  const gfx::ColorSpace& color_space() const { return color_space_; }
+  void set_generate_mipmap() { mipmap_state_ = GENERATE; }
+
+ private:
+  void Free();
+
+  raw_ptr<ContextProvider> context_provider_ = nullptr;
+  // The GL texture id.
+  GLuint gl_id_ = 0;
+  // Size of the resource in pixels.
+  gfx::Size size_;
+  // When true, and immutable textures are used, this specifies to
+  // generate mipmaps at powers of 2.
+  bool mipmap_ = false;
+  // TODO(xing.xu): Remove this and set the color space when we draw the
+  // CompositorRenderPassDrawQuad.
+  gfx::ColorSpace color_space_;
+  enum MipmapState { INVALID, GENERATE, VALID };
+  MipmapState mipmap_state_ = INVALID;
+};
+
+}  // namespace viz
+
+#endif  // COMPONENTS_VIZ_SERVICE_DISPLAY_SCOPED_RENDER_PASS_TEXTURE_H_
diff --git components/viz/service/display/shader.cc components/viz/service/display/shader.cc
new file mode 100644
index 0000000000000..e3ac6a999d7a5
--- /dev/null
+++ components/viz/service/display/shader.cc
@@ -0,0 +1,1167 @@
+// Copyright 2011 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "components/viz/service/display/shader.h"
+
+#include <stddef.h>
+
+#include <algorithm>
+#include <utility>
+#include <vector>
+
+#include "base/check_op.h"
+#include "base/notreached.h"
+#include "base/strings/strcat.h"
+#include "base/strings/string_util.h"
+#include "base/strings/stringprintf.h"
+#include "components/viz/service/display/static_geometry_binding.h"
+#include "gpu/command_buffer/client/gles2_interface.h"
+#include "ui/gfx/color_transform.h"
+#include "ui/gfx/geometry/point.h"
+#include "ui/gfx/geometry/size.h"
+
+constexpr base::StringPiece StripLambda(base::StringPiece shader) {
+  // Must contain at least "[]() {}".
+  DCHECK_EQ(shader.substr(0, 6), "[]() {");
+  DCHECK_EQ(shader.back(), '}');
+  shader.remove_prefix(6);
+  shader.remove_suffix(1);
+  return shader;
+}
+
+// Shaders are passed in with lambda syntax, which tricks clang-format into
+// handling them correctly. StripLambda removes this.
+#define SHADER0(Src) StripLambda(#Src)
+
+#define HDR(x)        \
+  do {                \
+    header += x "\n"; \
+  } while (0)
+#define SRC(x)             \
+  do {                     \
+    source += "  " x "\n"; \
+  } while (0)
+
+using gpu::gles2::GLES2Interface;
+
+namespace viz {
+
+namespace {
+
+static void GetProgramUniformLocations(GLES2Interface* context,
+                                       unsigned program,
+                                       size_t count,
+                                       const char** uniforms,
+                                       int* locations,
+                                       int* base_uniform_index) {
+  for (size_t i = 0; i < count; i++) {
+    locations[i] = (*base_uniform_index)++;
+    context->BindUniformLocationCHROMIUM(program, locations[i], uniforms[i]);
+  }
+}
+
+static void SetFragmentTexCoordPrecision(TexCoordPrecision requested_precision,
+                                         std::string* shader_string) {
+  const char* prefix = "";
+  switch (requested_precision) {
+    case TEX_COORD_PRECISION_HIGH:
+      DCHECK_NE(shader_string->find("TexCoordPrecision"), std::string::npos);
+      prefix =
+          "#ifdef GL_FRAGMENT_PRECISION_HIGH\n"
+          "  #define TexCoordPrecision highp\n"
+          "#else\n"
+          "  #define TexCoordPrecision mediump\n"
+          "#endif\n";
+      break;
+    case TEX_COORD_PRECISION_MEDIUM:
+      DCHECK_NE(shader_string->find("TexCoordPrecision"), std::string::npos);
+      prefix = "#define TexCoordPrecision mediump\n";
+      break;
+    case TEX_COORD_PRECISION_NA:
+      DCHECK_EQ(shader_string->find("TexCoordPrecision"), std::string::npos);
+      DCHECK_EQ(shader_string->find("texture2D"), std::string::npos);
+      DCHECK_EQ(shader_string->find("texture2DRect"), std::string::npos);
+      break;
+    default:
+      NOTREACHED();
+      break;
+  }
+  const char* lut_prefix = "#define LutLookup texture2D\n";
+  shader_string->insert(0, prefix);
+  shader_string->insert(0, lut_prefix);
+}
+
+TexCoordPrecision TexCoordPrecisionRequired(GLES2Interface* context,
+                                            int* highp_threshold_cache,
+                                            int highp_threshold_min,
+                                            int x,
+                                            int y) {
+  if (*highp_threshold_cache == 0) {
+    // Initialize range and precision with minimum spec values for when
+    // GetShaderPrecisionFormat is a test stub.
+    // TODO(brianderson): Implement better stubs of GetShaderPrecisionFormat
+    // everywhere.
+    GLint range[2] = {14, 14};
+    GLint precision = 10;
+    context->GetShaderPrecisionFormat(GL_FRAGMENT_SHADER, GL_MEDIUM_FLOAT,
+                                      range, &precision);
+    *highp_threshold_cache = 1 << precision;
+  }
+
+  int highp_threshold = std::max(*highp_threshold_cache, highp_threshold_min);
+  if (x > highp_threshold || y > highp_threshold)
+    return TEX_COORD_PRECISION_HIGH;
+  return TEX_COORD_PRECISION_MEDIUM;
+}
+
+void SetFragmentSamplerType(SamplerType requested_type,
+                            std::string* shader_string) {
+  const char* prefix = nullptr;
+  switch (requested_type) {
+    case SAMPLER_TYPE_2D:
+      DCHECK_NE(shader_string->find("SamplerType"), std::string::npos);
+      DCHECK_NE(shader_string->find("TextureLookup"), std::string::npos);
+      prefix =
+          "#define SamplerType sampler2D\n"
+          "#define TextureLookup texture2D\n";
+      break;
+    case SAMPLER_TYPE_2D_RECT:
+      DCHECK_NE(shader_string->find("SamplerType"), std::string::npos);
+      DCHECK_NE(shader_string->find("TextureLookup"), std::string::npos);
+      prefix =
+          "#extension GL_ARB_texture_rectangle : require\n"
+          "#define SamplerType sampler2DRect\n"
+          "#define TextureLookup texture2DRect\n";
+      break;
+    case SAMPLER_TYPE_EXTERNAL_OES:
+      DCHECK_NE(shader_string->find("SamplerType"), std::string::npos);
+      DCHECK_NE(shader_string->find("TextureLookup"), std::string::npos);
+      prefix =
+          "#extension GL_OES_EGL_image_external : enable\n"
+          "#extension GL_NV_EGL_stream_consumer_external : enable\n"
+          "#define SamplerType samplerExternalOES\n"
+          "#define TextureLookup texture2D\n";
+      break;
+    case SAMPLER_TYPE_NA:
+      DCHECK_EQ(shader_string->find("SamplerType"), std::string::npos);
+      DCHECK_EQ(shader_string->find("TextureLookup"), std::string::npos);
+      return;
+    default:
+      NOTREACHED();
+      return;
+  }
+  shader_string->insert(0, prefix);
+}
+
+}  // namespace
+
+TexCoordPrecision TexCoordPrecisionRequired(GLES2Interface* context,
+                                            int* highp_threshold_cache,
+                                            int highp_threshold_min,
+                                            const gfx::Point& max_coordinate) {
+  return TexCoordPrecisionRequired(context, highp_threshold_cache,
+                                   highp_threshold_min, max_coordinate.x(),
+                                   max_coordinate.y());
+}
+
+TexCoordPrecision TexCoordPrecisionRequired(GLES2Interface* context,
+                                            int* highp_threshold_cache,
+                                            int highp_threshold_min,
+                                            const gfx::Size& max_size) {
+  return TexCoordPrecisionRequired(context, highp_threshold_cache,
+                                   highp_threshold_min, max_size.width(),
+                                   max_size.height());
+}
+
+VertexShader::VertexShader() {}
+
+void VertexShader::Init(GLES2Interface* context,
+                        unsigned program,
+                        int* base_uniform_index) {
+  std::vector<const char*> uniforms;
+  std::vector<int> locations;
+
+  switch (tex_coord_transform_) {
+    case TEX_COORD_TRANSFORM_NONE:
+      break;
+    case TEX_COORD_TRANSFORM_VEC4:
+    case TEX_COORD_TRANSFORM_TRANSLATED_VEC4:
+      uniforms.push_back("vertexTexTransform");
+      break;
+    case TEX_COORD_TRANSFORM_MATRIX:
+      uniforms.push_back("texMatrix");
+      break;
+  }
+  if (is_ya_uv_) {
+    uniforms.push_back("yaTexScale");
+    uniforms.push_back("yaTexOffset");
+    uniforms.push_back("uvTexScale");
+    uniforms.push_back("uvTexOffset");
+  }
+  uniforms.push_back("matrix");
+  if (has_vertex_opacity_)
+    uniforms.push_back("opacity");
+  if (aa_mode_ == USE_AA) {
+    uniforms.push_back("viewport");
+    uniforms.push_back("edge");
+  }
+  if (position_source_ == POSITION_SOURCE_ATTRIBUTE_INDEXED_UNIFORM)
+    uniforms.push_back("quad");
+
+  locations.resize(uniforms.size());
+
+  GetProgramUniformLocations(context, program, uniforms.size(), uniforms.data(),
+                             locations.data(), base_uniform_index);
+
+  size_t index = 0;
+  switch (tex_coord_transform_) {
+    case TEX_COORD_TRANSFORM_NONE:
+      break;
+    case TEX_COORD_TRANSFORM_VEC4:
+    case TEX_COORD_TRANSFORM_TRANSLATED_VEC4:
+      vertex_tex_transform_location_ = locations[index++];
+      break;
+    case TEX_COORD_TRANSFORM_MATRIX:
+      tex_matrix_location_ = locations[index++];
+      break;
+  }
+  if (is_ya_uv_) {
+    ya_tex_scale_location_ = locations[index++];
+    ya_tex_offset_location_ = locations[index++];
+    uv_tex_scale_location_ = locations[index++];
+    uv_tex_offset_location_ = locations[index++];
+  }
+  matrix_location_ = locations[index++];
+  if (has_vertex_opacity_)
+    vertex_opacity_location_ = locations[index++];
+  if (aa_mode_ == USE_AA) {
+    viewport_location_ = locations[index++];
+    edge_location_ = locations[index++];
+  }
+  if (position_source_ == POSITION_SOURCE_ATTRIBUTE_INDEXED_UNIFORM)
+    quad_location_ = locations[index++];
+}
+
+std::string VertexShader::GetShaderString() const {
+  // We unconditionally use highp in the vertex shader since
+  // we are unlikely to be vertex shader bound when drawing large quads.
+  // Also, some vertex shaders mutate the texture coordinate in such a
+  // way that the effective precision might be lower than expected.
+  std::string header = "#define TexCoordPrecision highp\n";
+  std::string source = "void main() {\n";
+
+  // Define the size of quads for attribute indexed uniform arrays.
+  if (use_uniform_arrays_) {
+    header += base::StringPrintf("#define NUM_QUADS %d\n",
+                                 StaticGeometryBinding::NUM_QUADS);
+  }
+
+  // Read the index variables.
+  if (use_uniform_arrays_ || has_vertex_opacity_ ||
+      position_source_ == POSITION_SOURCE_ATTRIBUTE_INDEXED_UNIFORM) {
+    HDR("attribute float a_index;");
+    SRC("// Compute indices for uniform arrays.");
+    SRC("int vertex_index = int(a_index);");
+    if (use_uniform_arrays_)
+      SRC("int quad_index = int(a_index * 0.25);");
+    SRC("");
+  }
+
+  // Read the position and compute gl_Position.
+  HDR("attribute TexCoordPrecision vec4 a_position;");
+  SRC("// Compute the position.");
+  switch (position_source_) {
+    case POSITION_SOURCE_ATTRIBUTE:
+      SRC("vec4 pos = a_position;");
+      break;
+    case POSITION_SOURCE_ATTRIBUTE_INDEXED_UNIFORM:
+      HDR("uniform TexCoordPrecision vec2 quad[4];");
+      SRC("vec4 pos = vec4(quad[vertex_index], a_position.z, a_position.w);");
+      break;
+  }
+    if (use_uniform_arrays_) {
+      HDR("uniform mat4 matrix[NUM_QUADS];");
+      SRC("gl_Position = matrix[quad_index] * pos;");
+    } else {
+      HDR("uniform mat4 matrix;");
+      SRC("gl_Position = matrix * pos;");
+    }
+
+  // Compute the anti-aliasing edge distances.
+  if (aa_mode_ == USE_AA) {
+    HDR("uniform TexCoordPrecision vec3 edge[8];");
+    HDR("uniform vec4 viewport;");
+    HDR("varying TexCoordPrecision vec4 edge_dist[2];  // 8 edge distances.");
+    SRC("// Compute anti-aliasing properties.\n");
+    SRC("vec2 ndc_pos = 0.5 * (1.0 + gl_Position.xy / gl_Position.w);");
+    SRC("vec3 screen_pos = vec3(viewport.xy + viewport.zw * ndc_pos, 1.0);");
+    SRC("edge_dist[0] = vec4(dot(edge[0], screen_pos),");
+    SRC("                    dot(edge[1], screen_pos),");
+    SRC("                    dot(edge[2], screen_pos),");
+    SRC("                    dot(edge[3], screen_pos)) * gl_Position.w;");
+    SRC("edge_dist[1] = vec4(dot(edge[4], screen_pos),");
+    SRC("                    dot(edge[5], screen_pos),");
+    SRC("                    dot(edge[6], screen_pos),");
+    SRC("                    dot(edge[7], screen_pos)) * gl_Position.w;");
+  }
+
+  // Read, transform, and write texture coordinates.
+  if (tex_coord_source_ != TEX_COORD_SOURCE_NONE) {
+    if (is_ya_uv_) {
+      HDR("varying TexCoordPrecision vec2 v_uvTexCoord;");
+      HDR("varying TexCoordPrecision vec2 v_yaTexCoord;");
+    } else {
+      HDR("varying TexCoordPrecision vec2 v_texCoord;");
+    }
+
+    SRC("// Compute texture coordinates.");
+    // Read coordinates.
+    switch (tex_coord_source_) {
+      case TEX_COORD_SOURCE_NONE:
+        break;
+      case TEX_COORD_SOURCE_POSITION:
+        SRC("vec2 texCoord = pos.xy;");
+        break;
+      case TEX_COORD_SOURCE_ATTRIBUTE:
+        HDR("attribute TexCoordPrecision vec2 a_texCoord;");
+        SRC("vec2 texCoord = a_texCoord;");
+        break;
+    }
+    // Transform coordinates (except YUV).
+    switch (tex_coord_transform_) {
+      case TEX_COORD_TRANSFORM_NONE:
+        break;
+      case TEX_COORD_TRANSFORM_TRANSLATED_VEC4:
+        SRC("texCoord = texCoord + vec2(0.5);");
+        [[fallthrough]];
+      case TEX_COORD_TRANSFORM_VEC4:
+        if (use_uniform_arrays_) {
+          HDR("uniform TexCoordPrecision vec4 vertexTexTransform[NUM_QUADS];");
+          SRC("TexCoordPrecision vec4 texTrans =");
+          SRC("    vertexTexTransform[quad_index];");
+          SRC("texCoord = texCoord * texTrans.zw + texTrans.xy;");
+        } else {
+          HDR("uniform TexCoordPrecision vec4 vertexTexTransform;");
+          SRC("texCoord = texCoord * vertexTexTransform.zw +");
+          SRC("           vertexTexTransform.xy;");
+        }
+        break;
+      case TEX_COORD_TRANSFORM_MATRIX:
+        HDR("uniform TexCoordPrecision mat4 texMatrix;");
+        SRC("texCoord = (texMatrix * vec4(texCoord.xy, 0.0, 1.0)).xy;");
+        break;
+    }
+    // Write the output texture coordinates.
+    if (is_ya_uv_) {
+      HDR("uniform TexCoordPrecision vec2 uvTexOffset;");
+      HDR("uniform TexCoordPrecision vec2 uvTexScale;");
+      HDR("uniform TexCoordPrecision vec2 yaTexOffset;");
+      HDR("uniform TexCoordPrecision vec2 yaTexScale;");
+      SRC("v_yaTexCoord = texCoord * yaTexScale + yaTexOffset;");
+      SRC("v_uvTexCoord = texCoord * uvTexScale + uvTexOffset;");
+    } else {
+      SRC("v_texCoord = texCoord;");
+    }
+  }
+
+  // Write varying vertex opacity.
+  if (has_vertex_opacity_) {
+    HDR("varying float v_alpha;");
+    if (use_uniform_arrays_) {
+      HDR("uniform float opacity[NUM_QUADS * 4];");
+    } else {
+      HDR("uniform float opacity[4];");
+    }
+    SRC("v_alpha = opacity[vertex_index];");
+  }
+
+  // Add cargo-culted dummy variables for Android.
+  if (has_dummy_variables_) {
+    HDR("uniform TexCoordPrecision vec2 dummy_uniform;");
+    HDR("varying TexCoordPrecision vec2 dummy_varying;");
+    SRC("dummy_varying = dummy_uniform;");
+  }
+
+  source += "}\n";
+  return header + source;
+}
+
+FragmentShader::FragmentShader() {}
+
+std::string FragmentShader::GetShaderString() const {
+  TexCoordPrecision precision = tex_coord_precision_;
+  // The AA shader values will use TexCoordPrecision.
+  if (aa_mode_ == USE_AA && precision == TEX_COORD_PRECISION_NA)
+    precision = TEX_COORD_PRECISION_MEDIUM;
+  std::string shader = GetShaderSource();
+  SetBlendModeFunctions(&shader);
+  SetRoundedCornerFunctions(&shader);
+  SetFragmentSamplerType(sampler_type_, &shader);
+  SetFragmentTexCoordPrecision(precision, &shader);
+  return shader;
+}
+
+void FragmentShader::Init(GLES2Interface* context,
+                          unsigned program,
+                          int* base_uniform_index) {
+  std::vector<const char*> uniforms;
+  std::vector<int> locations;
+  if (has_blend_mode()) {
+    uniforms.push_back("s_backdropTexture");
+    uniforms.push_back("s_originalBackdropTexture");
+    uniforms.push_back("backdropRect");
+  }
+  if (mask_mode_ != NO_MASK) {
+    uniforms.push_back("s_mask");
+    uniforms.push_back("maskTexCoordScale");
+    uniforms.push_back("maskTexCoordOffset");
+  }
+  if (has_color_matrix_) {
+    uniforms.push_back("colorMatrix");
+    uniforms.push_back("colorOffset");
+  }
+  if (has_uniform_alpha_)
+    uniforms.push_back("alpha");
+  if (has_background_color_)
+    uniforms.push_back("background_color");
+  if (has_tex_clamp_rect_)
+    uniforms.push_back("tex_clamp_rect");
+  switch (input_color_type_) {
+    case INPUT_COLOR_SOURCE_RGBA_TEXTURE:
+      uniforms.push_back("s_texture");
+      if (has_rgba_fragment_tex_transform_)
+        uniforms.push_back("fragmentTexTransform");
+      break;
+    case INPUT_COLOR_SOURCE_YUV_TEXTURES:
+      uniforms.push_back("y_texture");
+      if (uv_texture_mode_ == UV_TEXTURE_MODE_UV)
+        uniforms.push_back("uv_texture");
+      if (uv_texture_mode_ == UV_TEXTURE_MODE_U_V) {
+        uniforms.push_back("u_texture");
+        uniforms.push_back("v_texture");
+      }
+      if (yuv_alpha_texture_mode_ == YUV_HAS_ALPHA_TEXTURE)
+        uniforms.push_back("a_texture");
+      uniforms.push_back("ya_clamp_rect");
+      uniforms.push_back("uv_clamp_rect");
+      uniforms.push_back("resource_multiplier");
+      uniforms.push_back("resource_offset");
+      break;
+    case INPUT_COLOR_SOURCE_UNIFORM:
+      uniforms.push_back("color");
+      break;
+  }
+  if (has_output_color_matrix_)
+    uniforms.emplace_back("output_color_matrix");
+
+  if (has_tint_color_matrix_)
+    uniforms.emplace_back("tint_color_matrix");
+
+  if (has_rounded_corner_) {
+    uniforms.emplace_back("roundedCornerRect");
+    uniforms.emplace_back("roundedCornerRadius");
+  }
+
+  locations.resize(uniforms.size());
+
+  GetProgramUniformLocations(context, program, uniforms.size(), uniforms.data(),
+                             locations.data(), base_uniform_index);
+
+  size_t index = 0;
+  if (has_blend_mode()) {
+    backdrop_location_ = locations[index++];
+    original_backdrop_location_ = locations[index++];
+    backdrop_rect_location_ = locations[index++];
+  }
+  if (mask_mode_ != NO_MASK) {
+    mask_sampler_location_ = locations[index++];
+    mask_tex_coord_scale_location_ = locations[index++];
+    mask_tex_coord_offset_location_ = locations[index++];
+  }
+  if (has_color_matrix_) {
+    color_matrix_location_ = locations[index++];
+    color_offset_location_ = locations[index++];
+  }
+  if (has_uniform_alpha_)
+    alpha_location_ = locations[index++];
+  if (has_background_color_)
+    background_color_location_ = locations[index++];
+  if (has_tex_clamp_rect_)
+    tex_clamp_rect_location_ = locations[index++];
+  switch (input_color_type_) {
+    case INPUT_COLOR_SOURCE_RGBA_TEXTURE:
+      sampler_location_ = locations[index++];
+      if (has_rgba_fragment_tex_transform_)
+        fragment_tex_transform_location_ = locations[index++];
+      break;
+    case INPUT_COLOR_SOURCE_YUV_TEXTURES:
+      y_texture_location_ = locations[index++];
+      if (uv_texture_mode_ == UV_TEXTURE_MODE_UV)
+        uv_texture_location_ = locations[index++];
+      if (uv_texture_mode_ == UV_TEXTURE_MODE_U_V) {
+        u_texture_location_ = locations[index++];
+        v_texture_location_ = locations[index++];
+      }
+      if (yuv_alpha_texture_mode_ == YUV_HAS_ALPHA_TEXTURE)
+        a_texture_location_ = locations[index++];
+      ya_clamp_rect_location_ = locations[index++];
+      uv_clamp_rect_location_ = locations[index++];
+      resource_multiplier_location_ = locations[index++];
+      resource_offset_location_ = locations[index++];
+      break;
+    case INPUT_COLOR_SOURCE_UNIFORM:
+      color_location_ = locations[index++];
+      break;
+  }
+
+  if (has_output_color_matrix_)
+    output_color_matrix_location_ = locations[index++];
+
+  if (has_tint_color_matrix_)
+    tint_color_matrix_location_ = locations[index++];
+
+  if (has_rounded_corner_) {
+    rounded_corner_rect_location_ = locations[index++];
+    rounded_corner_radius_location_ = locations[index++];
+  }
+
+  DCHECK_EQ(index, locations.size());
+}
+
+void FragmentShader::SetRoundedCornerFunctions(
+    std::string* shader_string) const {
+  if (!has_rounded_corner_)
+    return;
+
+  static constexpr base::StringPiece kUniforms = SHADER0([]() {
+    uniform vec4 roundedCornerRect;
+    uniform vec4 roundedCornerRadius;
+  });
+
+  static constexpr base::StringPiece kFunctionRcUtility = SHADER0([]() {
+    // Returns a vector of size 4. Each component of a vector is set to 1 or 0
+    // representing whether |rcCoord| is a part of the respective corner or
+    // not.
+    // The component ordering is:
+    //     [Top left, Top right, Bottom right, Bottom left]
+    vec4 IsCorner(vec2 rcCoord) {
+      // Top left corner
+      if (rcCoord.x < roundedCornerRadius.x &&
+          rcCoord.y < roundedCornerRadius.x) {
+        return vec4(1.0, 0.0, 0.0, 0.0);
+      }
+
+      // Top right corner
+      if (rcCoord.x > roundedCornerRect.z - roundedCornerRadius.y &&
+          rcCoord.y < roundedCornerRadius.y) {
+        return vec4(0.0, 1.0, 0.0, 0.0);
+      }
+
+      // Bottom right corner
+      if (rcCoord.x > roundedCornerRect.z - roundedCornerRadius.z &&
+          rcCoord.y > roundedCornerRect.w - roundedCornerRadius.z) {
+        return vec4(0.0, 0.0, 1.0, 0.0);
+      }
+
+      // Bottom left corner
+      if (rcCoord.x < roundedCornerRadius.w &&
+          rcCoord.y > roundedCornerRect.w - roundedCornerRadius.w) {
+        return vec4(0.0, 0.0, 0.0, 1.0);
+      }
+      return vec4(0.0, 0.0, 0.0, 0.0);
+    }
+
+    // Returns the center of the rounded corner. |corner| holds the info on
+    // which corner the center is requested for.
+    vec2 GetCenter(vec4 corner, float radius) {
+      if (corner.x == 1.0) {
+        // Top left corner
+        return vec2(radius, radius);
+      } else if (corner.y == 1.0) {
+        // Top right corner
+        return vec2(roundedCornerRect.z - radius, radius);
+      } else if (corner.z == 1.0) {
+        // Bottom right corner
+        return vec2(roundedCornerRect.z - radius, roundedCornerRect.w - radius);
+      } else {
+        // Bottom left corner
+        return vec2(radius, roundedCornerRect.w - radius);
+      }
+    }
+  });
+
+  static constexpr base::StringPiece kFunctionApplyRoundedCorner =
+      SHADER0([]() {
+        vec4 ApplyRoundedCorner(vec4 src) {
+          vec2 rcCoord = gl_FragCoord.xy - roundedCornerRect.xy;
+
+          vec4 isCorner = IsCorner(rcCoord);
+
+          // Get the radius to use based on the corner this fragment lies in.
+          float r = dot(isCorner, roundedCornerRadius);
+
+          // If the radius is 0, then there is no rounded corner here. We can do
+          // an early return.
+          if (r == 0.0)
+            return src;
+
+          // Vector to the corner's center this fragment is in.
+          // Due to precision errors on android, this variable requires a highp.
+          // See https://crbug.com/1009322
+          RoundedCornerPrecision vec2 cornerCenter = GetCenter(isCorner, r);
+
+          // Vector from the center of the corner to the current fragment center
+          vec2 cxy = rcCoord - cornerCenter;
+
+          // Compute the distance of the fragment's center from the corner's
+          // center.
+          float fragDst = length(cxy);
+
+          float alpha = smoothstep(r - 1.0, r + 1.0, fragDst);
+          return vec4(0.0) * alpha + src * (1.0 - alpha);
+        }
+      });
+
+  std::string shader;
+  shader.reserve(shader_string->size() + 2048);
+  shader += "precision mediump float;";
+  shader +=
+      "\n#ifdef GL_FRAGMENT_PRECISION_HIGH\n"
+      "  #define RoundedCornerPrecision highp\n"
+      "#else\n"
+      "  #define RoundedCornerPrecision mediump\n"
+      "#endif\n";
+  base::StrAppend(&shader, {kUniforms, kFunctionRcUtility,
+                            kFunctionApplyRoundedCorner, *shader_string});
+  *shader_string = std::move(shader);
+}
+
+void FragmentShader::SetBlendModeFunctions(std::string* shader_string) const {
+  if (!has_blend_mode()) {
+    return;
+  }
+
+  static constexpr base::StringPiece kUniforms = SHADER0([]() {
+    uniform sampler2D s_backdropTexture;
+    uniform sampler2D s_originalBackdropTexture;
+    uniform TexCoordPrecision vec4 backdropRect;
+  });
+
+  base::StringPiece function_apply_blend_mode;
+  if (mask_for_background_) {
+    static constexpr base::StringPiece kFunctionApplyBlendMode = SHADER0([]() {
+      vec4 ApplyBlendMode(vec4 src, float mask) {
+        TexCoordPrecision vec2 bgTexCoord = gl_FragCoord.xy - backdropRect.xy;
+        bgTexCoord *= backdropRect.zw;
+        vec4 backdrop = texture2D(s_backdropTexture, bgTexCoord);
+        vec4 original_backdrop =
+            texture2D(s_originalBackdropTexture, bgTexCoord);
+        vec4 dst = mix(original_backdrop, backdrop, mask);
+        return Blend(src, dst);
+      }
+    });
+    function_apply_blend_mode = kFunctionApplyBlendMode;
+  } else {
+    static constexpr base::StringPiece kFunctionApplyBlendMode = SHADER0([]() {
+      vec4 ApplyBlendMode(vec4 src) {
+        TexCoordPrecision vec2 bgTexCoord = gl_FragCoord.xy - backdropRect.xy;
+        bgTexCoord *= backdropRect.zw;
+        vec4 dst = texture2D(s_backdropTexture, bgTexCoord);
+        return Blend(src, dst);
+      }
+    });
+    function_apply_blend_mode = kFunctionApplyBlendMode;
+  }
+
+  std::string shader;
+  shader.reserve(shader_string->size() + 1024);
+  shader += "precision mediump float;";
+  AppendHelperFunctions(&shader);
+  AppendBlendFunction(&shader);
+  base::StrAppend(&shader,
+                  {kUniforms, function_apply_blend_mode, *shader_string});
+  *shader_string = std::move(shader);
+}
+
+void FragmentShader::AppendHelperFunctions(std::string* buffer) const {
+  static constexpr base::StringPiece kFunctionHardLight = SHADER0([]() {
+    vec3 hardLight(vec4 src, vec4 dst) {
+      vec3 result;
+      result.r =
+          (2.0 * src.r <= src.a)
+              ? (2.0 * src.r * dst.r)
+              : (src.a * dst.a - 2.0 * (dst.a - dst.r) * (src.a - src.r));
+      result.g =
+          (2.0 * src.g <= src.a)
+              ? (2.0 * src.g * dst.g)
+              : (src.a * dst.a - 2.0 * (dst.a - dst.g) * (src.a - src.g));
+      result.b =
+          (2.0 * src.b <= src.a)
+              ? (2.0 * src.b * dst.b)
+              : (src.a * dst.a - 2.0 * (dst.a - dst.b) * (src.a - src.b));
+      result.rgb += src.rgb * (1.0 - dst.a) + dst.rgb * (1.0 - src.a);
+      return result;
+    }
+  });
+
+  static constexpr base::StringPiece kFunctionColorDodgeComponent =
+      SHADER0([]() {
+        float getColorDodgeComponent(float srcc, float srca, float dstc,
+                                     float dsta) {
+          if (0.0 == dstc)
+            return srcc * (1.0 - dsta);
+          float d = srca - srcc;
+          if (0.0 == d)
+            return srca * dsta + srcc * (1.0 - dsta) + dstc * (1.0 - srca);
+          d = min(dsta, dstc * srca / d);
+          return d * srca + srcc * (1.0 - dsta) + dstc * (1.0 - srca);
+        }
+      });
+
+  static constexpr base::StringPiece kFunctionColorBurnComponent =
+      SHADER0([]() {
+        float getColorBurnComponent(float srcc, float srca, float dstc,
+                                    float dsta) {
+          if (dsta == dstc)
+            return srca * dsta + srcc * (1.0 - dsta) + dstc * (1.0 - srca);
+          if (0.0 == srcc)
+            return dstc * (1.0 - srca);
+          float d = max(0.0, dsta - (dsta - dstc) * srca / srcc);
+          return srca * d + srcc * (1.0 - dsta) + dstc * (1.0 - srca);
+        }
+      });
+
+  static constexpr base::StringPiece kFunctionSoftLightComponentPosDstAlpha =
+      SHADER0([]() {
+        float getSoftLightComponent(float srcc, float srca, float dstc,
+                                    float dsta) {
+          if (2.0 * srcc <= srca) {
+            return (dstc * dstc * (srca - 2.0 * srcc)) / dsta +
+                   (1.0 - dsta) * srcc + dstc * (-srca + 2.0 * srcc + 1.0);
+          } else if (4.0 * dstc <= dsta) {
+            float DSqd = dstc * dstc;
+            float DCub = DSqd * dstc;
+            float DaSqd = dsta * dsta;
+            float DaCub = DaSqd * dsta;
+            return (-DaCub * srcc +
+                    DaSqd * (srcc - dstc * (3.0 * srca - 6.0 * srcc - 1.0)) +
+                    12.0 * dsta * DSqd * (srca - 2.0 * srcc) -
+                    16.0 * DCub * (srca - 2.0 * srcc)) /
+                   DaSqd;
+          } else {
+            return -sqrt(dsta * dstc) * (srca - 2.0 * srcc) - dsta * srcc +
+                   dstc * (srca - 2.0 * srcc + 1.0) + srcc;
+          }
+        }
+      });
+
+  static constexpr base::StringPiece kFunctionLum = SHADER0([]() {
+    float luminance(vec3 color) { return dot(vec3(0.3, 0.59, 0.11), color); }
+
+    vec3 set_luminance(vec3 hueSat, float alpha, vec3 lumColor) {
+      float diff = luminance(lumColor - hueSat);
+      vec3 outColor = hueSat + diff;
+      float outLum = luminance(outColor);
+      float minComp = min(min(outColor.r, outColor.g), outColor.b);
+      float maxComp = max(max(outColor.r, outColor.g), outColor.b);
+      if (minComp < 0.0 && outLum != minComp) {
+        outColor =
+            outLum + ((outColor - vec3(outLum, outLum, outLum)) * outLum) /
+                         (outLum - minComp);
+      }
+      if (maxComp > alpha && maxComp != outLum) {
+        outColor = outLum + ((outColor - vec3(outLum, outLum, outLum)) *
+                             (alpha - outLum)) /
+                                (maxComp - outLum);
+      }
+      return outColor;
+    }
+  });
+
+  static constexpr base::StringPiece kFunctionSat = SHADER0([]() {
+    float saturation(vec3 color) {
+      return max(max(color.r, color.g), color.b) -
+             min(min(color.r, color.g), color.b);
+    }
+
+    vec3 set_saturation_helper(float minComp, float midComp, float maxComp,
+                               float sat) {
+      if (minComp < maxComp) {
+        vec3 result;
+        result.r = 0.0;
+        result.g = sat * (midComp - minComp) / (maxComp - minComp);
+        result.b = sat;
+        return result;
+      } else {
+        return vec3(0, 0, 0);
+      }
+    }
+
+    vec3 set_saturation(vec3 hueLumColor, vec3 satColor) {
+      float sat = saturation(satColor);
+      if (hueLumColor.r <= hueLumColor.g) {
+        if (hueLumColor.g <= hueLumColor.b) {
+          hueLumColor.rgb = set_saturation_helper(hueLumColor.r, hueLumColor.g,
+                                                  hueLumColor.b, sat);
+        } else if (hueLumColor.r <= hueLumColor.b) {
+          hueLumColor.rbg = set_saturation_helper(hueLumColor.r, hueLumColor.b,
+                                                  hueLumColor.g, sat);
+        } else {
+          hueLumColor.brg = set_saturation_helper(hueLumColor.b, hueLumColor.r,
+                                                  hueLumColor.g, sat);
+        }
+      } else if (hueLumColor.r <= hueLumColor.b) {
+        hueLumColor.grb = set_saturation_helper(hueLumColor.g, hueLumColor.r,
+                                                hueLumColor.b, sat);
+      } else if (hueLumColor.g <= hueLumColor.b) {
+        hueLumColor.gbr = set_saturation_helper(hueLumColor.g, hueLumColor.b,
+                                                hueLumColor.r, sat);
+      } else {
+        hueLumColor.bgr = set_saturation_helper(hueLumColor.b, hueLumColor.g,
+                                                hueLumColor.r, sat);
+      }
+      return hueLumColor;
+    }
+  });
+
+  switch (blend_mode_) {
+    case BLEND_MODE_OVERLAY:
+    case BLEND_MODE_HARD_LIGHT:
+      buffer->append(kFunctionHardLight.data(), kFunctionHardLight.size());
+      return;
+    case BLEND_MODE_COLOR_DODGE:
+      buffer->append(kFunctionColorDodgeComponent.data(),
+                     kFunctionColorDodgeComponent.size());
+      return;
+    case BLEND_MODE_COLOR_BURN:
+      buffer->append(kFunctionColorBurnComponent.data(),
+                     kFunctionColorBurnComponent.size());
+      return;
+    case BLEND_MODE_SOFT_LIGHT:
+      buffer->append(kFunctionSoftLightComponentPosDstAlpha.data(),
+                     kFunctionSoftLightComponentPosDstAlpha.size());
+      return;
+    case BLEND_MODE_HUE:
+    case BLEND_MODE_SATURATION:
+      base::StrAppend(buffer, {kFunctionLum, kFunctionSat});
+      return;
+    case BLEND_MODE_COLOR:
+    case BLEND_MODE_LUMINOSITY:
+      buffer->append(kFunctionLum.data(), kFunctionLum.size());
+      return;
+    default:
+      return;
+  }
+}
+
+void FragmentShader::AppendBlendFunction(std::string* buffer) const {
+  *buffer +=
+      "vec4 Blend(vec4 src, vec4 dst) {"
+      "    vec4 result;";
+  base::StrAppend(
+      buffer, {GetBlendFunctionBodyForAlpha(), GetBlendFunctionBodyForRGB()});
+  *buffer +=
+      "    return result;"
+      "}";
+}
+
+base::StringPiece FragmentShader::GetBlendFunctionBodyForAlpha() const {
+  if (blend_mode_ == BLEND_MODE_DESTINATION_IN)
+    return "result.a = src.a * dst.a;";
+  else
+    return "result.a = src.a + (1.0 - src.a) * dst.a;";
+}
+
+base::StringPiece FragmentShader::GetBlendFunctionBodyForRGB() const {
+  switch (blend_mode_) {
+    case BLEND_MODE_NORMAL:
+      return "result.rgb = src.rgb + dst.rgb * (1.0 - src.a);";
+    case BLEND_MODE_DESTINATION_IN:
+      return "result.rgb = dst.rgb * src.a;";
+    case BLEND_MODE_SCREEN:
+      return "result.rgb = src.rgb + (1.0 - src.rgb) * dst.rgb;";
+    case BLEND_MODE_LIGHTEN:
+      return "result.rgb = max((1.0 - src.a) * dst.rgb + src.rgb,"
+             "                 (1.0 - dst.a) * src.rgb + dst.rgb);";
+    case BLEND_MODE_OVERLAY:
+      return "result.rgb = hardLight(dst, src);";
+    case BLEND_MODE_DARKEN:
+      return "result.rgb = min((1.0 - src.a) * dst.rgb + src.rgb,"
+             "                 (1.0 - dst.a) * src.rgb + dst.rgb);";
+    case BLEND_MODE_COLOR_DODGE:
+      return "result.r = getColorDodgeComponent(src.r, src.a, dst.r, dst.a);"
+             "result.g = getColorDodgeComponent(src.g, src.a, dst.g, dst.a);"
+             "result.b = getColorDodgeComponent(src.b, src.a, dst.b, dst.a);";
+    case BLEND_MODE_COLOR_BURN:
+      return "result.r = getColorBurnComponent(src.r, src.a, dst.r, dst.a);"
+             "result.g = getColorBurnComponent(src.g, src.a, dst.g, dst.a);"
+             "result.b = getColorBurnComponent(src.b, src.a, dst.b, dst.a);";
+    case BLEND_MODE_HARD_LIGHT:
+      return "result.rgb = hardLight(src, dst);";
+    case BLEND_MODE_SOFT_LIGHT:
+      return "if (0.0 == dst.a) {"
+             "  result.rgb = src.rgb;"
+             "} else {"
+             "  result.r = getSoftLightComponent(src.r, src.a, dst.r, dst.a);"
+             "  result.g = getSoftLightComponent(src.g, src.a, dst.g, dst.a);"
+             "  result.b = getSoftLightComponent(src.b, src.a, dst.b, dst.a);"
+             "}";
+    case BLEND_MODE_DIFFERENCE:
+      return "result.rgb = src.rgb + dst.rgb -"
+             "    2.0 * min(src.rgb * dst.a, dst.rgb * src.a);";
+    case BLEND_MODE_EXCLUSION:
+      return "result.rgb = dst.rgb + src.rgb - 2.0 * dst.rgb * src.rgb;";
+    case BLEND_MODE_MULTIPLY:
+      return "result.rgb = (1.0 - src.a) * dst.rgb +"
+             "    (1.0 - dst.a) * src.rgb + src.rgb * dst.rgb;";
+    case BLEND_MODE_HUE:
+      return "vec4 dstSrcAlpha = dst * src.a;"
+             "result.rgb ="
+             "    set_luminance(set_saturation(src.rgb * dst.a,"
+             "                                 dstSrcAlpha.rgb),"
+             "                  dstSrcAlpha.a,"
+             "                  dstSrcAlpha.rgb);"
+             "result.rgb += (1.0 - src.a) * dst.rgb + (1.0 - dst.a) * src.rgb;";
+    case BLEND_MODE_SATURATION:
+      return "vec4 dstSrcAlpha = dst * src.a;"
+             "result.rgb = set_luminance(set_saturation(dstSrcAlpha.rgb,"
+             "                                          src.rgb * dst.a),"
+             "                           dstSrcAlpha.a,"
+             "                           dstSrcAlpha.rgb);"
+             "result.rgb += (1.0 - src.a) * dst.rgb + (1.0 - dst.a) * src.rgb;";
+    case BLEND_MODE_COLOR:
+      return "vec4 srcDstAlpha = src * dst.a;"
+             "result.rgb = set_luminance(srcDstAlpha.rgb,"
+             "                           srcDstAlpha.a,"
+             "                           dst.rgb * src.a);"
+             "result.rgb += (1.0 - src.a) * dst.rgb + (1.0 - dst.a) * src.rgb;";
+    case BLEND_MODE_LUMINOSITY:
+      return "vec4 srcDstAlpha = src * dst.a;"
+             "result.rgb = set_luminance(dst.rgb * src.a,"
+             "                           srcDstAlpha.a,"
+             "                           srcDstAlpha.rgb);"
+             "result.rgb += (1.0 - src.a) * dst.rgb + (1.0 - dst.a) * src.rgb;";
+    case BLEND_MODE_NONE:
+      NOTREACHED();
+  }
+  return "result = vec4(1.0, 0.0, 0.0, 1.0);";
+}
+
+std::string FragmentShader::GetShaderSource() const {
+  std::string header = "precision mediump float;\n";
+  std::string source = "void main() {\n";
+
+  // Read the input into vec4 texColor.
+  switch (input_color_type_) {
+    case INPUT_COLOR_SOURCE_RGBA_TEXTURE:
+      if (ignore_sampler_type_)
+        HDR("uniform sampler2D s_texture;");
+      else
+        HDR("uniform SamplerType s_texture;");
+      HDR("varying TexCoordPrecision vec2 v_texCoord;");
+      if (has_rgba_fragment_tex_transform_) {
+        HDR("uniform TexCoordPrecision vec4 fragmentTexTransform;");
+        SRC("// Transformed texture lookup");
+        SRC("TexCoordPrecision vec2 texCoord =");
+        SRC("    clamp(v_texCoord, 0.0, 1.0) * fragmentTexTransform.zw +");
+        SRC("   fragmentTexTransform.xy;");
+        SRC("vec4 texColor = TextureLookup(s_texture, texCoord);");
+        DCHECK(!ignore_sampler_type_);
+        DCHECK(!has_tex_clamp_rect_);
+      } else {
+        SRC("// Texture lookup");
+        if (ignore_sampler_type_) {
+          SRC("vec4 texColor = texture2D(s_texture, v_texCoord);");
+          DCHECK(!has_tex_clamp_rect_);
+        } else {
+          SRC("TexCoordPrecision vec2 texCoord = v_texCoord;");
+          if (has_tex_clamp_rect_) {
+            HDR("uniform vec4 tex_clamp_rect;");
+            SRC("texCoord = max(tex_clamp_rect.xy,");
+            SRC("    min(tex_clamp_rect.zw, texCoord));");
+          }
+          SRC("vec4 texColor = TextureLookup(s_texture, texCoord);");
+        }
+      }
+      break;
+    case INPUT_COLOR_SOURCE_YUV_TEXTURES:
+      DCHECK(!has_tex_clamp_rect_);
+      // Compute the clamped texture coordinates for the YA and UV textures.
+      HDR("uniform SamplerType y_texture;");
+      SRC("// YUV texture lookup and conversion to RGB.");
+      SRC("vec2 ya_clamped =");
+      SRC("    max(ya_clamp_rect.xy, min(ya_clamp_rect.zw, v_yaTexCoord));");
+      SRC("vec2 uv_clamped =");
+      SRC("    max(uv_clamp_rect.xy, min(uv_clamp_rect.zw, v_uvTexCoord));");
+      // Read the Y and UV or U and V textures into |yuv|.
+      SRC("vec4 texColor;");
+      SRC("texColor.w = 1.0;");
+      SRC("texColor.x = TextureLookup(y_texture, ya_clamped).x;");
+      if (uv_texture_mode_ == UV_TEXTURE_MODE_UV) {
+        HDR("uniform SamplerType uv_texture;");
+        SRC("texColor.yz = TextureLookup(uv_texture, uv_clamped).xy;");
+      }
+      if (uv_texture_mode_ == UV_TEXTURE_MODE_U_V) {
+        HDR("uniform SamplerType u_texture;");
+        HDR("uniform SamplerType v_texture;");
+        SRC("texColor.y = TextureLookup(u_texture, uv_clamped).x;");
+        SRC("texColor.z = TextureLookup(v_texture, uv_clamped).x;");
+      }
+      if (yuv_alpha_texture_mode_ == YUV_HAS_ALPHA_TEXTURE)
+        HDR("uniform SamplerType a_texture;");
+      HDR("uniform vec4 ya_clamp_rect;");
+      HDR("uniform vec4 uv_clamp_rect;");
+      HDR("uniform float resource_multiplier;");
+      HDR("uniform float resource_offset;");
+      HDR("varying TexCoordPrecision vec2 v_yaTexCoord;");
+      HDR("varying TexCoordPrecision vec2 v_uvTexCoord;");
+      SRC("texColor.xyz -= vec3(resource_offset);");
+      SRC("texColor.xyz *= resource_multiplier;");
+      break;
+    case INPUT_COLOR_SOURCE_UNIFORM:
+      DCHECK(!ignore_sampler_type_);
+      DCHECK(!has_rgba_fragment_tex_transform_);
+      DCHECK(!has_tex_clamp_rect_);
+      HDR("uniform vec4 color;");
+      SRC("// Uniform color");
+      SRC("vec4 texColor = color;");
+      break;
+  }
+
+  // Apply color conversion.
+  switch (color_conversion_mode_) {
+    case COLOR_CONVERSION_MODE_SHADER:
+      header += color_transform_->GetShaderSource();
+      // Un-premultiply by alpha.
+      if (premultiply_alpha_mode_ != NON_PREMULTIPLIED_ALPHA) {
+        SRC("// un-premultiply alpha");
+        SRC("if (texColor.a > 0.0) texColor.rgb /= texColor.a;");
+      }
+      SRC("texColor.rgb = DoColorConversion(texColor.xyz);");
+      SRC("texColor.rgb *= texColor.a;");
+      break;
+    case COLOR_CONVERSION_MODE_NONE:
+      // Premultiply by alpha.
+      if (premultiply_alpha_mode_ == NON_PREMULTIPLIED_ALPHA) {
+        SRC("// Premultiply alpha");
+        SRC("texColor.rgb *= texColor.a;");
+      }
+      break;
+  }
+
+  // Apply the color matrix to texColor.
+  if (has_color_matrix_) {
+    HDR("uniform mat4 colorMatrix;");
+    HDR("uniform vec4 colorOffset;");
+    SRC("// Apply color matrix");
+    SRC("float nonZeroAlpha = max(texColor.a, 0.00001);");
+    SRC("texColor = vec4(texColor.rgb / nonZeroAlpha, nonZeroAlpha);");
+    SRC("texColor = colorMatrix * texColor + colorOffset;");
+    SRC("texColor.rgb *= texColor.a;");
+    SRC("texColor = clamp(texColor, 0.0, 1.0);");
+  }
+
+  // Read the mask texture.
+  if (mask_mode_ != NO_MASK) {
+    HDR("uniform SamplerType s_mask;");
+    HDR("uniform vec2 maskTexCoordScale;");
+    HDR("uniform vec2 maskTexCoordOffset;");
+    SRC("// Read the mask");
+    SRC("TexCoordPrecision vec2 maskTexCoord =");
+    SRC("    vec2(maskTexCoordOffset.x + v_texCoord.x * maskTexCoordScale.x,");
+    SRC("         maskTexCoordOffset.y + v_texCoord.y * maskTexCoordScale.y);");
+    SRC("vec4 maskColor = TextureLookup(s_mask, maskTexCoord);");
+  }
+
+  // Compute AA.
+  if (aa_mode_ == USE_AA) {
+    HDR("varying TexCoordPrecision vec4 edge_dist[2];  // 8 edge distances.");
+    SRC("// Compute AA");
+    SRC("vec4 d4 = min(edge_dist[0], edge_dist[1]);");
+    SRC("vec2 d2 = min(d4.xz, d4.yw);");
+    SRC("float aa = clamp(gl_FragCoord.w * min(d2.x, d2.y), 0.0, 1.0);");
+  }
+
+  // Apply background texture.
+  if (has_background_color_) {
+    HDR("uniform vec4 background_color;");
+    SRC("// Apply uniform background color blending");
+    SRC("texColor += background_color * (1.0 - texColor.a);");
+  }
+
+  // Finally apply the output color matrix to texColor.
+  if (has_output_color_matrix_) {
+    HDR("uniform mat4 output_color_matrix;");
+    SRC("// Apply the output color matrix");
+    SRC("texColor = output_color_matrix * texColor;");
+  }
+
+  // Tint the final color. Used for debugging composited content.
+  if (has_tint_color_matrix_) {
+    HDR("uniform mat4 tint_color_matrix;");
+    SRC("// Apply the tint color matrix");
+    SRC("texColor = tint_color_matrix * texColor;");
+  }
+
+  // Include header text for alpha.
+  if (has_uniform_alpha_) {
+    HDR("uniform float alpha;");
+  }
+  if (has_varying_alpha_) {
+    HDR("varying float v_alpha;");
+  }
+
+  // Apply uniform alpha, aa, varying alpha, and the mask.
+  if (has_varying_alpha_ || aa_mode_ == USE_AA || has_uniform_alpha_ ||
+      mask_mode_ != NO_MASK) {
+    SRC("// Apply alpha from uniform, varying, aa, and mask.");
+    std::string line = "  texColor = texColor";
+    if (has_varying_alpha_)
+      line += " * v_alpha";
+    if (has_uniform_alpha_)
+      line += " * alpha";
+    if (aa_mode_ == USE_AA)
+      line += " * aa";
+    if (mask_mode_ != NO_MASK)
+      line += " * maskColor.a";
+    if (yuv_alpha_texture_mode_ == YUV_HAS_ALPHA_TEXTURE)
+      line += " * TextureLookup(a_texture, ya_clamped).x";
+    line += ";\n";
+    source += line;
+  }
+
+  // Write the fragment color.
+  SRC("// Write the fragment color");
+  switch (frag_color_mode_) {
+    case FRAG_COLOR_MODE_DEFAULT:
+      DCHECK_EQ(blend_mode_, BLEND_MODE_NONE);
+      SRC("gl_FragColor = texColor;");
+      break;
+    case FRAG_COLOR_MODE_OPAQUE:
+      DCHECK_EQ(blend_mode_, BLEND_MODE_NONE);
+      SRC("gl_FragColor = vec4(texColor.rgb, 1.0);");
+      break;
+    case FRAG_COLOR_MODE_APPLY_BLEND_MODE:
+      if (!has_blend_mode()) {
+        SRC("gl_FragColor = texColor;");
+      } else if (mask_mode_ != NO_MASK) {
+        if (mask_for_background_)
+          SRC("gl_FragColor = ApplyBlendMode(texColor, maskColor.w);");
+        else
+          SRC("gl_FragColor = ApplyBlendMode(texColor);");
+      } else {
+        SRC("gl_FragColor = ApplyBlendMode(texColor);");
+      }
+      break;
+  }
+
+  if (has_rounded_corner_)
+    SRC("gl_FragColor = ApplyRoundedCorner(gl_FragColor);");
+
+  source += "}\n";
+
+  return header + source;
+}
+
+}  // namespace viz
diff --git components/viz/service/display/shader.h components/viz/service/display/shader.h
new file mode 100644
index 0000000000000..41d6a000d662c
--- /dev/null
+++ components/viz/service/display/shader.h
@@ -0,0 +1,324 @@
+// Copyright 2011 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef COMPONENTS_VIZ_SERVICE_DISPLAY_SHADER_H_
+#define COMPONENTS_VIZ_SERVICE_DISPLAY_SHADER_H_
+
+#include <string>
+
+#include "base/memory/raw_ptr.h"
+#include "base/strings/string_piece.h"
+#include "components/viz/service/viz_service_export.h"
+
+namespace gfx {
+class ColorTransform;
+class Point;
+class Size;
+}  // namespace gfx
+
+namespace gpu {
+namespace gles2 {
+class GLES2Interface;
+}
+}  // namespace gpu
+
+namespace viz {
+
+enum TexCoordPrecision {
+  TEX_COORD_PRECISION_NA = 0,
+  TEX_COORD_PRECISION_MEDIUM = 1,
+  TEX_COORD_PRECISION_HIGH = 2,
+};
+
+// Texture coordinate sources for the vertex shader.
+enum TexCoordSource {
+  // Vertex shader does not populate a texture coordinate.
+  TEX_COORD_SOURCE_NONE,
+  // Texture coordinate is set to the untransformed position.
+  TEX_COORD_SOURCE_POSITION,
+  // Texture coordinate has its own attribute.
+  TEX_COORD_SOURCE_ATTRIBUTE,
+};
+
+// Texture coordinate transformation modes for the vertex shader.
+enum TexCoordTransform {
+  // Texture coordinates are not transformed.
+  TEX_COORD_TRANSFORM_NONE,
+  // Texture coordinates are transformed by a uniform vec4, scaling by zw and
+  // then translating by xy.
+  TEX_COORD_TRANSFORM_VEC4,
+  // Same as the above, but add vec2(0.5) to the texture coordinate first.
+  TEX_COORD_TRANSFORM_TRANSLATED_VEC4,
+  // Texture coordiantes are transformed by a uniform mat4.
+  TEX_COORD_TRANSFORM_MATRIX,
+};
+
+// Position source for the vertex shader.
+enum PositionSource {
+  // The position is read directly from the position attribute.
+  POSITION_SOURCE_ATTRIBUTE,
+  // The position is read by attribute index into a uniform array for xy, and
+  // getting zw from the attribute.
+  POSITION_SOURCE_ATTRIBUTE_INDEXED_UNIFORM,
+};
+
+enum AAMode {
+  NO_AA = 0,
+  USE_AA = 1,
+};
+
+enum PremultipliedAlphaMode {
+  PREMULTIPLIED_ALPHA = 0,
+  NON_PREMULTIPLIED_ALPHA = 1,
+};
+
+enum SamplerType {
+  SAMPLER_TYPE_NA = 0,
+  SAMPLER_TYPE_2D = 1,
+  SAMPLER_TYPE_2D_RECT = 2,
+  SAMPLER_TYPE_EXTERNAL_OES = 3,
+};
+
+enum BlendMode {
+  BLEND_MODE_NONE,
+  BLEND_MODE_NORMAL,
+  BLEND_MODE_DESTINATION_IN,
+  BLEND_MODE_SCREEN,
+  BLEND_MODE_OVERLAY,
+  BLEND_MODE_DARKEN,
+  BLEND_MODE_LIGHTEN,
+  BLEND_MODE_COLOR_DODGE,
+  BLEND_MODE_COLOR_BURN,
+  BLEND_MODE_HARD_LIGHT,
+  BLEND_MODE_SOFT_LIGHT,
+  BLEND_MODE_DIFFERENCE,
+  BLEND_MODE_EXCLUSION,
+  BLEND_MODE_MULTIPLY,
+  BLEND_MODE_HUE,
+  BLEND_MODE_SATURATION,
+  BLEND_MODE_COLOR,
+  BLEND_MODE_LUMINOSITY,
+  LAST_BLEND_MODE = BLEND_MODE_LUMINOSITY
+};
+
+enum InputColorSource {
+  // This includes RGB and RGBA textures.
+  INPUT_COLOR_SOURCE_RGBA_TEXTURE,
+  // This includes Y and either UV or U-and-V textures.
+  INPUT_COLOR_SOURCE_YUV_TEXTURES,
+  // A solid color specified as a uniform value.
+  INPUT_COLOR_SOURCE_UNIFORM,
+};
+
+enum UVTextureMode {
+  // Shader does not use YUV textures.
+  UV_TEXTURE_MODE_NA,
+  // UV plane is a single texture.
+  UV_TEXTURE_MODE_UV,
+  // U and V planes have separate textures.
+  UV_TEXTURE_MODE_U_V,
+};
+
+enum YUVAlphaTextureMode {
+  YUV_ALPHA_TEXTURE_MODE_NA,
+  YUV_NO_ALPHA_TEXTURE,
+  YUV_HAS_ALPHA_TEXTURE,
+};
+
+enum ColorConversionMode {
+  // No color conversion is performed.
+  COLOR_CONVERSION_MODE_NONE,
+  // Conversion is done analytically in the shader.
+  COLOR_CONVERSION_MODE_SHADER,
+};
+
+// TODO(ccameron): Merge this with BlendMode.
+enum FragColorMode {
+  FRAG_COLOR_MODE_DEFAULT,
+  FRAG_COLOR_MODE_OPAQUE,
+  FRAG_COLOR_MODE_APPLY_BLEND_MODE,
+};
+
+enum MaskMode {
+  NO_MASK = 0,
+  HAS_MASK = 1,
+};
+
+// Note: The highp_threshold_cache must be provided by the caller to make
+// the caching multi-thread/context safe in an easy low-overhead manner.
+// The caller must make sure to clear highp_threshold_cache to 0, so it can be
+// reinitialized, if a new or different context is used.
+VIZ_SERVICE_EXPORT TexCoordPrecision
+TexCoordPrecisionRequired(gpu::gles2::GLES2Interface* context,
+                          int* highp_threshold_cache,
+                          int highp_threshold_min,
+                          const gfx::Point& max_coordinate);
+
+VIZ_SERVICE_EXPORT TexCoordPrecision
+TexCoordPrecisionRequired(gpu::gles2::GLES2Interface* context,
+                          int* highp_threshold_cache,
+                          int highp_threshold_min,
+                          const gfx::Size& max_size);
+
+class VIZ_SERVICE_EXPORT VertexShader {
+ public:
+  VertexShader();
+  void Init(gpu::gles2::GLES2Interface* context,
+            unsigned program,
+            int* base_uniform_index);
+  std::string GetShaderString() const;
+
+ protected:
+  friend class Program;
+
+  // Use arrays of uniforms for matrix, texTransform, and opacity.
+  bool use_uniform_arrays_ = false;
+
+  PositionSource position_source_ = POSITION_SOURCE_ATTRIBUTE;
+  TexCoordSource tex_coord_source_ = TEX_COORD_SOURCE_NONE;
+  TexCoordTransform tex_coord_transform_ = TEX_COORD_TRANSFORM_NONE;
+
+  // Used only with TEX_COORD_TRANSFORM_VEC4.
+  int vertex_tex_transform_location_ = -1;
+
+  // Used only with TEX_COORD_TRANSFORM_MATRIX.
+  int tex_matrix_location_ = -1;
+
+  // Uniforms for YUV textures.
+  bool is_ya_uv_ = false;
+  int ya_tex_scale_location_ = -1;
+  int ya_tex_offset_location_ = -1;
+  int uv_tex_scale_location_ = -1;
+  int uv_tex_offset_location_ = -1;
+
+  // Matrix to transform the position.
+  int matrix_location_ = -1;
+
+  // Used only with POSITION_SOURCE_ATTRIBUTE_INDEXED_UNIFORM.
+  int quad_location_ = -1;
+
+  // Extra dummy variables to work around bugs on Android.
+  // TODO(ccameron): This is likley unneeded cargo-culting.
+  // http://crbug.com/240602
+  bool has_dummy_variables_ = false;
+
+  bool has_vertex_opacity_ = false;
+  int vertex_opacity_location_ = -1;
+
+  AAMode aa_mode_ = NO_AA;
+  int viewport_location_ = -1;
+  int edge_location_ = -1;
+};
+
+class VIZ_SERVICE_EXPORT FragmentShader {
+ public:
+  FragmentShader(const FragmentShader&) = delete;
+  FragmentShader& operator=(const FragmentShader&) = delete;
+
+  virtual void Init(gpu::gles2::GLES2Interface* context,
+                    unsigned program,
+                    int* base_uniform_index);
+  std::string GetShaderString() const;
+
+ protected:
+  FragmentShader();
+  virtual std::string GetShaderSource() const;
+  bool has_blend_mode() const { return blend_mode_ != BLEND_MODE_NONE; }
+
+  void SetBlendModeFunctions(std::string* shader_string) const;
+  void SetRoundedCornerFunctions(std::string* shader_string) const;
+
+  // Settings that are modified by sub-classes.
+  AAMode aa_mode_ = NO_AA;
+  bool has_varying_alpha_ = false;
+  PremultipliedAlphaMode premultiply_alpha_mode_ = PREMULTIPLIED_ALPHA;
+  FragColorMode frag_color_mode_ = FRAG_COLOR_MODE_DEFAULT;
+  InputColorSource input_color_type_ = INPUT_COLOR_SOURCE_RGBA_TEXTURE;
+
+  // Used only if |blend_mode_| is not BLEND_MODE_NONE.
+  int backdrop_location_ = -1;
+  int original_backdrop_location_ = -1;
+  int backdrop_rect_location_ = -1;
+
+  // Used only if |input_color_type_| is INPUT_COLOR_SOURCE_RGBA_TEXTURE.
+  bool has_rgba_fragment_tex_transform_ = false;
+  int sampler_location_ = -1;
+  int fragment_tex_transform_location_ = -1;
+
+  // Always use sampler2D and texture2D for the RGBA texture, regardless of the
+  // specified SamplerType.
+  // TODO(ccameron): Change GLRenderer to always specify the correct
+  // SamplerType.
+  bool ignore_sampler_type_ = false;
+
+  // Used only if |input_color_type_| is INPUT_COLOR_SOURCE_UNIFORM.
+  int color_location_ = -1;
+
+  MaskMode mask_mode_ = NO_MASK;
+  int mask_sampler_location_ = -1;
+  int mask_tex_coord_scale_location_ = -1;
+  int mask_tex_coord_offset_location_ = -1;
+
+  bool has_color_matrix_ = false;
+  int color_matrix_location_ = -1;
+  int color_offset_location_ = -1;
+
+  bool has_uniform_alpha_ = false;
+  int alpha_location_ = -1;
+
+  bool has_background_color_ = false;
+  int background_color_location_ = -1;
+
+  bool has_tex_clamp_rect_ = false;
+  int tex_clamp_rect_location_ = -1;
+
+  TexCoordPrecision tex_coord_precision_ = TEX_COORD_PRECISION_NA;
+  SamplerType sampler_type_ = SAMPLER_TYPE_NA;
+
+  BlendMode blend_mode_ = BLEND_MODE_NONE;
+  bool mask_for_background_ = false;
+
+  // YUV-only parameters.
+  YUVAlphaTextureMode yuv_alpha_texture_mode_ = YUV_ALPHA_TEXTURE_MODE_NA;
+  UVTextureMode uv_texture_mode_ = UV_TEXTURE_MODE_UV;
+
+  ColorConversionMode color_conversion_mode_ = COLOR_CONVERSION_MODE_NONE;
+  raw_ptr<const gfx::ColorTransform> color_transform_ = nullptr;
+
+  bool has_output_color_matrix_ = false;
+  int output_color_matrix_location_ = -1;
+
+  bool has_tint_color_matrix_ = false;
+  int tint_color_matrix_location_ = -1;
+
+  // YUV uniform locations.
+  int y_texture_location_ = -1;
+  int u_texture_location_ = -1;
+  int v_texture_location_ = -1;
+  int uv_texture_location_ = -1;
+  int a_texture_location_ = -1;
+  int ya_clamp_rect_location_ = -1;
+  int uv_clamp_rect_location_ = -1;
+
+  // Rounded corner locations
+  bool has_rounded_corner_ = false;
+  int rounded_corner_rect_location_ = -1;
+  int rounded_corner_radius_location_ = -1;
+
+  // The resource offset and multiplier to adjust for bit depth.
+  int resource_multiplier_location_ = -1;
+  int resource_offset_location_ = -1;
+
+ private:
+  friend class Program;
+
+  void AppendHelperFunctions(std::string* buffer) const;
+  void AppendBlendFunction(std::string* buffer) const;
+  base::StringPiece GetBlendFunctionBodyForAlpha() const;
+  base::StringPiece GetBlendFunctionBodyForRGB() const;
+};
+
+}  // namespace viz
+
+#endif  // COMPONENTS_VIZ_SERVICE_DISPLAY_SHADER_H_
diff --git components/viz/service/display/shader_unittest.cc components/viz/service/display/shader_unittest.cc
new file mode 100644
index 0000000000000..6990cbf14debb
--- /dev/null
+++ components/viz/service/display/shader_unittest.cc
@@ -0,0 +1,58 @@
+// Copyright 2013 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "components/viz/service/display/shader.h"
+
+#include "components/viz/test/test_context_provider.h"
+#include "components/viz/test/test_gles2_interface.h"
+#include "testing/gtest/include/gtest/gtest.h"
+#include "ui/gfx/geometry/point.h"
+#include "ui/gfx/geometry/size.h"
+
+namespace viz {
+
+TEST(ShaderTest, HighpThresholds) {
+  // The test gl always uses a mediump precision of 10 bits which
+  // corresponds to a native highp threshold of 2^10 = 1024
+  scoped_refptr<TestContextProvider> provider = TestContextProvider::Create();
+  provider->BindToCurrentThread();
+  gpu::gles2::GLES2Interface* test_gl = provider->ContextGL();
+
+  int threshold_cache = 0;
+  int threshold_min;
+  gfx::Point closePoint(512, 512);
+  gfx::Size smallSize(512, 512);
+  gfx::Point farPoint(2560, 2560);
+  gfx::Size bigSize(2560, 2560);
+
+  threshold_min = 0;
+  EXPECT_EQ(TEX_COORD_PRECISION_MEDIUM,
+            TexCoordPrecisionRequired(test_gl, &threshold_cache, threshold_min,
+                                      closePoint));
+  EXPECT_EQ(TEX_COORD_PRECISION_MEDIUM,
+            TexCoordPrecisionRequired(test_gl, &threshold_cache, threshold_min,
+                                      smallSize));
+  EXPECT_EQ(TEX_COORD_PRECISION_HIGH,
+            TexCoordPrecisionRequired(test_gl, &threshold_cache, threshold_min,
+                                      farPoint));
+  EXPECT_EQ(TEX_COORD_PRECISION_HIGH,
+            TexCoordPrecisionRequired(test_gl, &threshold_cache, threshold_min,
+                                      bigSize));
+
+  threshold_min = 3000;
+  EXPECT_EQ(TEX_COORD_PRECISION_MEDIUM,
+            TexCoordPrecisionRequired(test_gl, &threshold_cache, threshold_min,
+                                      closePoint));
+  EXPECT_EQ(TEX_COORD_PRECISION_MEDIUM,
+            TexCoordPrecisionRequired(test_gl, &threshold_cache, threshold_min,
+                                      smallSize));
+  EXPECT_EQ(TEX_COORD_PRECISION_MEDIUM,
+            TexCoordPrecisionRequired(test_gl, &threshold_cache, threshold_min,
+                                      farPoint));
+  EXPECT_EQ(TEX_COORD_PRECISION_MEDIUM,
+            TexCoordPrecisionRequired(test_gl, &threshold_cache, threshold_min,
+                                      bigSize));
+}
+
+}  // namespace viz
diff --git components/viz/service/display/skia_renderer.h components/viz/service/display/skia_renderer.h
index c6f95a30572cb..621fd8083c1a2 100644
--- components/viz/service/display/skia_renderer.h
+++ components/viz/service/display/skia_renderer.h
@@ -18,6 +18,7 @@
 #include "components/viz/service/display/direct_renderer.h"
 #include "components/viz/service/display/display_resource_provider_skia.h"
 #include "components/viz/service/display_embedder/buffer_queue.h"
+#include "components/viz/service/display/sync_query_collection.h"
 #include "components/viz/service/viz_service_export.h"
 #include "gpu/command_buffer/common/mailbox.h"
 #include "third_party/skia/include/core/SkCanvas.h"
diff --git components/viz/service/display/static_geometry_binding.cc components/viz/service/display/static_geometry_binding.cc
new file mode 100644
index 0000000000000..1dc0e9b717aa1
--- /dev/null
+++ components/viz/service/display/static_geometry_binding.cc
@@ -0,0 +1,74 @@
+// Copyright 2015 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "components/viz/service/display/static_geometry_binding.h"
+
+#include <stddef.h>
+#include <stdint.h>
+
+#include "gpu/command_buffer/client/gles2_interface.h"
+#include "ui/gfx/geometry/rect_f.h"
+
+namespace viz {
+
+StaticGeometryBinding::StaticGeometryBinding(gpu::gles2::GLES2Interface* gl,
+                                             const gfx::RectF& quad_vertex_rect)
+    : gl_(gl), quad_vertices_vbo_(0), quad_elements_vbo_(0) {
+  GeometryBindingQuad quads[NUM_QUADS];
+  GeometryBindingQuadIndex quad_indices[NUM_QUADS];
+
+  static_assert(sizeof(GeometryBindingQuad) == 24 * sizeof(float),
+                "struct Quad should be densely packed");
+  static_assert(sizeof(GeometryBindingQuadIndex) == 6 * sizeof(uint16_t),
+                "struct QuadIndex should be densely packed");
+
+  for (size_t i = 0; i < NUM_QUADS; i++) {
+    GeometryBindingVertex v0 = {
+        {quad_vertex_rect.x(), quad_vertex_rect.bottom(), 0.0f},
+        {0.0f, 1.0f},
+        i * 4.0f + 0.0f};
+    GeometryBindingVertex v1 = {
+        {quad_vertex_rect.x(), quad_vertex_rect.y(), 0.0f},
+        {0.0f, 0.0f},
+        i * 4.0f + 1.0f};
+    GeometryBindingVertex v2 = {
+        {quad_vertex_rect.right(), quad_vertex_rect.y(), 0.0f},
+        {1.0f, 0.0f},
+        i * 4.0f + 2.0f};
+    GeometryBindingVertex v3 = {
+        {quad_vertex_rect.right(), quad_vertex_rect.bottom(), 0.0f},
+        {1.0f, 1.0f},
+        i * 4.0f + 3.0f};
+    GeometryBindingQuad x(v0, v1, v2, v3);
+    quads[i] = x;
+    GeometryBindingQuadIndex y(
+        static_cast<uint16_t>(0 + 4 * i), static_cast<uint16_t>(1 + 4 * i),
+        static_cast<uint16_t>(2 + 4 * i), static_cast<uint16_t>(3 + 4 * i),
+        static_cast<uint16_t>(0 + 4 * i), static_cast<uint16_t>(2 + 4 * i));
+    quad_indices[i] = y;
+  }
+
+  gl_->GenBuffers(1, &quad_vertices_vbo_);
+  gl_->GenBuffers(1, &quad_elements_vbo_);
+
+  gl_->BindBuffer(GL_ARRAY_BUFFER, quad_vertices_vbo_);
+  gl_->BufferData(GL_ARRAY_BUFFER, sizeof(GeometryBindingQuad) * NUM_QUADS,
+                  quads, GL_STATIC_DRAW);
+
+  gl_->BindBuffer(GL_ELEMENT_ARRAY_BUFFER, quad_elements_vbo_);
+  gl_->BufferData(GL_ELEMENT_ARRAY_BUFFER,
+                  sizeof(GeometryBindingQuadIndex) * NUM_QUADS, &quad_indices,
+                  GL_STATIC_DRAW);
+}
+
+StaticGeometryBinding::~StaticGeometryBinding() {
+  gl_->DeleteBuffers(1, &quad_vertices_vbo_);
+  gl_->DeleteBuffers(1, &quad_elements_vbo_);
+}
+
+void StaticGeometryBinding::PrepareForDraw() {
+  SetupGLContext(gl_, quad_elements_vbo_, quad_vertices_vbo_);
+}
+
+}  // namespace viz
diff --git components/viz/service/display/static_geometry_binding.h components/viz/service/display/static_geometry_binding.h
new file mode 100644
index 0000000000000..2a09459426c22
--- /dev/null
+++ components/viz/service/display/static_geometry_binding.h
@@ -0,0 +1,41 @@
+// Copyright 2015 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef COMPONENTS_VIZ_SERVICE_DISPLAY_STATIC_GEOMETRY_BINDING_H_
+#define COMPONENTS_VIZ_SERVICE_DISPLAY_STATIC_GEOMETRY_BINDING_H_
+
+#include "base/memory/raw_ptr.h"
+#include "components/viz/service/display/geometry_binding.h"
+#include "components/viz/service/viz_service_export.h"
+
+using gpu::gles2::GLES2Interface;
+
+namespace viz {
+
+class VIZ_SERVICE_EXPORT StaticGeometryBinding {
+ public:
+  StaticGeometryBinding(gpu::gles2::GLES2Interface* gl,
+                        const gfx::RectF& quad_vertex_rect);
+
+  StaticGeometryBinding(const StaticGeometryBinding&) = delete;
+  StaticGeometryBinding& operator=(const StaticGeometryBinding&) = delete;
+
+  ~StaticGeometryBinding();
+
+  void PrepareForDraw();
+
+  enum {
+    NUM_QUADS = 9,
+  };
+
+ private:
+  raw_ptr<gpu::gles2::GLES2Interface> gl_;
+
+  GLuint quad_vertices_vbo_;
+  GLuint quad_elements_vbo_;
+};
+
+}  // namespace viz
+
+#endif  // COMPONENTS_VIZ_SERVICE_DISPLAY_STATIC_GEOMETRY_BINDING_H_
diff --git components/viz/service/display/sync_query_collection.cc components/viz/service/display/sync_query_collection.cc
new file mode 100644
index 0000000000000..51a85c415da18
--- /dev/null
+++ components/viz/service/display/sync_query_collection.cc
@@ -0,0 +1,151 @@
+// Copyright 2018 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "components/viz/service/display/sync_query_collection.h"
+
+#include <utility>
+
+#include "base/logging.h"
+#include "base/memory/raw_ptr.h"
+#include "base/memory/weak_ptr.h"
+#include "cc/base/container_util.h"
+#include "components/viz/service/display/resource_fence.h"
+#include "gpu/GLES2/gl2extchromium.h"
+#include "gpu/command_buffer/client/gles2_interface.h"
+
+namespace viz {
+namespace {
+// Block or crash if the number of pending sync queries reach this high as
+// something is seriously wrong on the service side if this happens.
+const size_t kMaxPendingSyncQueries = 16;
+}  // anonymous namespace
+
+class SyncQuery {
+ public:
+  explicit SyncQuery(gpu::gles2::GLES2Interface* gl)
+      : gl_(gl), query_id_(0u), is_pending_(false) {
+    gl_->GenQueriesEXT(1, &query_id_);
+  }
+
+  SyncQuery(const SyncQuery&) = delete;
+  SyncQuery& operator=(const SyncQuery&) = delete;
+
+  virtual ~SyncQuery() { gl_->DeleteQueriesEXT(1, &query_id_); }
+
+  scoped_refptr<ResourceFence> Begin() {
+    DCHECK(!IsPending());
+    // Invalidate weak pointer held by old fence.
+    weak_ptr_factory_.InvalidateWeakPtrs();
+    // Note: In case the set of drawing commands issued before End() do not
+    // depend on the query, defer BeginQueryEXT call until Set() is called and
+    // query is required.
+    return base::MakeRefCounted<Fence>(weak_ptr_factory_.GetWeakPtr());
+  }
+
+  void Set() {
+    if (is_pending_)
+      return;
+
+    // Note: BeginQueryEXT on GL_COMMANDS_COMPLETED_CHROMIUM is effectively a
+    // noop relative to GL, so it doesn't matter where it happens but we still
+    // make sure to issue this command when Set() is called (prior to issuing
+    // any drawing commands that depend on query), in case some future extension
+    // can take advantage of this.
+    gl_->BeginQueryEXT(GL_COMMANDS_COMPLETED_CHROMIUM, query_id_);
+    is_pending_ = true;
+  }
+
+  void End() {
+    if (!is_pending_)
+      return;
+
+    gl_->EndQueryEXT(GL_COMMANDS_COMPLETED_CHROMIUM);
+  }
+
+  bool IsPending() {
+    if (!is_pending_)
+      return false;
+
+    unsigned result_available = 1;
+    gl_->GetQueryObjectuivEXT(query_id_, GL_QUERY_RESULT_AVAILABLE_EXT,
+                              &result_available);
+    is_pending_ = !result_available;
+    return is_pending_;
+  }
+
+  void Wait() {
+    if (!is_pending_)
+      return;
+
+    unsigned result = 0;
+    gl_->GetQueryObjectuivEXT(query_id_, GL_QUERY_RESULT_EXT, &result);
+    is_pending_ = false;
+  }
+
+ private:
+  class Fence : public ResourceFence {
+   public:
+    explicit Fence(base::WeakPtr<SyncQuery> query) : query_(query) {}
+
+    Fence(const Fence&) = delete;
+    Fence& operator=(const Fence&) = delete;
+
+    // ResourceFence implementation.
+    void Set() override {
+      DCHECK(query_);
+      query_->Set();
+    }
+    bool HasPassed() override { return !query_ || !query_->IsPending(); }
+
+   private:
+    ~Fence() override {}
+
+    base::WeakPtr<SyncQuery> query_;
+  };
+
+  raw_ptr<gpu::gles2::GLES2Interface> gl_;
+  unsigned query_id_;
+  bool is_pending_;
+  base::WeakPtrFactory<SyncQuery> weak_ptr_factory_{this};
+};
+
+SyncQueryCollection::SyncQueryCollection(gpu::gles2::GLES2Interface* gl)
+    : gl_(gl) {}
+
+SyncQueryCollection::~SyncQueryCollection() = default;
+SyncQueryCollection::SyncQueryCollection(SyncQueryCollection&&) = default;
+SyncQueryCollection& SyncQueryCollection::operator=(SyncQueryCollection&&) =
+    default;
+
+scoped_refptr<ResourceFence> SyncQueryCollection::StartNewFrame() {
+  // Block until oldest sync query has passed if the number of pending queries
+  // ever reach kMaxPendingSyncQueries.
+  if (pending_sync_queries_.size() >= kMaxPendingSyncQueries) {
+    LOG(ERROR) << "Reached limit of pending sync queries.";
+
+    pending_sync_queries_.front()->Wait();
+    DCHECK(!pending_sync_queries_.front()->IsPending());
+  }
+
+  while (!pending_sync_queries_.empty()) {
+    if (pending_sync_queries_.front()->IsPending())
+      break;
+
+    available_sync_queries_.push_back(cc::PopFront(&pending_sync_queries_));
+  }
+
+  current_sync_query_ = available_sync_queries_.empty()
+                            ? std::make_unique<SyncQuery>(gl_)
+                            : cc::PopFront(&available_sync_queries_);
+
+  return current_sync_query_->Begin();
+}
+
+void SyncQueryCollection::EndCurrentFrame() {
+  DCHECK(current_sync_query_);
+  current_sync_query_->End();
+  pending_sync_queries_.push_back(std::move(current_sync_query_));
+}
+
+}  // namespace viz
diff --git components/viz/service/display/sync_query_collection.h components/viz/service/display/sync_query_collection.h
new file mode 100644
index 0000000000000..fd09cbba6d436
--- /dev/null
+++ components/viz/service/display/sync_query_collection.h
@@ -0,0 +1,42 @@
+// Copyright 2018 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef COMPONENTS_VIZ_SERVICE_DISPLAY_SYNC_QUERY_COLLECTION_H_
+#define COMPONENTS_VIZ_SERVICE_DISPLAY_SYNC_QUERY_COLLECTION_H_
+
+#include <memory>
+
+#include "base/containers/circular_deque.h"
+#include "base/memory/raw_ptr.h"
+#include "base/memory/ref_counted.h"
+
+namespace gpu {
+namespace gles2 {
+class GLES2Interface;
+}
+}  // namespace gpu
+
+namespace viz {
+class SyncQuery;
+class ResourceFence;
+
+class SyncQueryCollection {
+ public:
+  explicit SyncQueryCollection(gpu::gles2::GLES2Interface* gl);
+  SyncQueryCollection(SyncQueryCollection&&);
+  SyncQueryCollection& operator=(SyncQueryCollection&&);
+  ~SyncQueryCollection();
+  scoped_refptr<ResourceFence> StartNewFrame();
+  void EndCurrentFrame();
+
+ private:
+  base::circular_deque<std::unique_ptr<SyncQuery>> pending_sync_queries_;
+  base::circular_deque<std::unique_ptr<SyncQuery>> available_sync_queries_;
+  std::unique_ptr<SyncQuery> current_sync_query_;
+  raw_ptr<gpu::gles2::GLES2Interface> gl_;
+};
+
+}  // namespace viz
+
+#endif  // COMPONENTS_VIZ_SERVICE_DISPLAY_SYNC_QUERY_COLLECTION_H_
diff --git components/viz/service/display/texture_deleter.cc components/viz/service/display/texture_deleter.cc
new file mode 100644
index 0000000000000..76e2cf0b0f8b9
--- /dev/null
+++ components/viz/service/display/texture_deleter.cc
@@ -0,0 +1,87 @@
+// Copyright 2013 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "components/viz/service/display/texture_deleter.h"
+
+#include <stddef.h>
+#include <utility>
+
+#include "base/bind.h"
+#include "base/location.h"
+#include "base/memory/weak_ptr.h"
+#include "base/task/bind_post_task.h"
+#include "base/task/single_thread_task_runner.h"
+#include "components/viz/common/gpu/context_provider.h"
+#include "gpu/command_buffer/client/shared_image_interface.h"
+#include "gpu/command_buffer/common/mailbox.h"
+#include "gpu/command_buffer/common/sync_token.h"
+
+namespace viz {
+
+static void DeleteTextureOnImplThread(
+    const scoped_refptr<ContextProvider>& context_provider,
+    const gpu::Mailbox& mailbox,
+    const gpu::SyncToken& sync_token,
+    bool is_lost) {
+  context_provider->SharedImageInterface()->DestroySharedImage(sync_token,
+                                                               mailbox);
+}
+
+TextureDeleter::TextureDeleter(
+    scoped_refptr<base::SingleThreadTaskRunner> task_runner)
+    : impl_task_runner_(std::move(task_runner)) {}
+
+TextureDeleter::~TextureDeleter() {
+  for (auto& callback : impl_callbacks_)
+    std::move(*callback).Run(gpu::SyncToken(), /*is_lost=*/true);
+}
+
+ReleaseCallback TextureDeleter::GetReleaseCallback(
+    scoped_refptr<ContextProvider> context_provider,
+    const gpu::Mailbox& mailbox) {
+  // This callback owns the |context_provider|. It must be destroyed on the impl
+  // thread. Upon destruction of this class, the callback must immediately be
+  // destroyed.
+  auto impl_callback = std::make_unique<ReleaseCallback>(base::BindOnce(
+      &DeleteTextureOnImplThread, std::move(context_provider), mailbox));
+
+  impl_callbacks_.push_back(std::move(impl_callback));
+
+  // The raw pointer to the impl-side callback is valid as long as this
+  // class is alive. So we guard it with a WeakPtr.
+  ReleaseCallback run_impl_callback = base::BindOnce(
+      &TextureDeleter::RunDeleteTextureOnImplThread,
+      weak_ptr_factory_.GetWeakPtr(), impl_callbacks_.back().get());
+
+  // Provide a callback for the main thread that posts back to the impl
+  // thread.
+  ReleaseCallback main_callback;
+  if (impl_task_runner_) {
+    main_callback =
+        base::BindPostTask(impl_task_runner_, std::move(run_impl_callback));
+  } else {
+    main_callback = std::move(run_impl_callback);
+  }
+
+  return main_callback;
+}
+
+void TextureDeleter::RunDeleteTextureOnImplThread(
+    ReleaseCallback* impl_callback,
+    const gpu::SyncToken& sync_token,
+    bool is_lost) {
+  for (size_t i = 0; i < impl_callbacks_.size(); ++i) {
+    if (impl_callbacks_[i].get() == impl_callback) {
+      // Run the callback, then destroy it here on the impl thread.
+      std::move(*impl_callbacks_[i]).Run(sync_token, is_lost);
+      impl_callbacks_.erase(impl_callbacks_.begin() + i);
+      return;
+    }
+  }
+
+  NOTREACHED() << "The Callback returned by GetDeleteCallback() was called "
+               << "more than once.";
+}
+
+}  // namespace viz
diff --git components/viz/service/display/texture_deleter.h components/viz/service/display/texture_deleter.h
new file mode 100644
index 0000000000000..eadcd3dbcc265
--- /dev/null
+++ components/viz/service/display/texture_deleter.h
@@ -0,0 +1,64 @@
+// Copyright 2013 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef COMPONENTS_VIZ_SERVICE_DISPLAY_TEXTURE_DELETER_H_
+#define COMPONENTS_VIZ_SERVICE_DISPLAY_TEXTURE_DELETER_H_
+
+#include <memory>
+#include <vector>
+
+#include "base/memory/weak_ptr.h"
+#include "components/viz/common/resources/release_callback.h"
+#include "components/viz/service/viz_service_export.h"
+
+namespace base {
+class SingleThreadTaskRunner;
+}
+
+namespace gpu {
+struct Mailbox;
+struct SyncToken;
+}
+
+namespace viz {
+class ContextProvider;
+
+class VIZ_SERVICE_EXPORT TextureDeleter {
+ public:
+  // task_runner corresponds with the thread the delete task should be posted
+  // to. If null, the delete will happen on the calling thread.
+  explicit TextureDeleter(
+      scoped_refptr<base::SingleThreadTaskRunner> task_runner);
+
+  TextureDeleter(const TextureDeleter&) = delete;
+  TextureDeleter& operator=(const TextureDeleter&) = delete;
+
+  ~TextureDeleter();
+
+  // Returns a Callback that can be used as the ReleaseCallback for a
+  // |texture_id|. The ReleaseCallback can be passed to other threads and will
+  // destroy the texture, once it is run, on the impl thread. If the
+  // TextureDeleter is destroyed due to the compositor shutting down, then the
+  // ReleaseCallback will become a no-op and the texture will be deleted
+  // immediately on the impl thread, along with dropping the reference to the
+  // ContextProvider.
+  ReleaseCallback GetReleaseCallback(
+      scoped_refptr<ContextProvider> context_provider,
+      const gpu::Mailbox& mailbox);
+
+ private:
+  // Runs the |impl_callback| to delete the texture and removes the callback
+  // from the |impl_callbacks_| list.
+  void RunDeleteTextureOnImplThread(ReleaseCallback* impl_callback,
+                                    const gpu::SyncToken& sync_token,
+                                    bool is_lost);
+
+  scoped_refptr<base::SingleThreadTaskRunner> impl_task_runner_;
+  std::vector<std::unique_ptr<ReleaseCallback>> impl_callbacks_;
+  base::WeakPtrFactory<TextureDeleter> weak_ptr_factory_{this};
+};
+
+}  // namespace viz
+
+#endif  // COMPONENTS_VIZ_SERVICE_DISPLAY_TEXTURE_DELETER_H_
diff --git components/viz/service/display/texture_deleter_unittest.cc components/viz/service/display/texture_deleter_unittest.cc
new file mode 100644
index 0000000000000..e1df0821e0c73
--- /dev/null
+++ components/viz/service/display/texture_deleter_unittest.cc
@@ -0,0 +1,84 @@
+// Copyright 2013 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "components/viz/service/display/texture_deleter.h"
+
+#include <utility>
+
+#include "base/task/single_thread_task_runner.h"
+#include "base/threading/thread_task_runner_handle.h"
+#include "components/viz/common/resources/release_callback.h"
+#include "components/viz/test/test_context_provider.h"
+#include "gpu/command_buffer/client/shared_image_interface.h"
+#include "gpu/command_buffer/common/shared_image_usage.h"
+#include "testing/gtest/include/gtest/gtest.h"
+#include "ui/gfx/color_space.h"
+
+namespace viz {
+namespace {
+
+TEST(TextureDeleterTest, Destroy) {
+  auto deleter =
+      std::make_unique<TextureDeleter>(base::ThreadTaskRunnerHandle::Get());
+
+  scoped_refptr<TestContextProvider> context_provider =
+      TestContextProvider::Create();
+  context_provider->BindToCurrentThread();
+
+  auto* sii = context_provider->SharedImageInterface();
+
+  gpu::Mailbox mailbox = sii->CreateSharedImage(
+      ResourceFormat::RGBA_8888, gfx::Size(1, 1), gfx::ColorSpace(),
+      kTopLeft_GrSurfaceOrigin, kPremul_SkAlphaType,
+      gpu::SHARED_IMAGE_USAGE_GLES2, gpu::kNullSurfaceHandle);
+
+  EXPECT_TRUE(context_provider->HasOneRef());
+  EXPECT_EQ(1u, sii->shared_image_count());
+
+  ReleaseCallback cb = deleter->GetReleaseCallback(context_provider, mailbox);
+  EXPECT_FALSE(context_provider->HasOneRef());
+  EXPECT_EQ(1u, sii->shared_image_count());
+
+  // When the deleter is destroyed, it immediately drops its ref on the
+  // ContextProvider, and deletes the shared image.
+  deleter = nullptr;
+  EXPECT_TRUE(context_provider->HasOneRef());
+  EXPECT_EQ(0u, sii->shared_image_count());
+
+  // Run the scoped release callback before destroying it, but it won't do
+  // anything.
+  std::move(cb).Run(gpu::SyncToken(), false);
+}
+
+TEST(TextureDeleterTest, NullTaskRunner) {
+  auto deleter = std::make_unique<TextureDeleter>(nullptr);
+
+  scoped_refptr<TestContextProvider> context_provider =
+      TestContextProvider::Create();
+  context_provider->BindToCurrentThread();
+
+  auto* sii = context_provider->SharedImageInterface();
+
+  gpu::Mailbox mailbox = sii->CreateSharedImage(
+      ResourceFormat::RGBA_8888, gfx::Size(1, 1), gfx::ColorSpace(),
+      kTopLeft_GrSurfaceOrigin, kPremul_SkAlphaType,
+      gpu::SHARED_IMAGE_USAGE_GLES2, gpu::kNullSurfaceHandle);
+
+  EXPECT_TRUE(context_provider->HasOneRef());
+  EXPECT_EQ(1u, sii->shared_image_count());
+
+  ReleaseCallback cb = deleter->GetReleaseCallback(context_provider, mailbox);
+  EXPECT_FALSE(context_provider->HasOneRef());
+  EXPECT_EQ(1u, sii->shared_image_count());
+
+  std::move(cb).Run(gpu::SyncToken(), false);
+
+  // With no task runner the callback will immediately drops its ref on the
+  // ContextProvider and delete the shared image.
+  EXPECT_TRUE(context_provider->HasOneRef());
+  EXPECT_EQ(0u, sii->shared_image_count());
+}
+
+}  // namespace
+}  // namespace viz
diff --git components/viz/service/display_embedder/DEPS components/viz/service/display_embedder/DEPS
index 6f48eb9a6411f..4988c8b24d65e 100644
--- components/viz/service/display_embedder/DEPS
+++ components/viz/service/display_embedder/DEPS
@@ -45,12 +45,14 @@ include_rules = [
   "+ui/ozone/public",
 
   # TODO(danakj): Double check the layering for these dependencies.
+  "+components/viz/service/display/gl_renderer_copier.h",
   "+components/viz/service/display/overlay_processor.h",
   "+components/viz/service/display/overlay_processor_interface.h",
   "+components/viz/service/display/overlay_strategy_fullscreen.h",
   "+components/viz/service/display/overlay_strategy_single_on_top.h",
   "+components/viz/service/display/overlay_strategy_underlay_cast.h",
   "+components/viz/service/display/overlay_strategy_underlay.h",
+  "+components/viz/service/display/texture_deleter.h",
 ]
 
 specific_include_rules = {
diff --git components/viz/service/display_embedder/gl_output_surface.cc components/viz/service/display_embedder/gl_output_surface.cc
new file mode 100644
index 0000000000000..7e496db483a21
--- /dev/null
+++ components/viz/service/display_embedder/gl_output_surface.cc
@@ -0,0 +1,262 @@
+// Copyright 2014 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "components/viz/service/display_embedder/gl_output_surface.h"
+
+#include <utility>
+#include <vector>
+
+#include "base/bind.h"
+#include "base/threading/thread_task_runner_handle.h"
+#include "cc/base/math_util.h"
+#include "components/viz/common/frame_sinks/begin_frame_source.h"
+#include "components/viz/common/gpu/context_provider.h"
+#include "components/viz/service/display/output_surface_client.h"
+#include "components/viz/service/display/output_surface_frame.h"
+#include "components/viz/service/display/renderer_utils.h"
+#include "gpu/command_buffer/client/context_support.h"
+#include "gpu/command_buffer/client/gles2_interface.h"
+#include "gpu/command_buffer/common/swap_buffers_complete_params.h"
+#include "gpu/command_buffer/common/swap_buffers_flags.h"
+#include "gpu/config/gpu_feature_info.h"
+#include "ui/gfx/buffer_format_util.h"
+#include "ui/gfx/overlay_transform_utils.h"
+
+namespace viz {
+
+GLOutputSurface::GLOutputSurface(
+    scoped_refptr<VizProcessContextProvider> context_provider,
+    gpu::SurfaceHandle surface_handle)
+    : OutputSurface(context_provider),
+      viz_context_provider_(context_provider),
+      surface_handle_(surface_handle),
+      use_gpu_fence_(
+          context_provider->ContextCapabilities().chromium_gpu_fence &&
+          context_provider->ContextCapabilities()
+              .use_gpu_fences_for_overlay_planes) {
+  const auto& context_capabilities = context_provider->ContextCapabilities();
+  capabilities_.output_surface_origin = context_capabilities.surface_origin;
+  capabilities_.supports_stencil = context_capabilities.num_stencil_bits > 0;
+  // Since one of the buffers is used by the surface for presentation, there can
+  // be at most |num_surface_buffers - 1| pending buffers that the compositor
+  // can use.
+  capabilities_.pending_swap_params.max_pending_swaps =
+      context_capabilities.num_surface_buffers - 1;
+  capabilities_.supports_gpu_vsync = context_capabilities.gpu_vsync;
+  capabilities_.supports_dc_layers = context_capabilities.dc_layers;
+  capabilities_.supports_surfaceless = context_capabilities.surfaceless;
+  capabilities_.android_surface_control_feature_enabled =
+      context_provider->GetGpuFeatureInfo()
+          .status_values[gpu::GPU_FEATURE_TYPE_ANDROID_SURFACE_CONTROL] ==
+      gpu::kGpuFeatureStatusEnabled;
+  capabilities_.max_render_target_size = context_capabilities.max_texture_size;
+}
+
+GLOutputSurface::~GLOutputSurface() {
+  viz_context_provider_->SetUpdateVSyncParametersCallback(
+      UpdateVSyncParametersCallback());
+  viz_context_provider_->SetGpuVSyncCallback(GpuVSyncCallback());
+  if (gpu_fence_id_ > 0)
+    context_provider()->ContextGL()->DestroyGpuFenceCHROMIUM(gpu_fence_id_);
+}
+
+void GLOutputSurface::BindToClient(OutputSurfaceClient* client) {
+  DCHECK(client);
+  DCHECK(!client_);
+  client_ = client;
+}
+
+void GLOutputSurface::EnsureBackbuffer() {}
+
+void GLOutputSurface::DiscardBackbuffer() {
+  context_provider()->ContextGL()->DiscardBackbufferCHROMIUM();
+}
+
+void GLOutputSurface::BindFramebuffer() {
+  context_provider()->ContextGL()->BindFramebuffer(GL_FRAMEBUFFER, 0);
+}
+
+void GLOutputSurface::SetDrawRectangle(const gfx::Rect& rect) {
+  DCHECK(capabilities_.supports_dc_layers);
+
+  if (set_draw_rectangle_for_frame_)
+    return;
+  DCHECK(gfx::Rect(size_).Contains(rect));
+  DCHECK(has_set_draw_rectangle_since_last_resize_ ||
+         (gfx::Rect(size_) == rect));
+  set_draw_rectangle_for_frame_ = true;
+  has_set_draw_rectangle_since_last_resize_ = true;
+  context_provider()->ContextGL()->SetDrawRectangleCHROMIUM(
+      rect.x(), rect.y(), rect.width(), rect.height());
+}
+
+void GLOutputSurface::SetEnableDCLayers(bool enable) {
+  DCHECK(capabilities_.supports_dc_layers);
+  context_provider()->ContextGL()->SetEnableDCLayersCHROMIUM(enable);
+}
+
+void GLOutputSurface::Reshape(const ReshapeParams& params) {
+  size_ = params.size;
+  has_set_draw_rectangle_since_last_resize_ = false;
+  set_draw_rectangle_for_frame_ = false;
+  context_provider()->ContextGL()->ResizeCHROMIUM(
+      size_.width(), size_.height(), params.device_scale_factor,
+      params.color_space.AsGLColorSpace(),
+      gfx::AlphaBitsForBufferFormat(params.format));
+}
+
+void GLOutputSurface::SwapBuffers(OutputSurfaceFrame frame) {
+  DCHECK(context_provider_);
+
+  uint32_t flags = 0;
+  if (wants_vsync_parameter_updates_)
+    flags |= gpu::SwapBuffersFlags::kVSyncParams;
+
+  // The |swap_size| here should always be in the UI's logical screen space
+  // since it is forwarded to the client code which is unaware of the display
+  // transform optimization.
+  gfx::Size swap_size = ApplyDisplayInverse(gfx::Rect(size_)).size();
+  auto swap_callback = base::BindOnce(
+      &GLOutputSurface::OnGpuSwapBuffersCompleted,
+      weak_ptr_factory_.GetWeakPtr(), std::move(frame.latency_info),
+      frame.top_controls_visible_height_changed, swap_size);
+  gpu::ContextSupport::PresentationCallback presentation_callback;
+  presentation_callback = base::BindOnce(&GLOutputSurface::OnPresentation,
+                                         weak_ptr_factory_.GetWeakPtr());
+
+  set_draw_rectangle_for_frame_ = false;
+  if (frame.sub_buffer_rect) {
+    HandlePartialSwap(*frame.sub_buffer_rect, flags, std::move(swap_callback),
+                      std::move(presentation_callback));
+  } else if (!frame.content_bounds.empty()) {
+    context_provider_->ContextSupport()->SwapWithBounds(
+        frame.content_bounds, flags, std::move(swap_callback),
+        std::move(presentation_callback));
+  } else {
+    context_provider_->ContextSupport()->Swap(flags, std::move(swap_callback),
+                                              std::move(presentation_callback));
+  }
+}
+
+uint32_t GLOutputSurface::GetFramebufferCopyTextureFormat() {
+  auto* gl = static_cast<VizProcessContextProvider*>(context_provider());
+  return gl->GetCopyTextureInternalFormat();
+}
+
+bool GLOutputSurface::IsDisplayedAsOverlayPlane() const {
+  return false;
+}
+
+unsigned GLOutputSurface::GetOverlayTextureId() const {
+  return 0;
+}
+
+bool GLOutputSurface::HasExternalStencilTest() const {
+  return false;
+}
+
+void GLOutputSurface::ApplyExternalStencil() {}
+
+void GLOutputSurface::DidReceiveSwapBuffersAck(
+    const gfx::SwapResponse& response,
+    gfx::GpuFenceHandle release_fence) {
+  client_->DidReceiveSwapBuffersAck(response.timings, std::move(release_fence));
+}
+
+void GLOutputSurface::HandlePartialSwap(
+    const gfx::Rect& sub_buffer_rect,
+    uint32_t flags,
+    gpu::ContextSupport::SwapCompletedCallback swap_callback,
+    gpu::ContextSupport::PresentationCallback presentation_callback) {
+  context_provider_->ContextSupport()->PartialSwapBuffers(
+      sub_buffer_rect, flags, std::move(swap_callback),
+      std::move(presentation_callback));
+}
+
+void GLOutputSurface::OnGpuSwapBuffersCompleted(
+    std::vector<ui::LatencyInfo> latency_info,
+    bool top_controls_visible_height_changed,
+    const gfx::Size& pixel_size,
+    const gpu::SwapBuffersCompleteParams& params,
+    gfx::GpuFenceHandle release_fence) {
+  if (!params.texture_in_use_responses.empty())
+    client_->DidReceiveTextureInUseResponses(params.texture_in_use_responses);
+  if (!params.ca_layer_params.is_empty)
+    client_->DidReceiveCALayerParams(params.ca_layer_params);
+  DidReceiveSwapBuffersAck(params.swap_response, std::move(release_fence));
+
+  UpdateLatencyInfoOnSwap(params.swap_response, &latency_info);
+  latency_tracker_.OnGpuSwapBuffersCompleted(
+      std::move(latency_info), top_controls_visible_height_changed);
+
+  if (needs_swap_size_notifications_)
+    client_->DidSwapWithSize(pixel_size);
+}
+
+void GLOutputSurface::OnPresentation(
+    const gfx::PresentationFeedback& feedback) {
+  client_->DidReceivePresentationFeedback(feedback);
+}
+
+unsigned GLOutputSurface::UpdateGpuFence() {
+  if (!use_gpu_fence_)
+    return 0;
+
+  if (gpu_fence_id_ > 0)
+    context_provider()->ContextGL()->DestroyGpuFenceCHROMIUM(gpu_fence_id_);
+
+  gpu_fence_id_ = context_provider()->ContextGL()->CreateGpuFenceCHROMIUM();
+
+  return gpu_fence_id_;
+}
+
+void GLOutputSurface::SetNeedsSwapSizeNotifications(
+    bool needs_swap_size_notifications) {
+  needs_swap_size_notifications_ = needs_swap_size_notifications;
+}
+
+void GLOutputSurface::SetUpdateVSyncParametersCallback(
+    UpdateVSyncParametersCallback callback) {
+  wants_vsync_parameter_updates_ = !callback.is_null();
+  viz_context_provider_->SetUpdateVSyncParametersCallback(std::move(callback));
+}
+
+void GLOutputSurface::SetGpuVSyncCallback(GpuVSyncCallback callback) {
+  DCHECK(capabilities_.supports_gpu_vsync);
+  viz_context_provider_->SetGpuVSyncCallback(std::move(callback));
+}
+
+void GLOutputSurface::SetGpuVSyncEnabled(bool enabled) {
+  DCHECK(capabilities_.supports_gpu_vsync);
+  viz_context_provider_->SetGpuVSyncEnabled(enabled);
+}
+
+gfx::OverlayTransform GLOutputSurface::GetDisplayTransform() {
+  return gfx::OVERLAY_TRANSFORM_NONE;
+}
+
+gfx::Rect GLOutputSurface::ApplyDisplayInverse(const gfx::Rect& input) {
+  gfx::Transform display_inverse = gfx::OverlayTransformToTransform(
+      gfx::InvertOverlayTransform(GetDisplayTransform()), gfx::SizeF(size_));
+  return cc::MathUtil::MapEnclosedRectWith2dAxisAlignedTransform(
+      display_inverse, input);
+}
+
+base::ScopedClosureRunner GLOutputSurface::GetCacheBackBufferCb() {
+  return viz_context_provider_->GetCacheBackBufferCb();
+}
+
+gpu::SurfaceHandle GLOutputSurface::GetSurfaceHandle() const {
+  return surface_handle_;
+}
+
+void GLOutputSurface::SetFrameRate(float frame_rate) {
+  viz_context_provider_->ContextSupport()->SetFrameRate(frame_rate);
+}
+
+void GLOutputSurface::SetNeedsMeasureNextDrawLatency() {
+  viz_context_provider_->SetNeedsMeasureNextDrawLatency();
+}
+
+}  // namespace viz
diff --git components/viz/service/display_embedder/gl_output_surface.h components/viz/service/display_embedder/gl_output_surface.h
new file mode 100644
index 0000000000000..89ed78838e7b6
--- /dev/null
+++ components/viz/service/display_embedder/gl_output_surface.h
@@ -0,0 +1,110 @@
+// Copyright 2014 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef COMPONENTS_VIZ_SERVICE_DISPLAY_EMBEDDER_GL_OUTPUT_SURFACE_H_
+#define COMPONENTS_VIZ_SERVICE_DISPLAY_EMBEDDER_GL_OUTPUT_SURFACE_H_
+
+#include <memory>
+#include <vector>
+
+#include "base/callback_helpers.h"
+#include "base/memory/raw_ptr.h"
+#include "components/viz/common/display/update_vsync_parameters_callback.h"
+#include "components/viz/service/display/output_surface.h"
+#include "components/viz/service/display_embedder/viz_process_context_provider.h"
+#include "gpu/command_buffer/client/context_support.h"
+#include "ui/latency/latency_tracker.h"
+
+namespace viz {
+
+// An OutputSurface implementation that directly draws and
+// swaps to an actual GL surface.
+class GLOutputSurface : public OutputSurface {
+ public:
+  GLOutputSurface(scoped_refptr<VizProcessContextProvider> context_provider,
+                  gpu::SurfaceHandle surface_handle);
+  ~GLOutputSurface() override;
+
+  // OutputSurface implementation
+  void BindToClient(OutputSurfaceClient* client) override;
+  void EnsureBackbuffer() override;
+  void DiscardBackbuffer() override;
+  void BindFramebuffer() override;
+  void SetDrawRectangle(const gfx::Rect& draw_rectangle) override;
+  void SetEnableDCLayers(bool enabled) override;
+  void Reshape(const ReshapeParams& params) override;
+  void SwapBuffers(OutputSurfaceFrame frame) override;
+  uint32_t GetFramebufferCopyTextureFormat() override;
+  bool IsDisplayedAsOverlayPlane() const override;
+  unsigned GetOverlayTextureId() const override;
+  bool HasExternalStencilTest() const override;
+  void ApplyExternalStencil() override;
+  unsigned UpdateGpuFence() override;
+  void SetNeedsSwapSizeNotifications(
+      bool needs_swap_size_notifications) override;
+  void SetUpdateVSyncParametersCallback(
+      UpdateVSyncParametersCallback callback) override;
+  void SetGpuVSyncCallback(GpuVSyncCallback callback) override;
+  void SetGpuVSyncEnabled(bool enabled) override;
+  void SetDisplayTransformHint(gfx::OverlayTransform transform) override {}
+  gfx::OverlayTransform GetDisplayTransform() override;
+  base::ScopedClosureRunner GetCacheBackBufferCb() override;
+
+  gpu::SurfaceHandle GetSurfaceHandle() const override;
+  void SetFrameRate(float frame_rate) override;
+  void SetNeedsMeasureNextDrawLatency() override;
+
+ protected:
+  OutputSurfaceClient* client() const { return client_; }
+  ui::LatencyTracker* latency_tracker() { return &latency_tracker_; }
+  bool needs_swap_size_notifications() {
+    return needs_swap_size_notifications_;
+  }
+
+  // Called when a swap completion is signaled from ImageTransportSurface.
+  virtual void DidReceiveSwapBuffersAck(const gfx::SwapResponse& response,
+                                        gfx::GpuFenceHandle release_fence);
+
+  // Called in SwapBuffers() when a swap is determined to be partial. Subclasses
+  // might override this method because different platforms handle partial swaps
+  // differently.
+  virtual void HandlePartialSwap(
+      const gfx::Rect& sub_buffer_rect,
+      uint32_t flags,
+      gpu::ContextSupport::SwapCompletedCallback swap_callback,
+      gpu::ContextSupport::PresentationCallback presentation_callback);
+
+ private:
+  // Called when a swap completion is signaled from ImageTransportSurface.
+  void OnGpuSwapBuffersCompleted(std::vector<ui::LatencyInfo> latency_info,
+                                 bool top_controls_visible_height_changed,
+                                 const gfx::Size& pixel_size,
+                                 const gpu::SwapBuffersCompleteParams& params,
+                                 gfx::GpuFenceHandle release_fence);
+  void OnPresentation(const gfx::PresentationFeedback& feedback);
+  void OnGpuVSync(base::TimeTicks vsync_time, base::TimeDelta vsync_interval);
+  gfx::Rect ApplyDisplayInverse(const gfx::Rect& input);
+
+  scoped_refptr<VizProcessContextProvider> viz_context_provider_;
+  raw_ptr<OutputSurfaceClient> client_ = nullptr;
+  bool wants_vsync_parameter_updates_ = false;
+  ui::LatencyTracker latency_tracker_;
+
+  const gpu::SurfaceHandle surface_handle_;
+
+  bool set_draw_rectangle_for_frame_ = false;
+  // True if the draw rectangle has been set at all since the last resize.
+  bool has_set_draw_rectangle_since_last_resize_ = false;
+  gfx::Size size_;
+  bool use_gpu_fence_;
+  unsigned gpu_fence_id_ = 0;
+  // Whether to send OutputSurfaceClient::DidSwapWithSize notifications.
+  bool needs_swap_size_notifications_ = false;
+
+  base::WeakPtrFactory<GLOutputSurface> weak_ptr_factory_{this};
+};
+
+}  // namespace viz
+
+#endif  // COMPONENTS_VIZ_SERVICE_DISPLAY_EMBEDDER_GL_OUTPUT_SURFACE_H_
diff --git components/viz/service/display_embedder/gl_output_surface_android.cc components/viz/service/display_embedder/gl_output_surface_android.cc
new file mode 100644
index 0000000000000..741facb67427e
--- /dev/null
+++ components/viz/service/display_embedder/gl_output_surface_android.cc
@@ -0,0 +1,26 @@
+// Copyright 2018 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "components/viz/service/display_embedder/gl_output_surface_android.h"
+
+namespace viz {
+
+GLOutputSurfaceAndroid::GLOutputSurfaceAndroid(
+    scoped_refptr<VizProcessContextProvider> context_provider,
+    gpu::SurfaceHandle surface_handle)
+    : GLOutputSurface(context_provider, surface_handle) {}
+
+GLOutputSurfaceAndroid::~GLOutputSurfaceAndroid() = default;
+
+void GLOutputSurfaceAndroid::HandlePartialSwap(
+    const gfx::Rect& sub_buffer_rect,
+    uint32_t flags,
+    gpu::ContextSupport::SwapCompletedCallback swap_callback,
+    gpu::ContextSupport::PresentationCallback presentation_callback) {
+  DCHECK(sub_buffer_rect.IsEmpty());
+  context_provider_->ContextSupport()->CommitOverlayPlanes(
+      flags, std::move(swap_callback), std::move(presentation_callback));
+}
+
+}  // namespace viz
diff --git components/viz/service/display_embedder/gl_output_surface_android.h components/viz/service/display_embedder/gl_output_surface_android.h
new file mode 100644
index 0000000000000..8ad4a4326a95a
--- /dev/null
+++ components/viz/service/display_embedder/gl_output_surface_android.h
@@ -0,0 +1,32 @@
+// Copyright 2018 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef COMPONENTS_VIZ_SERVICE_DISPLAY_EMBEDDER_GL_OUTPUT_SURFACE_ANDROID_H_
+#define COMPONENTS_VIZ_SERVICE_DISPLAY_EMBEDDER_GL_OUTPUT_SURFACE_ANDROID_H_
+
+#include "components/viz/service/display_embedder/gl_output_surface.h"
+
+namespace viz {
+class GLOutputSurfaceAndroid : public GLOutputSurface {
+ public:
+  GLOutputSurfaceAndroid(
+      scoped_refptr<VizProcessContextProvider> context_provider,
+      gpu::SurfaceHandle surface_handle);
+
+  GLOutputSurfaceAndroid(const GLOutputSurfaceAndroid&) = delete;
+  GLOutputSurfaceAndroid& operator=(const GLOutputSurfaceAndroid&) = delete;
+
+  ~GLOutputSurfaceAndroid() override;
+
+  // GLOutputSurface implementation:
+  void HandlePartialSwap(
+      const gfx::Rect& sub_buffer_rect,
+      uint32_t flags,
+      gpu::ContextSupport::SwapCompletedCallback swap_callback,
+      gpu::ContextSupport::PresentationCallback presentation_callback) override;
+};
+
+}  // namespace viz
+
+#endif  // COMPONENTS_VIZ_SERVICE_DISPLAY_EMBEDDER_GL_OUTPUT_SURFACE_ANDROID_H_
diff --git components/viz/service/display_embedder/gl_output_surface_buffer_queue.cc components/viz/service/display_embedder/gl_output_surface_buffer_queue.cc
new file mode 100644
index 0000000000000..12fe6d47f4e5a
--- /dev/null
+++ components/viz/service/display_embedder/gl_output_surface_buffer_queue.cc
@@ -0,0 +1,309 @@
+// Copyright 2016 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "components/viz/service/display_embedder/gl_output_surface_buffer_queue.h"
+
+#include <utility>
+
+#include "base/bind.h"
+#include "base/command_line.h"
+#include "base/logging.h"
+#include "build/build_config.h"
+#include "build/chromeos_buildflags.h"
+#include "components/viz/common/frame_sinks/begin_frame_source.h"
+#include "components/viz/common/gpu/context_provider.h"
+#include "components/viz/common/switches.h"
+#include "components/viz/service/display/output_surface_client.h"
+#include "components/viz/service/display/output_surface_frame.h"
+#include "gpu/GLES2/gl2extchromium.h"
+#include "gpu/command_buffer/client/context_support.h"
+#include "gpu/command_buffer/client/gles2_interface.h"
+#include "gpu/command_buffer/common/gpu_memory_buffer_support.h"
+#include "gpu/command_buffer/common/sync_token.h"
+#include "ui/gl/buffer_format_utils.h"
+#include "ui/gl/gl_enums.h"
+#include "ui/gl/gl_fence.h"
+
+namespace viz {
+
+GLOutputSurfaceBufferQueue::GLOutputSurfaceBufferQueue(
+    scoped_refptr<VizProcessContextProvider> context_provider,
+    gpu::SurfaceHandle surface_handle,
+    std::unique_ptr<BufferQueue> buffer_queue)
+    : GLOutputSurface(context_provider, surface_handle),
+      buffer_queue_(std::move(buffer_queue)) {
+  capabilities_.only_invalidates_damage_rect = false;
+  capabilities_.uses_default_gl_framebuffer = false;
+  capabilities_.output_surface_origin = gfx::SurfaceOrigin::kTopLeft;
+  // Set |max_pending_swaps| to 2 for buffer_queue, which aligns scheduling
+  // more closely with the previous surfaced behavior.
+  // With a surface, swap buffer ack used to return early, before actually
+  // presenting the back buffer, enabling the browser compositor to run ahead.
+  // BufferQueue implementation acks at the time of actual buffer swap, which
+  // shifts the start of the new frame forward relative to the old
+  // implementation.
+  capabilities_.pending_swap_params.max_pending_swaps = 2;
+  // GetCurrentFramebufferDamage will return an upper bound of the part of the
+  // buffer that needs to be recomposited.
+#if BUILDFLAG(IS_APPLE)
+  capabilities_.supports_target_damage = false;
+#else
+  capabilities_.supports_target_damage = true;
+#endif
+  // Force the number of max pending frames to one when the switch
+  // "double-buffer-compositing" is passed.
+  // This will keep compositing in double buffered mode assuming |buffer_queue_|
+  // allocates at most one additional buffer.
+  base::CommandLine* command_line = base::CommandLine::ForCurrentProcess();
+  if (command_line->HasSwitch(switches::kDoubleBufferCompositing)) {
+    capabilities_.pending_swap_params.max_pending_swaps = 1;
+    buffer_queue_->SetMaxBuffers(2);
+  }
+
+  // It is safe to pass a raw pointer to *this because |buffer_queue_| is fully
+  // owned and it doesn't use the SyncTokenProvider after it's destroyed.
+  DCHECK(buffer_queue_);
+  buffer_queue_->SetSyncTokenProvider(this);
+  context_provider_->ContextGL()->GenFramebuffers(1, &fbo_);
+}
+
+GLOutputSurfaceBufferQueue::~GLOutputSurfaceBufferQueue() {
+  auto* gl = context_provider_->ContextGL();
+  DCHECK_NE(0u, fbo_);
+  gl->DeleteFramebuffers(1, &fbo_);
+  if (stencil_buffer_)
+    gl->DeleteRenderbuffers(1, &stencil_buffer_);
+  for (const auto& buffer_texture : buffer_queue_textures_)
+    gl->DeleteTextures(1u, &buffer_texture.second);
+  buffer_queue_textures_.clear();
+  current_texture_ = 0u;
+  last_bound_texture_ = 0u;
+  last_bound_mailbox_.SetZero();
+
+  // Freeing the BufferQueue here ensures that *this is fully alive in case the
+  // BufferQueue needs the SyncTokenProvider functionality.
+  buffer_queue_.reset();
+  fbo_ = 0u;
+  stencil_buffer_ = 0u;
+}
+
+void GLOutputSurfaceBufferQueue::BindFramebuffer() {
+  auto* gl = context_provider_->ContextGL();
+  gl->BindFramebuffer(GL_FRAMEBUFFER, fbo_);
+
+  // If we have a |current_texture_|, it means we haven't swapped the buffer, so
+  // we're just wanting to rebind the GL framebuffer.
+  if (current_texture_)
+    return;
+
+  DCHECK(buffer_queue_);
+  gpu::SyncToken creation_sync_token;
+  gfx::GpuFenceHandle release_fence;
+  const gpu::Mailbox current_buffer =
+      buffer_queue_->GetCurrentBuffer(&creation_sync_token, &release_fence);
+  if (current_buffer.IsZero())
+    return;
+  gl->WaitSyncTokenCHROMIUM(creation_sync_token.GetConstData());
+  if (!release_fence.is_null()) {
+    auto fence = gfx::GpuFence(std::move(release_fence));
+    if (gl::GLFence::IsGpuFenceSupported()) {
+      auto id = gl->CreateClientGpuFenceCHROMIUM(fence.AsClientGpuFence());
+      gl->WaitGpuFenceCHROMIUM(id);
+      gl->DestroyGpuFenceCHROMIUM(id);
+    } else {
+      fence.Wait();
+    }
+  }
+  unsigned& buffer_texture = buffer_queue_textures_[current_buffer];
+  if (!buffer_texture) {
+    buffer_texture =
+        gl->CreateAndTexStorage2DSharedImageCHROMIUM(current_buffer.name);
+  }
+  current_texture_ = buffer_texture;
+  gl->BeginSharedImageAccessDirectCHROMIUM(
+      current_texture_, GL_SHARED_IMAGE_ACCESS_MODE_READWRITE_CHROMIUM);
+  gl->FramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0,
+                           texture_target_, current_texture_, 0);
+  last_bound_texture_ = current_texture_;
+  last_bound_mailbox_ = current_buffer;
+
+#if DCHECK_IS_ON() && BUILDFLAG(IS_CHROMEOS_ASH)
+  const GLenum result = gl->CheckFramebufferStatus(GL_FRAMEBUFFER);
+  if (result != GL_FRAMEBUFFER_COMPLETE)
+    DLOG(ERROR) << " Incomplete fb: " << gl::GLEnums::GetStringError(result);
+#endif
+
+  // Reshape() must be called to go from using a stencil buffer to not using it.
+  DCHECK(use_stencil_ || !stencil_buffer_);
+  if (use_stencil_ && !stencil_buffer_) {
+    gl->GenRenderbuffers(1, &stencil_buffer_);
+    CHECK_NE(stencil_buffer_, 0u);
+    gl->BindRenderbuffer(GL_RENDERBUFFER, stencil_buffer_);
+    gl->RenderbufferStorage(GL_RENDERBUFFER, GL_STENCIL_INDEX8,
+                            reshape_size_.width(), reshape_size_.height());
+    gl->BindRenderbuffer(GL_RENDERBUFFER, 0);
+    gl->FramebufferRenderbuffer(GL_FRAMEBUFFER, GL_STENCIL_ATTACHMENT,
+                                GL_RENDERBUFFER, stencil_buffer_);
+  }
+}
+
+// We call this on every frame that a value changes, but changing the size once
+// we've allocated backing NativePixmapBufferQueue instances will cause a DCHECK
+// because Chrome never Reshape(s) after the first one from (0,0). NB: this
+// implies that screen size changes need to be plumbed differently. In
+// particular, we must create the native window in the size that the hardware
+// reports.
+void GLOutputSurfaceBufferQueue::Reshape(const ReshapeParams& params) {
+  reshape_size_ = params.size;
+  use_stencil_ = params.use_stencil;
+  GLOutputSurface::Reshape(params);
+  DCHECK(buffer_queue_);
+  const bool may_have_freed_buffers =
+      buffer_queue_->Reshape(params.size, params.color_space, params.format);
+  if (may_have_freed_buffers || (stencil_buffer_ && !params.use_stencil)) {
+    auto* gl = context_provider_->ContextGL();
+    gl->BindFramebuffer(GL_FRAMEBUFFER, fbo_);
+    if (stencil_buffer_) {
+      gl->FramebufferRenderbuffer(GL_FRAMEBUFFER, GL_STENCIL_ATTACHMENT,
+                                  GL_RENDERBUFFER, 0);
+      gl->DeleteRenderbuffers(1, &stencil_buffer_);
+      stencil_buffer_ = 0u;
+    }
+
+    // Note that |texture_target_| is initially set to 0, and so if it has not
+    // been set to a valid value, then no buffers have been allocated.
+    if (texture_target_ && may_have_freed_buffers) {
+      gl->FramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0,
+                               texture_target_, 0, 0);
+      for (const auto& buffer_texture : buffer_queue_textures_)
+        gl->DeleteTextures(1u, &buffer_texture.second);
+      buffer_queue_textures_.clear();
+      current_texture_ = 0u;
+      last_bound_texture_ = 0u;
+      last_bound_mailbox_.SetZero();
+    }
+  }
+
+  texture_target_ =
+      gpu::GetBufferTextureTarget(gfx::BufferUsage::SCANOUT, params.format,
+                                  context_provider_->ContextCapabilities());
+}
+
+void GLOutputSurfaceBufferQueue::SwapBuffers(OutputSurfaceFrame frame) {
+  DCHECK(buffer_queue_);
+
+  // TODO(rjkroege): What if swap happens again before DidReceiveSwapBuffersAck
+  // then it would see the wrong size?
+  DCHECK(reshape_size_ == frame.size);
+  swap_size_ = reshape_size_;
+
+  gfx::Rect damage_rect =
+      frame.sub_buffer_rect ? *frame.sub_buffer_rect : gfx::Rect(swap_size_);
+
+  // If the client is currently drawing, we first end access to the
+  // corresponding shared image. Then, we can swap the buffers. That way, we
+  // know that whatever GL commands GLOutputSurface::SwapBuffers() emits can
+  // access the shared image.
+  auto* gl = context_provider_->ContextGL();
+  if (current_texture_) {
+    gl->EndSharedImageAccessDirectCHROMIUM(current_texture_);
+    gl->BindFramebuffer(GL_FRAMEBUFFER, 0u);
+    current_texture_ = 0u;
+  }
+  buffer_queue_->SwapBuffers(damage_rect);
+  GLOutputSurface::SwapBuffers(std::move(frame));
+}
+
+gfx::Rect GLOutputSurfaceBufferQueue::GetCurrentFramebufferDamage() const {
+  return buffer_queue_->CurrentBufferDamage();
+}
+
+uint32_t GLOutputSurfaceBufferQueue::GetFramebufferCopyTextureFormat() {
+  return base::strict_cast<GLenum>(
+      gl::BufferFormatToGLInternalFormat(buffer_queue_->buffer_format()));
+}
+
+bool GLOutputSurfaceBufferQueue::IsDisplayedAsOverlayPlane() const {
+  return true;
+}
+
+unsigned GLOutputSurfaceBufferQueue::GetOverlayTextureId() const {
+  DCHECK(last_bound_texture_);
+  return last_bound_texture_;
+}
+
+gpu::Mailbox GLOutputSurfaceBufferQueue::GetOverlayMailbox() const {
+  return last_bound_mailbox_;
+}
+
+void GLOutputSurfaceBufferQueue::DidReceiveSwapBuffersAck(
+    const gfx::SwapResponse& response,
+    gfx::GpuFenceHandle release_fence) {
+  bool force_swap = false;
+  if (response.result == gfx::SwapResult::SWAP_NAK_RECREATE_BUFFERS) {
+    // Even through the swap failed, this is a fixable error so we can pretend
+    // it succeeded to the rest of the system.
+    buffer_queue_->FreeAllSurfaces();
+
+    // TODO(andrescj): centralize the logic that deletes the stencil buffer and
+    // the textures since we do this in multiple places.
+    auto* gl = context_provider_->ContextGL();
+    gl->BindFramebuffer(GL_FRAMEBUFFER, fbo_);
+    if (stencil_buffer_) {
+      gl->FramebufferRenderbuffer(GL_FRAMEBUFFER, GL_STENCIL_ATTACHMENT,
+                                  GL_RENDERBUFFER, 0);
+      gl->DeleteRenderbuffers(1, &stencil_buffer_);
+      stencil_buffer_ = 0u;
+    }
+
+    // Reshape() must have been called before we got here, so |texture_target_|
+    // should contain a valid value.
+    DCHECK(texture_target_);
+    gl->FramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0,
+                             texture_target_, 0, 0);
+    for (const auto& buffer_texture : buffer_queue_textures_)
+      gl->DeleteTextures(1u, &buffer_texture.second);
+    buffer_queue_textures_.clear();
+    current_texture_ = 0u;
+    last_bound_texture_ = 0u;
+    last_bound_mailbox_.SetZero();
+
+    force_swap = true;
+  }
+
+  buffer_queue_->PageFlipComplete(release_fence.Clone());
+  client()->DidReceiveSwapBuffersAck(response.timings,
+                                     std::move(release_fence));
+
+  if (force_swap)
+    client()->SetNeedsRedrawRect(gfx::Rect(swap_size_));
+}
+
+gpu::SyncToken GLOutputSurfaceBufferQueue::GenSyncToken() {
+  // This should only be called as long as the BufferQueue is alive. We cannot
+  // use |buffer_queue_| to detect this because in the dtor, |buffer_queue_|
+  // becomes nullptr before BufferQueue's dtor is called, so GenSyncToken()
+  // would be called after |buffer_queue_| is nullptr when in fact, the
+  // BufferQueue is still alive. Hence, we use |fbo_| to detect that the
+  // BufferQueue is still alive.
+  DCHECK(fbo_);
+  gpu::SyncToken sync_token;
+  context_provider_->ContextGL()->GenUnverifiedSyncTokenCHROMIUM(
+      sync_token.GetData());
+  return sync_token;
+}
+
+void GLOutputSurfaceBufferQueue::SetDisplayTransformHint(
+    gfx::OverlayTransform transform) {
+  display_transform_ = transform;
+
+  if (context_provider_)
+    context_provider_->ContextSupport()->SetDisplayTransform(transform);
+}
+
+gfx::OverlayTransform GLOutputSurfaceBufferQueue::GetDisplayTransform() {
+  return display_transform_;
+}
+
+}  // namespace viz
diff --git components/viz/service/display_embedder/gl_output_surface_buffer_queue.h components/viz/service/display_embedder/gl_output_surface_buffer_queue.h
new file mode 100644
index 0000000000000..10f9309fa1e62
--- /dev/null
+++ components/viz/service/display_embedder/gl_output_surface_buffer_queue.h
@@ -0,0 +1,107 @@
+// Copyright 2016 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef COMPONENTS_VIZ_SERVICE_DISPLAY_EMBEDDER_GL_OUTPUT_SURFACE_BUFFER_QUEUE_H_
+#define COMPONENTS_VIZ_SERVICE_DISPLAY_EMBEDDER_GL_OUTPUT_SURFACE_BUFFER_QUEUE_H_
+
+#include <stdint.h>
+
+#include <memory>
+
+#include "base/containers/flat_map.h"
+#include "base/gtest_prod_util.h"
+#include "base/memory/weak_ptr.h"
+#include "components/viz/common/gpu/context_provider.h"
+#include "components/viz/service/display/output_surface.h"
+#include "components/viz/service/display_embedder/buffer_queue.h"
+#include "components/viz/service/display_embedder/gl_output_surface.h"
+#include "components/viz/service/display_embedder/viz_process_context_provider.h"
+#include "components/viz/service/viz_service_export.h"
+#include "gpu/command_buffer/common/mailbox.h"
+#include "ui/gfx/geometry/rect.h"
+#include "ui/gfx/geometry/size.h"
+#include "ui/gfx/native_widget_types.h"
+#include "ui/gfx/swap_result.h"
+#include "ui/gl/gl_surface.h"
+
+namespace viz {
+
+// An OutputSurface implementation that directly draws and swap to a GL
+// "buffer_queue" surface (aka one backed by a buffer managed explicitly).
+class VIZ_SERVICE_EXPORT GLOutputSurfaceBufferQueue
+    : public GLOutputSurface,
+      public BufferQueue::SyncTokenProvider {
+ public:
+  GLOutputSurfaceBufferQueue(
+      scoped_refptr<VizProcessContextProvider> context_provider,
+      gpu::SurfaceHandle surface_handle,
+      std::unique_ptr<BufferQueue> buffer_queue);
+
+  GLOutputSurfaceBufferQueue(const GLOutputSurfaceBufferQueue&) = delete;
+  GLOutputSurfaceBufferQueue& operator=(const GLOutputSurfaceBufferQueue&) =
+      delete;
+
+  ~GLOutputSurfaceBufferQueue() override;
+
+  // BufferQueue::SyncTokenProvider implementation.
+  gpu::SyncToken GenSyncToken() override;
+
+ protected:
+  // OutputSurface implementation.
+  void SetDisplayTransformHint(gfx::OverlayTransform transform) override;
+  gfx::OverlayTransform GetDisplayTransform() override;
+  void Reshape(const ReshapeParams& params) override;
+
+ private:
+  FRIEND_TEST_ALL_PREFIXES(GLOutputSurfaceBufferQueueTest, HandleSwapNAK);
+
+  // OutputSurface implementation.
+  void BindFramebuffer() override;
+  void SwapBuffers(OutputSurfaceFrame frame) override;
+  gfx::Rect GetCurrentFramebufferDamage() const override;
+  uint32_t GetFramebufferCopyTextureFormat() override;
+  bool IsDisplayedAsOverlayPlane() const override;
+  unsigned GetOverlayTextureId() const override;
+  gpu::Mailbox GetOverlayMailbox() const override;
+
+  // GLOutputSurface:
+  void DidReceiveSwapBuffersAck(const gfx::SwapResponse& response,
+                                gfx::GpuFenceHandle release_fence) override;
+
+  std::unique_ptr<BufferQueue> buffer_queue_;
+
+  // |buffer_queue_textures_| caches the textures generated by consuming the
+  // SharedImage mailboxes from the |buffer_queue_| so that we don't have to
+  // generate a new texture every time a shared image is re-used.
+  base::flat_map<gpu::Mailbox, unsigned> buffer_queue_textures_;
+
+  // |current_texture_| is the texture currently being drawn to. It's one of
+  // |buffer_queue_textures_| or 0 if the client is not currently drawing (i.e.,
+  // we're not currently in between a BindFramebuffer()/SwapBuffers() pair).
+  // |last_bound_texture_| is the texture that was last bound to |fbo_|. It's
+  // also one of |buffer_queue_textures_| or 0 if no texture has been bound to
+  // |fbo_| or all the buffers in the buffer queue have been freed.
+  // |last_bound_mailbox_| is the mailbox corresponding to
+  // |last_bound_texture_|.
+  //
+  // TODO(andrescj): use an RAII pattern to scope access to |current_texture_|
+  // because it requires Begin/EndSharedImageAccessDirectCHROMIUM().
+  unsigned current_texture_ = 0u;
+  unsigned last_bound_texture_ = 0u;
+  gpu::Mailbox last_bound_mailbox_;
+  unsigned texture_target_ = 0u;
+
+  unsigned fbo_ = 0u;
+
+  bool use_stencil_ = false;
+  unsigned stencil_buffer_ = 0u;
+
+  gfx::OverlayTransform display_transform_ = gfx::OVERLAY_TRANSFORM_NONE;
+  gfx::Size reshape_size_;
+  gfx::Size swap_size_;
+};
+
+}  // namespace viz
+
+#endif  // COMPONENTS_VIZ_SERVICE_DISPLAY_EMBEDDER_GL_OUTPUT_SURFACE_BUFFER_QUEUE_H_
diff --git components/viz/service/display_embedder/gl_output_surface_buffer_queue_unittest.cc components/viz/service/display_embedder/gl_output_surface_buffer_queue_unittest.cc
new file mode 100644
index 0000000000000..6730a7cb0fe93
--- /dev/null
+++ components/viz/service/display_embedder/gl_output_surface_buffer_queue_unittest.cc
@@ -0,0 +1,362 @@
+// Copyright 2019 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "components/viz/service/display_embedder/gl_output_surface_buffer_queue.h"
+
+#include <utility>
+#include <vector>
+
+#include "base/memory/raw_ptr.h"
+#include "components/viz/service/display/output_surface_client.h"
+#include "components/viz/service/display/output_surface_frame.h"
+#include "components/viz/service/display_embedder/buffer_queue.h"
+#include "components/viz/test/test_context_provider.h"
+#include "components/viz/test/test_context_support.h"
+#include "components/viz/test/test_gles2_interface.h"
+#include "gpu/command_buffer/common/command_buffer_id.h"
+#include "gpu/command_buffer/common/constants.h"
+#include "gpu/command_buffer/common/mailbox.h"
+#include "gpu/command_buffer/common/sync_token.h"
+#include "gpu/ipc/common/surface_handle.h"
+#include "testing/gmock/include/gmock/gmock.h"
+#include "testing/gtest/include/gtest/gtest.h"
+#include "ui/gfx/buffer_types.h"
+#include "ui/gfx/swap_result.h"
+
+using testing::_;
+using testing::DoAll;
+using testing::Eq;
+using testing::InSequence;
+using testing::Mock;
+using testing::Ne;
+using testing::NotNull;
+using testing::Pointee;
+using testing::Return;
+using testing::SetArgPointee;
+using testing::StrictMock;
+
+namespace viz {
+namespace {
+
+class TestVizProcessContextProvider : public VizProcessContextProvider {
+ public:
+  TestVizProcessContextProvider(std::unique_ptr<TestContextSupport> support,
+                                std::unique_ptr<TestGLES2Interface> gl)
+      : support_(std::move(support)), context_gl_(std::move(gl)) {}
+  TestVizProcessContextProvider(const TestVizProcessContextProvider&) = delete;
+  TestVizProcessContextProvider& operator=(
+      const TestVizProcessContextProvider&) = delete;
+
+  // ContextProvider implementation.
+  gpu::gles2::GLES2Interface* ContextGL() override { return context_gl_.get(); }
+  gpu::ContextSupport* ContextSupport() override { return support_.get(); }
+  const gpu::Capabilities& ContextCapabilities() const override {
+    return gpu_capabilities_;
+  }
+
+  const gpu::GpuFeatureInfo& GetGpuFeatureInfo() const override {
+    return gpu_feature_info_;
+  }
+
+  void SetUpdateVSyncParametersCallback(
+      UpdateVSyncParametersCallback callback) override {}
+  void SetGpuVSyncCallback(GpuVSyncCallback callback) override {}
+  void SetGpuVSyncEnabled(bool enabled) override {}
+  bool UseRGB565PixelFormat() const override { return false; }
+  uint32_t GetCopyTextureInternalFormat() override { return 0u; }
+  base::ScopedClosureRunner GetCacheBackBufferCb() override {
+    return base::ScopedClosureRunner(base::DoNothing());
+  }
+
+ protected:
+  ~TestVizProcessContextProvider() override = default;
+
+ private:
+  std::unique_ptr<TestContextSupport> support_;
+  std::unique_ptr<TestGLES2Interface> context_gl_;
+  gpu::Capabilities gpu_capabilities_;
+  gpu::GpuFeatureInfo gpu_feature_info_;
+};
+
+class MockGLES2Interface : public TestGLES2Interface {
+ public:
+  MockGLES2Interface() = default;
+  ~MockGLES2Interface() override = default;
+
+  MOCK_METHOD2(DeleteTextures, void(GLsizei, const GLuint*));
+  MOCK_METHOD2(BindFramebuffer, void(GLenum, GLuint));
+  MOCK_METHOD2(GenRenderbuffers, void(GLsizei, GLuint*));
+  MOCK_METHOD2(BindRenderbuffer, void(GLenum, GLuint));
+  MOCK_METHOD2(DeleteRenderbuffers, void(GLsizei n, const GLuint*));
+  MOCK_METHOD1(CreateAndTexStorage2DSharedImageCHROMIUM, GLuint(const GLbyte*));
+  MOCK_METHOD1(WaitSyncTokenCHROMIUM, void(const GLbyte*));
+  MOCK_METHOD2(BeginSharedImageAccessDirectCHROMIUM, void(GLuint, GLenum));
+  MOCK_METHOD1(EndSharedImageAccessDirectCHROMIUM, void(GLuint));
+};
+
+class MockBufferQueue : public BufferQueue {
+ public:
+  MockBufferQueue() : BufferQueue(/*sii_=*/nullptr, gpu::kNullSurfaceHandle) {}
+  ~MockBufferQueue() override = default;
+
+  MOCK_METHOD2(GetCurrentBuffer,
+               gpu::Mailbox(gpu::SyncToken*, gfx::GpuFenceHandle*));
+  MOCK_CONST_METHOD0(CurrentBufferDamage, gfx::Rect());
+  MOCK_METHOD1(SwapBuffers, void(const gfx::Rect&));
+  MOCK_METHOD1(PageFlipComplete, void(gfx::GpuFenceHandle));
+  MOCK_METHOD0(FreeAllSurfaces, void());
+  MOCK_METHOD3(Reshape,
+               bool(const gfx::Size&,
+                    const gfx::ColorSpace&,
+                    gfx::BufferFormat));
+
+  MOCK_METHOD0(DoSetSyncTokenProvider, void());
+  void SetSyncTokenProvider(SyncTokenProvider* sync_token_provider) override {
+    BufferQueue::SetSyncTokenProvider(sync_token_provider);
+    DoSetSyncTokenProvider();
+  }
+};
+
+}  // namespace
+
+class GLOutputSurfaceBufferQueueTest : public ::testing::Test,
+                                       public OutputSurfaceClient {
+ public:
+  GLOutputSurfaceBufferQueueTest() = default;
+  ~GLOutputSurfaceBufferQueueTest() override = default;
+
+  void SetUp() override {
+    auto buffer_queue = std::make_unique<StrictMock<MockBufferQueue>>();
+    buffer_queue_ = buffer_queue.get();
+
+    auto gles2_interface = std::make_unique<StrictMock<MockGLES2Interface>>();
+    gles2_interface_ = gles2_interface.get();
+
+    EXPECT_CALL(*buffer_queue_, DoSetSyncTokenProvider());
+    surface_ = std::make_unique<GLOutputSurfaceBufferQueue>(
+        base::MakeRefCounted<TestVizProcessContextProvider>(
+            std::make_unique<TestContextSupport>(), std::move(gles2_interface)),
+        gpu::kNullSurfaceHandle, std::move(buffer_queue));
+    surface_->BindToClient(this);
+
+    Mock::VerifyAndClearExpectations(gles2_interface_);
+    Mock::VerifyAndClearExpectations(buffer_queue_);
+  }
+
+  // OutputSurfaceClient implementation.
+  void DidReceiveSwapBuffersAck(const gfx::SwapTimings& timings,
+                                gfx::GpuFenceHandle release_fence) override {}
+  void SetNeedsRedrawRect(const gfx::Rect& damage_rect) override {}
+  void DidReceiveTextureInUseResponses(
+      const gpu::TextureInUseResponses& responses) override {}
+  void DidReceiveCALayerParams(
+      const gfx::CALayerParams& ca_layer_params) override {}
+  void DidSwapWithSize(const gfx::Size& pixel_size) override {}
+  void DidReceivePresentationFeedback(
+      const gfx::PresentationFeedback& feedback) override {}
+  void DidReceiveReleasedOverlays(
+      const std::vector<gpu::Mailbox>& released_overlays) override {}
+
+ protected:
+  std::unique_ptr<OutputSurface> surface_;
+  raw_ptr<StrictMock<MockGLES2Interface>> gles2_interface_;
+  raw_ptr<StrictMock<MockBufferQueue>> buffer_queue_;
+};
+
+MATCHER_P(SyncTokenEqualTo, expected_sync_token, "") {
+  auto* actual_sync_token = reinterpret_cast<const gpu::SyncToken*>(arg);
+  return expected_sync_token == *actual_sync_token;
+}
+
+MATCHER_P(SharedImageEqualTo, expected_shared_image, "") {
+  gpu::Mailbox actual_shared_image;
+  actual_shared_image.SetName(arg);
+  return expected_shared_image == actual_shared_image;
+}
+
+// Make sure that the surface uses the buffer queue and the GL context correctly
+// when we request it to bind the framebuffer twice and then swap the buffer.
+TEST_F(GLOutputSurfaceBufferQueueTest, BindFramebufferAndSwap) {
+  const gpu::SyncToken fake_sync_token(
+      gpu::CommandBufferNamespace::GPU_IO,
+      gpu::CommandBufferId::FromUnsafeValue(567u),
+      /*release_count=*/5u);
+  const gpu::Mailbox fake_shared_image = gpu::Mailbox::GenerateForSharedImage();
+  constexpr GLuint kFakeTexture = 123u;
+  {
+    InSequence dummy_sequence;
+
+    // The first call to |surface_|->BindFramebuffer() should result in binding
+    // the GL framebuffer, requesting a new buffer, waiting on the corresponding
+    // sync token, and beginning read/write access to the shared image.
+    EXPECT_CALL(*gles2_interface_, BindFramebuffer(_, Ne(0u)));
+    EXPECT_CALL(*buffer_queue_, GetCurrentBuffer(NotNull(), NotNull()))
+        .WillOnce(DoAll(SetArgPointee<0>(fake_sync_token),
+                        Return(fake_shared_image)));
+    EXPECT_CALL(*gles2_interface_,
+                WaitSyncTokenCHROMIUM(SyncTokenEqualTo(fake_sync_token)));
+    EXPECT_CALL(*gles2_interface_, CreateAndTexStorage2DSharedImageCHROMIUM(
+                                       SharedImageEqualTo(fake_shared_image)))
+        .WillOnce(Return(kFakeTexture));
+    EXPECT_CALL(
+        *gles2_interface_,
+        BeginSharedImageAccessDirectCHROMIUM(
+            kFakeTexture, GL_SHARED_IMAGE_ACCESS_MODE_READWRITE_CHROMIUM));
+
+    // The second call to |surface_|->BindFramebuffer() should only result in
+    // binding the GL framebuffer because the underlying buffer hasn't been
+    // swapped.
+    EXPECT_CALL(*gles2_interface_, BindFramebuffer(_, Ne(0u)));
+
+    // Calling |surface_|->SwapBuffers() should result in ending read/write
+    // access to the underlying buffer and unbinding the GL framebuffer.
+    EXPECT_CALL(*gles2_interface_,
+                EndSharedImageAccessDirectCHROMIUM(kFakeTexture));
+    EXPECT_CALL(*gles2_interface_, BindFramebuffer(_, Eq(0u)));
+    EXPECT_CALL(*buffer_queue_, SwapBuffers(_));
+
+    // Destroying |surface_| should result in the deletion of the texture
+    // obtained from consuming the shared image.
+    EXPECT_CALL(*gles2_interface_,
+                DeleteTextures(1u, Pointee(Eq(kFakeTexture))));
+  }
+
+  surface_->BindFramebuffer();
+  surface_->BindFramebuffer();
+  surface_->SwapBuffers(OutputSurfaceFrame());
+}
+
+TEST_F(GLOutputSurfaceBufferQueueTest, EmptySwap) {
+  const gpu::SyncToken fake_sync_token(
+      gpu::CommandBufferNamespace::GPU_IO,
+      gpu::CommandBufferId::FromUnsafeValue(567u),
+      /*release_count=*/5u);
+  const gpu::Mailbox fake_shared_image = gpu::Mailbox::GenerateForSharedImage();
+  constexpr GLuint kFakeTexture = 123u;
+  {
+    InSequence dummy_sequence;
+
+    // The call to |surface_|->BindFramebuffer() should result in binding the GL
+    // framebuffer, requesting a new buffer, waiting on the corresponding sync
+    // token, and beginning read/write access to the shared image.
+    EXPECT_CALL(*gles2_interface_, BindFramebuffer(_, Ne(0u)));
+    EXPECT_CALL(*buffer_queue_, GetCurrentBuffer(NotNull(), NotNull()))
+        .WillOnce(DoAll(SetArgPointee<0>(fake_sync_token),
+                        Return(fake_shared_image)));
+    EXPECT_CALL(*gles2_interface_,
+                WaitSyncTokenCHROMIUM(SyncTokenEqualTo(fake_sync_token)));
+    EXPECT_CALL(*gles2_interface_, CreateAndTexStorage2DSharedImageCHROMIUM(
+                                       SharedImageEqualTo(fake_shared_image)))
+        .WillOnce(Return(kFakeTexture));
+    EXPECT_CALL(
+        *gles2_interface_,
+        BeginSharedImageAccessDirectCHROMIUM(
+            kFakeTexture, GL_SHARED_IMAGE_ACCESS_MODE_READWRITE_CHROMIUM));
+
+    // The first call to |surface_|->SwapBuffers() should result in ending
+    // read/write access to the underlying buffer and unbinding the GL
+    // framebuffer.
+    EXPECT_CALL(*gles2_interface_,
+                EndSharedImageAccessDirectCHROMIUM(kFakeTexture));
+    EXPECT_CALL(*gles2_interface_, BindFramebuffer(_, Eq(0u)));
+    EXPECT_CALL(*buffer_queue_, SwapBuffers(_));
+
+    // The two empty swaps should only result in telling the buffer queue to
+    // swap the buffers.
+    EXPECT_CALL(*buffer_queue_, SwapBuffers(_)).Times(2);
+
+    // Destroying |surface_| should result in the deletion of the texture
+    // obtained from consuming the shared image.
+    EXPECT_CALL(*gles2_interface_,
+                DeleteTextures(1u, Pointee(Eq(kFakeTexture))));
+  }
+  surface_->BindFramebuffer();
+  unsigned texture_for_first_buffer = surface_->GetOverlayTextureId();
+  EXPECT_GT(texture_for_first_buffer, 0u);
+  surface_->SwapBuffers(OutputSurfaceFrame());
+
+  // Now do two empty swaps (which don't call BindFramebuffer()).
+  EXPECT_EQ(texture_for_first_buffer, surface_->GetOverlayTextureId());
+  surface_->SwapBuffers(OutputSurfaceFrame());
+  EXPECT_EQ(texture_for_first_buffer, surface_->GetOverlayTextureId());
+  surface_->SwapBuffers(OutputSurfaceFrame());
+}
+
+// Make sure that receiving a swap NAK doesn't cause us to leak resources.
+TEST_F(GLOutputSurfaceBufferQueueTest, HandleSwapNAK) {
+  const gpu::SyncToken fake_sync_token(
+      gpu::CommandBufferNamespace::GPU_IO,
+      gpu::CommandBufferId::FromUnsafeValue(567u),
+      /*release_count=*/5u);
+  constexpr gfx::Size kBufferSize(100, 100);
+  const gpu::Mailbox fake_shared_image = gpu::Mailbox::GenerateForSharedImage();
+  constexpr GLuint kFakeTexture = 123u;
+  constexpr GLuint kFakeStencilBuffer = 456u;
+  {
+    InSequence dummy_sequence;
+
+    EXPECT_CALL(*buffer_queue_, Reshape(_, _, _)).WillOnce(Return(true));
+    EXPECT_CALL(*gles2_interface_, BindFramebuffer(_, Ne(0u)));
+
+    // The call to |surface_|->BindFramebuffer() should result in binding the GL
+    // framebuffer, requesting a new buffer, waiting on the corresponding sync
+    // token, beginning read/write access to the shared image, and creating a
+    // stencil buffer.
+    EXPECT_CALL(*gles2_interface_, BindFramebuffer(_, Ne(0u)));
+    EXPECT_CALL(*buffer_queue_, GetCurrentBuffer(NotNull(), NotNull()))
+        .WillOnce(DoAll(SetArgPointee<0>(fake_sync_token),
+                        Return(fake_shared_image)));
+
+    EXPECT_CALL(*gles2_interface_,
+                WaitSyncTokenCHROMIUM(SyncTokenEqualTo(fake_sync_token)));
+    EXPECT_CALL(*gles2_interface_, CreateAndTexStorage2DSharedImageCHROMIUM(
+                                       SharedImageEqualTo(fake_shared_image)))
+        .WillOnce(Return(kFakeTexture));
+    EXPECT_CALL(
+        *gles2_interface_,
+        BeginSharedImageAccessDirectCHROMIUM(
+            kFakeTexture, GL_SHARED_IMAGE_ACCESS_MODE_READWRITE_CHROMIUM));
+    EXPECT_CALL(*gles2_interface_, GenRenderbuffers(1u, NotNull()))
+        .WillOnce(SetArgPointee<1>(kFakeStencilBuffer));
+    EXPECT_CALL(*gles2_interface_,
+                BindRenderbuffer(GL_RENDERBUFFER, kFakeStencilBuffer));
+    EXPECT_CALL(*gles2_interface_, BindRenderbuffer(GL_RENDERBUFFER, 0u));
+
+    // Calling |surface_|->SwapBuffers() should result in ending read/write
+    // access to the underlying buffer and unbinding the GL framebuffer.
+    EXPECT_CALL(*gles2_interface_,
+                EndSharedImageAccessDirectCHROMIUM(kFakeTexture));
+    EXPECT_CALL(*gles2_interface_, BindFramebuffer(_, Eq(0u)));
+    EXPECT_CALL(*buffer_queue_, SwapBuffers(_));
+
+    // Receiving a swap NAK should result in the deletion of the texture
+    // obtained from consuming the shared image. It should also result in the
+    // deletion of the stencil buffer.
+    EXPECT_CALL(*buffer_queue_, FreeAllSurfaces());
+    EXPECT_CALL(*gles2_interface_, BindFramebuffer(_, Ne(0u)));
+    EXPECT_CALL(*gles2_interface_,
+                DeleteRenderbuffers(1u, Pointee(Eq(kFakeStencilBuffer))));
+    EXPECT_CALL(*gles2_interface_,
+                DeleteTextures(1u, Pointee(Eq(kFakeTexture))));
+    EXPECT_CALL(*buffer_queue_, PageFlipComplete(_));
+  }
+
+  OutputSurface::ReshapeParams reshape_params;
+  reshape_params.size = kBufferSize;
+  reshape_params.color_space = gfx::ColorSpace::CreateSRGB();
+  reshape_params.format = gfx::BufferFormat::BGRA_8888;
+  reshape_params.use_stencil = true;
+  surface_->Reshape(reshape_params);
+  surface_->BindFramebuffer();
+  OutputSurfaceFrame frame;
+  frame.size = kBufferSize;
+  surface_->SwapBuffers(std::move(frame));
+  gfx::SwapResponse swap_response{};
+  swap_response.result = gfx::SwapResult::SWAP_NAK_RECREATE_BUFFERS;
+  (static_cast<GLOutputSurfaceBufferQueue*>(surface_.get()))
+      ->DidReceiveSwapBuffersAck(swap_response,
+                                 /*release_fence=*/gfx::GpuFenceHandle());
+}
+
+}  // namespace viz
diff --git components/viz/service/display_embedder/gl_output_surface_chromeos.cc components/viz/service/display_embedder/gl_output_surface_chromeos.cc
new file mode 100644
index 0000000000000..d3cc855865805
--- /dev/null
+++ components/viz/service/display_embedder/gl_output_surface_chromeos.cc
@@ -0,0 +1,25 @@
+// Copyright 2019 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "components/viz/service/display_embedder/gl_output_surface_chromeos.h"
+
+namespace viz {
+
+GLOutputSurfaceChromeOS::GLOutputSurfaceChromeOS(
+    scoped_refptr<VizProcessContextProvider> context_provider,
+    gpu::SurfaceHandle surface_handle)
+    : GLOutputSurface(context_provider, surface_handle) {}
+
+GLOutputSurfaceChromeOS::~GLOutputSurfaceChromeOS() = default;
+
+void GLOutputSurfaceChromeOS::SetDisplayTransformHint(
+    gfx::OverlayTransform transform) {
+  display_transform_ = transform;
+}
+
+gfx::OverlayTransform GLOutputSurfaceChromeOS::GetDisplayTransform() {
+  return display_transform_;
+}
+
+}  // namespace viz
diff --git components/viz/service/display_embedder/gl_output_surface_chromeos.h components/viz/service/display_embedder/gl_output_surface_chromeos.h
new file mode 100644
index 0000000000000..63ad613a96ddd
--- /dev/null
+++ components/viz/service/display_embedder/gl_output_surface_chromeos.h
@@ -0,0 +1,33 @@
+// Copyright 2019 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef COMPONENTS_VIZ_SERVICE_DISPLAY_EMBEDDER_GL_OUTPUT_SURFACE_CHROMEOS_H_
+#define COMPONENTS_VIZ_SERVICE_DISPLAY_EMBEDDER_GL_OUTPUT_SURFACE_CHROMEOS_H_
+
+#include "components/viz/service/display_embedder/gl_output_surface.h"
+
+namespace viz {
+
+class GLOutputSurfaceChromeOS : public GLOutputSurface {
+ public:
+  GLOutputSurfaceChromeOS(
+      scoped_refptr<VizProcessContextProvider> context_provider,
+      gpu::SurfaceHandle surface_handle);
+
+  GLOutputSurfaceChromeOS(const GLOutputSurfaceChromeOS&) = delete;
+  GLOutputSurfaceChromeOS& operator=(const GLOutputSurfaceChromeOS&) = delete;
+
+  ~GLOutputSurfaceChromeOS() override;
+
+  // GLOutputSurface:
+  void SetDisplayTransformHint(gfx::OverlayTransform transform) override;
+  gfx::OverlayTransform GetDisplayTransform() override;
+
+ private:
+  gfx::OverlayTransform display_transform_ = gfx::OVERLAY_TRANSFORM_NONE;
+};
+
+}  // namespace viz
+
+#endif  // COMPONENTS_VIZ_SERVICE_DISPLAY_EMBEDDER_GL_OUTPUT_SURFACE_CHROMEOS_H_
diff --git components/viz/service/display_embedder/gl_output_surface_offscreen.cc components/viz/service/display_embedder/gl_output_surface_offscreen.cc
new file mode 100644
index 0000000000000..5de766dce7263
--- /dev/null
+++ components/viz/service/display_embedder/gl_output_surface_offscreen.cc
@@ -0,0 +1,135 @@
+// Copyright 2018 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "components/viz/service/display_embedder/gl_output_surface_offscreen.h"
+
+#include <stdint.h>
+
+#include <algorithm>
+#include <utility>
+#include <vector>
+
+#include "base/bind.h"
+#include "components/viz/common/resources/resource_format_utils.h"
+#include "components/viz/service/display/output_surface_client.h"
+#include "components/viz/service/display/output_surface_frame.h"
+#include "gpu/command_buffer/client/context_support.h"
+#include "gpu/command_buffer/client/gles2_interface.h"
+#include "gpu/command_buffer/client/shared_image_interface.h"
+#include "gpu/command_buffer/common/shared_image_usage.h"
+#include "third_party/khronos/GLES2/gl2.h"
+#include "third_party/khronos/GLES2/gl2ext.h"
+#include "ui/gfx/swap_result.h"
+#include "ui/gl/gl_utils.h"
+
+namespace viz {
+namespace {
+
+constexpr ResourceFormat kFboTextureFormat = RGBA_8888;
+
+}  // namespace
+
+GLOutputSurfaceOffscreen::GLOutputSurfaceOffscreen(
+    scoped_refptr<VizProcessContextProvider> context_provider)
+    : GLOutputSurface(context_provider, gpu::kNullSurfaceHandle) {}
+
+GLOutputSurfaceOffscreen::~GLOutputSurfaceOffscreen() {
+  DiscardBackbuffer();
+}
+
+void GLOutputSurfaceOffscreen::EnsureBackbuffer() {
+  if (size_.IsEmpty())
+    return;
+
+  if (!texture_id_) {
+    gpu::SharedImageInterface* sii = context_provider_->SharedImageInterface();
+    gpu::gles2::GLES2Interface* gl = context_provider_->ContextGL();
+
+    const int max_texture_size =
+        context_provider_->ContextCapabilities().max_texture_size;
+    gfx::Size texture_size(std::min(size_.width(), max_texture_size),
+                           std::min(size_.height(), max_texture_size));
+
+    const uint32_t flags = gpu::SHARED_IMAGE_USAGE_GLES2 |
+                           gpu::SHARED_IMAGE_USAGE_GLES2_FRAMEBUFFER_HINT |
+                           gpu::SHARED_IMAGE_USAGE_DISPLAY;
+
+    mailbox_ = sii->CreateSharedImage(
+        kFboTextureFormat, texture_size, color_space_, kTopLeft_GrSurfaceOrigin,
+        kPremul_SkAlphaType, flags, gpu::kNullSurfaceHandle);
+
+    // Ensure mailbox is valid before using it.
+    gl->WaitSyncTokenCHROMIUM(sii->GenUnverifiedSyncToken().GetConstData());
+
+    texture_id_ = gl->CreateAndTexStorage2DSharedImageCHROMIUM(mailbox_.name);
+
+    gl->GenFramebuffers(1, &fbo_);
+    gl->BindFramebuffer(GL_FRAMEBUFFER, fbo_);
+    gl->FramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0,
+                             GL_TEXTURE_2D, texture_id_, 0);
+  }
+}
+
+void GLOutputSurfaceOffscreen::DiscardBackbuffer() {
+  if (fbo_) {
+    gpu::gles2::GLES2Interface* gl = context_provider_->ContextGL();
+    gl->BindFramebuffer(GL_FRAMEBUFFER, fbo_);
+    gl->DeleteFramebuffers(1, &fbo_);
+    fbo_ = 0;
+  }
+
+  if (texture_id_) {
+    gpu::SharedImageInterface* sii = context_provider_->SharedImageInterface();
+    sii->DestroySharedImage(gpu::SyncToken(), mailbox_);
+    mailbox_.SetZero();
+    texture_id_ = 0;
+  }
+}
+
+void GLOutputSurfaceOffscreen::BindFramebuffer() {
+  if (!texture_id_) {
+    EnsureBackbuffer();
+  } else {
+    gpu::gles2::GLES2Interface* gl = context_provider_->ContextGL();
+    gl->BindFramebuffer(GL_FRAMEBUFFER, fbo_);
+  }
+}
+
+void GLOutputSurfaceOffscreen::Reshape(const ReshapeParams& params) {
+  size_ = params.size;
+  color_space_ = params.color_space;
+  DiscardBackbuffer();
+  EnsureBackbuffer();
+}
+
+void GLOutputSurfaceOffscreen::SwapBuffers(OutputSurfaceFrame frame) {
+  DCHECK_EQ(frame.size, size_);
+
+  gpu::gles2::GLES2Interface* gl = context_provider_->ContextGL();
+
+  gpu::SyncToken sync_token;
+  gl->GenUnverifiedSyncTokenCHROMIUM(sync_token.GetData());
+  context_provider_->ContextSupport()->SignalSyncToken(
+      sync_token,
+      base::BindOnce(&GLOutputSurfaceOffscreen::OnSwapBuffersComplete,
+                     weak_ptr_factory_.GetWeakPtr(),
+                     std::move(frame.latency_info)));
+}
+
+void GLOutputSurfaceOffscreen::OnSwapBuffersComplete(
+    std::vector<ui::LatencyInfo> latency_info) {
+  latency_tracker()->OnGpuSwapBuffersCompleted(std::move(latency_info));
+  // Swap timings are not available since for offscreen there is no Swap, just a
+  // SignalSyncToken. We use base::TimeTicks::Now() as an overestimate.
+  auto now = base::TimeTicks::Now();
+  client()->DidReceiveSwapBuffersAck({.swap_start = now},
+                                     /*release_fence=*/gfx::GpuFenceHandle());
+  client()->DidReceivePresentationFeedback(
+      gfx::PresentationFeedback(now, base::Milliseconds(16), /*flags=*/0));
+
+  if (needs_swap_size_notifications())
+    client()->DidSwapWithSize(size_);
+}
+
+}  // namespace viz
diff --git components/viz/service/display_embedder/gl_output_surface_offscreen.h components/viz/service/display_embedder/gl_output_surface_offscreen.h
new file mode 100644
index 0000000000000..a9cef0b921dae
--- /dev/null
+++ components/viz/service/display_embedder/gl_output_surface_offscreen.h
@@ -0,0 +1,54 @@
+// Copyright 2018 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef COMPONENTS_VIZ_SERVICE_DISPLAY_EMBEDDER_GL_OUTPUT_SURFACE_OFFSCREEN_H_
+#define COMPONENTS_VIZ_SERVICE_DISPLAY_EMBEDDER_GL_OUTPUT_SURFACE_OFFSCREEN_H_
+
+#include <memory>
+#include <vector>
+
+#include "components/viz/common/frame_sinks/begin_frame_source.h"
+#include "components/viz/service/display_embedder/gl_output_surface.h"
+#include "components/viz/service/display_embedder/viz_process_context_provider.h"
+#include "components/viz/service/viz_service_export.h"
+#include "gpu/command_buffer/common/mailbox.h"
+#include "ui/gfx/color_space.h"
+
+namespace viz {
+
+// An OutputSurface implementation that draws and swaps to an offscreen GL
+// framebuffer.
+class VIZ_SERVICE_EXPORT GLOutputSurfaceOffscreen : public GLOutputSurface {
+ public:
+  explicit GLOutputSurfaceOffscreen(
+      scoped_refptr<VizProcessContextProvider> context_provider);
+
+  GLOutputSurfaceOffscreen(const GLOutputSurfaceOffscreen&) = delete;
+  GLOutputSurfaceOffscreen& operator=(const GLOutputSurfaceOffscreen&) = delete;
+
+  ~GLOutputSurfaceOffscreen() override;
+
+  // OutputSurface implementation.
+  void EnsureBackbuffer() override;
+  void DiscardBackbuffer() override;
+  void BindFramebuffer() override;
+  void Reshape(const ReshapeParams& params) override;
+  void SwapBuffers(OutputSurfaceFrame frame) override;
+
+ private:
+  void OnSwapBuffersComplete(std::vector<ui::LatencyInfo> latency_info);
+
+  gpu::Mailbox mailbox_;
+
+  uint32_t fbo_ = 0;
+  uint32_t texture_id_ = 0;
+  gfx::Size size_;
+  gfx::ColorSpace color_space_;
+
+  base::WeakPtrFactory<GLOutputSurfaceOffscreen> weak_ptr_factory_{this};
+};
+
+}  // namespace viz
+
+#endif  // COMPONENTS_VIZ_SERVICE_DISPLAY_EMBEDDER_GL_OUTPUT_SURFACE_OFFSCREEN_H_
diff --git components/viz/service/display_embedder/output_surface_provider.h components/viz/service/display_embedder/output_surface_provider.h
index ff8c242467f57..b8e3bae0a34e0 100644
--- components/viz/service/display_embedder/output_surface_provider.h
+++ components/viz/service/display_embedder/output_surface_provider.h
@@ -28,7 +28,8 @@ class OutputSurfaceProvider {
   // of this should feed into the CreateOutputSurface function.
   virtual std::unique_ptr<DisplayCompositorMemoryAndTaskController>
   CreateGpuDependency(bool gpu_compositing,
-                      gpu::SurfaceHandle surface_handle) = 0;
+                      gpu::SurfaceHandle surface_handle,
+                      const RendererSettings& renderer_settings) = 0;
 
   // Creates a new OutputSurface for |surface_handle|. If creating an
   // OutputSurface fails this function will return null.
diff --git components/viz/service/display_embedder/output_surface_provider_impl.cc components/viz/service/display_embedder/output_surface_provider_impl.cc
index 99a1b8a1bb995..1c0d000ca4918 100644
--- components/viz/service/display_embedder/output_surface_provider_impl.cc
+++ components/viz/service/display_embedder/output_surface_provider_impl.cc
@@ -20,10 +20,14 @@
 #include "components/viz/common/display/renderer_settings.h"
 #include "components/viz/common/frame_sinks/begin_frame_source.h"
 #include "components/viz/service/display/display_compositor_memory_and_task_controller.h"
+#include "components/viz/service/display_embedder/gl_output_surface.h"
+#include "components/viz/service/display_embedder/gl_output_surface_buffer_queue.h"
+#include "components/viz/service/display_embedder/gl_output_surface_offscreen.h"
 #include "components/viz/service/display_embedder/server_shared_bitmap_manager.h"
 #include "components/viz/service/display_embedder/skia_output_surface_dependency_impl.h"
 #include "components/viz/service/display_embedder/skia_output_surface_impl.h"
 #include "components/viz/service/display_embedder/software_output_surface.h"
+#include "components/viz/service/display_embedder/viz_process_context_provider.h"
 #include "components/viz/service/gl/gpu_service_impl.h"
 #include "gpu/command_buffer/client/gpu_memory_buffer_manager.h"
 #include "gpu/command_buffer/client/shared_memory_limits.h"
@@ -36,11 +40,17 @@
 #include "gpu/ipc/service/gpu_channel_manager_delegate.h"
 #include "gpu/ipc/service/image_transport_surface.h"
 #include "ui/base/ui_base_switches.h"
+#include "ui/gl/gl_context.h"
+#include "ui/gl/init/gl_factory.h"
 
 #if BUILDFLAG(IS_WIN)
 #include "components/viz/service/display_embedder/software_output_device_win.h"
 #endif
 
+#if BUILDFLAG(IS_ANDROID)
+#include "components/viz/service/display_embedder/gl_output_surface_android.h"
+#endif
+
 #if BUILDFLAG(IS_APPLE)
 #include "components/viz/service/display_embedder/software_output_device_mac.h"
 #include "ui/base/cocoa/remote_layer_api.h"
@@ -56,6 +66,7 @@
 #endif
 
 #if BUILDFLAG(IS_CHROMEOS_ASH)
+#include "components/viz/service/display_embedder/gl_output_surface_chromeos.h"
 #include "components/viz/service/display_embedder/output_surface_unified.h"
 #endif
 
@@ -90,15 +101,23 @@ OutputSurfaceProviderImpl::~OutputSurfaceProviderImpl() = default;
 std::unique_ptr<DisplayCompositorMemoryAndTaskController>
 OutputSurfaceProviderImpl::CreateGpuDependency(
     bool gpu_compositing,
-    gpu::SurfaceHandle surface_handle) {
+    gpu::SurfaceHandle surface_handle,
+    const RendererSettings& renderer_settings) {
   if (!gpu_compositing)
     return nullptr;
 
-  gpu::ScopedAllowScheduleGpuTask allow_schedule_gpu_task;
-  auto skia_deps = std::make_unique<SkiaOutputSurfaceDependencyImpl>(
-      gpu_service_impl_, surface_handle);
-  return std::make_unique<DisplayCompositorMemoryAndTaskController>(
-      std::move(skia_deps));
+  if (renderer_settings.use_skia_renderer) {
+    gpu::ScopedAllowScheduleGpuTask allow_schedule_gpu_task;
+    auto skia_deps = std::make_unique<SkiaOutputSurfaceDependencyImpl>(
+        gpu_service_impl_, surface_handle);
+    return std::make_unique<DisplayCompositorMemoryAndTaskController>(
+        std::move(skia_deps));
+  } else {
+    DCHECK(task_executor_);
+    gpu::ScopedAllowScheduleGpuTask allow_schedule_gpu_task;
+    return std::make_unique<DisplayCompositorMemoryAndTaskController>(
+        task_executor_, image_factory_);
+  }
 }
 
 std::unique_ptr<OutputSurface> OutputSurfaceProviderImpl::CreateOutputSurface(
@@ -120,7 +139,7 @@ std::unique_ptr<OutputSurface> OutputSurfaceProviderImpl::CreateOutputSurface(
   if (!gpu_compositing) {
     output_surface = std::make_unique<SoftwareOutputSurface>(
         CreateSoftwareOutputDeviceForPlatform(surface_handle, display_client));
-  } else {
+  } else if (renderer_settings.use_skia_renderer) {
     DCHECK(gpu_dependency);
     {
       gpu::ScopedAllowScheduleGpuTask allow_schedule_gpu_task;
@@ -149,6 +168,74 @@ std::unique_ptr<OutputSurface> OutputSurfaceProviderImpl::CreateOutputSurface(
 #endif
       return nullptr;
     }
+  } else {
+    DCHECK(task_executor_);
+    DCHECK(gpu_dependency);
+
+    scoped_refptr<VizProcessContextProvider> context_provider;
+
+    // Retry creating and binding |context_provider| on transient failures.
+    gpu::ContextResult context_result = gpu::ContextResult::kTransientFailure;
+    while (context_result != gpu::ContextResult::kSuccess) {
+      // We are about to exit the GPU process so don't try to create a context.
+      // It will be recreated after the GPU process restarts. The same check
+      // also happens on the GPU thread before the context gets initialized
+      // there. If GPU process starts to exit after this check but before
+      // context initialization we'll encounter a transient error, loop and hit
+      // this check again.
+      if (gpu_channel_manager_delegate_->IsExiting())
+        return nullptr;
+
+      context_provider = base::MakeRefCounted<VizProcessContextProvider>(
+          task_executor_, surface_handle, gpu_memory_buffer_manager_.get(),
+          image_factory_, gpu_channel_manager_delegate_, gpu_dependency,
+          renderer_settings);
+      context_result = context_provider->BindToCurrentThread();
+
+#if BUILDFLAG(IS_ANDROID)
+      display_client->OnContextCreationResult(context_result);
+#endif
+
+      if (IsFatalOrSurfaceFailure(context_result)) {
+#if BUILDFLAG(IS_CHROMEOS_ASH) || BUILDFLAG(IS_CHROMECAST)
+        // GL compositing is expected to always work on Chrome OS so we should
+        // never encounter fatal context error. This could be an unrecoverable
+        // hardware error or a bug.
+        LOG(FATAL) << "Unexpected fatal context error";
+#elif !BUILDFLAG(IS_ANDROID)
+        gpu_service_impl_->DisableGpuCompositing();
+#endif
+        return nullptr;
+      }
+    }
+
+    if (surface_handle == gpu::kNullSurfaceHandle) {
+      output_surface = std::make_unique<GLOutputSurfaceOffscreen>(
+          std::move(context_provider));
+    } else if (context_provider->ContextCapabilities().surfaceless) {
+#if defined(USE_OZONE) || BUILDFLAG(IS_APPLE) || BUILDFLAG(IS_ANDROID)
+      output_surface = std::make_unique<GLOutputSurfaceBufferQueue>(
+          std::move(context_provider), surface_handle,
+          std::make_unique<BufferQueue>(
+              context_provider->SharedImageInterface(), surface_handle));
+#else
+      NOTREACHED();
+#endif
+    } else {
+#if BUILDFLAG(IS_WIN)
+      output_surface = std::make_unique<GLOutputSurface>(
+          std::move(context_provider), surface_handle);
+#elif BUILDFLAG(IS_ANDROID)
+      output_surface = std::make_unique<GLOutputSurfaceAndroid>(
+          std::move(context_provider), surface_handle);
+#elif BUILDFLAG(IS_CHROMEOS_ASH)
+      output_surface = std::make_unique<GLOutputSurfaceChromeOS>(
+          std::move(context_provider), surface_handle);
+#else
+      output_surface = std::make_unique<GLOutputSurface>(
+          std::move(context_provider), surface_handle);
+#endif
+    }
   }
 
   return output_surface;
diff --git components/viz/service/display_embedder/output_surface_provider_impl.h components/viz/service/display_embedder/output_surface_provider_impl.h
index fca555eb4bae3..ad20727e97d14 100644
--- components/viz/service/display_embedder/output_surface_provider_impl.h
+++ components/viz/service/display_embedder/output_surface_provider_impl.h
@@ -56,7 +56,8 @@ class VIZ_SERVICE_EXPORT OutputSurfaceProviderImpl
 
   std::unique_ptr<DisplayCompositorMemoryAndTaskController> CreateGpuDependency(
       bool gpu_compositing,
-      gpu::SurfaceHandle surface_handle) override;
+      gpu::SurfaceHandle surface_handle,
+      const RendererSettings& renderer_settings) override;
 
   // OutputSurfaceProvider implementation.
   std::unique_ptr<OutputSurface> CreateOutputSurface(
diff --git components/viz/service/display_embedder/skia_output_surface_impl_unittest.cc components/viz/service/display_embedder/skia_output_surface_impl_unittest.cc
index 0418b4cbc7517..5ce3ca3fd1d7c 100644
--- components/viz/service/display_embedder/skia_output_surface_impl_unittest.cc
+++ components/viz/service/display_embedder/skia_output_surface_impl_unittest.cc
@@ -79,13 +79,15 @@ SkiaOutputSurfaceImplTest::~SkiaOutputSurfaceImplTest() {
 }
 
 void SkiaOutputSurfaceImplTest::SetUpSkiaOutputSurfaceImpl() {
+  RendererSettings settings;
+  settings.use_skia_renderer = true;
   auto skia_deps = std::make_unique<SkiaOutputSurfaceDependencyImpl>(
       GetGpuService(), gpu::kNullSurfaceHandle);
   display_controller_ =
       std::make_unique<DisplayCompositorMemoryAndTaskController>(
           std::move(skia_deps));
-  output_surface_ = SkiaOutputSurfaceImpl::Create(
-      display_controller_.get(), RendererSettings(), &debug_settings_);
+  output_surface_ = SkiaOutputSurfaceImpl::Create(display_controller_.get(),
+                                                  settings, &debug_settings_);
   output_surface_->BindToClient(&output_surface_client_);
 }
 
diff --git components/viz/service/display_embedder/viz_process_context_provider.cc components/viz/service/display_embedder/viz_process_context_provider.cc
new file mode 100644
index 0000000000000..ed33d5f717fd3
--- /dev/null
+++ components/viz/service/display_embedder/viz_process_context_provider.cc
@@ -0,0 +1,348 @@
+// Copyright 2016 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "components/viz/service/display_embedder/viz_process_context_provider.h"
+
+#include <stdint.h>
+
+#include <utility>
+
+#include "base/bind.h"
+#include "base/lazy_instance.h"
+#include "base/metrics/histogram_macros.h"
+#include "base/observer_list.h"
+#include "base/system/sys_info.h"
+#include "base/task/single_thread_task_runner.h"
+#include "base/threading/thread_task_runner_handle.h"
+#include "base/trace_event/memory_dump_manager.h"
+#include "build/build_config.h"
+#include "build/chromeos_buildflags.h"
+#include "components/viz/common/display/renderer_settings.h"
+#include "components/viz/common/gpu/context_lost_observer.h"
+#include "components/viz/common/gpu/context_lost_reason.h"
+#include "components/viz/common/resources/platform_color.h"
+#include "components/viz/common/viz_utils.h"
+#include "components/viz/service/display/display_compositor_memory_and_task_controller.h"
+#include "gpu/GLES2/gl2extchromium.h"
+#include "gpu/command_buffer/client/gles2_cmd_helper.h"
+#include "gpu/command_buffer/client/gles2_implementation.h"
+#include "gpu/command_buffer/client/raster_implementation_gles.h"
+#include "gpu/command_buffer/client/shared_memory_limits.h"
+#include "gpu/command_buffer/client/transfer_buffer.h"
+#include "gpu/config/gpu_feature_info.h"
+#include "gpu/config/gpu_preferences.h"
+#include "gpu/config/skia_limits.h"
+#include "gpu/ipc/common/surface_handle.h"
+#include "gpu/ipc/in_process_command_buffer.h"
+#include "gpu/skia_bindings/gles2_implementation_with_grcontext_support.h"
+#include "gpu/skia_bindings/grcontext_for_gles2_interface.h"
+#include "third_party/khronos/GLES2/gl2.h"
+#include "third_party/khronos/GLES2/gl2ext.h"
+#include "third_party/skia/include/gpu/GrDirectContext.h"
+#include "third_party/skia/include/gpu/gl/GrGLInterface.h"
+
+namespace viz {
+
+namespace {
+
+gpu::ContextCreationAttribs CreateAttributes(
+    bool requires_alpha_channel,
+    const RendererSettings& renderer_settings) {
+  gpu::ContextCreationAttribs attributes;
+  attributes.alpha_size = requires_alpha_channel ? 8 : -1;
+  attributes.depth_size = 0;
+#if BUILDFLAG(IS_CHROMEOS_ASH)
+  // Chrome OS uses surfaceless when running on a real device and stencil
+  // buffers can then be added dynamically so supporting them does not have an
+  // impact on normal usage. If we are not running on a real Chrome OS device
+  // but instead on a workstation for development, then stencil support is
+  // useful as it allows the overdraw feedback debugging feature to be used.
+  attributes.stencil_size = 8;
+#else
+  attributes.stencil_size = 0;
+#endif
+  attributes.samples = 0;
+  attributes.sample_buffers = 0;
+  attributes.bind_generates_resource = false;
+  attributes.fail_if_major_perf_caveat = false;
+  attributes.lose_context_when_out_of_memory = true;
+
+#if BUILDFLAG(IS_ANDROID)
+  if (renderer_settings.color_space == gfx::ColorSpace::CreateSRGB()) {
+    attributes.color_space = gpu::COLOR_SPACE_SRGB;
+  } else if (renderer_settings.color_space ==
+             gfx::ColorSpace::CreateDisplayP3D65()) {
+    attributes.color_space = gpu::COLOR_SPACE_DISPLAY_P3;
+  } else {
+    // The browser only sends the above two color spaces.
+    NOTREACHED();
+  }
+
+  if (!requires_alpha_channel && PreferRGB565ResourcesForDisplay()) {
+    // See compositor_impl_android.cc for more information about this.
+    // It is inside GetCompositorContextAttributes().
+    attributes.alpha_size = 0;
+    attributes.red_size = 5;
+    attributes.green_size = 6;
+    attributes.blue_size = 5;
+  }
+
+  attributes.enable_swap_timestamps_if_supported = true;
+#endif  // BUILDFLAG(IS_ANDROID)
+
+  return attributes;
+}
+
+void UmaRecordContextLost(ContextLostReason reason) {
+  UMA_HISTOGRAM_ENUMERATION("GPU.ContextLost.DisplayCompositor", reason);
+}
+
+gpu::SharedMemoryLimits SharedMemoryLimitsForRendererSettings(
+    const RendererSettings& renderer_settings) {
+#if BUILDFLAG(IS_ANDROID)
+  return gpu::SharedMemoryLimits::ForDisplayCompositor(
+      renderer_settings.initial_screen_size);
+#else
+  return gpu::SharedMemoryLimits::ForDisplayCompositor();
+#endif
+}
+
+}  // namespace
+
+VizProcessContextProvider::VizProcessContextProvider(
+    gpu::CommandBufferTaskExecutor* task_executor,
+    gpu::SurfaceHandle surface_handle,
+    gpu::GpuMemoryBufferManager* gpu_memory_buffer_manager,
+    gpu::ImageFactory* image_factory,
+    gpu::GpuChannelManagerDelegate* gpu_channel_manager_delegate,
+    DisplayCompositorMemoryAndTaskController* display_controller,
+    const RendererSettings& renderer_settings)
+    : attributes_(CreateAttributes(renderer_settings.requires_alpha_channel,
+                                   renderer_settings)) {
+  InitializeContext(std::move(task_executor), surface_handle,
+                    gpu_memory_buffer_manager, image_factory,
+                    gpu_channel_manager_delegate, display_controller,
+                    SharedMemoryLimitsForRendererSettings(renderer_settings));
+
+  if (context_result_ == gpu::ContextResult::kSuccess) {
+    // |gles2_implementation_| is owned here so bind an unretained pointer or
+    // there will be a circular reference preventing destruction.
+    gles2_implementation_->SetLostContextCallback(base::BindOnce(
+        &VizProcessContextProvider::OnContextLost, base::Unretained(this)));
+
+    base::trace_event::MemoryDumpManager::GetInstance()->RegisterDumpProvider(
+        this, "VizProcessContextProvider", base::ThreadTaskRunnerHandle::Get());
+  } else {
+    UmaRecordContextLost(CONTEXT_INIT_FAILED);
+  }
+}
+
+VizProcessContextProvider::VizProcessContextProvider() = default;
+
+VizProcessContextProvider::~VizProcessContextProvider() {
+  if (context_result_ == gpu::ContextResult::kSuccess) {
+    base::trace_event::MemoryDumpManager::GetInstance()->UnregisterDumpProvider(
+        this);
+  }
+
+  // cache_controller_ might ne nullptr if we failed to initialize
+  if (cache_controller_)
+    cache_controller_->SetGrContext(nullptr);
+}
+
+void VizProcessContextProvider::AddRef() const {
+  base::RefCountedThreadSafe<VizProcessContextProvider>::AddRef();
+}
+
+void VizProcessContextProvider::Release() const {
+  base::RefCountedThreadSafe<VizProcessContextProvider>::Release();
+}
+
+gpu::ContextResult VizProcessContextProvider::BindToCurrentThread() {
+  return context_result_;
+}
+
+gpu::gles2::GLES2Interface* VizProcessContextProvider::ContextGL() {
+  return gles2_implementation_.get();
+}
+
+gpu::ContextSupport* VizProcessContextProvider::ContextSupport() {
+  return gles2_implementation_.get();
+}
+
+class GrDirectContext* VizProcessContextProvider::GrContext() {
+  if (gr_context_)
+    return gr_context_->get();
+
+  size_t max_resource_cache_bytes;
+  size_t max_glyph_cache_texture_bytes;
+  gpu::DetermineGrCacheLimitsFromAvailableMemory(
+      &max_resource_cache_bytes, &max_glyph_cache_texture_bytes);
+
+  gr_context_ = std::make_unique<skia_bindings::GrContextForGLES2Interface>(
+      ContextGL(), ContextSupport(), ContextCapabilities(),
+      max_resource_cache_bytes, max_glyph_cache_texture_bytes);
+  cache_controller_->SetGrContext(gr_context_->get());
+  return gr_context_->get();
+}
+
+gpu::SharedImageInterface* VizProcessContextProvider::SharedImageInterface() {
+  return command_buffer_->GetSharedImageInterface();
+}
+
+ContextCacheController* VizProcessContextProvider::CacheController() {
+  return cache_controller_.get();
+}
+
+base::Lock* VizProcessContextProvider::GetLock() {
+  // Locking isn't supported on display compositor contexts.
+  return nullptr;
+}
+
+const gpu::Capabilities& VizProcessContextProvider::ContextCapabilities()
+    const {
+  return command_buffer_->GetCapabilities();
+}
+
+const gpu::GpuFeatureInfo& VizProcessContextProvider::GetGpuFeatureInfo()
+    const {
+  return command_buffer_->GetGpuFeatureInfo();
+}
+
+void VizProcessContextProvider::AddObserver(ContextLostObserver* obs) {
+  observers_.AddObserver(obs);
+}
+
+void VizProcessContextProvider::RemoveObserver(ContextLostObserver* obs) {
+  observers_.RemoveObserver(obs);
+}
+
+void VizProcessContextProvider::SetUpdateVSyncParametersCallback(
+    UpdateVSyncParametersCallback callback) {
+  command_buffer_->SetUpdateVSyncParametersCallback(std::move(callback));
+}
+
+void VizProcessContextProvider::SetGpuVSyncCallback(GpuVSyncCallback callback) {
+  command_buffer_->SetGpuVSyncCallback(std::move(callback));
+}
+
+void VizProcessContextProvider::SetGpuVSyncEnabled(bool enabled) {
+  command_buffer_->SetGpuVSyncEnabled(enabled);
+}
+
+bool VizProcessContextProvider::UseRGB565PixelFormat() const {
+  return attributes_.alpha_size == 0 && attributes_.red_size == 5 &&
+         attributes_.green_size == 6 && attributes_.blue_size == 5;
+}
+
+uint32_t VizProcessContextProvider::GetCopyTextureInternalFormat() {
+  return attributes_.alpha_size > 0 ? GL_RGBA : GL_RGB;
+}
+
+void VizProcessContextProvider::InitializeContext(
+    gpu::CommandBufferTaskExecutor* task_executor,
+    gpu::SurfaceHandle surface_handle,
+    gpu::GpuMemoryBufferManager* gpu_memory_buffer_manager,
+    gpu::ImageFactory* image_factory,
+    gpu::GpuChannelManagerDelegate* gpu_channel_manager_delegate,
+    DisplayCompositorMemoryAndTaskController* display_controller,
+    const gpu::SharedMemoryLimits& mem_limits) {
+  const bool is_offscreen = surface_handle == gpu::kNullSurfaceHandle;
+  DCHECK(display_controller);
+  gpu_task_scheduler_helper_ = display_controller->gpu_task_scheduler();
+
+  command_buffer_ = std::make_unique<gpu::InProcessCommandBuffer>(
+      task_executor,
+      GURL("chrome://gpu/VizProcessContextProvider::InitializeContext"));
+  context_result_ = command_buffer_->Initialize(
+      /*surface=*/nullptr, is_offscreen, surface_handle, attributes_,
+      gpu_memory_buffer_manager, image_factory, gpu_channel_manager_delegate,
+      base::ThreadTaskRunnerHandle::Get(),
+      gpu_task_scheduler_helper_->GetTaskSequence(),
+      display_controller->controller_on_gpu(), nullptr, nullptr);
+  if (context_result_ != gpu::ContextResult::kSuccess) {
+    DLOG(ERROR) << "Failed to initialize InProcessCommmandBuffer";
+    return;
+  }
+
+  // Create the GLES2 helper, which writes the command buffer protocol.
+  gles2_helper_ =
+      std::make_unique<gpu::gles2::GLES2CmdHelper>(command_buffer_.get());
+  context_result_ = gles2_helper_->Initialize(mem_limits.command_buffer_size);
+  if (context_result_ != gpu::ContextResult::kSuccess) {
+    DLOG(ERROR) << "Failed to initialize GLES2CmdHelper";
+    return;
+  }
+
+  if (gpu_task_scheduler_helper_)
+    gpu_task_scheduler_helper_->Initialize(gles2_helper_.get());
+
+  transfer_buffer_ = std::make_unique<gpu::TransferBuffer>(gles2_helper_.get());
+
+  // Create the object exposing the OpenGL API.
+  gles2_implementation_ =
+      std::make_unique<skia_bindings::GLES2ImplementationWithGrContextSupport>(
+          gles2_helper_.get(), /*share_group=*/nullptr, transfer_buffer_.get(),
+          attributes_.bind_generates_resource,
+          attributes_.lose_context_when_out_of_memory,
+          /*support_client_side_arrays=*/false, command_buffer_.get());
+
+  context_result_ = gles2_implementation_->Initialize(mem_limits);
+  if (context_result_ != gpu::ContextResult::kSuccess) {
+    DLOG(ERROR) << "Failed to initialize GLES2Implementation";
+    return;
+  }
+
+  cache_controller_ = std::make_unique<ContextCacheController>(
+      gles2_implementation_.get(), base::ThreadTaskRunnerHandle::Get());
+
+  // TraceEndCHROMIUM is implicit when the context is destroyed
+  gles2_implementation_->TraceBeginCHROMIUM("VizCompositor",
+                                            "DisplayCompositor");
+}
+
+void VizProcessContextProvider::OnContextLost() {
+  for (auto& observer : observers_)
+    observer.OnContextLost();
+  if (gr_context_)
+    gr_context_->OnLostContext();
+
+  gpu::CommandBuffer::State state = command_buffer_->GetLastState();
+  UmaRecordContextLost(
+      GetContextLostReason(state.error, state.context_lost_reason));
+}
+
+bool VizProcessContextProvider::OnMemoryDump(
+    const base::trace_event::MemoryDumpArgs& args,
+    base::trace_event::ProcessMemoryDump* pmd) {
+  DCHECK_EQ(context_result_, gpu::ContextResult::kSuccess);
+  if (args.level_of_detail ==
+      base::trace_event::MemoryDumpLevelOfDetail::BACKGROUND) {
+    if (gr_context_)
+      gpu::raster::DumpBackgroundGrMemoryStatistics(gr_context_->get(), pmd);
+
+    // Early out, no need for more detail in a BACKGROUND dump.
+    return true;
+  }
+
+  gles2_implementation_->OnMemoryDump(args, pmd);
+  gles2_helper_->OnMemoryDump(args, pmd);
+
+  if (gr_context_) {
+    gpu::raster::DumpGrMemoryStatistics(
+        gr_context_->get(), pmd,
+        gles2_implementation_->ShareGroupTracingGUID());
+  }
+  return true;
+}
+
+base::ScopedClosureRunner VizProcessContextProvider::GetCacheBackBufferCb() {
+  return command_buffer_->GetCacheBackBufferCb();
+}
+
+void VizProcessContextProvider::SetNeedsMeasureNextDrawLatency() {
+  return command_buffer_->SetNeedsMeasureNextDrawLatency();
+}
+
+}  // namespace viz
diff --git components/viz/service/display_embedder/viz_process_context_provider.h components/viz/service/display_embedder/viz_process_context_provider.h
new file mode 100644
index 0000000000000..8ff0ccce7329f
--- /dev/null
+++ components/viz/service/display_embedder/viz_process_context_provider.h
@@ -0,0 +1,136 @@
+// Copyright 2016 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef COMPONENTS_VIZ_SERVICE_DISPLAY_EMBEDDER_VIZ_PROCESS_CONTEXT_PROVIDER_H_
+#define COMPONENTS_VIZ_SERVICE_DISPLAY_EMBEDDER_VIZ_PROCESS_CONTEXT_PROVIDER_H_
+
+#include <stdint.h>
+
+#include <memory>
+
+#include "base/callback_helpers.h"
+#include "base/memory/raw_ptr.h"
+#include "base/observer_list.h"
+#include "base/trace_event/memory_dump_provider.h"
+#include "components/viz/common/display/update_vsync_parameters_callback.h"
+#include "components/viz/common/gpu/context_cache_controller.h"
+#include "components/viz/common/gpu/context_provider.h"
+#include "components/viz/common/gpu/gpu_vsync_callback.h"
+#include "components/viz/service/viz_service_export.h"
+#include "gpu/command_buffer/common/context_creation_attribs.h"
+#include "gpu/ipc/common/surface_handle.h"
+#include "gpu/ipc/gpu_task_scheduler_helper.h"
+#include "ui/gfx/native_widget_types.h"
+
+class GrDirectContext;
+
+namespace gpu {
+namespace gles2 {
+class GLES2CmdHelper;
+class GLES2Implementation;
+}  // namespace gles2
+class CommandBufferTaskExecutor;
+class GpuChannelManagerDelegate;
+class GpuMemoryBufferManager;
+class ImageFactory;
+class InProcessCommandBuffer;
+class TransferBuffer;
+struct SharedMemoryLimits;
+}  // namespace gpu
+
+namespace skia_bindings {
+class GrContextForGLES2Interface;
+}
+
+namespace viz {
+class ContextLostObserver;
+class DisplayCompositorMemoryAndTaskController;
+class GpuTaskSchedulerHelper;
+class RendererSettings;
+
+// A ContextProvider used in the viz process to setup an InProcessCommandBuffer
+// for the display compositor.
+class VIZ_SERVICE_EXPORT VizProcessContextProvider
+    : public base::RefCountedThreadSafe<VizProcessContextProvider>,
+      public ContextProvider,
+      public base::trace_event::MemoryDumpProvider {
+ public:
+  VizProcessContextProvider(
+      gpu::CommandBufferTaskExecutor* task_executor,
+      gpu::SurfaceHandle surface_handle,
+      gpu::GpuMemoryBufferManager* gpu_memory_buffer_manager,
+      gpu::ImageFactory* image_factory,
+      gpu::GpuChannelManagerDelegate* gpu_channel_manager_delegate,
+      DisplayCompositorMemoryAndTaskController* display_controller,
+      const RendererSettings& renderer_settings);
+
+  // ContextProvider implementation.
+  void AddRef() const override;
+  void Release() const override;
+  gpu::ContextResult BindToCurrentThread() override;
+  gpu::gles2::GLES2Interface* ContextGL() override;
+  gpu::ContextSupport* ContextSupport() override;
+  class GrDirectContext* GrContext() override;
+  gpu::SharedImageInterface* SharedImageInterface() override;
+  ContextCacheController* CacheController() override;
+  base::Lock* GetLock() override;
+  const gpu::Capabilities& ContextCapabilities() const override;
+  const gpu::GpuFeatureInfo& GetGpuFeatureInfo() const override;
+  void AddObserver(ContextLostObserver* obs) override;
+  void RemoveObserver(ContextLostObserver* obs) override;
+
+  virtual void SetUpdateVSyncParametersCallback(
+      UpdateVSyncParametersCallback callback);
+  virtual void SetGpuVSyncCallback(GpuVSyncCallback callback);
+  virtual void SetGpuVSyncEnabled(bool enabled);
+  virtual bool UseRGB565PixelFormat() const;
+
+  // Provides the GL internal format that should be used when calling
+  // glCopyTexImage2D() on the default framebuffer.
+  virtual uint32_t GetCopyTextureInternalFormat();
+
+  virtual base::ScopedClosureRunner GetCacheBackBufferCb();
+
+  void SetNeedsMeasureNextDrawLatency();
+
+ protected:
+  friend class base::RefCountedThreadSafe<VizProcessContextProvider>;
+  VizProcessContextProvider();  // For testing only.
+  ~VizProcessContextProvider() override;
+
+ private:
+  void InitializeContext(
+      gpu::CommandBufferTaskExecutor* task_executor,
+      gpu::SurfaceHandle surface_handle,
+      gpu::GpuMemoryBufferManager* gpu_memory_buffer_manager,
+      gpu::ImageFactory* image_factory,
+      gpu::GpuChannelManagerDelegate* gpu_channel_manager_delegate,
+      DisplayCompositorMemoryAndTaskController* display_controller,
+      const gpu::SharedMemoryLimits& mem_limits);
+  void OnContextLost();
+
+  // base::trace_event::MemoryDumpProvider implementation.
+  bool OnMemoryDump(const base::trace_event::MemoryDumpArgs& args,
+                    base::trace_event::ProcessMemoryDump* pmd) override;
+
+  const gpu::ContextCreationAttribs attributes_;
+
+  // The |gpu_task_scheduler_helper_| has 1:1 relationship with the Display
+  // compositor.
+  raw_ptr<gpu::GpuTaskSchedulerHelper> gpu_task_scheduler_helper_;
+  std::unique_ptr<gpu::InProcessCommandBuffer> command_buffer_;
+  std::unique_ptr<gpu::gles2::GLES2CmdHelper> gles2_helper_;
+  std::unique_ptr<gpu::TransferBuffer> transfer_buffer_;
+  std::unique_ptr<gpu::gles2::GLES2Implementation> gles2_implementation_;
+  std::unique_ptr<ContextCacheController> cache_controller_;
+  gpu::ContextResult context_result_ = gpu::ContextResult::kSuccess;
+
+  std::unique_ptr<skia_bindings::GrContextForGLES2Interface> gr_context_;
+
+  base::ObserverList<ContextLostObserver>::Unchecked observers_;
+};
+
+}  // namespace viz
+
+#endif  // COMPONENTS_VIZ_SERVICE_DISPLAY_EMBEDDER_VIZ_PROCESS_CONTEXT_PROVIDER_H_
diff --git components/viz/service/frame_sinks/root_compositor_frame_sink_impl.cc components/viz/service/frame_sinks/root_compositor_frame_sink_impl.cc
index dc270ca19b0b2..382a2447b940e 100644
--- components/viz/service/frame_sinks/root_compositor_frame_sink_impl.cc
+++ components/viz/service/frame_sinks/root_compositor_frame_sink_impl.cc
@@ -82,7 +82,7 @@ RootCompositorFrameSinkImpl::Create(
   mojo::Remote<mojom::DisplayClient> display_client(
       std::move(params->display_client));
   auto display_controller = output_surface_provider->CreateGpuDependency(
-      params->gpu_compositing, params->widget);
+      params->gpu_compositing, params->widget, params->renderer_settings);
   auto output_surface = output_surface_provider->CreateOutputSurface(
       params->widget, params->gpu_compositing, display_client.get(),
       display_controller.get(), params->renderer_settings, debug_settings);
@@ -176,7 +176,9 @@ RootCompositorFrameSinkImpl::Create(
   auto* output_surface_ptr = output_surface.get();
 #endif
   gpu::SharedImageInterface* sii = nullptr;
-  if (display_controller)
+  if (output_surface->context_provider())
+    sii = output_surface->context_provider()->SharedImageInterface();
+  else if (display_controller)
     sii = display_controller->shared_image_interface();
 
   auto overlay_processor = OverlayProcessorInterface::CreateOverlayProcessor(
diff --git components/viz/test/test_in_process_context_provider.cc components/viz/test/test_in_process_context_provider.cc
index 84c7020c6848f..2cf6e92b1ea59 100644
--- components/viz/test/test_in_process_context_provider.cc
+++ components/viz/test/test_in_process_context_provider.cc
@@ -41,7 +41,8 @@ namespace {
 std::unique_ptr<gpu::GLInProcessContext> CreateGLInProcessContext(
     TestGpuMemoryBufferManager* gpu_memory_buffer_manager,
     TestImageFactory* image_factory,
-    scoped_refptr<base::SingleThreadTaskRunner> task_runner) {
+    scoped_refptr<base::SingleThreadTaskRunner> task_runner,
+    DisplayCompositorMemoryAndTaskController* display_controller) {
   const bool is_offscreen = true;
   gpu::ContextCreationAttribs attribs;
   attribs.alpha_size = -1;
@@ -54,13 +55,23 @@ std::unique_ptr<gpu::GLInProcessContext> CreateGLInProcessContext(
   attribs.enable_oop_rasterization = false;
 
   auto context = std::make_unique<gpu::GLInProcessContext>();
-  auto result = context->Initialize(
-      TestGpuServiceHolder::GetInstance()->task_executor(), nullptr,
-      is_offscreen, gpu::kNullSurfaceHandle, attribs, gpu::SharedMemoryLimits(),
-      gpu_memory_buffer_manager, image_factory, nullptr, nullptr,
-      std::move(task_runner));
-  DCHECK_EQ(result, gpu::ContextResult::kSuccess);
+  if (display_controller) {
+    auto result = context->Initialize(
+        TestGpuServiceHolder::GetInstance()->task_executor(), nullptr,
+        is_offscreen, gpu::kNullSurfaceHandle, attribs,
+        gpu::SharedMemoryLimits(), gpu_memory_buffer_manager, image_factory,
+        display_controller->gpu_task_scheduler(),
+        display_controller->controller_on_gpu(), std::move(task_runner));
 
+    DCHECK_EQ(result, gpu::ContextResult::kSuccess);
+  } else {
+    auto result = context->Initialize(
+        TestGpuServiceHolder::GetInstance()->task_executor(), nullptr,
+        is_offscreen, gpu::kNullSurfaceHandle, attribs,
+        gpu::SharedMemoryLimits(), gpu_memory_buffer_manager, image_factory,
+        nullptr, nullptr, std::move(task_runner));
+    DCHECK_EQ(result, gpu::ContextResult::kSuccess);
+  }
   return context;
 }
 
@@ -68,7 +79,7 @@ std::unique_ptr<gpu::GLInProcessContext> CreateGLInProcessContext(
 
 std::unique_ptr<gpu::GLInProcessContext> CreateTestInProcessContext() {
   return CreateGLInProcessContext(nullptr, nullptr,
-                                  base::ThreadTaskRunnerHandle::Get());
+                                  base::ThreadTaskRunnerHandle::Get(), nullptr);
 }
 
 TestInProcessContextProvider::TestInProcessContextProvider(
@@ -95,9 +106,13 @@ gpu::ContextResult TestInProcessContextProvider::BindToCurrentThread() {
   auto* holder = TestGpuServiceHolder::GetInstance();
 
   if (type_ == TestContextType::kGLES2) {
-    gles2_context_ =
-        CreateGLInProcessContext(&gpu_memory_buffer_manager_, &image_factory_,
-                                 base::ThreadTaskRunnerHandle::Get());
+    display_controller_ =
+        std::make_unique<DisplayCompositorMemoryAndTaskController>(
+            holder->task_executor(), &image_factory_);
+
+    gles2_context_ = CreateGLInProcessContext(
+        &gpu_memory_buffer_manager_, &image_factory_,
+        base::ThreadTaskRunnerHandle::Get(), display_controller_.get());
 
     caps_ = gles2_context_->GetCapabilities();
   } else {
diff --git components/viz/test/test_in_process_context_provider.h components/viz/test/test_in_process_context_provider.h
index 0882a3b05c44e..d73817da15670 100644
--- components/viz/test/test_in_process_context_provider.h
+++ components/viz/test/test_in_process_context_provider.h
@@ -35,6 +35,7 @@ class GrContextForGLES2Interface;
 }
 
 namespace viz {
+class DisplayCompositorMemoryAndTaskController;
 
 std::unique_ptr<gpu::GLInProcessContext> CreateTestInProcessContext();
 
@@ -87,6 +88,7 @@ class TestInProcessContextProvider
   gpu::Capabilities caps_;
 
   // Used for GLES2 contexts only.
+  std::unique_ptr<DisplayCompositorMemoryAndTaskController> display_controller_;
   std::unique_ptr<gpu::GLInProcessContext> gles2_context_;
   std::unique_ptr<skia_bindings::GrContextForGLES2Interface> gr_context_;
 
diff --git components/viz/test/test_output_surface_provider.cc components/viz/test/test_output_surface_provider.cc
index 59dd80087ada0..28d8e5547f03b 100644
--- components/viz/test/test_output_surface_provider.cc
+++ components/viz/test/test_output_surface_provider.cc
@@ -18,7 +18,8 @@ TestOutputSurfaceProvider::~TestOutputSurfaceProvider() = default;
 std::unique_ptr<DisplayCompositorMemoryAndTaskController>
 TestOutputSurfaceProvider::CreateGpuDependency(
     bool gpu_compositing,
-    gpu::SurfaceHandle surface_handle) {
+    gpu::SurfaceHandle surface_handle,
+    const RendererSettings& renderer_settings) {
   // The output surface doesn't have a real gpu thread, and there is no overlay
   // support.
   return nullptr;
diff --git components/viz/test/test_output_surface_provider.h components/viz/test/test_output_surface_provider.h
index cc1ceb263a60b..6a84e220674f7 100644
--- components/viz/test/test_output_surface_provider.h
+++ components/viz/test/test_output_surface_provider.h
@@ -25,7 +25,8 @@ class TestOutputSurfaceProvider : public OutputSurfaceProvider {
   // OutputSurfaceProvider implementation.
   std::unique_ptr<DisplayCompositorMemoryAndTaskController> CreateGpuDependency(
       bool gpu_compositing,
-      gpu::SurfaceHandle surface_handle) override;
+      gpu::SurfaceHandle surface_handle,
+      const RendererSettings& renderer_settings) override;
   std::unique_ptr<OutputSurface> CreateOutputSurface(
       gpu::SurfaceHandle surface_handle,
       bool gpu_compositing,
diff --git content/browser/renderer_host/compositor_impl_android.cc content/browser/renderer_host/compositor_impl_android.cc
index 0f49fbe7d68ae..56bb1879f56d6 100644
--- content/browser/renderer_host/compositor_impl_android.cc
+++ content/browser/renderer_host/compositor_impl_android.cc
@@ -928,6 +928,7 @@ void CompositorImpl::InitializeVizLayerTreeFrameSink(
   renderer_settings.highp_threshold_min = 2048;
   renderer_settings.requires_alpha_channel = requires_alpha_channel_;
   renderer_settings.initial_screen_size = display_props.GetSizeInPixel();
+  renderer_settings.use_skia_renderer = features::IsUsingSkiaRenderer();
   renderer_settings.color_space = display_color_spaces_.GetOutputColorSpace(
       gfx::ContentColorUsage::kHDR, requires_alpha_channel_);
 
diff --git services/viz/privileged/mojom/compositing/renderer_settings.mojom services/viz/privileged/mojom/compositing/renderer_settings.mojom
index cd780528ccb55..c6c5d0fe76238 100644
--- services/viz/privileged/mojom/compositing/renderer_settings.mojom
+++ services/viz/privileged/mojom/compositing/renderer_settings.mojom
@@ -18,6 +18,7 @@ struct RendererSettings {
   bool release_overlay_resources_after_gpu_query;
   bool should_clear_root_render_pass;
   int32 slow_down_compositing_scale_factor;
+  bool use_skia_renderer;
   bool auto_resize_output_surface;
   bool requires_alpha_channel;
 
diff --git services/viz/privileged/mojom/compositing/renderer_settings_mojom_traits.cc services/viz/privileged/mojom/compositing/renderer_settings_mojom_traits.cc
index f86172f445d7a..0a1aae73807f4 100644
--- services/viz/privileged/mojom/compositing/renderer_settings_mojom_traits.cc
+++ services/viz/privileged/mojom/compositing/renderer_settings_mojom_traits.cc
@@ -43,6 +43,7 @@ bool StructTraits<viz::mojom::RendererSettingsDataView, viz::RendererSettings>::
   out->highp_threshold_min = data.highp_threshold_min();
   out->slow_down_compositing_scale_factor =
       data.slow_down_compositing_scale_factor();
+  out->use_skia_renderer = data.use_skia_renderer();
   out->auto_resize_output_surface = data.auto_resize_output_surface();
   out->requires_alpha_channel = data.requires_alpha_channel();
 
diff --git services/viz/privileged/mojom/compositing/renderer_settings_mojom_traits.h services/viz/privileged/mojom/compositing/renderer_settings_mojom_traits.h
index 53ff4935d2055..a5028a91981e2 100644
--- services/viz/privileged/mojom/compositing/renderer_settings_mojom_traits.h
+++ services/viz/privileged/mojom/compositing/renderer_settings_mojom_traits.h
@@ -89,6 +89,10 @@ struct StructTraits<viz::mojom::RendererSettingsDataView,
     return input.slow_down_compositing_scale_factor;
   }
 
+  static bool use_skia_renderer(const viz::RendererSettings& input) {
+    return input.use_skia_renderer;
+  }
+
   static bool auto_resize_output_surface(const viz::RendererSettings& input) {
     return input.auto_resize_output_surface;
   }
diff --git services/viz/privileged/mojom/mojom_traits_unittest.cc services/viz/privileged/mojom/mojom_traits_unittest.cc
index efa164f0037a3..1dcc51cf9ee89 100644
--- services/viz/privileged/mojom/mojom_traits_unittest.cc
+++ services/viz/privileged/mojom/mojom_traits_unittest.cc
@@ -27,6 +27,7 @@ TEST_F(StructTraitsTest, RendererSettings) {
   input.should_clear_root_render_pass = false;
   input.release_overlay_resources_after_gpu_query = true;
   input.highp_threshold_min = -1;
+  input.use_skia_renderer = true;
 
   RendererSettings output;
   mojom::RendererSettings::Deserialize(
@@ -43,6 +44,7 @@ TEST_F(StructTraitsTest, RendererSettings) {
   EXPECT_EQ(input.release_overlay_resources_after_gpu_query,
             output.release_overlay_resources_after_gpu_query);
   EXPECT_EQ(input.highp_threshold_min, output.highp_threshold_min);
+  EXPECT_EQ(input.use_skia_renderer, output.use_skia_renderer);
 }
 
 TEST_F(StructTraitsTest, DebugRendererSettings) {
diff --git third_party/blink/renderer/platform/widget/compositing/android_webview/synchronous_layer_tree_frame_sink.cc third_party/blink/renderer/platform/widget/compositing/android_webview/synchronous_layer_tree_frame_sink.cc
index 4eb245ec83e33..166904ff2788d 100644
--- third_party/blink/renderer/platform/widget/compositing/android_webview/synchronous_layer_tree_frame_sink.cc
+++ third_party/blink/renderer/platform/widget/compositing/android_webview/synchronous_layer_tree_frame_sink.cc
@@ -30,6 +30,7 @@
 #include "components/viz/service/display/output_surface_frame.h"
 #include "components/viz/service/display/overlay_processor_stub.h"
 #include "components/viz/service/display/software_output_device.h"
+#include "components/viz/service/display/texture_deleter.h"
 #include "components/viz/service/frame_sinks/compositor_frame_sink_support.h"
 #include "components/viz/service/frame_sinks/frame_sink_manager_impl.h"
 #include "gpu/command_buffer/client/context_support.h"
-- 
2.36.1.windows.1

